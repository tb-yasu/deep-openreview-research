[
  {
    "id": "5sRnsubyAK",
    "title": "Neuroacoustic Patterns: Constant Q Cepstral Coefficients for the Classification of Neurodegenerative Disorders",
    "authors": [
      "Aastha Kachhi",
      "Shashank Ojha",
      "Megha Pandey",
      "Ajay Kumar Sharma",
      "Anurag Pandey"
    ],
    "abstract": "Early identification of neurodegenerative diseases is crucial for effective diagnosis in neurological disorders. However, the quasi-periodic nature of vocal tract sampling often results in inadequate spectral resolution in traditional spectral features, such as Mel Frequency Cepstral Coefficients (MFCC), thereby limiting their classification effectiveness. In this study, we propose the use of Constant Q Cepstral Coefficients (CQCC), which leverage geometrically spaced frequency bins to provide superior spectrotemporal resolution, particularly for capturing the fundamental frequency and its harmonics in speech signals associated with neurodegenerative disorders. Our results demonstrate that CQCC, when integrated with Random Forest and Support Vector Machine classifiers, significantly outperform MFCC, achieving absolute improvements of 5.6 % and 7.7 %, respectively. Furthermore, CQCC show enhanced performance over traditional acoustic measures, such as Jitter, Shimmer, and Teager Energy. The effectiveness of CQCC is underpinned by the form-invariance property of the Constant Q Transform (CQT), which ensures consistent feature representation across varying pitch and tonal conditions, thereby enhancing classification robustness. Furthermore, the robustness of CQCC features against MFCC features are validated using LDA plots. These findings are validated using the Italian Parkinson’s database and the Minsk2019 database of Amyotrophic Lateral Sclerosis, underscoring the potential of CQCC to advance the classification of neurodegenerative disorders.",
    "keywords": [
      "Neurodegenerative Disorder",
      "Constant Q Cepstral Coefficient",
      "Form Invariance",
      "Random Forest",
      "SVM."
    ],
    "venue": "ICLR",
    "year": 2025,
    "pdf_url": "https://openreview.net/pdf?id=5sRnsubyAK",
    "forum_url": "https://openreview.net/forum?id=5sRnsubyAK",
    "reviews": [
      {
        "rating": "5",
        "confidence": "3",
        "summary": "The paper introduces a new feature extraction method that leverages the form-invariance property of the Constant Q Transform (CQT). It is applied for the classification of neurodegenerative disorders, specifically Parkinson's Disease (PD) and Amyotrophic Lateral Sclerosis (ALS). The authors propose that CQCC, which leverages geometrically spaced frequency bins, provides superior spectrotemporal resolution compared to traditional Mel Frequency Cepstral Coefficients (MFCC). The study demonstrates that CQCC, when integrated with Random Forest and Support Vector Machine classifiers, significantly outperforms MFCC, achieving absolute improvements of 5.6% and 7.7%, respectively. The effectiveness of CQCC is validated using the Italian Parkinson’s database and the Minsk2019 database of ALS",
        "strengths": "This paper leverages the form-invariance property of the Constant Q Transform (CQT) to achieve superior spectrotemporal resolution compared to traditional Mel Frequency Cepstral Coefficients (MFCC). The authors demonstrate significant improvements in classification accuracy using Random Forest and Support Vector Machine classifiers, validated across multiple datasets. While the technical complexity may pose challenges for some readers, the research is of high quality and holds significant potential for advancing early diagnosis and treatment of neurodegenerative diseases. The paper's contributions are a valuable addition to the niche application area of disease diagnosis via audio.",
        "weaknesses": "1. Rigor in experimentation \n1a. Error Analysis/ Literature comparison \n Although the paper includes spectrographic analysis and Linear Discriminant Analysis (LDA) plots to visualize feature separability, It is necessary to Conduct a detailed literature analysis of the SoTA models used for this task such as Deep feature extractors. A useful analysis would be to Identify common patterns or features that contribute to the errors and provide insights into the specific cases where the proposed method fails. This would help in understanding the contribution of CQCC as an efficient feature extractor. \n\n1a. Cross validation/ 10 fold CV-\nThe paper lacks external validation of the proposed CQCC method. While simple accuracy score results are promising, additional validation using independent datasets not used in the training phase would provide stronger evidence of the method's effectiveness. This could involve cross-validation with other publicly available datasets or non intersecting splits from current dataset to achieve error estimates or uncertainty scores. *(Ref see Uncertainty Quantification of Deep Learning Models)\n\n\n2. Dataset Diversity:\nThe study primarily uses the Italian Parkinson’s Voice and Speech dataset and the Minsk2019 ALS database. While these datasets are well-established, the paper could benefit from including more diverse datasets to ensure the generalizability of the findings. It would strengthen the validity of the results and demonstrate the robustness of the proposed method across various contexts\n\n3 Lack of Comparison with Other Deep models/ deep feature extractors:\nThe paper compares CQCC primarily with traditional acoustic features like MFCC, Jitter, Shimmer, and Teager Energy. However, it does not provide a comparison with other advanced feature extraction methods or machine learning techniques that have go-to in most cases of such applications. Including such comparisons would provide a more comprehensive evaluation of the proposed method's performance and highlight its relative strengths and weaknesses"
      },
      {
        "rating": "6",
        "confidence": "4",
        "summary": "The authors have proposed Constant Q Cepstral Coefficients (CQCC) as a measure to identify neurodegenerative diseases  (like Parkinson’s and Amyotrophic lateral sclerosis). The proposed measure is compared against basic acoustic features Jitter Shimmer Teager Energy and MFCC using traditional machine learning classifiers like random forest and Support vector machines. The discriminator power of CQCC is demonstrated using two different datasets i.e. Italian Parkinson’s Voice and Speech dataset and Minsk2019 ALS database.",
        "strengths": "1. The paper contributes towards developing interpretable features representation for neurodegenerative diseases. \n2. A comparison with mostly commonly used features like MFCC\n3. evaluation on two different languages and diseases. \n4. achievement of significant performance over widely used feature sets by neurodegenerative research community. \n5. demonstration of improved class separation of CQCC over MFCC using LDA plots.",
        "weaknesses": "1. hyperparameter optimization is not performed.\n2. it is not clear what is the dimensionality of each feature set, consider adding a table or paragraph in the methodology section detailing the dimensionality of each feature set used.  \n3. Have you considered discussing the trade-offs between your approach and deep learning methods like wav2vec or BERT? This could help contextualize your choice of method and highlight any advantages in terms of interpretability or computational efficiency.\n4. As the research field lacks large amount of datasets. In the limitations section, could you discuss how the scarcity of large datasets in this field might impact the generalizability of the findings, and what implications this has for future research?   \n5. Could you provide more context in the methodology section about why these specific traditional feature sets were chosen for comparison? Are there particular characteristics of these features that make them relevant benchmarks for neurodegenerative disease detection?\n6. consider adding more references"
      },
      {
        "rating": "3",
        "confidence": "5",
        "summary": "The article investigates constant-Q cepstral coefficients (CQCC) to perform classification of neuro-degenarative disorder from speech, and compared the results with respect to standard mel-frequency cepstral coefficients (MFCCs) and other low-level acoustic features, such as jitter, shimmer, teager-energy etc. The results presented in the paper indicate sufficient performance improvement compared to the MFCC baseline. \n\nWhile this is a well motivated work that has the potential to impact detection of neuro-degenerative diseases using speech as the input modality, however it is not clear completely what the main novelty of the paper is. The authors did specify that the constant-Q cepstra is the main novelty presented in this work, however that is fairly incremental as such features have been used in speech technologies, perhaps not in the same application area as this article.",
        "strengths": "The paper focuses on speech based detection of neuro-degenerative disease, specifically Parkinson's disease and Amyotrophic lateral sclerosis (ALS). The paper is well motivated, clearly outlines the prior work that has been done and the contribution of the paper. Results presented in the article shows a strong performance demonstrated by the proposed approach as compared with MFCC-based system.",
        "weaknesses": "This is an interesting and relevant work focusing on detection/recognition of Parkinson's disease and Amyotrophic lateral sclerosis (ALS) from speech data, consisting of sustained vowels, specifically focusing on constant-Q cepstral coefficients (CQCC) as acoustic features. There are certain aspects that needs to be addressed - \n(1) Given the findings are primarily based on sustained vowels, how do the observations generalize to spontaneous speech? Is it absolutely needed to have speech containing sustained vowel to be able to detect/recognize the condition investigated in this work?\n(2) Table 2 in the dataset section, introduces three datasets: D1, D2 and D3. However it is not clear which one of these correspond to the datasets detailed in section 4.1. Also, in section 4.1, there are two datasets that are introduced: (a) Italian Parkinson’s Voice and Speech dataset, and (b) Minsk2019 ALS database. Table 2 is confusing as it introduces three datasets, and it is not clear what is the 3rd dataset, and which datasets correspond to D1, D2 and D3.\n(3) Section 4.3 introduces MFCCs as state-of-the-art: I wonder about the rationale behind stating that MFCCs are state-of-the-art. Is there any prior work that established MFCCs as the state-of-the-art feature for this specific application? \n(4) There are some typing errors that can be addressed by proof-reading the paper: \n(a) page 2, section 2, line 094: \"•Furthermore, no studies...\" >> \"• Furthermore, no studies... \"\n(b) page 2, section 2, line 097: \"this is the first study of it;s kind ... \" >> \"this is the first study of it's kind ... \"\n(c) page 5, section 4.1, line 264: \"..sustained sounds of all vowel sounds .. \" > please rephrase this line, \"sounds\" is repeated twice and it makes the sentence a bit confusing."
      },
      {
        "rating": "1",
        "confidence": "5",
        "summary": "The paper explores the discriminatory ability of Constant Q Cepstral Coefficients (CQCC) to classify neurodegenerative disorders based on the utterance of sustained vowels. The experimental setup includes samples from patients suffering from Parkinson-s Disease (PD) and Amyotrophic Lateral Sclerosis. The proposed pipeline includes using SMOTE to compensate for class-inbalance problems and two classical ML classification models: SVM and RF. The results show a comparison between CQCC against the well-known MFCC and classical acoustic parameters related to the fundamental frequency variability.",
        "strengths": "The paper presents results demonstrating that the use of CQCC enhances classification accuracy in detecting neurodegenerative disorders compared to traditional MFCC and acoustic parameters.",
        "weaknesses": "The main drawback of the paper is its novelty. Moreover, I consider it entirely out of the Conference's scope since it does not introduce any approach incorporating the idea of a \"learning representation.\" The components related to Machine Learning used in the paper are traditional ML models. Regarding its novelty, the set of features analysed in the paper was introduced back in 2017 and has been tested before in several voice/speech processing applications, so its contribution would be more focused on the academic community interested in the specific area of neurodegenerative disorders classification from speech signals. However, even considering the potential contribution in the area of neurodegenerative disorders detection, the comparison proposed in the paper is pretty limited since some previous works have shown that, in the context of PD detection, Rasta-PLP coefficients have better performance than MFCC but more importantly, that sustained vowels lack articulatory information which is critical to the PD detection. Indeed, there are not many datasets available out there, but the Italian Dataset used in the experiments has pretty low recording quality, and many works have shown that classifying PD vs. Control in that dataset is not a difficult task, so it should not be used as a benchmark."
      }
    ],
    "rating_avg": 3.75,
    "confidence_avg": 4.25,
    "decision": "N/A",
    "meta_review": "",
    "author_remarks": "",
    "decision_comment": ""
  },
  {
    "id": "J1SGf2lyr6",
    "title": "A Feature-Aware Federated Learning Framework for Unsupervised Anomaly Detection in 5G Networks",
    "authors": [
      "Saeid Sheikhi"
    ],
    "abstract": "The expansion of 5G networks has led to remarkable data volume and complexity, introducing significant security challenges that require the implementation of robust and scalable anomaly detection mechanisms. Traditional centralized approaches pose privacy risks and scalability challenges due to the distributed nature of 5G infrastructures. Federated Learning (FL) offers a decentralized solution but often overlooks the importance of feature relevance and privacy preservation during model aggregation. This paper introduces a novel Feature-Aware Federated framework that integrates feature importance into the aggregation process while ensuring differential privacy. We employ integrated gradients to compute feature importance for each client, aggregate them globally with differential privacy noise, and use these insights to weight model parameters during aggregation. Additionally, we propose Dynamic Feature Importance Adaptation (DFIA) to update feature importance occasionally, enhancing the model's adaptability to evolving data distributions. Experimental results demonstrate that our framework outperforms traditional federated approaches like FedAvg and FedProx in unsupervised anomaly detection tasks within 5G networks, achieving higher accuracy and robustness while preserving data privacy.",
    "keywords": [
      "Federated Learning",
      "Anomaly Detection",
      "5G Networks",
      "Privacy-Preserving"
    ],
    "venue": "ICLR",
    "year": 2025,
    "pdf_url": "https://openreview.net/pdf?id=J1SGf2lyr6",
    "forum_url": "https://openreview.net/forum?id=J1SGf2lyr6",
    "reviews": [
      {
        "rating": "3",
        "confidence": "5",
        "summary": "This paper presents a Feature-Aware Federated Learning framework for anomaly detection in 5G networks, addressing challenges of data privacy and scalability. The framework incorporates feature importance into model aggregation using integrated gradients to compute feature relevance, with differential privacy to protect client data. Additionally, a Dynamic Feature Importance Adaptation (DFIA) mechanism periodically updates feature importance to adapt to changing data distributions. Experiments show that this approach outperforms traditional federated methods like FedAvg and FedProx in unsupervised anomaly detection tasks, achieving improved accuracy, robustness, and privacy preservation.",
        "strengths": "Strengths:\n+ This work offers a Feature-Aware Federated Learning framework for anomaly detection in 5G networks, addressing challenges of data privacy and scalability.",
        "weaknesses": "Weaknesses:\n- The novelty of this paper needs to be further improved.\n- The experimental results of this paper are not convincing.\n- More STOA baselines need to be included.\n- The writing quality of this paper needs another round of polishing."
      },
      {
        "rating": "3",
        "confidence": "4",
        "summary": "Federated learning provides a decentralised solution for anomaly detection in 5G networks, but neglects the importance of feature relevance and privacy preservation during model aggregation. This paper presents a federated learning framework for 5G networks, incorporating feature importance to improve anomaly detection. It uses integrated gradients to determine feature relevance and dynamically adapts to changing data distributions, integrating differential privacy to secure data. Experiments on real-world 5G network datasets show the advantages of the FAFL framework in terms of anomaly detection accuracy and robustness.",
        "strengths": "1、The proposed framework effectively addresses conditional joint learning methods in the context of data heterogeneity, lack of labelling, privacy issues and dynamic environment challenges faced in 5G network scenarios. \n2、The paper considers the protection of customer privacy by applying differential privacy when aggregating cross-customer feature importance to prevent leakage of sensitive information.\n3、The paper utilises a 5G testbed environment containing two 5G cores to collect datasets and conduct experiments with a certain degree of authenticity and credibility that are relevant.",
        "weaknesses": "1、The applicable scenario of the proposed method is unclear. Further clarification is necessary. \n2、The paper lacks innovation, appearing as a fusion of multiple existing technologies rather than presenting original contributions.\n3、This paper compares a limited number of methods, necessitating the inclusion of additional federated anomaly detection techniques to enhance its persuasive ability. Furthermore, while the paper discusses differential privacy, it fails to conduct privacy attack experiments to substantiate the need for this mechanism. Additionally, the paper lacks a comprehensive experimental analysis.\n4、This paper resembles a scientific report more than an academic publication. It lacks standardization in language, contains several writing errors ( line 126 ), and fails to provide a detailed description of the proposed framework.\n5、The paper does not align well with the conference theme and fails to address the domains of representation learning and deep learning."
      },
      {
        "rating": "3",
        "confidence": "4",
        "summary": "This paper proposes a Feature-Aware Federated Learning (FAFL) framework, which incorporates feature importance into FL process. The framework utilizes integrated gradients to compute feature relevance and adapts dynamically to changing data distributions, aiming to handle the heterogeneity of client data.",
        "strengths": "The modeling of the 5G scenario in the paper is commendable, and the proposed method is an interesting attempt to handle heterogeneous features.",
        "weaknesses": "1. The background research in this paper is insufficient. There is already a substantial body of work focused on heterogeneous data and features in FL, but the authors only mention the classic approaches, FedAvg and FedProx.\n\n2. The experiments are lacking. The authors only use the two aforementioned methods as baselines and conduct a limited number of experiments. A significant portion of the paper is devoted to details about model architecture.\n\n3. The paper lacks motivation. Why do we need a feature weighting method instead of letting the model learn it? It would be better if the necessity of this method in certain scenarios could be clarified.\n\n4. In the introduction, it’s stated: \"this (FedAvg’s) assumption overlooks the heterogeneity inherent in client data,\" which suggests that the 5G scenario involves non-i.i.d data. However, the authors' method directly averages the 'feature importance vectors' from different clients (Eq.5). The rationale behind this step doesn’t seem intuitive.\n\n5. Eq.10 seems incorrect. Since \\theta_k is a vector representing the model parameters, this implies that w_k should also be a vector. Meanwhile, \\Sigma a_i doesn’t appear to make sense. The unclear nature of this formula makes it difficult to fully understand the proposed method."
      },
      {
        "rating": "1",
        "confidence": "5",
        "summary": "The authors propose an explainable AI-based algorithm, integrated gradients, to employ the feature importance of each client in the aggregation of the FL system, apply it to the 5G-related tasks, and process the importance estimation in each round to adopt the dynamic feature of 5G networks. Results compared with traditional aggregation algorithms, such as FedAvg and FedProx show some performance gain on one standard dataset.",
        "strengths": "1. The method of employing integrated gradients to estimate the contribution/importance of each client is interesting.",
        "weaknesses": "1. The proposed scheme seems standard and simply applied to the FL system. Details on the key steps are largely omitted. For example, it is not clear how the local client calculates the feature importance of its own data. According to Eq. 3 and my basic understanding of integrated gradients, this step needs a basis from other clients or the global model. However, this detail has not been fully explored in the provided content.\n\n2. To adopt the dynamic characters of the environment, the authors just let the importance calculation happen in every T round, which is kind of straight and trivial. In addition, the advantages of this step are not investigated in the experiments.\n\n3. Wrong use of DP. Adding random noise on the feature importance will not protect the raw data of clients, and the related experiments are also confusing as many details are not provided."
      }
    ],
    "rating_avg": 2.5,
    "confidence_avg": 4.5,
    "decision": "N/A",
    "meta_review": "",
    "author_remarks": "",
    "decision_comment": ""
  },
  {
    "id": "49ti6LOUw5",
    "title": "UnoLoRA: Single Low-Rank Adaptation for Efficient Multitask Fine-tuning",
    "authors": [
      "Anirudh Lakhotia",
      "Akash Kamalesh",
      "Prerana Sanjay Kulkarni",
      "Nischal H S",
      "Gowri Srinivasa"
    ],
    "abstract": "Recent advances in Parameter-Efficient Fine-Tuning (PEFT) have shown Low- Rank Adaptation (LoRA) to be an effective implicit regularizer for large language models. Building on these findings, we propose UnoLoRA, a novel approach that leverages a single shared LoRA module for efficient multi-task learning. While existing methods typically use separate LoRA adaptations for each task, our approach demonstrates that a single shared adapter can effectively capture both task-specific and task-agnostic knowledge. We further introduce UnoLoRA*, an enhanced variant that employs a shared hypernetwork to generate task-specific embeddings, improving convergence and task adaptation. Our method significantly reduces trainable parameters to just 0.05% per task while maintaining competitive performance on the GLUE benchmark. Our analysis reveals that the A and B matrices in our shared LoRA adapter naturally develop complementary roles: A matrices capture generalizable features across tasks, while B matrices specialize in task-specific representations. Our results show that sharing a single LoRA adapter can achieve efficient multi-task learning while significantly reducing memory requirements, making it particularly valuable for resource-constrained applications.",
    "keywords": [
      "lora",
      "multi-task learning",
      "peft"
    ],
    "venue": "ICLR",
    "year": 2025,
    "pdf_url": "https://openreview.net/pdf?id=49ti6LOUw5",
    "forum_url": "https://openreview.net/forum?id=49ti6LOUw5",
    "reviews": [
      {
        "rating": "3",
        "confidence": "4",
        "summary": "The paper presents UnoLoRA, an approach for parameter-efficient multitask learning in large language models (LLMs) using a single Low-Rank Adaptation (LoRA) module shared across multiple tasks. Building upon LoRA as an implicit regularizer, the authors explore its application in a multitasking context, aiming to reduce the number of trainable parameters while maintaining competitive performance. The paper introduces an architecture, UnoLoRA, which integrates a shared hypernetwork that generates task-specific scaling factors.",
        "strengths": "- The paper conducts comprehensive experiments and analysis to verify the proposed method.\n- The paper is well structured, proposing an architecture, UnoLoRA, which integrates a shared hypernetwork that generates task-specific scaling factors.",
        "weaknesses": "- The experiments are conducted on T5-series models, which are from 4 years ago. Using a more recent model doesn't necessarily mean aiming for the current SOTA (state-of-the-art), but rather that the behaviors of stronger models might differ, making experiments on T5 impractical. For instance, current models, after instruction tuning, demonstrate strong zero-shot generalization across tasks, making multi-task learning less important.\n- In the first table, the method proposed in this paper does not outperform HyperFormer++, even though they have different amounts of training parameters, the average effectiveness is also quite lacking. Therefore, the experimental results of this paper are not very convincing."
      },
      {
        "rating": "3",
        "confidence": "3",
        "summary": "The paper introduces UnoLoRA, a method for parameter-efficient multitask fine-tuning of large language models (LLMs) through a shared Low-Rank Adaptation (LoRA) module. UnoLoRA leverages LoRA's implicit regularization properties to facilitate multitask learning by using a single adapter shared across all tasks, instead of separate adapters for each task. This approach drastically reduces trainable parameters to 0.05% per task while maintaining competitive performance with existing multitask methods. The model is evaluated on the GLUE benchmark and demonstrates parameter efficiency and improved generalization by capturing both shared and task-specific information. The authors further refine their method with UnoLoRA⋆, which converges faster and performs better in early training stages compared to the initial UnoLoRA.",
        "strengths": "- The authors conduct in-depth analyses of LoRA matrices in both single-task and multitask settings, highlighting distinctions in their properties (like effective rank and Frobenius norm) and the roles of A and B matrices. Visualizations like PCA further illustrate how UnoLoRA efficiently manages task-shared and task-specific information.\n- The study’s experiments on the GLUE benchmark provide extensive evidence of UnoLoRA's effectiveness and competitive performance.",
        "weaknesses": "- For the experiments on the GLUE benchmark, no repeated experiments with different random seeds were performed, and the experimental results are not completely convincing due to the randomness.\n- Only the T5-base model was used for the experiment. The effectiveness of the method was not verified on larger or smaller models, nor on decoder-only models."
      },
      {
        "rating": "3",
        "confidence": "4",
        "summary": "This paper presents a method called UnoLoRA, a procedure for constructing\nlow-rank Transformer adapters in a multi-task setting by training a network to\napply task-specific transformations to a shared adapter. In particular, while\nstandard LoRA parameterizes weight matrices as $W + AB^\\top$ for low-rank\n$A$ and $B$, UnoLoRA parameterizes them as $W + A ~\\mathrm{diag}(H(t)) ~ B^\\top$,\nwhere $t$ is a task representation that includes both a discrete identifier\nand example data and positional embeddings, and $H$ is a hypernetwork. A similar recipe was previously\nexplored by Karimi Mahabadi et al. (2021) under the name of \"HyperFormers\"; as\nfar as I can tell, the main differences are that:\n\n- HyperFormers condition only on task IDs, while UnoLoRA conditions on example\n  input data\n\n- HyperFormers also modulate LayerNorm parameters, and not just adapters\n\n- HyperFormers use a slightly different adapter parameterization from the modern LoRA recipe, with\n  a nonlinearity in the middle",
        "strengths": "- Simple and seemingly effective way of parameterizing low-rank adapters in the multitask setting. The idea is timely---there have been a lot of improvements in LoRA and related schemes in the last couple of years, and revisiting conditional computation + adapter combinations seems like a promising direction.",
        "weaknesses": "- Comparatively minor tweak of an existing idea. This wouldn't be an issue on\n  its own, except for the fact that the various changes are not evaluated in\n  a way that enables direct comparison to HyperFormers, as described below.\n\n- Inconsistencies and missing details in the description of the method. Fig 1\n  makes reference to a \"Task-specific A\" parameter that is not mentioned\n  anywhere in the formal description of the method---is it used, and if so,\n  where? Additionally, the experiments make reference to a method called\n  UnoLoRA$^*$, which achieves slightly better performance than the base method\n  but does not appear to be described anywhere.\n\n- Major issues in evaluation. The paper's main results are summarized in Fig\n  6(a), which show that UnoLoRA and HyperFormers both pareto-dominate training\n  separate adapters for each task---UnoLoRA involves fewer parameters at the\n  same level of performance, while HyperFormers give increased accuracy but are\n  slightly less parameter-efficient than UnoLoRA. I have two concerns here.\n\n    - First, the individual differences between UnoLoRA and HyperFormers are\n      never individually evaluated, making it impossible to figure which (if any)\n      are responsible for the performance differences.\n\n    - Second, and more fundamentally---the whole point of adapter-based methods\n      is that they provide a tunable parameter (the adapter rank) that trades\n      off between accuracy and parameter count. So what we really need to see\n      is the entire accuracy / efficiency curve for both model classes, rather\n      than an arbitrary point on each. In fact, if I understand correctly,\n      even the size of the adapter is totally incomparable between the two\n      models being compared: this paper trains UnoLoRA with a rank of 8, while\n      the results copied from the HyperFormers paper appear to use a rank of 24.\n\n  Without a minimal comparison (or a complete frontier from each model), it is\n  possible that all observed differences between methods result from\n  incomparable hyperparameter choices.\n\n- Major formatting issues: nearly every citation in the paper is incorrectly formatted (using \\citet instead of \\citep). It seems likely that this paper didn't receive even a single round of proofreading, and should not have been submitted to ICLR in its current form."
      },
      {
        "rating": "3",
        "confidence": "3",
        "summary": "This article proposes a new method called UNOLORA, which utilizes shared low-rank adaptation (LoRA) modules to achieve efficient multi-task learning for large language models, and has achieved outstanding performance on the GLUE benchmark.",
        "strengths": "- The method proposed by the authors is simple but effective.",
        "weaknesses": "- The writing and presentation is not good, for example, the caption and figure of Figure 1 seems confusing. Also the font size in the figure is too small to understand.\n\n- The training of Shared Hypernetwork will introduce additional training cost.\n\n- The method is only evaluated on one model, without scaling up the model size/architecture."
      }
    ],
    "rating_avg": 3.0,
    "confidence_avg": 3.5,
    "decision": "N/A",
    "meta_review": "",
    "author_remarks": "",
    "decision_comment": ""
  },
  {
    "id": "zkNCWtw2fd",
    "title": "Synergistic Approach for Simultaneous Optimization of Monolingual, Cross-lingual, and Multilingual Information Retrieval",
    "authors": [
      "Adel Elmahdy",
      "Sheng-Chieh Lin",
      "Amin Ahmad"
    ],
    "abstract": "Information retrieval across different languages is an increasingly important challenge in natural language processing. Recent approaches based on multilingual pre-trained language models have achieved remarkable success, yet they often optimize for either monolingual, cross-lingual, or multilingual retrieval performance at the expense of others. This paper proposes a novel hybrid batch training strategy to simultaneously improve zero-shot retrieval performance across monolingual, cross-lingual, and multilingual settings while mitigating language bias. The approach fine-tunes multilingual language models using a mix of monolingual and cross-lingual question-answer pair batches sampled based on dataset size. Experiments on XQuAD-R, MLQA-R, and MIRACL benchmark datasets show that the proposed method consistently achieves comparable or superior results in zero-shot retrieval across various languages and retrieval tasks compared to monolingual-only or cross-lingual-only training. Hybrid batch training also substantially reduces language bias in multilingual retrieval compared to monolingual training. These results demonstrate the effectiveness of the proposed approach for learning language-agnostic representations that enable strong zero-shot retrieval performance across diverse languages.",
    "keywords": [
      "Information Retrieval",
      "Multilingualism and Cross-Lingual NLP",
      "Question Answering"
    ],
    "venue": "ICLR",
    "year": 2025,
    "pdf_url": "https://openreview.net/pdf?id=zkNCWtw2fd",
    "forum_url": "https://openreview.net/forum?id=zkNCWtw2fd",
    "reviews": [
      {
        "rating": "3",
        "confidence": "4",
        "summary": "This paper introduces a hybrid batch training approach for multilingual information retrieval by combining monolingual and cross-lingual training data. The core methodology relies on mixing different types of training data using probability weights α and β. While the implementation is straightforward, the novelty of the contribution is limited.",
        "strengths": "1. Addresses a relevant challenge in multilingual information retrieval.\n2. Provides comprehensive experimental validation across multiple benchmark datasets (XQuAD-R, MLQA-R, MIRACL).",
        "weaknesses": "1. The primary contribution merely combines two existing training approaches with probability weights, presenting a straightforward and obvious solution.\n2. The paper employs translated QA pairs as data augmentation, creating an unfair comparison with baseline methods that do not utilize this advantage."
      },
      {
        "rating": "3",
        "confidence": "3",
        "summary": "The paper studies information retrieval tasks where monolingual, cross-lingual, and multilingual setups are examined. The paper studies different batch sampling approaches at the training time without modifying existing training loss (e.g., contrastive learning loss) or model architectures. Specifically, the paper argues that existing approaches either use (i) monolingual batching where the languages of query and documents are matched, but they can be of different languages, or (ii) cross-lingual batching where the languages of query and documents are different. Based on this, the paper proposes hybrid batching, which is the mixing of these two batching methods.\n\nExperiments are conducted on two base models (XLM-R and LaBSE) and evaluated on two tasks (XQuAD-R, MLQA-R, MIRACL). To train systems with data in various languages, the paper employs in-house machine translation to translate existing training corpora (described in Section 3.1). The experimental results show that hybrid batching, generally, outperforms monolingual-only and cross-lingual-only in a range of setups, including monolingual, cross-lingual, and multilingual.",
        "strengths": "The paper shows that two standard batching strategies are complementary for information retrieval tasks, as the combination of them shows improvements.",
        "weaknesses": "1. Limited evaluations are only QA datasets (e.g., the main text only shows XLM-R and LaBSE). Also, the main text consists of many large tables where each does not present as much information as the space it takes, e.g., the authors could summarize how many languages/scenarios the proposed method shows improvements instead of providing large tables like Table 3, Table 4, Table 5, etc.\n\n2. It is not clear if the proposed method is actually effective. In many cases, the improvements appear rather small. For example, in Table 1, on XQuAD-R for XLM-R (0.792 vs 0.798; 0.705 vs 0.700; 0.593 vs 0.593). Are they even statistically significant?\n\n3. As this paper mainly provides empirical observations, it would be stronger if the paper provides insights on which scenario (e.g., what kind of base model or dataset) where hybrid batching is expected to show significant improvements and when it does not. The current paper pretty much reports experimental findings which could limit its usefulness. Several questions remain, for example, what is the size and mixed of training data does one need to see the impact of this hybrid batching? I expect that if there is limited training data, the impact would be marginal."
      },
      {
        "rating": "3",
        "confidence": "4",
        "summary": "This paper introduces a simple method called hybrid batch training, which involves translating to obtain parallel data in multiple languages, and sampling these data to construct a multilingual training dataset. The model is trained by inputting monolingual or multilingual training data with a certain probability, thereby balancing its performance in both scenarios.",
        "strengths": "1.  This paper proposes a hybrid batch training strategy to simultaneously improve zero-shot retrieval performance across monolingual, cross-lingual, and multilingual settings while mitigating language bias.\n2.  The hybrid batch training strategy simply modifies the training data batches without necessitating the introduction of loss functions or new architectural components.",
        "weaknesses": "1. The proposed hybrid batch training strategy only modifies the input training data, which lacks novelty.\n2. This paper lacks sufficient analysis to the field of multilingual information retrieval. It does not adequately demonstrate the shortcomings of existing work nor the importance and necessity of this study.\n3. The experiments only compare the performance of different input strategies but not various multilingual information retrieval methods."
      }
    ],
    "rating_avg": 3.0,
    "confidence_avg": 3.6666666666666665,
    "decision": "Reject",
    "meta_review": "Although reviewers emphasized the interesting hybrid batch sampling approach, then all agree on the shortcomings:\n\n- limited contributions and experimentation: the paper only combines the previous existing approaches and show improvements in some cases (not always significant) but little has been done to dive deeper to into finding an optimal recipe (e.g., per language sampling, comparing to different cross-lingual batch samplings with different up/downsampling, etc.). Also one interesting direction is how this approach should be aligned with the capabilities of the pretrained model? For example, if the pretrained model is bad at language X, is it possible to improve that with that approach during fine-tuning? Should this hybrid sampling approach focus more monolingual batches in language X for example?\n- limited scope: the scope is limited to retrieval for QA but it is important to see what is the effect on other cross-lingual benchmarks (XGLUE, Xtreme). Also it may also be interesting to do some \"scaling\" analysis on the approach to see how much of this matter at scale.",
    "author_remarks": "",
    "decision_comment": ""
  },
  {
    "id": "viQ1bLqKY0",
    "title": "EXecution-Eval: Can language models execute real-world code?",
    "authors": [
      "Rob Kopel"
    ],
    "abstract": "As Large Language Models (LLMs) advance, traditional benchmarks face challenges of dataset saturation and disconnection from real-world performance, limiting our understanding of true model capabilities. We introduce EXecution-Eval (EXE), a benchmark designed to assess LLMs' ability to execute code and predict program states. EXE attempts to address key limitations in existing evaluations: difficulty scaling, task diversity, training data contamination, and cost-effective scalability.\nComprising over 30,000 tasks derived from 1,000 popular Python repositories on GitHub, EXE spans a range of context lengths and algorithmic complexities. Tasks require models to execute code, necessitating various operations including mathematical reasoning, logical inference, bit manipulation, string operations, loop execution, and maintaining multiple internal variable states during computation. Our methodology involves: (a) selecting and preprocessing GitHub repositories, (b) generating diverse inputs for functions, (c) executing code to obtain ground truth outputs, and (d) formulating tasks that require models to reason about code execution. This approach allows for continuous new task generation for as few as 1,200 tokens, significantly reducing the risk of models \"training on the test set.\"\nWe evaluate several state-of-the-art LLMs on EXE, revealing insights into their code comprehension and execution capabilities. Our results show that even the best-performing models struggle with complex, multi-step execution tasks, highlighting specific computational concepts that pose the greatest challenges for today's LLMs. Furthermore, we review EXE's potential for finding and predicting errors to aid in assessing a model's cybersecurity capabilities. We propose EXE as a sustainable and challenging testbed for evaluating frontier models, offering potential insights into their internal mechanistic advancement",
    "keywords": [
      "large language model",
      "evaluation",
      "benchmark",
      "code execution"
    ],
    "venue": "ICLR",
    "year": 2025,
    "pdf_url": "https://openreview.net/pdf?id=viQ1bLqKY0",
    "forum_url": "https://openreview.net/forum?id=viQ1bLqKY0",
    "reviews": [
      {
        "rating": "3",
        "confidence": "4",
        "summary": "The paper introduces EXE, a new benchmark designed to evaluate language models (LLMs) on their ability to execute Python code sourced from real-world applications. This benchmark aims to address several limitations of existing evaluations, particularly the issues of scalability, task diversity, training data contamination, and benchmarking costs.  \n\nThe benchmark comprises over 30,000 tasks drawn from 1,000 popular GitHub repositories, spanning different complexities and computational operations like logical inference, mathematical reasoning, and state management. \n\nTo construct this benchmark, the authors first select the top 1,000 most popular pypi packages and collate the corresponding github repos, after that, the authores perform a static ast analysis to filter to functions with LLM generatable argument and return type annotations. Finally, the authors apply LLM to generate test cases.\n\nThe evaluation with GPT-4 model demonstrate the limitation of existing code models.",
        "strengths": "### 1. This paper is well-written and easy to follow.\n\n### 2. Benchmarking code LLM is an important problem.\n\n### 3.  The findings are interesting.",
        "weaknesses": "## 1. The motivation for this work is not clearly articulated. \n\nThe paper proposes benchmarking the code execution capabilities of LLMs, but it is unclear why such a capability is needed given the existing roles of compilers and interpreters. A possible motivation might be that LLMs are more lightweight and could predict execution outcomes without running the code. However, I did not see any evaluation results to support this assumption.\n\n## 2. The paper suggests that the proposed dataset can guard against data contamination [1, 2], but lacks a detailed explanation of how this is achieved. \n\nThe authors claim that the dataset is dynamically collected from GitHub, which could help mitigate contamination. However, since the benchmark is built from popular GitHub repositories that do not frequently change, the dataset may not be as dynamic as implied. Additionally, because the test inputs are generated by LLMs, it is unclear how this setup effectively prevents data contamination.\n\n## 3. Certain methodological details are missing. \n\nFirst, in \"Function Selection and Dependency Collation,\" the authors mention using static AST analysis, but it is not clear how this process is performed. Second, regarding the error metric, the authors state that they \"compare the type and message (excluding stacktrace) using a language model comparison,\" which is described too vaguely to understand how this metric is actually computed.\n\n## 4. This work lacks soundness in the following areas: \n\n(1) The authors claim the benchmark is diverse; however, there is no diversity evaluation regarding the prompts and solutions. (2) Since all test cases are generated by an LLM, there is no guarantee that the test cases are sound or appropriate for the programs. Given that some test cases result in errors during execution, this raises soundness concerns.\n\n## 5. Minor: Some figures are of low resolution and unclear.\n\n\n[1] GSM-Symbolic: Understanding the Limitations of Mathematical Reasoning in Large Language Models\n\n[2] PPM: Automated Generation of Diverse Programming Problems for Benchmarking Code Generation Models"
      },
      {
        "rating": "5",
        "confidence": "3",
        "summary": "The authors present a new benchmark to evaluate LLMs' capability in executing real-world code. To collect a set of executable code from the real world, they built a pipeline to collect repos from GitHub to construct self-contained, deterministic code. They performed static analysis to inline the dependencies to make it self-contained, and then generated inputs using LLMs. The benchmark includes 30,000 tasks across 1,000 popular Python repos. They evaluated GPT-4o and GPT-4o mini and showed that these strong models still struggle with more complex tasks.",
        "strengths": "* The benchmark addresses the issue in the prior work, i.e. CruxEval, by collecting real-world Python functions, instead of synthetically generated ones from LLMs.\n* The benchmark includes diverse tasks and spans across 1000 repos\n* The pipeline is mostly automatic and can be updated to include newer repos to address the benchmark contamination problem\n* They provide analysis regarding the relationship between performance and line count, number of function calls, execution time, etc. to better understand what affects performance",
        "weaknesses": "* The main issue with the work is that it lacks certain insights as to how this benchmark would shed light. For example, many people use CruxEval because it correlates well with model's code generation/understanding ability. Does evaluating on this benchmark instead of CruxEval serve as a better predictor of such capability?\n* The paper evaluates on two models: GPT4o and GPT4o-mini. It would be better to also evaluate some open source models to compare against the closed API-only ones, especially the StarCoder model which explicitly provides training data, so one can check whether the code in the training data affects the execution prediction or not\n* The input test cases are LLM generated. Since the work emphasizes real-world scenarios, it would be good to assess whether the LLM-generated test cases are of reasonable quality, and whether it gives an advantage to the LLM that generated the test cases in performing the task"
      },
      {
        "rating": "3",
        "confidence": "3",
        "summary": "The authors introduce a dataset of executable python functions mined from Github. The functions chosen have certain type annotations for which test cases can be generated. The task consists in providing a code snippet as well as the input arguments into an LLM and asking the LLM to predict the output (this task has been referred to as \"program induction\" in some literature of the past, and I will refer to it as \"program understanding\")\n\nThe authors argue that this is a non-trivial benchmark and that the methodology allows the benchmark to evolve over time to include test cases or functions that are not in the training set. The authors also argue that this program understanding task could be an useful gauge of LLMs performance for coding tasks. \n\nThe authors evaluate GPT4o and GPT4o-mini on this task and provide some analysis on performance by certain proxies for ``difficulty\" such as lines of code, number of function calls, etc.",
        "strengths": "The authors deserve credit for their creative use of open-source software on Github. I believe that more executable coding benchmarks will be beneficial to the community and the authors have elements to create something very interesting! The steps taken to create the dataset seem non-trivial and the scale of the dataset is notable (>30K functions). There is preliminary evidence that the task is non-trivial, and the authors also have interesting analysis on factors that lead to more difficult program understanding on this task. I think there is potential for the authors to leverage their ingenuity in constructing this dataset for interesting applications. After skimming CruxEval which seems to propose a similar approach, my judgment is that the underlying dataset scale and difficulty of EXE is more noteworthy.",
        "weaknesses": "I think the motivation of this paper is great, and the creativity to create an executable programming benchmark is excellent! I think there is great potential in this work! I would recommend the authors try to focus on some of the following facets. \n\n1. Clarification of Test case generation methodology\n\nI may have missed it, but I tried to look for details on methodology of test case input generation. The authors are clear on the accepted types are allowed for inputs/outpus, but it is unclear how generation is done. The best I could find is: \"Based on the type definition (used for setting the function calling schema) inputs/ output pairs have been generated with the goal of maximising diversity of control flow paths within the function.\" and \"Using the argument type annotations we construct a LLM function calling schema that generates a diverse set of inputs.\" The paper requires more details and clarification on this, and depending on the methodology chosen, this could affect the merits of the approach. \n\n2. Experiments / Lack of Models Considered\n\nBecause this is a datasets and benchmarks paper and the paper's motivation emphasizes \"difficulty\" of the task, not enough is done to substantiate this claim. My expectation for a dataset/benchmark paper should be at least to evaluate numerous open source models (e.g. CodeLLama, LLama3 family, CodeT5, etc) of varying sizes in addition to commercial models. Additionally, only 2 commercial models from OpenAI are used. Performing wider evaluation will strengthen these claims and the analysis, otherwise, it is an open question on how other models would perform on this task. \n\n3. The framing of experiments + context of other works (a potential lack of novelty)\n\nThe authors do not distinguish their approach or experiments from a dataset like CodeNet. The code understanding experiments provided here can also be done with CodeNet. If the authors could show that LLM performance or the nature of LLM performance is different on their task vs. CodeNet, this would substantiate the contribution. Of course the code on github is more diverse in nature, but on the other hand, the input/output types are still limited, and a dataset like CodeNet is multi-lingual. \n\nMy recommendation would be to consider other creative uses of this dataset besides the ones you currently have. \n\n\n4. Polished Writing\n\nA paper for this venue should have a higher standard of polishing. For example, the term AST should be introduced as an Abstract Syntax Tree (AST) and referred to as AST. At one point the authors colloquially refer to evaluation benchmarks as \"evals.\" These are minor points and easy to fix, but are nevertheless are standards. \n\n5. Clarification on Licensing, Copyright, etc. \n\nI did not see clarification if the authors filtered code for permissively licensed software and if the dataset falls under acceptable use of the software."
      },
      {
        "rating": "5",
        "confidence": "4",
        "summary": "This paper introduces a new benchmark EXE, focusing on testing the capability of LLMs to simulate code execution. EXE is made up of over 30000 tasks derived from 1,000 popular Python repositories on GitHub. In this scenario, LLMs need to execute code, involving operations like mathematical reasoning, logical inference, loop execution, and maintaining internal variable states. This paper provides a shallow breakdown on this. The pipeline to create EXE involves selecting and preprocessing GitHub repositories, synthesizing inputs based on function signatures, and then creating test cases (unit tests, and potentially, chaining functions tests) with the inputs. The authors claim their pipeline is automatic and capable of continuous new task generation with newest repositories to avoid test set contamination.\n\n\n————after rebuttal————\n\nThe substantial revisions made during the rebuttal period addressed some of my concerns regarding model evaluation and test set contamination. The clarifications on dependency solving are also convincing. However, as the rest of my concerns are not fully addressed and the substantial revisions are making it a new paper with too many raw details without careful organizations. I think it would be better to be revised and submitted to follow-up venues like ICML. Besides, knowing the capabilities of LLMs in code executions should be the outcome of this paper, and I think current easy subset(see weakness 8) evaluation somehow weakens it.\n\nNonetheless, I have raised my score to 5 and presentation to 2 to praise for the authors’ efforts.\n\nGood luck,\n\nReviewer o62o",
        "strengths": "1.Provide a benchmark of real-world Python code for testing LLM execution, the test cases are significantly harder and more representative for real-world usage, therefore providing a more realistic assessment of model capabilities, \n\n2.Establish an automatic pipeline to create a real-world dataset for LLM-based code execution tasks.\n\n3.Cover a wide range of programming concepts and can be potentially scaled up or updated with new tasks.\n\n4.The unit-test based evaluation is correct, the authors also mention the potential to create more complicated test cases like using chaining functions.",
        "weaknesses": "## Major weaknesses:\n1.Only GPT-4o and GPT-4o-mini are evaluated, contrary to the claim of evaluating **\"several state-of-the-art LLMs.\"** Additional evaluation with different LLMs are recommended, like Claude, Gemini, Deepseek, Phi, Qwen, etc.\n\n2.The claim of **\"avoiding training on the test set\"** relies heavily on the quality and effectiveness of the pipeline's ability to generate new test cases, which is not thoroughly demonstrated in the paper, no supplementary materials provided either. The Lack of supportive materials (either the benchmark itself or its creating code) to support claims about the framework's capabilities, weakens the contribution of a dataset paper.\n\n3.The handling of import dependencies and the process of inlining required elements are not clearly explained. It's technically important here. Need clarification.\n\n4.A bit limited to Python code, which may not represent the full spectrum of programming challenges across different languages. Since LLMs are pretrained on various programming languages, it's worth to know the execution capability on other programming languages.\n\n5.Poor quality of figures in the paper, with low-precision images that are difficult to see clearly, the authors should use vector figures instead of jpgs or pngs, \n\n6.The appendix uses 8 pages to show an example, which is excessive and poorly organized, besides, it's still not intuitive for understanding. This needs significant revision for clarity and conciseness.\n\n## Minor weaknesses:\n\n7.A bit limited evaluation metrics, using only Pass@1 accuracy. Considering more evaluations on Pass@k, or try some self-correction mechanism with LLM.\n\n8.Filtering on limited acceptable types and functions seems to make EXE an **easy subset of the real real-world programs**, although it is a fair design choice for a benchmark to avoid environment configuration issues. I think it's more interesting to know the capabilities and limitations of LLMs when executing harder cases, containing real-world types like numpy.array, torch.tensor for example. Can the authors add some discussions about their findings here?\n\n## Typos and Presentation Issues:\n\nLine 294: tense issues, ...**increase** task difficulty, however bit manipulation and boolean operations only **showed**...  Should use unified tense throughout a paragraph.\n\nLine 297: however for loops **on (73 Pass@1) on** average did not have a significant impact.\n\nLine 303: Incorrect spacing on the title of the rightmost subfigure.\n\nFigure 7: Examining only on LLM really executed code makes the accuracy normal now. However, it seems the results are not clearly illsutrated (only a small part of the figure is valid now, which is not clear). Consider to use some new figures.\n\nAppendix A.2: These are important part of your paper, since current version only uses 8 pages, consider to move this section to the main page and explain them with more details."
      }
    ],
    "rating_avg": 4.0,
    "confidence_avg": 3.5,
    "decision": "Reject",
    "meta_review": "Reject by reviewer consensus.\n\nThe paper introduces EXE, a benchmark designed to evaluate language models (LLMs) on their ability to execute Python code sourced from github and with LLM generated test cases. Reviewers generally understood this work and liked the motivation as well as how it represents real-world Python code.\n\nSeveral reviewers think that only evaluating on GPT-* models is insufficient and urged inclusion of at least some open models. Reviewers also pointed out various issues such as diversity (only Python), and whether model generated test cases are trustworthy.",
    "author_remarks": "",
    "decision_comment": ""
  },
  {
    "id": "vdUYa7N8Mt",
    "title": "The Rate-Distortion-Perception Trade-Off with Algorithmic Realism",
    "authors": [
      "Yassine Hamdi",
      "Aaron B. Wagner",
      "Deniz Gunduz"
    ],
    "abstract": "Realism constraints (or constraints on perceptual quality) have received considerable recent attention within the context of lossy compression, particularly of images. Theoretical studies of lossy compression indicate that high-rate common randomness between the compressor and the decompressor is a valuable resource for achieving realism. On the other hand, the utility of significant amounts of common randomness at test time has not been noted in practice. We offer an explanation for this discrepancy by considering a realism constraint that requires satisfying a universal critic that inspects realizations of individual compressed images, or batches thereof. We characterize the optimal rate-distortion-perception trade-off under such a realism constraint, and show that it is asymptotically achievable without any common randomness, unless the batch size is impractically large.",
    "keywords": [
      "lossy compression",
      "perceptual quality",
      "rate-distortion-perception trade-off",
      "randomization",
      "universal critics"
    ],
    "venue": "ICLR",
    "year": 2025,
    "pdf_url": "https://openreview.net/pdf?id=vdUYa7N8Mt",
    "forum_url": "https://openreview.net/forum?id=vdUYa7N8Mt",
    "reviews": [
      {
        "rating": "5",
        "confidence": "4",
        "summary": "The paper concerns with the rate-distortion-perception tradeoff (RDP) in the context of lossy compression and argues that previous theoretical results, which suggest that common randomness between the encoder and the decoder is crucial for good performance, do not accurately reflect how humans perceive realism. To address this, the authors reformulate the RDP with reaslim constraints by adopting the concept of universal critic that generalizes no-reference metrics and divergences and insecpt batches of samples. Under this framework, they prove that near-perfect realism is achievable without common randomness unless the batch size is impractically large and the proposed realism measure reduces to a divergence.",
        "strengths": "* The paper provides a novel perspective on the rate-distortion-perception tradeoff by adopting the concept of universal critics.\n* The paper presents rigorous theoretical analysis and proofs to support its claims.\n* The theoretical finding that near-perfect realism is achievable without common randomness has significant practical implications for lossy compression.",
        "weaknesses": "While the paper presents a novel and potentially impactful contribution, its clarity and accessibility are hindered by a dense presentation style. The heavy use of technical notation and the lack of illustrative examples make it challenging to grasp the core concepts and implications of the proposed framework.\n\nSpecifically, the paper would benefit from:\n\n* More explanatory discussions: For instance, a concise discussion following Definition 3.3 would clarify the meaning and significance of the new formulation in comparison to the original RDP framework.\n\n* Illustrative examples: Simple case studies or visual examples would help readers understand the practical implications of the theoretical results. The authors could consider drawing inspiration from the original RDP paper by Blau & Michaeli, which effectively uses examples to convey its ideas.\n\nAddressing these issues would make the paper more accessible to a wider audience and increase its impact. While the core contribution merits acceptance, I strongly encourage the authors to revise the paper with a focus on clarity and illustrative examples."
      },
      {
        "rating": "5",
        "confidence": "2",
        "summary": "The study addresses a core issue in lossy image compression: achieving high perceptual quality in the decompressed images while minimizing distortion and compression rate. A unique aspect of this paper is its focus on algorithmic realism — a concept that considers human perception and aims to create compressed images that appear realistic to a critic. This builds on prior work on the rate-distortion-perception (RDP) trade-off, but instead of relying heavily on common randomness, it introduces a framework that reduces or eliminates the need for shared randomness between encoder and decoder in practical settings.",
        "strengths": "1. Interesting Insight into Realism Constraints: By redefining perceptual realism through an algorithmic lens, the paper provides a fresh perspective on the RDP trade-off and its practical applications in lossy compression.\n2. Reduced Dependency on Common Randomness: The finding that common randomness is only needed in impractically large batches addresses a significant gap in previous theoretical predictions versus experimental observations.\n3. Good Theoretical Foundation: The study provides rigorous proof and aligns well with information theory, making it a valuable resource for researchers interested in theoretical advances in compression.",
        "weaknesses": "While the paper provides rigorous theoretical derivations and proofs, one significant limitation is the lack of practical illustrations or implementations that could help readers appreciate the impact and contributions of the proposed framework in real-world applications. The authors claim that algorithmic realism simplifies the practical attainment of the rate-distortion-perception (RDP) trade-off by reducing the dependency on common randomness between encoder and decoder. However, without practical visualizations or demonstration attempts, it becomes challenging for readers to intuitively evaluate the work’s contributions.\n\nThough I acknowledge the value of theoretical derivations, the paper appears incomplete and, consequently, less persuasive without empirical validation. I strongly recommend that the authors complement their theoretical results with practical experiments, such as specific implementations, visual examples, or a demonstration. This would significantly enhance the paper’s credibility and provide readers with a tangible understanding of the theory’s implications.\n\nTo make these points more specific, I propose the following questions:\n\n **1. Evaluation of Practical Applicability**\n\nThe paper offers extensive theoretical proofs, yet there is no concrete implementation provided to demonstrate how this framework could be integrated into real-world image compression tasks. Could the authors consider validating the proposed approach on an actual compression system to illustrate its practical efficacy?\n\n **2. Feasibility of Reducing Common Randomness.**\n\nWhile the theory is sound, it would benefit from an empirical investigation to verify that reducing common randomness does not detract from visual quality. Without experimental validation, how can readers assess the applicability of these theoretical findings to practical compression systems?\n\n   **3. Experimental Support for Theory-Practice Connection**\n\n The paper’s theoretical framework is detailed but lacks experimental applications or use cases. Could the authors consider providing experiments to demonstrate the balance of visual quality and compression rate achieved by the proposed approach?\n\n   **4. Inclusion of Visual Case Studies**\n\n Given the claims of practical feasibility, is it possible to provide specific examples of compressed and decompressed images to offer readers a more direct perception of the quality improvement achieved by the proposed approach?\n\nThese additions would substantially enhance the paper by bridging the gap between theoretical results and their practical impact, allowing readers to more fully appreciate the contributions of this work."
      },
      {
        "rating": "6",
        "confidence": "4",
        "summary": "This paper propose a new rate-distortion-perception function and proves its achievabiliy and converse, in both zero-shot and asymptotical setting. The proposed RDP function replace the P from divergence to a realism measure defined by authors. The propose RDP function is achievable without common randomness.",
        "strengths": "It is great to have a RDP which is achievable without randomness. Afterall, the human eye distinguishs images in a per-image setting without randomness. The proposed RDP is better aligned to human perception in this sense. I have not went through the details of proofs due to the complex notation. However, I am in general glad to see a new RDP function with achievability & converse, zero-shot & asymptotic.",
        "weaknesses": "The reason why I am not willing to give this paper a higher rating is that the authors have not shown how the proposed RDP can guide perceptual compression / super-resolution, not even a toy example.\n\nThe RDP function in [Blau & Michaeli 2019] has many disadvantages, which this paper does not have:\n* [Blau & Michaeli 2019] does not prove the converse.\n* [Blau & Michaeli 2019] does not distinguish zero-shot and asymptotic function.\nThose issues have not been fixed until [A coding theorem for the rate-distortion-perception function].\n\nHowever, those weakness does not stop [Blau & Michaeli 2019] being popular. This is because [Blau & Michaeli 2019] has clear application in perceptual compression / super-resolution. It explains why previous work using GAN for perceptual compression; It aligns very well with the practically used \"real vs. fake\" test; It even guides later works in diffusion based image compression.\n\nICLR is a machine learning venue, not a pure information theory venue such as ISIT / TIT. It is better to have numerical examples (even toy size) and suggestions for later application works, so that the later works in ICLR can benefits from this paper more.\n\n(minor) It is better to move the converse to the main paper, as this year we have 10 page budget. It is strange to have a 8 page paper and 20 page appendix. At least for me, the converse is as important as achievability."
      },
      {
        "rating": "6",
        "confidence": "4",
        "summary": "This paper proposes a new mathematical formulation for the rate-perception-distortion tradeoff. Specifically, in the previous rate-perception-distortion formulation, the perceptual quality constraint is a constraint on the statistical divergence between the distribution of the decoded images and that of the clean images. In theory, this typically leads to randomized decoders, which produce many different decoded images given an encoded one. However, in practice, high-perceptual-quality compression-decompression algorithms rarely incorporate such randomness.\nTo explain this phenomenon, the authors replace the perceptual quality constraint with a new interesting concept called the \"universal critic\", which poses a perceptual quality constraint on individual images (or on a batch of images).\nThe new rate-perception-distortion formulation leads to solutions which do not incorporate randomness. This is a sensible result given the fact that now there is no constraint on the *distribution* of the decoded images.",
        "strengths": "This paper is incredibly interesting, and written very well. The theoretical results are interesting and serve a highly important contribution to the community of information theorists.",
        "weaknesses": "1. There are no experiments, demonstrations, simulations, presented evidence, etc. This paper contains only theoretical results, which is not necessarily a bad thing, but I am not sure whether it's a fit for the ICLR community (most of which are practitioners). I would expect to see this paper in a theoretical journal.\n\n2. There is no discussion/limitation section discussing the possible future continuation of this work."
      }
    ],
    "rating_avg": 5.5,
    "confidence_avg": 3.5,
    "decision": "Reject",
    "meta_review": "Reviewers find the theoretical work interesting, but they agree that the paper lacks significant experimental demonstration of their results and also missing motivation for the utility of the presented work.\nFor that, the paper is recommended for rejection at this current state, but authors are encouraged to perform the experiments and resubmit.",
    "author_remarks": "",
    "decision_comment": ""
  },
  {
    "id": "PwxYoMvmvy",
    "title": "Beyond Random Masking: When Dropout meets Graph Convolutional Networks",
    "authors": [
      "Yuankai Luo",
      "Xiao-Ming Wu",
      "Hao Zhu"
    ],
    "abstract": "Graph Convolutional Networks (GCNs) have emerged as powerful tools for learning on graph-structured data, yet the behavior of dropout in these models remains poorly understood. This paper presents a comprehensive theoretical analysis of dropout in GCNs, revealing that its primary role differs fundamentally from standard neural networks - preventing oversmoothing rather than co-adaptation. We demonstrate that dropout in GCNs creates dimension-specific stochastic sub-graphs, leading to a form of structural regularization not present in standard neural networks. Our analysis shows that dropout effects are inherently degree-dependent, resulting in adaptive regularization that considers the topological importance of nodes. We provide new insights into dropout's role in mitigating oversmoothing and derive novel generalization bounds that account for graph-specific dropout effects. Furthermore, we analyze the synergistic interaction between dropout and batch normalization in GCNs, uncovering a mechanism that enhances overall regularization. Our theoretical findings are validated through extensive experiments on both node-level and graph-level tasks across 14 datasets. Notably, GCN with dropout and batch normalization outperforms state-of-the-art methods on several benchmarks, demonstrating the practical impact of our theoretical insights.",
    "keywords": [
      "Graph neural networks",
      "Dropout"
    ],
    "venue": "ICLR",
    "year": 2025,
    "pdf_url": "https://openreview.net/pdf?id=PwxYoMvmvy",
    "forum_url": "https://openreview.net/forum?id=PwxYoMvmvy",
    "reviews": [
      {
        "rating": "6",
        "confidence": "3",
        "summary": "This paper investigates the role of dropout in GCNs, addressing a gap in understanding how dropout interacts with graph structure in these models. The authors provide a theoretical analysis that dropout in GCNs generates dimension-specific stochastic subgraphs, which introduces a unique form of structural regularization that doesn’t appear in traditional neural networks. The study highlights that dropout’s effects vary based on node degree, leading to adaptive regularization that leverages topological node importance. The paper also discuss dropout’s capacity to reduce oversmoothing and presents generalization bounds tailored to graph-specific dropout effects. Additionally, it explores the combined effect of dropout and batch normalization in GCNs, identifying a mechanism that enhances overall regularization.",
        "strengths": "- The paper focuses on the role of dropout in GCNs, specifically analyzing its unique interactions with graph structure. This originality is meaningful to the community.\n- The work presents a well-developed theoretical framework, introducing concepts like dimension-specific stochastic subgraphs, adaptive regularization based on node degree, and graph-specific generalization bounds.\n- Including comprehensive experiments across 16 datasets for both node-level and graph-level tasks is encouraging.",
        "weaknesses": "- The authors provide generalization bounds for graph neural networks with dropout. However, further clarification is needed on how this finding offers insights into understanding and designing graph neural networks, or any specific guidance on selecting dropout rates. With this theory, is it possible to get the best dropout rate with a specific graph structure and GNN? This would help demonstrate the practical relevance of the theory. Additionally, can the experiments provide corresponding analyses regarding this theory? For example, whether the change in performance at different dropout rates is consistent with the change in generalization bounds can be analyzed from the theory.\n- The use of dropout or similar strategies designed specifically for graphs is also widely applied in GNNs, like DropNode, DropEdge, DropMeassge, etc [1, 2, 3]. The authors may need to discuss its relevance to this study, including whether the proposed theory can analyze these methods and the essential difference and connection between dropout and these methods. Compared to traditional dropout, does dropout on the graph structure more directly enhance the performance of graph neural networks?\n\n[1] Dropedge: Towards deep graph convolutional networks on node classification\n\n[2] Dropmessage: Unifying random dropping for graph neural networks\n\n[3] Graph random neural networks for semi-supervised learning on graphs"
      },
      {
        "rating": "6",
        "confidence": "3",
        "summary": "This paper focuses on the theoretical analysis of dropout in Graph Convolutional Networks (GCNs) and its impact on regularization and model performance.\n\nThis paper establishes a mathematical framework to analyze dropout's behavior in GCNs. \nIt shows the dropout in GCN is similar to adaptive regularization that considers the topological importance of nodes, and is effective in mitigating over-smoothing in GCNs. And the dropout has synergy with batch normalization in GCNs for enhanced regularization.",
        "strengths": "1. The paper provides a mathematical framework that deepens the understanding of dropout in Graph Convolutional Networks (GCNs), addressing its relation to adaptive regularization and batch normalization.\n2. The empirical analysis is extensive, including empirical observation of theorems and evaluation results on various datasets.\n3. The idea of using active path subgraphs to understand graph feature dropout is interesting.",
        "weaknesses": "1. Dropout is a general and well-known technique, to achieve performance gain via dropout, the question can be how to tune the parameter. Can the theoretical analysis of dropout in GCNs provide insights on how to select the dropout hyperparameter?\n2.  The paper primarily focuses on dropout in GCNs, but it may not sufficiently compare the method with other graph learning regularization techniques, e.g. [1], [2]\n\n[1] Tackling Over-Smoothing for General Graph Convolutional Networks. Wenbing Huang, Yu Rong, Tingyang Xu, Fuchun Sun, Junzhou Huang.  (extension of DropEdge) Arxiv 2020\n\n[2] Rethinking Graph Regularization for Graph Neural Networks. Han Yang, Kaili Ma, James Cheng. AAAI 2021"
      },
      {
        "rating": "6",
        "confidence": "2",
        "summary": "This paper develops a comprehensive theoretical framework analyzing how dropout uniquely interacts with Graph Convolutional Networks (GCNs), revealing that it creates dimension-specific stochastic sub-graphs and provides degree-dependent adaptive regularization. The research provides new theoretical insights into dropout's role in mitigating oversmoothing and its synergistic interaction with batch normalization, deriving novel generalization bounds specific to graph structures. These theoretical findings are validated through extensive experiments across 16 datasets, demonstrating improved performance on benchmark datasets like Cora, CiteSeer, and PubMed.",
        "strengths": "The paper demonstrates rigorous theoretical analysis with a comprehensive mathematical framework for understanding dropout in GCNs, introducing well-defined concepts like dimension-specific sub-graphs and feature-topology coupling matrices.\n\nThe research reveals novel insights about unique interactions between dropout and graph structure, particularly showing how dropout creates dimension-specific stochastic sub-graphs and exhibits degree-dependent effects leading to adaptive regularization.\n\nThe analysis is thorough and multi-faceted, examining structural regularization, oversmoothing mitigation, and interaction with batch normalization, supported by extensive experiments across 16 datasets for both node-level and graph-level tasks.\n\nThe work successfully bridges theory and practice, providing actionable insights for GCN design and training while demonstrating improved performance on benchmark datasets like Cora, CiteSeer, and PubMed.",
        "weaknesses": "The experimental validation lacks detailed information about the 16 datasets used, and the comparative analysis with state-of-the-art methods could be more comprehensive. Some experimental results mentioned in figures are truncated in the provided content.\n\nThe theoretical framework makes limiting assumptions about undirected graphs, and doesn't adequately address the extension to directed graphs. The interaction between dropout and different activation functions, as well as the impact of graph density on dropout effectiveness, need more exploration.\n\nThe paper lacks clear guidelines for selecting optimal dropout rates based on graph properties, analysis of scalability to very large graphs, and discussion of computational overhead for implementing the theoretical framework."
      },
      {
        "rating": "6",
        "confidence": "4",
        "summary": "The paper performs a comprehensive theoretical analysis of dropout in the case of Graph Convolution Networks (GCN) from multiple perspectives: dimension-specific graph structure modification during training, degree-dependent effect on nodes, impact on over-smoothing, and it’s combined effect with batch normalization.",
        "strengths": "- The theoretical analyses are detailed and sound. \n- Mathematics and the overall logic of the paper is easy to follow.\n- The paper attempts to better understand the internal workings of dropout in GCNs.",
        "weaknesses": "While I like the theoretical analyses presented in the paper, I think the experiments do not quite align to support the theoretical claims. Below are my concerns with the paper.\n\n- The authors referring to the dropout and batch normalization as “our approach” in lines 409-410 and 466 is misleading since the techniques have been well-established in deep learning for improving performance. The contribution of the authors lies in the detailed theoretical analysis of these techniques within the context of a GCN. While it is a valuable contribution, the techniques should not be claimed as their approaches.\n- The major concern is with the conclusions drawn from the experiments. It is already established in deep learning that dropout and batch normalization enhance performance through regularization. Therefore, only comparing the performance in Tables 1, 2, and 3 does not provide sufficient evidence that the observed improvements are specifically due to the additional effects of dropout in graph neural networks, as analyzed in the theorems. The authors need to design experiments that can directly validate their theoretical analysis.\n- Section 3.4 describes an interesting connection between dropout, the number of GCN layers, and over-smoothing. However, the authors fail to provide experimental evidence to support this relationship. Demonstrating how dropout affects over-smoothing in GCN with varying layer depths would strengthen the paper.\n- Line 472 (regarding Table 1) and line 483 (regarding Table 2) draw contrasting conclusions about the effect of dropout on Dirichlet Energy. What is the reason behind this difference in the behavior of dropout?\n- Minor: Repeated use of variable 'd' for denoting degree (line 133) and node feature dimensionality (line 141).\n\nWith a sound experimental design that can directly validate the theoretical claims, I believe the paper would be a good contribution to the GCN community."
      }
    ],
    "rating_avg": 6.0,
    "confidence_avg": 3.0,
    "decision": "Accept (Poster)",
    "meta_review": "This paper introduces a novel theoretical analysis of the dropout in GCNs. It shows that dropout creates a degree-dependent dimension-specific stochastic sub-graph, which performs an adaptive structural regularization and prevents the over-smoothing issue. Besides, a deep understanding of the interplay between dropout and batch normalization is presented. The theoretical analysis of this paper is rigorous and the experimental evaluations are sufficient to justify the statements.",
    "author_remarks": "",
    "decision_comment": ""
  },
  {
    "id": "YaRzuMaubS",
    "title": "Defining Deception in Decision Making",
    "authors": [
      "Marwa Abdulhai",
      "Micah Carroll",
      "Justin Svegliato",
      "Aryansh Shrivastava",
      "Anca Dragan",
      "Sergey Levine"
    ],
    "abstract": "With the growing capabilities of machine learning systems, particularly those that interact with humans, there is an increased risk of systems that can easily deceive and manipulate people. Preventing unintended behaviors therefore represents an important challenge for creating aligned AI systems. To approach this challenge in a principled way, we first need to define deception formally. In this work, we present a concrete definition of deception under the formalism of rational decision making in partially observed Markov decision processes. Specifically, we propose a general regret theory of deception under which the degree of deception can be quantified in terms of the actor's beliefs, actions, and utility. To evaluate our definition, we study the degree to which our definition aligns with human judgments about deception. We hope that our work will constitute a step toward both systems that aim to avoid deception, and detection mechanisms to identify deceptive agents.",
    "keywords": [
      "deception",
      "AI safety"
    ],
    "venue": "ICLR",
    "year": 2025,
    "pdf_url": "https://openreview.net/pdf?id=YaRzuMaubS",
    "forum_url": "https://openreview.net/forum?id=YaRzuMaubS",
    "reviews": [
      {
        "rating": "3",
        "confidence": "4",
        "summary": "This paper presents a new quantitative definition of deception in agent-to-agent dialogue interactions modelled as partially observable Markov decision processes (POMDPs). One of the agents is the speaker (S), and the other agent is the listener (L). The listener L is modelled as a POMDP over a certain set of world states. The set of observations of the POMDP representing L is the same as the set of actions available to S. The speaker S is modelled as a POMDP over a state space that contains the world states plus belief states over L. Essentially, S has access to the ground truth of the world and the actions provided by L, and has a belief model over the beliefs and policies of L, while L has no access to the ground truth, and has a belief model over the ground truth guided by the actions of S. \n\nEach agent (S and L) has its own reward function.\n\nDegree of deception is defined as the difference between the expected reward of L if it listens to (and therefore updates its beliefs over) S, and the expected reward of L if it does not listen to (and therefore does not update its beliefs over) S. This way, a positive value indicates an altruistic speaker (S makes the reward of L larger if L listens to S), a negative value indicates a deceptive speaker (S makes the reward of L smaller than it would be if L did not listen to S), or neutral if they are the same. (*)\n\nThe paper states that different concepts of deceptiveness can be captured by plugging different reward functions in Eq. (1). In particular, deceptiveness can be defined as (i) S producing worse outcomes (reward for deception = reward for the task), (ii) S producing beliefs in L further from the truth (reward for deception = belief is close to reality), or (iii) a combination of both (i) and (ii). \n\nArmed with this definition, the paper presents an experimental study, where they generate scenarios with different pairs of agents, ask human subjects to rate the degree of deceptiveness and compare the results with the degree of deceptiveness given by Eq. (1), as well as the degree of deceptiveness when substituting human subjects by state of the art large language models (LLMs). The paper claims that their results support the hypothesis that their definitions of deceptiveness align with human intuition, especially when the reward combines outcome and beliefs, and that the alignment with human intuition is much better than that given by state of the art LLMs. \n\n-------\n(*) This is inverted to what is stated in the text (lines 198-209). I believe there is either a negative sign missing in Eq. (1) or a mismatch in describing the equation in lines 208-209. In any case, it is at the level of a typo, it does not significantly affect the contribution or quality of the paper.",
        "strengths": "S1. The topic of deception in autonomous systems is relevant and timely. The use of autonomous systems in day-to-day decision-making is increasing (especially with the current development of LLMs), and it is fundamental to have models of different intentional harms to increase trust in these systems by the public and accountability for potential harms caused by them. Deceptive language, especially in interactive systems, is of particular relevance.\n\nS2. The paper is written nicely, with a strong motivation, clear structure and understandable examples to guide the reader. \n\nS3. As an experimental evaluation, the paper includes a study on human subjects and addresses state of the art LLMs. The scenarios presented are a good balance of simple and realistic.\n\nS4. The paper has a fair discussion on the limitations of their approach, mentioning how there is work to be done to deploy the proposed concept in more complex and realistic scenarios.\n\nS5. The paper engages with current literature on different definitions of deception and use of LLMs in relation to deception.",
        "weaknesses": "**MAIN WEAKNESSES**\n\nW1. The formalism has no clear novelty. Defining deceptiveness as the level of regret just passes the ball of defining deceptiveness to the reward function. This is not in itself a bad decision, but it does mean that the interest does not lie so much in the definition as proposed in Eq. (1), but rather lies in the choice of reward function. The choice of reward function feels underexplored to me as part of the experimental report. \n\nW2. I think the experimental evaluation goes in the right direction, and most of the data obtained will be useful, but I find it weak as it is now. I will structure my criticism into points that I believe are misleading and points that I believe are incomplete. I also number them, to facilitate later discussion.\n\n\nW2.1. Misleading.\n\n- W2.1.1. In Table 1, the numbers presented indicate the correlation between human perceived deceptiveness and the values given by regret and by LLMs. In the table it states that these results were statistically significant, with a p-value < 0.001. I do not see in the text what statistical test this p-value refers to, I can only assume by context that the null hypothesis was \"there is no correlation between human ratings and machine ratings\". If this is the case, the result is hardly surprising (although it is useful as a means of a sanity check), and I find it misleading to accompany it to the concrete values given in this table.\n\n- W2.1.2. The nutritionist scenario is a bad choice, and I do not agree with the reason given to its lower correlation in lines 361-363. In the nutritionist scenario, human subjects are presented with facts that are controversial in the current public opinion (whether protein, restriction of carbohydrates or herbal teas boost energy). The human subject is going to come with its own beliefs to the task, and they would certainly influence their perception of deceptiveness. I think the nutritionist example is a bad choice and without having prior information on the beliefs of the human subjects with respect to protein, carbohydrates and teas, no reliable conclusions can be extracted from the data of that experiment.\n\n- W2.1.3. Lines 355-356 state that \"We largely find that a combined regret formulation better captures human intuitive notions of deception across all three scenarios, confirming our hypothesis from Section 2.3 that both belief and task reward contribute to improving the correlation with human judgment\". While it is true that the \"Combined\" column is larger than the \"Belief\" column, it is not by much. It would be helpful to accompany this statement with a statistical test and its corresponding p-value. \n\n\nW2.2. Incomplete.\n\n- W2.2.1. Lines 368-373 include information about multi-step conversations. It would be useful to have a table similar to Table 1 summarizing the information, maybe in an appendix if it does not fit in the main text. Also, a conclusion is given that the correlation between humans and regret is higher for multi-step conversations. It would be helpful to accompany this statement with its corresponding statistical test and p-value. It would also be interesting to know how much (if any) the LLMs improve in multi-step conversation. \n\n- W2.2.2. One of the conclusions derived from the experimental evaluation is that the presented regret-based formalism aligns better with human intuition than the estimation given by LLMs. Again, it would be interesting to know the statistical significance of this statement, but more importantly, it would be interesting to understand why. Given the 1-5 scale, it is possible that the LLM produces a less extreme (but still on the correct side) value than the human (for example, the LLM would choose 2 instead of 1, or 4 instead of 5). This would produce a smaller correlation, while indicating that the LLMs are still aligned with human intuition. Another possibility is that the lower correlation comes from the LLMs contradicting human intuition (i.e. the LLM choosing a value >3, when the human chooses a value <3, and vice versa). Of course, in reality, it is probably a combination of both phenomena. It would be however very informative to include some information about this, maybe as part of a qualitative analysis (currently Sec. F in the appendix).\n\n- W2.2.3. One of the questions in the study is which reward function produces deceptiveness degrees that best align with human intuition, and the winner is the \"combined one\". However, as far as I can tell, it is not stated in the paper what is the weight used in combining these values. As an extra step, it would also be interesting to see how the correlation varies for different weights, and whether an \"optimal\" weight arises from the experiments.\n\n\nI hope the authors do not get discouraged by this review. I really like the study presented in the paper and think it has much value.  With some additional depth and clarity in the experimental evaluation, this paper could be a strong contribution for a top-tier venue like ICLR in the future.\n\n\n**OTHER (MINOR) REMARKS**\n\nThese are smaller remarks, mostly editing issues. I hope the feedback serves to polish the paper.\n\nR1. The bibliography needs to be polished. Here is a list of issues I found. \n\n- R1.1. There are repeated items, for example [He et al. 2018], [Lewis et al. 2017], [Wang et al. 2020].\n- R1.2. There are many items that lack a journal, conference, arxiv id or similar. I know in the era of the internet one can find papers just from the title, but let's keep good practices. For example [Abdulhai et al. 2023], [Amodei et al. 2016], [Bai et al. 2022], [Sung et al. 2023], [Pan et al. 2023], [Park et al. 2023], [Touvron et al. 2023], [Ward et al. 2023], [Wei et al. 2023].\n- R1.3. There are typos: <i>diplomacy</i> in [Bakhtin et al. 2022], missing capitalization in [Greene 2007], [Wang et al. 2021] .\n- R1.4. This may be a quirk of mine, but I find it misleading to cite papers that have been presented at major AI/ML venues giving only their arxiv id, while other papers are cited in the proceedings of some conference or journal. For example [Aakanksha et al. 2022] appeared in JAIR 2024, [He et al. 2018] in EMNLP 20218, [Lin et al. 2021] in ACL 2022, or [Pan et al. 2023] in ICML 2023. I would appreciate at least consistency.\n- R1.5. I don't think [Brown et al. 2020] is an appropriate citation for GPT3.5-Turbo. See the discussion here for example: https://community.openai.com/t/how-to-cite-text-davinci-003-in-academic-paper/369821.\n\n\nR2. Apart from the missing details mentioned in W2, there are some missing definitions. When defining POMDP (line 104), the set of beliefs (B) is mentioned, without stating what it is. I assume that a belief is a probability distribution over states (as usual), but this should be stated for the sake of completeness. On a similar note, it is not clear to me what b_L(s) means in Eq.(3). To my understanding, b_L is a probability distribution of states, and b_L(s) is the probability of state s. If so, I would find it more suitable for the reward function to be a distance between the probability distribution b_L and the probability distribution where \"s\" has probability 1, and the rest of the states have probability zero. This is a small change, but as a reader, I spent some time having to think over the definition because it was missing. This distracting confusion could be easily avoided by providing the complete definitions.\n\nR3. The authors could consider engaging with the recent literature of explainable RL in terms of deception and intentional behaviour, and how this can be used to analyse harmful behaviours (deception being here a harmful behaviour). See for example:\n- Liu, Z. et al. Deceptive Reinforcement Learning for Privacy Preserving Planning. AAMAS 2021.\n- Lewis, A. et al. Deceptive Reinforcement Learning in Model-Free Domains. ICAPS 2023.\n- Cordoba, F.C. et al. Analyzing Intentional Behavior in Autonomous Agents under Uncertainty. IJCAI 2023.\n- Beckers, S. et al. Quantifying Harm. IJCAI 2023.\n\n\nR4. These are just two suggestions: \n- I would make section 2.4 significantly shorter to allow for more details on the experimental evaluation. The definition is easy enough to grasp, it may not need so much redundant explanations.\n- In lines 256-257 I would put a different example.\n\nR5. The paper needs an editorial pass. Here is a list of typos and the like.\n- obtains --> obtained (line 079)\n- Figures 3, 4, and 5 are mentioned in the main text without stating that they are part of the appendix.\n- Reference to Fig. 4 in line 315-316 should be to Fig. 6. \n- I do not understand the point of Fig. 4 at all. Does it add any insight that is not already provided by Fig. 6?\n- left --> right (line 931).\n- The caption of Fig.4 is misleading, and seems to be referring to Fig. 5 instead.\n- In Figure 7, the image representation of practising photography and being part of community events are swapped. If this is not only a typo in the paper, but this is also how the examples were presented to the human subjects and LLMs, this fact should be stated somewhere, or the experiment repeated.\n- Table 2 is not mentioned in the text. \n- The font in Figures 3 and 4 is significantly smaller than the main text. Consider making it larger to improve readability. Especially in the appendix, where the page limit does not apply."
      },
      {
        "rating": "5",
        "confidence": "4",
        "summary": "This paper presents a formalisation of deception in terms of POMDPs (partially observable Markov Decision Processes). Two agents, a speaker and a listener have their own PODMDPs. The listener has a model of the speaker's policies, and the speaker has a probability distribution over this model.\n\nThe speaker communicates information to the listener. The speaker may be honest or deceptive (including deception by omission), and the listener takes actions based on their model of the speaker's honesty or deception.\n\nThen deception is defined in terms of the listener's regret. This regret is measured, in the paper, via two reward functions: the listener's true reward function (which measures how much they have been harmed by the speaker's possible deception) or a reward function based on the accuracy of the listener's beliefs (which measures how much they have been mislead by the speaker's possible deception).\n\nSome human feedback experiments on simulated data show that human judgments of deception are somewhat correlated with these two regret measures, with the correlation being stronger with the accuracy-of-belief based regret.",
        "strengths": "The formalism is fine and intuitively plausible (though somewhat idealised). The experiments are well executed and well presented.",
        "weaknesses": "The formalism is interesting, but is only a mild variation of multi-agent POMDP (and MDP) formalisms from other papers (see, eg CIRL papers such as \"Cooperative Inverse Reinforcement Learning\"; searching for competitive MDP and POMDP papers will give many other examples).\n\nIt is not that the formalism is exactly the same as previous formalisms, but that it is very similar to many of them. Nevertheless, the formalism is fine (as mentioned above), and, if it lead to powerful examples and demonstrations, would be an excellent introduction to a great paper. But without those powerful examples or demonstrations, it is not enough to make the paper worthwhile in itself. The experiments show that there is a certain overlap between human judgements and these measures (especially the second regret measure with accuracy of beliefs as the reward), but all the correlations, bar one, are below 0.5, and \"humans weakly agree with this regret measure in three examples\" is not enough meat on the bones for this paper.\n\nWhat the paper needs is a great use case for this formalism, powerful experiments that show its use. An intuitively plausible definition is not enough."
      },
      {
        "rating": "5",
        "confidence": "3",
        "summary": "The paper introduces a formal definition of deception based on the interaction between a speaker and a listener, both modeled as Partially Observable Markov Decision Processes (POMDPs). In particular, a \"regret\" theory is proposed to quantify deception by measuring the speaker's influence on the listener's beliefs, actions, and utility. Experiments and evaluations were conducted to assess whether the formal \"regret\" theory aligns with human judgments about deception.",
        "strengths": "Originality: \n- The paper introduces a novel approach to quantifying deception within the framework of POMDPs, capturing different forms of deceptive behavior.\n\nQuality:\n- Several well-designed experiments were conducted to assess how well the formal definition aligns with human intuition regarding deception.\n\nSignificance:\n- The work is highly relevant to the fields of AI ethics and safety, providing a foundation for future work.",
        "weaknesses": "- A realistic scenario of deception typically involves multi-step interactions between the speaker and listener. Although the paper states, \"While we consider this single-step formulation for simplicity of exposition, it is straightforward to extend the formalism into a sequential setting,\" it is not clear how the current single-step communication (PO)MDP model could be adapted to capture multi-step interactions. The extension to a sequential setting is not sufficiently demonstrated or explained.\n\n- The paper overlooks the importance of the speaker’s beliefs and intentions. For example, does the speaker believe their statement is false? This omission can lead to misclassifications, such as confusing incompetence with deception, as noted in the paper’s limitations. Furthermore, intent is crucial in legal and ethical definitions of deception, where AI agents may exhibit intentional deception towards users. The paper’s \"regret\" theory is purely consequentialist, focusing solely on the outcome or utility without considering the speaker's intent. [1][2]\n\n- The experiments involving large language models (LLMs) don't  explore the diversity of deceptive capabilities these models might show. For instance, LLMs can engage in strategic deception under specific conditions, such as when pressured. This aspect needs further  evaluation of LLM deception. [3]\n\n1.Francis Rhys Ward, Francesco Belardinelli, Francesca Toni, and Tom Everitt. Honesty is the best\npolicy: Defining and mitigating ai deception, 2023.\n\n2. Jaume Masip, Eugenio Garrido, and Carmen Herrero. Defining deception. Anales de Psicología, 2004.\nISSN 0212-9728. URL https://www.redalyc.org/articulo.oa?id=16720112.\n\n3. Large Language Models can Strategically Deceive their Users when Put Under Pressure\nhttps://openreview.net/forum?id=HduMpot9sJ"
      },
      {
        "rating": "3",
        "confidence": "3",
        "summary": "The paper provides a formal definition of deception in a setting where a Speaker and a Listener interact with each other over multiple rounds. The goal of the proposed definition is to capture the Speaker's degree of deception by measuring to what extent its action(s) affect the Listener's beliefs and individual utility. The framework that is used to formalize the Speaker-Listener interactions is a POMDP variation, termed as Communication POMDP, where the Listener is modeled as part of the environment and the Speaker plays the role of the acting agent. Under this decision making framework, the Speaker's degree of deception is formalized through a function that measures the Listener's regret w.r.t. the accuracy of its beliefs and its personal utility, that results from the Speaker's actions. Finally, the paper includes extensive experimentation over a diverse set of scenarios that aims to showcase how well the proposed approach aligns with human intuition and how it compares to LLM baselines.",
        "strengths": "The paper is well-structured and the work well-motivated. Related work is sufficiently covered and the gap that the proposed definition aims to address is clearly highlighted.\n\nThe problem of detecting or preventing deception in AI systems is a very important one, and has become especially relevant these days with all the recent advancements in the field. The main idea promoted by this paper, i.e., that a formal definition for measuring deception is needed, is indeed crucial for making progress in this problem. To the best of my knowledge, this is the first work that attempts to provide such a definition that does not merely measure the truthfulness of agent's statements but instead looks deeper into the intricacies of the problem.\n\nThe Speaker-Listener setting on which this paper focuses does not of course capture all real-world decision making scenarios where detecting deception would be useful, but I find it general enough. The regret function proposed for measuring deception is simple to understand and quite reasonable, although far from complete as also mentioned in the Limitations section of the paper (see also Weaknesses below).\n\nThe biggest strength of the paper in my opinion is the experimental evaluation of the approach. I find it to be rigorous and very well-thought. Even though the proposed method does no do that well in all metrics, it significantly outperforms the LLM baselines.",
        "weaknesses": "**Presentation:** My main issue with this paper is Section 2.2 and the proposed POMDP framework. First, I found the presentation of this section to be quite poor: (a) Many things are not adequately explained, e.g., it is not explicitly mentioned that the world state does not change over time; (b) There are non-standard parts of this framework that are not revisited later on in the paper. This can hinder the understanding of the reader w.r.t. the role of these notions in the framework and why they are needed, e.g., caligraphic omicron in lines 162-164 -> no matter how many times I read this part I could not understand what is used for or what it means; (c) There are notions that are mentioned first and introduced later, e.g., reward r_L which shows up in line 145 and later in line 204 is properly explained in Section 2.4 for the first time. In general, I believe that this paper suffers from serious notational issues which can bring confusion to the reader, e.g., I understand what is the difference between states s_S and s_L but it was never made clear what plain s (Equations 1, 2, 3) stands for, to my understanding is the same as s_L but I am also not sure.\n\n**Framework complexity:** Regarding the Communication POMDP framework, I find it overly complicated and poorly motivated, why is this the correct framework to use? Given that the main purpose of this paper is to be the starting point for research on formalizing deception, I believe that a more comprehensive framework would be quite more helpful. Furthermore, the regret notion in Section 2.3 seems quite simple, which does not justify why all this complexity in the proposed framework. Even though, I have not worked out the details, it seems that turn-based Dec-POMDPs [1, 2, 3] with two agents, Listener and Speaker, could be a potentially suitable framework for expressing your regret notion.\n\n**Definition:** I appreciate the honesty in the limitations section, and I think that since you present your solution as a starting point this part is fine. I believe however that your definition has one additional important weakness that is not mentioned in the Limitations section. In case, Speaker tries to deceive Listener, but the latter does not trust the former and hence it is not influenced by its actions, your approach would classify Speaker as not deceitful, even though it is.\n\n[1] Sidford, Aaron, et al. \"Solving discounted stochastic two-player games with near-optimal time and sample complexity.\" International Conference on Artificial Intelligence and Statistics. PMLR, 2020.\n\n[2] Jia, Zeyu, Lin F. Yang, and Mengdi Wang. \"Feature-based q-learning for two-player stochastic games.\" arXiv preprint arXiv:1906.00423 (2019).\n\n[3] Frans A. Oliehoek and Christopher Amato. 2016. A concise introduction to decentralized POMDPs. Springer"
      }
    ],
    "rating_avg": 4.0,
    "confidence_avg": 3.5,
    "decision": "Reject",
    "meta_review": "The reviewers of this paper provided detailed and high-quality feedback. The main concerns raised are as follows:\n\n- The formalization is relatively straightforward and lacks significant novelty.\n- The experimental evaluations include several misleading or incomplete aspects (see Reviewer fzYT’s comments).\n- The presentation could be significantly improved and simplified. For instance, while the formulation is based on POMDP, the world state remains static in both the theoretical framework and the experiments. If the state does not transition, why base the formulation on POMDP in the first place?\n\nThe authors didn't respond to any above concerns, so it's a clear reject.",
    "author_remarks": "",
    "decision_comment": ""
  },
  {
    "id": "ONfWFluZBI",
    "title": "Self-supervised contrastive learning performs non-linear system identification",
    "authors": [
      "Rodrigo González Laiz",
      "Tobias Schmidt",
      "Steffen Schneider"
    ],
    "abstract": "Self-supervised learning (SSL) approaches have brought tremendous success across many tasks and domains. It has been argued that these successes can be attributed to a link between SSL and identifiable representation learning: Temporal structure and auxiliary variables ensure that latent representations are related to the true underlying generative factors of the data. Here, we deepen this connection and show that SSL can perform system identification in latent space. We propose dynamics contrastive learning, a framework to uncover linear, switching linear and non-linear dynamics under a non-linear observation model, give theoretical guarantees and validate them empirically.",
    "keywords": [
      "system identification",
      "dynamics learning",
      "identifiability",
      "self-supervised learning"
    ],
    "venue": "ICLR",
    "year": 2025,
    "pdf_url": "https://openreview.net/pdf?id=ONfWFluZBI",
    "forum_url": "https://openreview.net/forum?id=ONfWFluZBI",
    "reviews": [
      {
        "rating": "6",
        "confidence": "2",
        "summary": "The main contribution of this paper is to provide identifiability theory for contrastive learning on time-series data with non-linear mixing, in the same spirit as time-contrastive learning (Hyvärinen & Morioka, 2016) for non-linear ICA. However, the authors discard the independence assumptions typically made in non-linear ICA with respect to the latent variables, and instead define a dynamical system as the data generating process. The proof operates under the assumption that the mapping from latent states to observables is injective but not necessarily linear, which is exploited to show that the composition of mixing and de-mixing by the model is an affine transform. As such, the estimated dynamics via contrastive estimation identify the true dynamics up to affine transformation in the latent space. There are experiments that corroborate the validity of this approach.",
        "strengths": "Applying contrastive learning to recover latent dynamics is itself a relatively new approach and the paper is well organised. The proofs use standard jacobian analysis tools and is easy to follow.",
        "weaknesses": "The paper needs refinement, with minor typos and inadequately captioned figures. While studying the identifiability of time-series contrastive learning might be novel, all the technical tools require carefully controlled assumptions and specific behavior of Jacobians under contrastive loss minimization, which typically do not hold in practice. Nonetheless, such assumptions are common in the literature on the identifiability of dynamical systems from observed time series."
      },
      {
        "rating": "6",
        "confidence": "3",
        "summary": "The paper explores the use of self-supervised contrastive learning for dynamic system identification. It connects self-supervised learning (SSL) with identifiable representation learning, showing that SSL can identify system dynamics in latent space. The authors propose a model to uncover linear, switching linear, and non-linear dynamics under a non-linear observation model, providing theoretical guarantees and empirical validation.",
        "strengths": "1. The connection between contrastive learning and dynamic system identification is novel and could lead to simple encoder-only implementations favored in practice.\n2. The synthetic experiments, especially the ablation studies, are extensive and investigate many aspects of the theoretical results.",
        "weaknesses": "1. The contributions (comparison with previous work), theoretical techniques, and novelty are very lightly discussed. I would appreciate a detailed discussion comparing this work's conditions with those in recent literature on temporal causal representation learning (e.g., [1] and its follow-up work). This would aid the contextualization of this work and make the contribution more transparent. \n\n2. This work strikes me as theoretically oriented. There is a lack of discussion on the theoretical conditions, limitations, and implications. Just to name a few: \n\n(a) the theorem requires the length for each time series to be infinite, which appears to be quite a strong assumption and not necessitated in recent work (e.g., [1], admittedly I am not an expert and would appreciate correction if I have misunderstood the statements). Why is this necessary, and would it be possible to show results for finite-length series?\n\n(b) How does the control distribution influence the identification results? what conditions should it meet (does it have to be a time-independent Gaussian distribution)?\n\n(c) Line 175: what is the significance of $A$ -- is it previously defined? Could you comment on lines 175-177?\n\n3. Some minor issues:\n\n(a) Line 145: what is (...)?\n\n(b) Line 165: shouldn't $L^{\\top} L$ be a matrix?\n\n\n[1] Temporally Disentangled Representation Learning. Yao et al. NeurIPS 2022."
      },
      {
        "rating": "6",
        "confidence": "3",
        "summary": "In this paper, the authors propose a system-identification scheme for non-linear observations of non-linear time series data. In particular, they propose a modified contrastive learning set-up that posits linear latent dynamics. Compared to prior works in (time) contrastive learning, this directly enforces a notion of sequential temporal consistency, and seems to provide some benefit in system identification settings. Some supporting theory is provided, demonstrating that if the underlying dynamics are linear and invertible, then the proposed method asymptotically recovers the true dynamics up to affine ambiguity. For general non-linear systems, a (soft) switched-linear system heuristic is proposed, where Jacobian linearizations are applied at user-provided reference points.",
        "strengths": "Automatic identification of latent variables or dynamics is of critical importance in modern machine / reinforcement learning. The method the authors propose follows a line of self-supervised methods in contrastive learning. In comparison to its closest relative in time-contrastive learning (Hyvarinen and Morioka, 2016), the proposed method is seemingly more well-fit for fitting non-linear time-series data by fitting a latent time-series, rather than predicting a categorical label as in the aforementioned paper.\n\nSince a main inductive bias built into the base method is that the latent dynamics are linear, the proposed method of iterative Jacobian linearizations is a sensible adaptation, and seems to benefit performance significantly.\n\nNumerically, the proposed method appears to make contrastive methods more robustly performant.",
        "weaknesses": "In my opinion, the paper leaves quite a few critical questions unanswered, and in general suffers from a lack of polish. In its current state, I cannot recommend the paper for acceptance. The main weaknesses in my eyes are the following:\n\nThe paper claims to perform latent nonlinear system identification. This is a key desideratum in various fields such as reinforcement learning and continuous control, and thus has a rich history and literature. However, the assumptions in this paper--and notably how these inductive biases propagate to the algorithm design--severely restrict the applicability of the method without further evidence. Notably, a design assumption in this paper is that the observer function (i.e.\"mixing function\") is invertible. This is a very strong assumption in the context of *non-linear system identification*, where even the foundational theory of linear system identification does not presume: in the Linear-Quadratic Gaussian (LQG) model, where the underlying state evolves linearly $x_{t+1} = Ax_t + Bu_t + w_t$, and observations are a linear function of state $y_t = Cx_t + v_t$ (ignoring the control input term for simplicity), the classical set-up has $d_y < d_x$, such that the observations are per-timestep a low-dimensional measurement of the underlying state. This immediately rules out the mixing function $g(x) = Cx$ being invertible, and this is precisely the motivation for notions such as observability/detectability. Partial observability presents the key challenge in non-linear sysID or reinforcement learning. In particular, it is well-known in controls and RL that ignoring partial observability and imposing a Markovian model (which this paper does implicitly by enforcing the state estimate as a function solely of the current observation) can lead to very undesirable outcomes. In the contrastive learning literature, partial observability is usually not a central issue, often because it is irrelevant for the motivating application (e.g. in computer vision), but one must address this problem for time-series data. In fact, the cited Time-Contrastive Learning method (Hyvarinen and Tomioka, 2016), despite making the same assumption in theory, actually propose a method that is more amenable to partial observability, since they predict categorical labels to *chunks* of observed data.\n\nRegarding the polish of the paper, there are various typos and lacking definitions that make the paper hard to parse at times. The minor ones that I have caught are listed below. A particularly confusing point is the role of the control input $u_t$. The paper presents the control input as entering the latent dynamics directly. However, it is typically the case that the control input enters the state through a (possibly state-dependent) actuation matrix $\\mathbf B(x_t) u_t$. In any case, how the control input enters the dynamics should be dependent on the parameterization of the dynamics, e.g. the affine ambiguity in $\\mathbf L$ in the paper, which is not reflected in the authors' method as far as I can tell. Furthermore, it is unclear if the control input is available to the learner (which is usually the case in sysID), or if it is playing the role of stochastic noise, which eq (9) seems to suggest compared to eq (1). In either case, what role is the control input playing here: in the authors' set-up, there is no need to learn the actuation matrix, and the experiments involve learning a low-noise, nearly deterministic Lorenz system, which rules out some persistency of excitation effect (Tsiamis and Pappas, 2019).\n\n**Minor comments/typos:**\n\nFigure 1: x -> $x$\n\nPage 3: \"linear identifiability (...)\", missing eqref?\n\nTheorem 1: \"bijective dynamics model $\\mathbf f$\", should probably mathematically define what that means.\n\nTheorem 1: $\\lambda$ is not defined in the main paper, only in the appendix.\n\nCorollary 1: \"$\\hat{\\mathbf f} :=1$\", seems to be bad notation.\n\nBeginning of Sec 4: \"non-lineary\" -> \"non-linearly\"\n\nEquation (7): where is $g_k$ defined? Possible hash collision with mixing function notation.\n\nTable 1: should probably introduce acronym \"LDS\" = Linear Dynamical System somewhere\n\nTable 1: What does LDS$\\downarrow$ mean?\n\nTable 1: What do $\\mathbf L$, $\\mathbf L'$, $(\\checkmark)$, $\\mathbf I$ in the theory column indicate?\n\nBetween (11) and (12): \"tailor\" -> \"Taylor\"\n\nBefore Sec 5: \"matices\" -> \"matrices\"\n\nImplementation paragraph: possibly missing number of A100 cards?\n\nEq (23): where is $p_u$ defined?\n\nEq (25): what does $p_{D}(y)$ denote precisely?\n\nAfter Eq (50): \"which is probably still fine because $\\exp(-\\|\\mathbf L \\cdot \\|^2)$ is a valid kernel function (?)\". This probably needs to be formalized/reworded.\n\n**References:**\n\nAnastasios Tsiamis and George J. Pappas, \"Finite Sample Analysis of Stochastic System Identification\", 2019."
      },
      {
        "rating": "6",
        "confidence": "3",
        "summary": "The paper \"Self-Supervised Contrastive Learning Performs Non-Linear System Identification\" explores contrastive learning (CL) for identifying non-linear temporal representations. It presents proof of the identifiability of latent variables up to a linear transformation, removing the requirement for independent noise. The proposed model, DynCL, is validated using synthetic data to support the theoretical findings. Additionally, the authors introduce a model called delta-SLDS, designed to capture switching between linear and non-linear dynamic systems.",
        "strengths": "- The theorem is both interesting and novel, demonstrating that the learned latent variables can be identifiable up to linear transformations even in the absence of independent noise, provided that some other assumptions are met.\n- This theorem provides valuable insights into the mechanisms underlying contrastive self-supervised learning methods.\n- A lot of ablation studies and visualization experiments are conducted, which makes the paper more convincing.",
        "weaknesses": "- Notations are not clear. For example, in Eq (3), the meanings of $x, x', x''$ should be mentioned in advance.\n- In theorem (1) and its proof, the assumption is not aligned with Equation (1-2), where all noise disappears. Further discussion is required.\n- The difference in theorem part should be compared with previous works on CL more detailed, since it is a work focusing on theorem. Making the difference more clear will make it more readable.\n- In experiment parts\n    - Baselines like TCL should be compared\n    - By identifiability, some metrics like MCC should be compared even though they are not component-wise identifiable.\n- Lots of typos:\n    - line 133 (supp figure), line 145 (...), seems unfinished part\n    - line 250: tailor -> talyor\n    - line 637: Theorem 2 -> Theorem A1\n    - footnote of page 13: broken reference  \n    - line 659, 665: missing reference"
      },
      {
        "rating": "8",
        "confidence": "3",
        "summary": "This paper focuses on contrastive learning (CL) methods for dynamical systems.\nThe authors show that under certain assumptions CL performs system identification and can therefore uncover the latent dynamics of the data.\nThe theoretical findings are applied to switching linear dynamics and non-linear dynamics, and are demonstrated from an empirical point of view using simulated data.",
        "strengths": "1. Overall this is an interesting paper, that gives an insight on why CL techniques are effective for system identification\n2. The introduced CL variant is well presented and theoretically grounded, and could inspire further theoretical research and models\n3. DynCL can effectively identify latent states and system dynamics in the experiments on simulated data\n4. The authors present a good selection of ablation studies to demonstrate the impact of the different modeling/parametric choices",
        "weaknesses": "MORE REALISTIC EXPERIMENTS\n\nAs stated by the authors in the limitations of this work, the focus of this paper is only on simulated data. While I understand their point of view, and I also agree that the theoretical contribution/simulated experiments are also valuable by themselves, I fear that the impact of this work in this current state will be more limited than it could be if there was a better demonstration of real world applicability.\n\nYou could for example try to apply your method to some of the datasets used in \"Discovering State Variables Hidden in Experimental Data\" (https://www.cs.columbia.edu/~bchen/neural-state-variables/).\n\nIf the above is too challenging to achieve, you should at least try to discuss more in detail what each of you theoretical assumptions means in practice, and what you expect to happen if they are not met in real-world experiments. For example, the fact that $p(u_t)$ is a normal distribution seems quite strict in many applications. \n\nBASELINE\n\nThe baseline you use in your experiment seems quite weak, as it does not even use a dynamics model. Have you tried other approaches, for example models doing next-token prediction tasks?\n\n\n\n\nCLARITY\n\nThere are several missing definitions/clarifications in the paper that make it a bit harder to follow:\n1. N in (3) is not defined\n2. \"Supp figure\" in line 133 is unclear\n3. Not sure what \"(…)\" in line 145 means\n4. The name $\\nabla$-SLDS is never formally defined\n5. In table 1 you have a column called \"theory\" with different options. What do these option represent exactly?\n6. The abbreviation \"GT\", which I assume stands for ground truth is used in many places but never defined\n7. What is $\\pi$ in equation (8)?\n8. The vMF abbreviation is never defined\n9. The DynCL results from Table 1 should be discussed more in depth."
      }
    ],
    "rating_avg": 6.4,
    "confidence_avg": 2.8,
    "decision": "Accept (Poster)",
    "meta_review": "The paper studies representation learning for system identification of the time-series data. Namely, under the assumption that the ground-true time-evolution happens in the latent space, the authors examine the question of whether one can identify the system, i.e. learn the latent representation and the dynamics in the latent space from the time-series observations.\n\nBuilding on the ideas of contrastive learning, the authors propose a model and prove a theoretical result for this model that in the limit of infinite time-series, the dynamical system can be identified up to a linear transformation (notably, assuming that the observation is obtained from the latent by an injective map). They apply their theory to identify the switching linear dynamics (linear dynamics in which parameters change in time by switching between a finite number of values). Furthermore, the authors argue that the non-linear dynamics can be approximated within the family of switching linear dynamics by the corresponding linearization of the dynamics around the time-series points in the latent space. Finally, the authors empirically validate the proposed framework for linear, switching linear, and Lorenz dynamical systems generating synthetic data in 3 and 6 dimensions.\n\nDespite the reviewers' unanimous low confidence and the much room for improvement left in the presentation, I'm leaning toward accepting the paper. The main reason for this is that different reviewers found different parts of the work to be appealing. This signals that the paper might be relevant beyond a single community of researchers.",
    "author_remarks": "",
    "decision_comment": ""
  },
  {
    "id": "Ql7msQBqoF",
    "title": "MAC-CAFE: Multi-actor, Centralized Critic Architecture for Feedback-driven Editing",
    "authors": [
      "Naman Gupta",
      "Shashank Kirtania",
      "Priyanshu Gupta",
      "Krishna Kariya",
      "Sumit Gulwani",
      "Arun Iyer",
      "Suresh Parthasarathy Iyengar",
      "Arjun Radhakrishna",
      "Sriram K. Rajamani",
      "Gustavo Soares"
    ],
    "abstract": "Large Language Models (LLMs) often generate incorrect or outdated information, especially in low-resource settings or when dealing with private data. To address this, Retrieval-Augmented Generation (RAG) uses external knowledge bases (KBs), but these can also suffer from inaccuracies. We introduce MAC-CAFE, a novel Multi-actor, Centralized Critic Architecture for Feedback-driven Editing approach that iteratively refines the KB based on expert feedback using a multi-actor, centralized critic reinforcement learning framework. Each document is assigned to an actor, modeled as a ReACT agent, which performs structured edits based on document-specific targeted instructions from a centralized critic. Experimental results show that MAC-CAFE significantly improves KB quality and RAG system performance, enhancing accuracy by up to 8% over baselines.",
    "keywords": [
      "Retrieval-Augmented Generation",
      "Large Language Models",
      "Knowledge Base Editing",
      "Prompt Optimization"
    ],
    "venue": "ICLR",
    "year": 2025,
    "pdf_url": "https://openreview.net/pdf?id=Ql7msQBqoF",
    "forum_url": "https://openreview.net/forum?id=Ql7msQBqoF",
    "reviews": [
      {
        "rating": "6",
        "confidence": "3",
        "summary": "The paper presents a framework for editing and refining information in a knowledge base used in a RAG setup. The framework, MAC-CAFE, has several steps, including a multi-agent updating process where each agent proposes updates for an individual document and updates are aggregated using a critic model. The method improves performance in situations with incomplete or out of date knowledge.",
        "strengths": "S1. This is an important problem, and the paper examines it across several reasonable domains. The method clearly outperforms the baselines presented. \n\nS2. The idea of using multiple agents to control knowledge updates and refinement is a nice one, and seems well-executed here.\n\nS3. I like the idea of defining multiple metrics for knowledge base edits and evaluating along these axes. I think the three chosen are reasonable choices for this task, although I don't have much familiarity with current metrics (if any) used to evaluate this.",
        "weaknesses": "W1. The centralized feedback analysis should be compared with self-reflection / self-refine methodologies. \n\nW2. Managing each document with an agent seems quite computationally expensive-- can you provide some analysis of cost/benefit?\n\nW3. Not a factor in my score-- the contributions listed in the intro don't tie back clearly to sections in the paper; it would be stronger to identify which section each of these contributions is described within. This particular subsection also feels like it may have been LLM-generated; I'm not concerned about that for the rest of the paper, but that section reads a bit poorly."
      },
      {
        "rating": "3",
        "confidence": "3",
        "summary": "This paper addresses the issue of hallucination in large language models (LLMs) within the Retrieval-Augmented Generation (RAG) framework. It introduces MAC-CAFE, a novel multi-agent reinforcement learning approach that iteratively refines external knowledge using expert feedback. Experimental results demonstrate that MAC-CAFE enhances LLM prediction accuracy by 8% compared to baseline methods.",
        "strengths": "1. The focused issue of LLM hallucination is an important problem.\n\n2. The motivation of the study that emphasizes knowledge editing makes sense.",
        "weaknesses": "My major concern lies in two aspects:\n1. The rationale behind the design of the proposed method is insufficiently detailed. Although the authors thoroughly describe their implementation, particularly in Section 4, the intuition underlying each component of the design is not clearly described.\n\n2. The result analysis section is quite limited. The authors mainly emphasize the effectiveness of the proposed approach but miss a variety of experiments, such as ablation studies or error analysis, to offer a deeper understanding of its characteristics. For example, which components of the approach are more influential than others? Are there any identifiable patterns in the prediction errors?\n\nAdditionally, the paper writing could be improved. For example, I’m a bit confused about the purpose of section 3. If the illustrative example is intended to motivate MAC-CAFE, it might be more effective to condense this description and incorporate it into the Introduction. Doing so would allow for a more detailed and thorough result analysis in the corresponding section."
      },
      {
        "rating": "3",
        "confidence": "4",
        "summary": "This paper proposes MAC-CAFE, a framework to iteratively refine a knowledge based based on expert feedback. They provide experiments on a relatively lesser used coding language, Pony, to simulate a setting where current KBs do not have high amounts of information available. They also provide results on other datasets such as SciPy, Tensorflow, etc.",
        "strengths": "The idea of knowledge-base fixes via edits/additions/deletions is highly relevant today, and MAC-CAFE proposes an interesting and feasible way to approach the same.",
        "weaknesses": "* Section 4.1 that introduces the problem formulation can be written more clearly, especially regarding the following points:\n    * Introduce tau(q_i, K) before equation-1 in page 4, to ensure the equation is understandable - currently tau is first introduced in the next subsection.\n    * Explain the function g - is g supposed to give a higher score when o_i=c_i?\n    * Define o_i=B(qi, tau(qi, K)) [is this the definition?]\n* I'd suggest to add a short note describing the ReACT agent (perhaps near line 348) - even though it has been cited, not everyone might have a working knowledge of it.\n* Line 348, Actors: I assume a real-life knowledge base would have a huge number of documents - how feasible is it to have a distinct actor model for each document?\n* What are the models used for (1) B the LLM, and (2) the actors? I was unable to find it in Section 6. I suggest to add a subsection or paragraph on the same in Section 6. \n* I also suggest the authors to add a paragraph each about the baseline PromptAgent and about Monte Carlo Tree Search for more accessibility of the paper."
      },
      {
        "rating": "1",
        "confidence": "4",
        "summary": "This paper applies ideas from prompt optimization to optimizing KBs for RAG. \nThe domain considered is text-to-code using documentation as context, focusing on lower-resource coding languages.\nThe authors take a multi-agent approach, splitting a KB into multiple documents and proposing edits for each document according to a fixed set of edits, based on execution feedback. \nAfter a global document selection stage, each document is edited by a separate editing agent (implemented via REACT prompting and PromptAgent's Monte-Carlo tree search) that proposes a sequence of edits to the document.\nTheir method, MAC-CAFE, is evaluated on five text-to-code datasets, with two covering cases where the documentation is incomplete and three covering cases where the documentation is incorrect. \nThe method is evaluated by looking at accuracy before and after editing, as well as coherence metrics. \nMAC-CAFE improves accuracy on the test set for all datasets as compared to the base model and a PromptAgent-based baseline. \nMAC-CAFE also results in more coherent documentation according to G-Eval.",
        "strengths": "1. **Motivating problem**: The problem of outdated KBs (especially in text-to-code) is interesting and well-motivated, as information in these domains does change consistently. A solution for automatically keeping documentation up-to-date here would indeed be interesting. \n\n2. **Multiple domains**: The authors evaluate the method across multiple domains and datasets and include two different settings (incomplete vs. incorrect info). Their method shows improvements across all domains. \n\n3. **Clear method figure**: Figure 2 is easy to parse and describes the MAC-CAFE method in a way that is easy to understand.",
        "weaknesses": "1. **Limited methodological contribution**: Besides the splitting of the problem into multiple documents, the paper seems like a fairly direct application of PromptAgent with limited technical novelty besides the application to a new domain. \n\n2. **Assumption of error knowledge**: The method uses LLMs to generate code and then use feedback from generated code to update the docs. In lines 194-199, the authors correctly point out that there could be multiple sources of error, including sources that do not stem from incorrect docs. However, the authors then say that they assume errors result from *only* from incorrect docs. It's not clear at all from the writing how -- or whether -- this is enforced, i.e. how the authors ensure that the errors are in fact from errors in the docs rather than the generator's shortcomings. This is especially troubling given that they evaluate on lower-resource coding languages where the model might be worse at generating even with correct docs. If this assumption is enforced, the authors should explain how. If it's not enforced, it's the authors responsibility to convince readers that their benefits come from the system in fact improving the docs in some interpretable way, as opposed to addressing simpler kinds of errors. \n\n3. **Limited results**: the \"extensive experiments\" mentioned in fact boil down to 2 short paragraphs on the last page of the paper. There are no ablations for the design choices made (e.g. action space, state representation) and no ablations showing the necessity of splitting the task into a multi-actor setup. The authors only evaluate a single LLM. There is no analysis of the resulting KBs after editing. \n\n4. **Unclear baselines and metrics**: It's not clear what the baseline PromptAgent-E is/how it is implemented, why it was chosen, and why it is a fair/relevant baseline. This kind of detail should be brought up in the main paper (which the paper fails to do) and can then be elaborated in supplementary material (which the paper lacks). The authors also do not convincingly argue for the completeness metric measures completeness. The coherence metric is not clearly explained. The metric section is split across 5 and 6.3 in a way that is very hard to follow \n\n5. **Unclear writing and organization**: In addition to the clarity issues above, the rest of the paper also omits a large number of details. To give a few examples: \n- The method hinges almost entirely on prompting but the authors do not provide their prompts. \n- In Table 3, it's not clear what any of the numbers refer to. They aren't percentages, but they also don't add up to the number of documents. \n- Much of the writing could be compressed. There are several sections that conceptually should be subsections/compressed together. At the same time, other parts are overcompressed, e.g. the results section, where Table 3 is unreadably small. \n\n6. **Method described as using gradients**: The method (which is in fact gradient-free) is described in terms of gradients. My feeling is that the authors should make clear that the \"gradient\" part here is purely a helpful metaphor, as the method does not actually compute any gradients at all. However, from the writing, this point is not brought through clearly."
      }
    ],
    "rating_avg": 3.25,
    "confidence_avg": 3.5,
    "decision": "Reject",
    "meta_review": "The paper introduces MAC-CAFE, a novel Multi-actor, Centralized Critic Architecture for Feedback-driven Editing to improve knowledge bases (KBs) used in Retrieval-Augmented Generation (RAG) systems. By employing a multi-agent framework with structured edits guided by a centralized critic, MAC-CAFE refines KBs iteratively using expert feedback.\n\nStrength:\nAll reviewers agree the problem studied in this paper is quite interesting and has important practical value.\n\nWeakness:\nThe paper writing needs improvement, such as more clarification about the motivation and rationales behind the designs of the proposed method. And also there is insufficient analysis / ablation experiments to justify the effectiveness of the approach. Also, it is also pointed out by Reviewer eoD8 that this paper has some issues in its error knowledge. \n\nOverall, this paper still needs significant work in its writing and experiments in order to make it publishable.",
    "author_remarks": "",
    "decision_comment": ""
  },
  {
    "id": "NHe6guO3l6",
    "title": "Achieving Exact Federated Unlearning with Improved Post-Unlearning Performance",
    "authors": [
      "Ze Yu Zhang",
      "Bui Thi Cam Nhung",
      "Arun Verma",
      "Bolin Ding",
      "Bryan Kian Hsiang Low"
    ],
    "abstract": "Federated learning is a machine learning paradigm that allows multiple clients to train aggregated model via sharing model updates to a central server without sharing their data. Even though the data is not shared, it can indirectly influence the aggregated model via the shared model updates. In many real-life scenarios, we need to completely remove a client's influence (unlearning) from the aggregated model, such as competitive clients who want to remove their influence from the aggregated model after leaving the coalition to ensure other clients do not benefit from their contributions. The influence removal is also needed when the adversarial client negatively affects the aggregated model. Though the aggregated model can be retrained from scratch to ensure exact unlearning (completely removing the client's influence from the aggregated model), it performs poorly just after the unlearning, which is undesirable during deployment. To overcome this challenge, this paper proposes federated unlearning algorithms that ensure exact unlearning while achieving better performance post-unlearning. Our experimental results on different real datasets validate the performance of the proposed algorithms.",
    "keywords": [
      "Exact Federated Unlearning",
      "Improved Post-Unlearning Performance",
      "Multi-Models Training"
    ],
    "venue": "ICLR",
    "year": 2025,
    "pdf_url": "https://openreview.net/pdf?id=NHe6guO3l6",
    "forum_url": "https://openreview.net/forum?id=NHe6guO3l6",
    "reviews": [
      {
        "rating": "3",
        "confidence": "4",
        "summary": "This paper tackles the challenge of achieving exact federated unlearning while maintaining good post-unlearning performance. Existing methods, such as retraining the federated model from scratch, fail to provide satisfactory initial performance after unlearning. Therefore, the authors propose  Bi-Models Training (BMT) and Multi-Models Training (MMT) to address this issue. BMT preserves isolated copies of local models and reuses clients' existing knowledge during unlearning. MMT trains multiple sub-federated learning models on disjoint subsets of clients and aggregates the best sub-models upon unlearning. Both methods ensure exact federated unlearning while achieving improved performance compared to retraining from scratch.",
        "strengths": "**S1**. The topic of how to simultaneously preserve the model performance while exactly removing one client's influence is an important problem in practice.\n\n**S2**. Both theoretical and empirical results were provided to verify the effectiveness of the proposed method.",
        "weaknesses": "**W1**. The technical contributions of the proposed methods are limited. For BMT, it only re-initializes the global model with local models that are only trained once by remaining clients, which is only equal to saving one round's communication cost compared to the random initialization case. For MMT, it maintains multiple series of model training (e.g., global model training, sub-FL training, and local training) to increase the training process's robustness to clients' exclusion. The local computation and communication cost can be larger than restart training the model from the randomly initialized one.\n\n**W2**. Some claims are confusing. For example, the reasons for the new model's low accuracy need further clarification in line 161 \"the new model may have very low accuracy compared to the aggregated model before unlearning due to restarting the FL process with random initialization \", since restarting the FL process with remaining clients should not cause performance drop given unlimited the communication and computation resources. \n\n**W3**. The definition of *double influence* and its impact are also unclear. Please clarify this term in the response."
      },
      {
        "rating": "5",
        "confidence": "5",
        "summary": "In this paper, the authors propose an exact unlearning method for federated model training. The main idea behind this paper is to better initialize the global model and re-train the global model on the remaining clients in a federated way. The authors further propose two strategies for the global model initialization in federated unlearning, including using the first-round local models of remaining clients and using the first-round local models and the corresponding sub-FL models of the remaining clients. Experiments on several datasets show the proposed method can outperform a naive baseline.",
        "strengths": "1. The federated unlearning studied in this paper is an important research problem.\n2. This paper is well-written and easy to follow.",
        "weaknesses": "1. The academic findings found in this paper are not novel. \nThe main academic findings brought by this paper are that using the proposed initialization strategies (using some locally trained models) rather than random initialization can improve the efficiency of federated exact unlearning. However, it is straightforward that using some locally trained models can speed up the convergence of the federated exact unlearning.\n\n2. The proposed initialization algorithm, i.e., MMT, is not well-motivated. \n(1) In lines 241-253, the authors claim that we should capture the joint influence of multiple clients for better global model initialization. However, the authors do not give any clear definition of the client's joint influence. To the best of my knowledge, \"client joint influence\" is not common knowledge in the area of federated learning. \n(2) In lines 263-269, the authors claim that \"If the number of models to aggregate is less, it implies that the initialization of the global model contains the most joint influence of clients\". It is also difficult to understand this statement. If we only use a small part of local models for global model initialization, why can we better capture the client joint influence?\n\n3. The MMT method is inefficient in both computation and storage.\nIn the proposed MMT method, the authors introduce a lot of sub-models to memorize the historical training state. However, this will introduce many extra computation costs. For example, if there exists $n = 2^m$ clients, and we maintain an influence tree with $h$ levels (including the top level and the bottom level), the computation costs of the FL systems will increase $h$ times, which may be impractical in real-world applications.\n\n4. The experiments in this paper can be improved.\n(1) Only small-scale datasets are used for experiments, i.e., MNIST, FMNIST, and CIFAR. The authors should compare different methods on larger datasets to demonstrate the superiority of the proposed method.\n(2) Only small-scale models, i.e., two-layer MLPs and two-layer CNNs, are used for experiments. Can the proposed method be applied to large-scale models, especially for the LLMs?\n(3) The authors only compare a trivial baseline method, i.e. training from scratch. However, there are many SOTA federated unlearning methods, the authors should compare them in this paper."
      },
      {
        "rating": "3",
        "confidence": "4",
        "summary": "This paper proposes an exact federated unlearning method which completely removes the influence of a particular client on the aggregated model. The traditional method for exact unlearning involves retraining the model from scratch. This is effective in removing influence, but also leads to degrading performance after unlearning. To address this issue, the authors propose to maintain a local model that is trained fully on local datasets. Instead of randomly reinitializing the model after unlearning, they use isolated local models for initialization. This method ensures exact unlearning while improving the post-unlearning performance.",
        "strengths": "1. The proposed algorithm effectively achieves exact unlearning by retraining from isolated local models instead of random reinitializations.\n2. The method maintains model performance post-unlearning, making it highly practical for deployment in real-world federated systems.\n3. The method is validated across multiple datasets, demonstrating its effectiveness in achieving better post-unlearning accuracy.",
        "weaknesses": "1. The core idea of this paper stems from using local models instead of random initialization. This trick is quite common in regular federated learning.\n2. Definition 1 and theorem 1 seem redundant. Utilizing a disjoint binary tree structure to eliminate double influence is intuitive enough that it does not require additional justification or explanation.\n3. The paper assumes that each local client has the same amount of data. However, varying data quantities can lead to significant differences in the performance of local models, which may impact post-unlearning aggregation. The authors should investigate this realistic scenario.\n4. In figure 4(d), there seems to be a performance decline in BMT and MMT while the curve for retraining is still rising. Can the authors let the curve to converge and explain why this happens?"
      }
    ],
    "rating_avg": 3.6666666666666665,
    "confidence_avg": 4.333333333333333,
    "decision": "Reject",
    "meta_review": "The paper studies unlearning from an FL standpoint. The authors propose two new methods for federated unlearning, that require training multiple models per subsets of clients, which is made efficient though the construction of a hierarchy of influence across client subsets, identifying how to group them together. This is shown to be performant w.r.t. to unlearning but also w.r.t. post unlearning predictions via experiments.\n\nSome reviewers recognized strengths in the importance of the problem and in the experiments. Including larger datasets both for vision and text during the rebuttal stage improved the paper, and the diversity of datasets was considered a strength.\n\nIssues were raised regarding the technical novelty of the paper: techniques were considered straightforward heuristics. Both the motivation of the proposed method and its overall efficiency were brought into question.",
    "author_remarks": "",
    "decision_comment": ""
  },
  {
    "id": "LJWPYzjDz4",
    "title": "Extending Flexibility of Image Coding Enhancement Framework for IoTs",
    "authors": [
      "Yu Mao",
      "Jingzong LI",
      "Jun Wang",
      "Hong Xu",
      "Tei-Wei Kuo",
      "Nan Guan",
      "Chun Jason Xue"
    ],
    "abstract": "Neural image compression, necessary in various edge-device scenarios, suffers from its heavy encode-decode structures and inflexible compression level switch. The primary issue is that the computational and storage capabilities of edge devices are weaker than those of servers, preventing them from handling the same amount of computation and storage. One solution is to downsample images and reconstruct them on the receiver side; however, current methods uniformly downsample the image and limit flexibility in compression levels. We take a step to break up this paradigm by proposing a conditional uniform-based sampler that allows for flexible image size reduction and reconstruction. Building on this, we introduce a lightweight transformer-based reconstruction structure to further reduce the reconstruction load on the receiver side. Extensive evaluations conducted on a real-world testbed demonstrate multiple advantages of our system over existing compression techniques, especially in terms of adaptability to different compression levels, computational efficiency, and image reconstruction quality.",
    "keywords": [
      "Data Compression",
      "IoT infrastructure",
      "Edge Computing",
      "Scalable Design"
    ],
    "venue": "ICLR",
    "year": 2025,
    "pdf_url": "https://openreview.net/pdf?id=LJWPYzjDz4",
    "forum_url": "https://openreview.net/forum?id=LJWPYzjDz4",
    "reviews": [
      {
        "rating": "3",
        "confidence": "5",
        "summary": "This paper proposes a new downsampling strategy for image compression on edge devices. The method achieves non-uniform sampling by erasing and squeezing the image blocks. In addition, the down-sampled image can be recovered using a transformer. Experiments show that the proposed method achieves superior rate-distortion performance (distortion measured by Brisque, Pi and Tres) with reduced computational complexity.",
        "strengths": "1. The paper is well written and easy to follow.\n2. The idea of erasing and squeezing is interesting.",
        "weaknesses": "1. The proposed method is not suitable for image compression. The erasing process removes the image blocks randomly, which can lead to irretrievable losses of objects. An importance-based or smoothness-based method may be a better choice.\n2. There is no comparison with uniform sampling methods, which is necessary to show the advantages and disadvantages of the proposed sampling method.\n3. The non-reference distortion metrics used in this paper are not appropriate. As far as I know, the non-reference metrics can only measure whether the image is real, which has nothing to do with fidelity. So we can generate a completely different image at the decoder size with an image generation model without any bitstreams to get a high rate-distortion performance, which may be meaningless in applications."
      },
      {
        "rating": "3",
        "confidence": "5",
        "summary": "The paper proposes Easz, a novel image compression framework designed for edge devices, addressing the limitations of existing NN-based compression methods. By introducing an erase-and-squeeze technique, Easz allows for flexible compression levels and efficient image reconstruction, making it suitable for various IoT applications.",
        "strengths": "1. The erase-and-squeeze method offers a flexible alternative to traditional uniform downsampling techniques, enhancing compression adaptability.\n2. The framework is evaluated on a real-world testbed, providing credible evidence of its performance compared to existing compression methods.\n3. Easz is compatible with existing compression algorithms, increasing its utility in practical applications.",
        "weaknesses": "1. The review of related work lacks depth, particularly regarding recent advancements in image compression techniques applicable to edge devices.\n2. The reliance on GPU capabilities for reconstruction may limit the framework's applicability in low-power or resource-constrained environments."
      },
      {
        "rating": "5",
        "confidence": "5",
        "summary": "This paper propose a paradigm to offer compression flexibility and efficiency improvement for edge-device scenarios. It propose a conditional uniform-based sampler for flexible image size reduction and reconstruction, as well as a lightweight transformer-based structure to redeuce reconstruction load on the receiver side.",
        "strengths": "- To avoid issues stems from adjacent sampled areas, this paper add constraints for row-based randoming sampling.\n\n- This paper introduces an erase-and-squeeze method to enhance flexibility and efficiency.",
        "weaknesses": "- The proposed uniform-based sampler gives better results by adding constraints. However, it is still a rule-based sampling method that is unaware of the content. Why didn't you consider a learn-based sampler solution to improve the performance?\n\n- The input of the reconstruction. Is the masking map also needs to be coded and transmitted? Is it also an input of the reconstruction network? I think these details should also be described in Figure 2.\n\n- Settings about Table 1. Easz is a lossy compression method but other super-resolution methods such as SwinIR are free from bit cost constraints. Why does the proposed method Easz show such a performance improvement (larger than 3dB)? What are the testing settings(such as the input size) for the proposed method and the other methods? \n\n- Some citations are neglected, e.g., the citation for the methods in Table 1 and Table 2. Please check about these problems."
      },
      {
        "rating": "3",
        "confidence": "5",
        "summary": "This paper proposes an image compression enhancement framework for edge devices called Easz, which uses the ‘erase-and-squeeze’ technique to improve compression flexibility and efficiency.",
        "strengths": "It seems reasonable to downsample the original image to reduce the coding complexity at the transmitter side.",
        "weaknesses": "1. Under the experimental conditions where GT images are available, relying on no-reference metrics to assess the reconstruction quality will result in an incomplete assessment and make it difficult to clearly demonstrate the advantages of the method in preserving image details. Reference metrics can provide more direct quantitative comparisons in the presence of GT, so the inclusion of metrics such as PSNR and SSIM in the paper will make the experimental results more convincing and comparable.\n\n2. The NN-based image compression models compared in this article all use autoregressive context modules, thus resulting in coding and decoding times that can be very long, and the authors need to compare them with parallel context modules (e.g. checkerboard [1]).. \n\n3. Higher complexity occurs on the receiver side using transformer reconstruction, especially for HD images. The complexity calculation in Supplementary Material Section B seems to be wrong. If the patch size is $N \\\\times N$, then the dim should be $d \\\\times N \\\\times N$, so the complexity of the model is not reduced.\n\n\n\n[1] He, Dailan, et al. \"Checkerboard context model for efficient learned image compression.\" Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2021."
      }
    ],
    "rating_avg": 3.5,
    "confidence_avg": 5.0,
    "decision": "N/A",
    "meta_review": "",
    "author_remarks": "",
    "decision_comment": ""
  },
  {
    "id": "llW4qRsF0o",
    "title": "Physics-Transfer Learning: A Framework to Address the Accuracy-Performance Dilemma in Modeling Complexity Problems in Engineering Sciences",
    "authors": [
      "Yingjie Zhao",
      "Zhiping Xu"
    ],
    "abstract": "The development of theoretical sciences traditionally adheres to an observation-assumption-model paradigm, which is effective in simple systems but challenged by the `curse of complexity’ in modern engineering sciences. Advancements in artificial intelligence (AI) and machine learning (ML) offer a data-driven alternative, capable of interpolating and extrapolating scientific inference where direct solutions are intractable. Moreover, feature engineering in ML resembles dimensional analysis in classical physics, suggesting that data-driven ML methods could potentially extract new physics behind complex data. Here we propose a physics-transfer (PT) learning framework to learn physics across digital models of varying fidelities and complexities, which addresses the accuracy-performance dilemma in understanding representative multiscale problems. The capability of our approach is showcased through screening metallic alloys by their strengths and predicting the morphological development of brains. The physics of crystal plasticity is learned from low-fidelity molecular dynamics simulation and the model is then fed by material parameters from high-fidelity, electronic structures level, density functional theory calculations, offering chemically accurate strength predictions with several orders lower computational costs. The physics of bifurcation in the evolution of brain morphologies is learned from simple sphere and ellipsoid models and then applied to predict the morphological development of human brains, showing excellent agreement with longitudinal magnetic resonance imaging (MRI) data. The learned latent variables are shown to be highly relevant to uncovered physical descriptors, explaining the effectiveness of the PT framework, which holds great potential in closing the gaps in understanding complexity problems in engineering sciences.",
    "keywords": [
      "Physics-Transfer Learning; Accuracy-Performance Dilemma; Engineering Sciences; Complexity; Materials Strength; Brain Development"
    ],
    "venue": "ICLR",
    "year": 2025,
    "pdf_url": "https://openreview.net/pdf?id=llW4qRsF0o",
    "forum_url": "https://openreview.net/forum?id=llW4qRsF0o",
    "reviews": [
      {
        "rating": "5",
        "confidence": "1",
        "summary": "This paper introduces a physics-transfer (PT) learning framework designed to bridge digital models of varying fidelities and complexities, effectively addressing the accuracy-performance trade-off in multiscale problem analysis. By leveraging PT learning, the model achieves reduced computational costs compared to traditional machine learning models, making it a more efficient solution for understanding complex, representative physical phenomena.",
        "strengths": "This model achieves lower computational costs than traditional ML models, with a method that is easy to understand.",
        "weaknesses": "1. No new models have been proposed.\n2. Why was CNN chosen over other state-of-the-art models?\n3. The comparison methods are insufficient.\n4. Appropriate statistical analysis is required."
      },
      {
        "rating": "5",
        "confidence": "3",
        "summary": "In this manuscript, the authors present a physics-transfer (PT) learning framework to merge physics-based modeling and machine learning techniques in complex engineering problems. The framework aims to resolve the accuracy-performance dilemma by learning physics across digital models of varying fidelities. The paper demonstrates the framework's capabilities through two case studies: predicting the strength of metallic alloys and modeling the morphological development of human brains. The authors claim that their approach not only enhances predictive accuracy but also provides new insights into the underlying physics of these systems.",
        "strengths": "The PT framework represents a novel integration of physics and machine learning, introducing an approach to the challenges posed by multiscale problems in engineering sciences. By considering both low-fidelity and high-fidelity models, the authors creatively combine existing ideas to form a new methodology. The motivation for the PT framework is articulated clearly, establishing a strong rationale for the research. The paper successfully outlines the accuracy-performance dilemma, making it accessible to readers familiar with the challenges in engineering modeling. Furthermore, the potential applications in materials science and neuroscience could lead to substantial advancements in these fields.",
        "weaknesses": "The manuscript lacks a comprehensive comparison with existing methods such as $\\Delta$-learning and transfer learning. A more in-depth analysis highlighting the advantages and limitations of the PT framework relative to these approaches may enhance the credibility of the manuscript. Specific metrics and results demonstrating improved performance would provide stronger evidence of the framework's contributions.\nThe manuscript contains sections that are overly technical, which may limit its accessibility to a broader audience. E.g., the explanation of the PT framework's mechanics could benefit from simpler language and additional visual aids to enhance understanding.\nThe manuscript does not adequately address the scalability of the PT framework, particularly regarding its application to larger datasets or more intricate models. A discussion about the challenges and potential solutions for scaling the approach would be valuable."
      },
      {
        "rating": "1",
        "confidence": "3",
        "summary": "The authors purport to develop a novel framework for modeling physical systems using deep learning architectures in this work. The authors claim that models that first learn the \"physics\" of a given simple system will generalize better to more complex system variants. The authors utilize metallic alloy strength and brain morphological development as two systems of study, providing simple examples of how learning lower-fidelity models can aid in modeling more complex systems.",
        "strengths": "Transfer learning from low to high fidelity systems is an interesting sub-domain within transfer learning at large. I thank the authors for highlighting this problem in their work, even if it is a domain which has already been significantly explored elsewhere.\n\nI do think the core intuition at work in this paper is interesting - the use of lower-fidelity models for developing physics is quite common in the engineering sciences and the sciences at large; however, I think this core insight is marred by a lack of detail or acknowledgement of other related works which approach these problems in similar ways.",
        "weaknesses": "I am chiefly concerned with the significance of this contribution to the literature on transfer learning and the deep learning community at large. Many approaches to transfer learning using lower-fidelity systems or simulations exist already in the literature, and it is well-understood that such approaches can provide benefits over training directly on the more complex system. It is not clear to me how the approach in this work differs from these methodologies significantly other than in applications.  See [1], [2], [3], [4] for some examples which utilize a very similar underlying approach to that in this work. I would like to challenge the authors to differentiate their work more from this existing literature and consider a resubmission. If anything, the authors should consider these other works as baseline approaches for the sake of comparison. \n\nAdditionally, this paper suffers from a lack of detail regarding the proposed framework. The most obvious omission is any rigorous definition of what the \"learning the physics\" means within this work. In previous literature, \"learning the physics\" more frequently means learning a set of differential equations which describe the system, rather than learning a black-box model with parameters which can predict system changes, but which doesn't provide any direct physical interpretation. Based on the discussion in section 2, the authors seem to be utilizing the latter kind of approach. It is not at all clear to me how learning a simple convolutional neural network provides any manner of learning of the physics of a system. The authors either need to clarify this connection, or clarify that they are doing something other than learning the physics of the system. I am willing to reconsider this point given a very compelling argument from the authors; however, I think even if an argument is provided here, a more significant revision would be needed to further clarify the details omitted in this work.\n\n[1] De, Subhayan, et al. \"On transfer learning of neural networks using bi-fidelity data for uncertainty propagation.\" International Journal for Uncertainty Quantification 10.6 (2020).\n\n[2] Chakraborty, Souvik. \"Transfer learning based multi-fidelity physics informed deep neural network.\" Journal of Computational Physics 426 (2021): 109942.\n\n[3] Liu, Zeyu, Meng Jiang, and Tengfei Luo. \"Leveraging low-fidelity data to improve machine learning of sparse high-fidelity thermal conductivity data via transfer learning.\" Materials Today Physics 28 (2022): 100868.\n\n[4] Song, Dong H., and Daniel M. Tartakovsky. \"Transfer learning on multifidelity data.\" Journal of Machine Learning for Modeling and Computing 3.1 (2022)."
      },
      {
        "rating": "1",
        "confidence": "4",
        "summary": "This paper proposes a framework called Physics Transfer Learning (PT) that aims to learn underlying physics from low-fidelity data to enable extrapolation to high-fidelity data. The authors conduct experiments on two entirely different domains: crystal and brain morphologies. While the paper claims to learn the underlying physics through the PT framework, it does not propose any specific method for achieving this beyond simply inputting data and training a model via supervised learning. Furthermore, there is a significant lack of consideration for competing methods and related work in AI, which raises substantial concerns about the contribution and novelty of the work.",
        "strengths": "1. The idea of considering ellipsoids in brain morphology analysis is intriguing. With more extensive analysis and theoretical development, this concept has the potential for significant advancement in the field.",
        "weaknesses": "1. Despite the title \"Physics Transfer,\" the proposed framework does not modify the input data format used in existing Machine Learning Force Field (MLFF) methods or models that embed brain networks. No additional optimization techniques are introduced. The framework does not adequately consider physics principles or employ transfer learning methodologies.\n\n2. The paper lacks any discussion of AI methodologies or competing methods. The absence of comparisons with existing approaches makes it difficult to evaluate the effectiveness and innovation of the proposed framework.\n\n3. There is no illustration or explanation of how the \"physics\" is learned within the model. The paper fails to demonstrate the underlying mechanisms that enable the model to capture or learn physical laws.\n\n4. The structure and composition of the proposed framework remain unclear. The paper does not present a cohesive framework that can be commonly applied across two entirely different domains, such as crystal structures and brain morphologies."
      }
    ],
    "rating_avg": 3.0,
    "confidence_avg": 2.75,
    "decision": "Reject",
    "meta_review": "The paper presents a transfer learning framework to learn the underlying physics of complex system through low fidelity simulations and transfer this knowledge to generalize to complex systems. The paper applies this framework to two interesting scientific applications and presents results that highlight its performance.\n\nStrengths: The paper tackles an important and challenging research direction in extrapolating physics from low fidelity data \nWeaknesses: Insufficient details to judge the contributions, insufficient comparisons to other transfer learning frameworks",
    "author_remarks": "",
    "decision_comment": ""
  },
  {
    "id": "DlZ97cVwr0",
    "title": "Exploring the Recall of Language Models: Case Study on Molecules",
    "authors": [
      "Philipp Guevorguian",
      "Knarik Mheryan",
      "Hasmik Mnatsakanyan",
      "Hrant Khachatrian"
    ],
    "abstract": "Most of the current benchmarks evaluate Generative Language Models based on the accuracy of the generated output. However, in some scenarios, it is also important to evaluate the recall of the generations, i.e., whether a model can generate all correct outputs, such as all security vulnerabilities of a given codebase. There are two challenges in evaluating the recall: the lack of complete sets of correct outputs for any task and the existence of many distinct but similar outputs (e.g., two exploits that target the same vulnerability).\n\nIn this paper, we propose a benchmark from the domain of small organic molecules. We define several sets of molecules of varying complexity and fine-tune language models on subsets of those sets. We attempt to generate as many molecules from the target sets as possible and measure the recall, i.e., the percentage of generated molecules from the target set. We examine the impact of the training loss function and sampling strategy on the recall. We propose a sampling strategy based on beam search that avoids duplicates and maximizes recall. Finally, we show that given a small validation set, one can predict the recall of the model without actually generating many samples, which can act as a model selection strategy for maximizing generation recall.",
    "keywords": [
      "recall",
      "language models",
      "molecular language models",
      "sampling methods for language models"
    ],
    "venue": "ICLR",
    "year": 2025,
    "pdf_url": "https://openreview.net/pdf?id=DlZ97cVwr0",
    "forum_url": "https://openreview.net/forum?id=DlZ97cVwr0",
    "reviews": [
      {
        "rating": "5",
        "confidence": "3",
        "summary": "This paper introduces a benchmark for evaluating the recall of language models in the domain of small organic molecules. Specifically, based on the famous dataset GDB-13, the authors prepare a new dataset with four subsets, e.g., a new subset contains molecules that share a certain percentage of substructures with aspirin. Based on the constructed dataset, the molecule generation capability of language models (LMs) in terms of recall before and after fine-tuning has been evaluated. A new method for predicting the recall of LMs has also been designed. The average probability of a desired molecule to be generated and the ground truth recall values are used to build a regression model for the recall prediction. The evaluation demonstrated the correlation is more than 0.99. Finally, a recall-oriented molecule generation method and a loss function have been introduced to boost the recall of LMs.",
        "strengths": "1. An interesting and important problem in analyzing the recall of language models.\n2. Multiple solutions with promising results have been proposed in the same work\n3. The paper is well-written",
        "weaknesses": "1. Even though the motivation is clear and good, the studied objective does not fit the motivation well, is the recall metric more important in the molecule generation domain?\n2. Many design choices are unclear, e.g., why use Beam search in section 3.4 not others?\n3. Many problems, e.g., capability estimation and new loss design, have been studied, but each of them lacks a comparison with baselines.\n\nOverall, this paper studies an important problem and proposes promising solutions for recall estimation and LMs enhancement. However, there are some concerns that need to be addressed.\n\nFirstly, even though the main point, evaluating whether a model can generate all correct outputs is important for safety-critical problems, it is unclear whether this is the case for the studied objective molecule generation. It is better to give clear motivation for the importance of evaluating recall for this task. \n\nFor the subset construction, in Table 1, it is unclear how the threshold is determined, e.g., 0.4 for Sasp and 0.2 ≤ sim(m, d) ≤ 0.2165. Please clarify it.\n\nIn Section 4.1, Table 2 and Table 3 suggest different solutions as the best, which one we should accept in practice. It is better to add more discussion here.\n\nIn Section 4.2, considering the recall estimation, there are many works that have been proposed to evaluate deep learning models in an unsupervised manner [1, 2, 3], it is necessary to at least discuss the difference between the proposed method and these works.\n\nIn Section 4.3, it is unclear why Beam search is used here since there are many other options (search methods). \n\nIn Section 4.4, first, it is better to add baselines without using the designed loss function in Table 5. Besides, the recall values decreased after comparing the results in Table 5 and Table 4. It is unclear which factors lead to this degradation. \n \n[1] Unsupervised Evaluation of Code LLMs with Round-Trip Correctness.\t\n[2] Estimating Model Performance Under Covariate Shift Without Labels.\n[3] Agreement-on-the-Line: Predicting the Performance of Neural Networks under Distribution Shift"
      },
      {
        "rating": "3",
        "confidence": "3",
        "summary": "This paper presents a benchmark for modelling molecules, based on GDB-13 (an exhaustive set of molecules with at most 13 heavy atoms that satisfy certain conditions). The authors pretrained LMs to generate the molecule sequences, and aim to bring up recall via 1) better sampling in generation and 2) better training data design. In addition to that, the authors proposed ways to predict the recall value with a small-scale experiment and a set of empirical studies on how should one best represent the molecules in LM inputs.",
        "strengths": "1. Maximizing recall is indeed valuable for a lot of applications, as the authors discussed in the paper, this paper is of empirical importance.\n2. The formulation of the problem is novel, the molecular generation domain provides an excellent testbed due to well-defined equivalence classes and complete reference sets.\n3. The experiments are done with rigor. I like the comprehensive analysis of factors affecting recall (pretraining, molecular representations, etc.)\n4. The dataset and benchmark would make a good contribution to the community.",
        "weaknesses": "My main concern with this paper is around its technical contributions:\n1. The author proposed using random sampling with temperature and beam search (with a large beam size) to improve recall coverage. These two methods are well-known methods in language models' (LM) generation, and I was expecting a novel generation approach such as generating with penalizing the likelihood of already generated sequences.\n2. The method that predicts recall has a lot of similarities with perplexity measure in language modelling, would the authors clarify how is the proposed metric different from the perplexity-based measures?\n3. Removing duplicates and selecting data in each batch are sensible approaches, but they don't appear to be anything novel.\n\nI have some minor questions listed in the below section."
      },
      {
        "rating": "5",
        "confidence": "2",
        "summary": "This paper introduces a benchmark for evaluating models based on recall rather than just accuracy. The authors tackle two challenges: the lack of complete correct output sets and the presence of multiple similar outputs. Using small organic molecules from the GDB-13 database, they fine-tune models and develop a method to predict recall based on perplexity. They also propose a novel beam search decoding method to maximize recall by avoiding duplicates, alongside a recall-aware loss function. This approach aims to enhance the ability of GLMs to generate all correct outputs, with potential applications in various fields, including security.",
        "strengths": "- This paper explores the evaluation of recall rates for small language models, which is a meaningful endeavor.\n- The paper investigates various methods to enhance the recall rates of models and has achieved some positive results.",
        "weaknesses": "- The contributions of this paper are limited. On one hand, in improving recall through sampling methods and loss functions, the authors merely attempt different strategies, which can sometimes harm precision, and no solutions are provided. On the other hand, the improvements through fine-tuning appear to offer no significant contribution, as it is generally expected that fine-tuning would enhance performance on a specific task.\n- The model is too singular, as the experiments in this paper only include the OPT-1.3B model. Therefore, the evaluation results and methods for enhancing recall may not generalize well."
      },
      {
        "rating": "3",
        "confidence": "3",
        "summary": "This paper introduces a new benchmark of molecules for evaluating generative language models with a focus on recall. It aims to investigate the model's ability on tasks requiring distinct output generation, like detecting all vulnerabilities in code. Using organic molecule dataset, the study shows that model recall can be anticipated via perplexity on a validation set. Moreover, the authors use beam search decoding to reduce duplicates and a recall-aware loss function to improve performance, providing insights into molecular representation and model pretraining effects.",
        "strengths": "This paper presents a meaningful investigation into the recall of model generation, with a well-articulated and compelling motivation.",
        "weaknesses": "1. From section 3.1 onward, this paper becomes quite difficult to follow, largely due to the use of specialized terminology from fields like chemistry without providing sufficient foundational overviews or introductory explanations. This approach makes it challenging for readers to fully grasp the content and nuances of the work. For instance, important details and statistics regarding the dataset collected by the authors are not included, and terms like SELFIES are mentioned without any straightforward elaboration to help readers understand what SELFIES actually represents. This lack of accessible explanations hinders the reader’s ability to form a clear understanding of the paper’s specifics. I recommend that the authors incorporate diagrams or more detailed descriptions of key terminology to enhance clarity.\n\n2.In section 4.2, a new method for estimating recall is proposed. First, the statement \"Given that evaluating recall provides a meaningful and interpretable measure of an approach’s ability to model data, estimating recall without needing to perform generations would be useful\" lacks a convincing motivation for why recall estimation without actual generation is necessary. There is no clear justification for the need to use an alternative method to evaluate recall. Furthermore, using probability to estimate recall does not align with the standard definition of recall, which traditionally measures the proportion of correctly generated instances rather than a probabilistic expectation. Thus, it is both imprecise and misleading to label this metric as recall. For instance, in earlier sections (Table 2), the authors appear to use a conventional method for calculating recall; however, after introducing this new approach, they apply it in Table 4 but use the same metric name. This inconsistency undermines reliability and creates confusion regarding the validity of the reported recall values.\n\n\n3.In section 4.3, I don’t see a substantial difference between your proposed recall-oriented generation and the standard beam search. \n\n4. Mean aggregation is equivalent to the regular loss function\" lack clarity—specifically, it is not defined what the “regular loss function” refers to. Furthermore, the section does not directly present the actual loss function or provide a detailed explanation. Instead, it relies solely on textual descriptions, which makes it difficult to understand the specifics of the proposed loss. Including the explicit mathematical form of the loss function along with a step-by-step explanation would significantly improve clarity and accessibility.\n\n5.In addition to the presentation issues mentioned above, the paper lacks a coherent structure throughout both the methods and experiments sections. The presentation feels fragmented, and critical details regarding the experimental setup, such as baseline configurations, are insufficiently described. To improve clarity, a major revision is needed to reorganize the paper, providing a more cohesive structure and a thorough explanation of the experimental settings."
      },
      {
        "rating": "6",
        "confidence": "3",
        "summary": "This paper identifies the challenges in evaluating the recall of generative models and introduces a recall benchmark in the domain of molecular generation. It also proposes sampling strategies and loss formulations to enhance recall.",
        "strengths": "This paper is well-written and easy to understand, addressing a problem that has not been extensively explored before. Additionally, the paper addresses crucial research directions, such as measuring recall without generation and methods to enhance recall, presenting intriguing experimental results.",
        "weaknesses": "**Scalability of Research**\n\nThe study in this paper is limited to a specific domain, namely molecular generation, and there needs to be a discussion on how this research can be extended to other domains. For example, a crucial aspect of measuring recall, as highlighted in the paper, is identifying the equivalence class of the model’s generated results. As mentioned in lines 60-62, there is a technique for identifying equivalence classes for SELFIES strings. How could this issue be addressed in other domains you mentioned in the introduction, such as “vulnerable code generation”?\n\n\n**Completeness in Method**\n\nIn my opinion, the sections proposing the sampling strategy and loss to improve the model’s recall are crucial for establishing the novelty of your paper. However, these aspects are not fully developed and lack sufficient explanation. For instance, in the case of the recall-oriented loss function, the approach of changing the aggregation to min or max seems quite extreme to me, with significant potential for refinement. Additionally, the proposed method only showed effectiveness for a very small and underperforming model with 800K parameters. Therefore, improvements in this area are essential. Additionally, the motivation for using beam search in recall-oriented generation and the intuition behind why increasing the beam size leads to improved recall need to be more thoroughly explained.\n\n**Evaluation**\n\nMost experiments in this paper are validated using a single model and dataset, making it difficult to consider the proposed benchmark method and the approaches to improve recall as thoroughly validated. I believe there should be verification to ensure that the trends in the experimental results hold consistently across at least several models.\nAdditionally, there are confusing aspects regarding the details of the experiments, which should be described and justified more comprehensively (see the questions section for more details)."
      }
    ],
    "rating_avg": 4.4,
    "confidence_avg": 2.8,
    "decision": "Reject",
    "meta_review": "The paper explores the problem of evaluating language models with a focus on recall as opposed to accuracy and introduces a new benchmark for molecules. The methodology primarily involves random sampling with temperature and beam search using large beam width for decoding using a recall-aware loss function. Using a dataset of organic molecules, the paper shows that recall can be predicted using perplexity on a validation set.\n\nThe reviewer assessments were mixed on this paper. All reviewers appreciated the research question, formulation, and benchmarking. The negative reviewers' complained about the lack of technical novelty and/or more comprehensive experiments. The authors' response to some of the other questions were mostly satisfactory even though couple of reviewers didn't respond to rebuttal.\n\nIn my own reading and assessment of the paper, it certainty has some strengths but needs improvement for acceptance. The paper can potentially take two routes to strengthen it.\n- Increase the technical novelty and add additional experiments on more molecule datasets (if the focus is on molecules as a case study).\n- Increase the experiments by adding more use-cases (as alluded in the paper) beyond molecules to drive home the general message for benchmarking and importance of this research.\n\nTherefore, I'm recommending to reject this paper and strongly encourage the authors' to improve the paper based on the feedback from reviewers' for resubmission.",
    "author_remarks": "",
    "decision_comment": ""
  },
  {
    "id": "0vtftmYQGV",
    "title": "SNAP-TTA: Sparse Test-Time Adaptation for Latency-Sensitive Applications",
    "authors": [
      "Hyeongheon Cha",
      "Dong Min Kim",
      "Taesik Gong",
      "Hye Won Chung",
      "Sung-Ju Lee"
    ],
    "abstract": "Test-Time Adaptation (TTA) methods use unlabeled test data to dynamically adjust models in response to distribution changes. However, existing TTA methods are not tailored for practical use on edge devices with limited computational capacity, resulting in a latency-accuracy trade-off. To address this problem, we propose SNAP-TTA, a sparse TTA framework that significantly reduces adaptation frequency and data usage, delivering latency reductions proportional to adaptation rate. It achieves competitive accuracy even with an adaptation rate as low as 0.01, demonstrating its ability to adapt infrequently while utilizing only a small portion of the data relative to full adaptation. Our approach involves (i) Class and Domain Representative Memory (CnDRM), which identifies key samples that are both class-representative and domain-representative to facilitate adaptation with minimal data, and (ii) Inference-only Batch-aware Memory Normalization (IoBMN), which leverages representative samples to adjust normalization layers on-the-fly during inference, aligning the model effectively to changing domains. When combined with five state-of-the-art TTA algorithms, SNAP-TTA maintains the performances of these methods even with much-reduced adaptation rates from 0.01 to 0.5, making it suitable for edge devices serving latency-sensitive applications.",
    "keywords": [
      "Test-Time Adaptation",
      "Unsupervised Domain Adaptation"
    ],
    "venue": "ICLR",
    "year": 2025,
    "pdf_url": "https://openreview.net/pdf?id=0vtftmYQGV",
    "forum_url": "https://openreview.net/forum?id=0vtftmYQGV",
    "reviews": [
      {
        "rating": "6",
        "confidence": "2",
        "summary": "This paper introduces SNAP-TTA, a sparse Test-Time Adaptation (STTA) framework designed for latency-sensitive applications on resource-constrained edge devices. Traditional TTA methods dynamically adjust models using unlabeled test data to handle distribution shifts, but they often incur high computational costs and latency, making them impractical for real-time edge environments. SNAP-TTA addresses these challenges by introducing two key components: (i) Class and Domain Representative Memory (CnDRM), which selects class-representative and domain-representative samples to enable effective adaptation with minimal data, and (ii) Inference-only Batch-aware Memory Normalization (IoBMN), which corrects feature distribution shifts during inference without additional training. By combining SNAP-TTA with five state-of-the-art TTA algorithms, the paper demonstrates that SNAP-TTA achieves significant latency reductions (up to 87.5%) while maintaining competitive accuracy. Experimental results on benchmarks like CIFAR10-C and ImageNet-C show SNAP-TTA’s superior performance in edge settings, making it suitable for real-world, latency-sensitive applications.",
        "strengths": "1. This paper addresses the challenge of achieving high adaptation accuracy while maintaining computational efficiency in Sparse Test-Time Adaptation (STTA), where updates rely on only a small subset of data.\n2. SNAP-TTA demonstrates improved classification accuracy across adaptation rates (0.01 to 0.5) compared to baseline TTA methods on CIFAR10-C, CIFAR100-C, and ImageNet-C. At an adaptation rate of 0.1, SNAP-TTA reduces latency by up to 87.5% while mitigating accuracy loss, validating its effectiveness in STTA\n3. IoBMN combines memory statistics from domain-representative samples with current inference batch statistics, using a soft shrinkage function to balance them. This dynamic normalization adjustment during inference effectively addresses domain shift, ensuring model adaptability and performance stability.",
        "weaknesses": "1. The reliance on a fixed confidence threshold of CnDRM may limit adaptability across varying data distributions and could lead to suboptimal sampling.\n2. In table 5, accuracy differences between methods are small, without statistical analysis, making it unclear if these differences are significant (In Detailed comments 4)"
      },
      {
        "rating": "6",
        "confidence": "5",
        "summary": "This paper addresses the problem of test-time adaptation for out-of-distribution generalization. To reduce the adaptation rate and improve the overall latency of TTA, the authors propose a SNAP framework that selects partial samples for adaptation. Experimental results highlight the potential of the proposed method. However, I still have several concerns as outlined below.",
        "strengths": "The design of the SNAP method is well-motivated and reasonable from the technical perspective. \n\nThe proposed approach is a plug-and-play module that can be integrated with existing TTA methods to reduce adaptation steps and enhance efficiency. \n\nExperimental results underscore the effectiveness of the proposed method.",
        "weaknesses": "On edge devices, the most critical factor in determining whether a TTA method is feasible is actually peak memory usage, as highlighted by MECTA [A]. While this work does reduce the number of adaptation steps, it does not decrease peak memory usage. In this sense, the primary motivation for applying the proposed method to edge devices may be misplaced.\n\n[A] MECTA: Memory-Economic Continual Test-time Adaptation"
      },
      {
        "rating": "5",
        "confidence": "5",
        "summary": "This paper focuses on Test-Time Adaptation (TTA) for edge devices with limited computational capacity. The authors propose SNAP-TTA, a sparse TTA framework with two key components, Class and Domain Representative Memory (CnDRM) and Inference-only Batch-aware Memory Normalization (IoBMN), aiming to reduce model adaptation frequency and data usage while maintaining accuracy.",
        "strengths": "The proposed SNAP-TTA framework addresses the latency-accuracy trade-off issue in existing TTA methods for edge devices in some cases. It reduces latency while achieving competitive accuracy, as demonstrated by extensive experiments on multiple benchmarks and with integration of several existing TTA algorithms.",
        "weaknesses": "- In the background section, the mention of applications like real-time health monitoring for IoT edge devices may not be entirely appropriate as these devices often have extremely limited memory.\nWith limited memory, these devices are difficult and even impossible for backward-propagation and gradient decent. In this sense, memory should perhaps be prioritized over latency as the primary concern.\n- It is unclear whether the proposed method reduces the delay per batch or the average delay (adaptation occurs once every several batches as shown in Figure 1). If it is the latter, its effectiveness for latency-sensitive applications may be limited as the inference delay could increase significantly every several batches.\n- The method reduces the cost of backpropagation by filtering samples to decrease the inference latency. However, EATA also uses a similar strategy, but in Figure 2, the delay of EATA is the same as that of Tent, and the delay of SAR is inconsistent with the results reported in its original paper.\n- The paper could compare the inference latency in Tables 1, 2, and 3.\n- In Table 6 for ImageNet-C, only the Tent method is compared, ignoring other methods, which could provide more comprehensive and convincing results.\n- In the experiments, it is not clear how the number of participating samples is controlled to meet the adaptation rate. Is it through adjusting the $tau_conf$ hyperparameter? Also, it is not described how other compared methods meet the adaptation rate.\n- The description of lines 10-15 of the algorithm in the paper is relatively brief, considering its importance for the proposed method. More detailed explanation in the paper would assist readers in understanding."
      },
      {
        "rating": "6",
        "confidence": "3",
        "summary": "The authors propose a sparse test-time adaptation (TTA) framework, which they call SNAP, that improves the latency-accuracy trade-off of existing TTA algorithms to enable practical use of TTA on ede devices.\nTo this end, the authors propose \"CnDRM\", a method for identifying \"important\" samples for training based on class- and domain-representative sampling, and \"IoBMN\", a method for mitigating the effects of domain shifts on the model's internal feature distributions.",
        "strengths": "- The method is promising in that, at least on a Raspberry Pi 4 and when used together with STTA, SNAP provides a significant reduction in latency, as shown in Table 4, while being able to maintain accuracy comparable to using STTA alone.\n- The authors show empirically that SNAP works well with a number of different TTA algorithms (TENT, CoTTA, EATA, SAR, RoTTA) and with different adaptation rates for different datasets (CIFAR10-C, CIFAR100-C, ImageNet-C).",
        "weaknesses": "- The claimed contribution of the paper is that SNAP can make existing TTA algorithms more latency efficient and suitable for edge devices. However, this is only demonstrated in Table 4 for one algorithm (STTA) and one target device (Raspberry Pi 4). All other experiments focus only on accuracy. And while it is an important and valuable contribution to properly demonstrate that SNAP does not reduce the effectiveness of the TTA algorithms it is applied to, I think the evaluation overall fails to adequately demonstrate the claimed contribution of latency reduction across various edge devices."
      }
    ],
    "rating_avg": 5.75,
    "confidence_avg": 3.75,
    "decision": "Reject",
    "meta_review": "This paper proposes a sparse test-time adaptation (TTA) framework called SNAP-TTA, which aims to address the latency-accuracy trade-off in existing TTA methods when applied to edge devices. The main benefit of SNAP-TTA is reducing latency. The motivation of the paper is reasonable, and it can be seamlessly integrated into existing TTA methods. However, the main issues lie in some experimental setups and the overall contribution. Some reviewers raised concerns about memory usage during experiments and compatibility across different hardware scenarios, and the authors' experimental additions and analyses did not fully address these concerns. The AC reviewed the paper and all discussions and believes that the study still needs improvement.",
    "author_remarks": "",
    "decision_comment": ""
  },
  {
    "id": "DnBjhWLVU1",
    "title": "Recovering Plasticity of Neural Networks via Soft Weight Rescaling",
    "authors": [
      "Seungwon Oh",
      "Sangyeon Park",
      "Isaac Han",
      "Kyung-Joong Kim"
    ],
    "abstract": "Recent studies have shown that as training progresses, neural networks gradually lose their capacity to learn new information, a phenomenon known as plasticity loss. An unbounded weight growth is one of the main causes of plasticity loss. Furthermore, it harms generalization capability and disrupts optimization dynamics. Re-initializing the network can be a solution, but it results in the loss of learned information, leading to performance drops. In this paper, we propose Soft Weight Rescaling (SWR), a novel approach that prevents unbounded weight growth without losing information. SWR recovers the plasticity of the network by simply scaling down the weight at each step of the learning process. We theoretically prove that SWR bounds weight magnitude and balances weight magnitude between layers. Our experiment shows that SWR improves performance on warm-start learning, continual learning, and single-task learning setups on standard image classification benchmarks.",
    "keywords": [
      "loss of plasticity",
      "plasticity",
      "continual learning",
      "online learning"
    ],
    "venue": "ICLR",
    "year": 2025,
    "pdf_url": "https://openreview.net/pdf?id=DnBjhWLVU1",
    "forum_url": "https://openreview.net/forum?id=DnBjhWLVU1",
    "reviews": [
      {
        "rating": "5",
        "confidence": "3",
        "summary": "The paper addresses the issue of plasticity loss in neural networks, where the capacity to learn new information diminishes over time due to unbounded weight growth. The authors propose a method called Soft Weight Rescaling (SWR), which mitigates this issue by scaling down the weights at each learning step, and claiming to maintain the network's plasticity without losing previously learned information. Some experimental results, such as continual leaning and single-task in image classification, demonstrate that SWR can enhance performance, outperforming existing weight regularization and re-initialization techniques.",
        "strengths": "1. The paper is easy to follow.\n2. I think the authors are focusing on an interesting topic, i.e. loss of plasticity, that is worthy to probe.\n3. The method proposed is simple and can be easily implemented in practice.",
        "weaknesses": "1. An unbounded weight growth is one of the main causes of plasticity loss, and the authors propose reducing weight magnitude through weight scaling. Reducing the weight magnitude could be a common implementation in training, where L2 is widely used. So I think the key here lies in comparing the proposed method to L2. However, after reviewing the text, I did not find a clear rationale why we should choose the proposed method over L2. Could the authors provide specific cases that demonstrate the essence regarding how the proposed method targets improvements over L2 regularization?\n\n2. I notice that the authors define the rate of how much the model has changed from the initial state as the ratio between the Frobenius norm of the current weight matrix and that of the initial one. Could the author give more explanations regarding this metric? In my opinion, this metric may not well capture the extent of change in the model. For instance, applying weight regularization could significantly alter the weights, yet the model's performance may change only marginally. \n\n3. I have not found any theoretical insights regarding the claims made about magnitude boundedness and weight balance in the main text. However, I did locate some proofs in the appendix. Since these proofs appear to be one of the main contributions of the proposed work, I recommend that the authors reorganize the paper to better highlight this important content.\n\n4. I think the authors should improve the experiments presented in the paper. Firstly, the current training performance falls significantly below existing baselines, with VGG achieving only 0.72 on CIFAR-10 and below 0.4 on CIFAR-100, which is unacceptable. Secondly, the authors should broaden their experimental scope beyond VGG on CIFAR, MNIST, and TinyImage. It would be beneficial to include experiments relevant to current RL or NLP scenarios, especially where pre-trained models are commonly utilized. For now, I could barely sense the superiority of the proposed method.\n\n5. It would be helpful if the authors could release the code."
      },
      {
        "rating": "5",
        "confidence": "3",
        "summary": "The authors introduce Soft Weight Rescaling (SWR), a novel weight regularization method that prevents unbounded weight growth to preserve information and maintain network plasticity. The theoretical analysis shows that SWR bounds weight magnitudes and balances them across layers without degrading model performance. Empirical evaluations, particularly with VGG-16, show that SWR improves generalization performance compared to other regularization methods.",
        "strengths": "- The paper is overall clearly written and the method is adequately described.\n- The proposed method SWR is computationally more efficient than previously proposed methods.\n- The experiment results and analysis provided in the paper are insightful.",
        "weaknesses": "- The experimental results on smaller models are quite weak. For example, in warm-start and continual learning experiments, L2 (or S&P) seems to be better in most experiments (including the ones in the appendix). Even in Table 1, except for VGG, I wouldn't say the improvements are significantly higher since there's quite a bit of overlap with L2 in terms of standard deviations in MLP, and CNN cases. SWR only performs well on VGG which is not a very popular architecture even for vision-based experiments in this domain compared to ResNet. It would be interesting to see the comparison between SWR and baselines on bigger models. The assumptions of affine, conv layers in Theorem 1 are also strong and limit the applicability of SWR.\n- I think the main novelty of the idea is limited and comes primarily from \"scaling the bias vectors according to a certain rule\". From Eq on line 220, one may assume that $W_l$ will attain a higher magnitude than $W_{init}$. As a result, $c_l \\approx 1 - \\lambda$, which implies that SWR would behave like a layer-wise version of S&P with weight_scale = $1 - \\lambda$ and no initial weights. \n- Missing baselines: Lyle et al. 2024 recently also showed that the L2 + Layer norm generally outperforms the majority of the existing methods. Lee et al. 2024 have also shown that their method results in superior generalization performance on these benchmarks. \n\n\n\nSome grammatical/clarity related issues:\n- Line 161: investigated the following theorem shows that\n- Line 213: the change rate"
      },
      {
        "rating": "3",
        "confidence": "4",
        "summary": "The paper focuses on the solution to recovering the plasticity of DNNs via weight regularization. The paper proposes a simple yet effective weight regularization method that prevents unbounded weight growth. The authors also provided the technique's theoretical and empirical insights, which prove the generalization performance in different learning.",
        "strengths": "- This work progressively establishes and justifies its framework, making this paper easy to follow.\n- The results are promising, however, I have some concerns regarding the results as discussed below",
        "weaknesses": "- One main drawback of the paper is the limited application of the paper. The authors made many assumptions (e.g., the network is affine, homogeneous with ReLU), which impedes the contributions and the applicability of the paper in real-world scenarios.\n- Some crucial statements are made without proper references. Furthermore, these statements are conflicted with the statements in various peer-reviewed and significant publications.\n- The paper came up with many theorems and definitions without explaining the usages and necessities of these statements.\n- Ablation tests according to Theorem 1 needed to be conducted to verify the paper's significance.\n- All in all, the aforementioned issue impedes the contribution and significance of the paper method. The authors please consider carefully about these issues. If the issues are addressed, the score can be modified.\n- The experimental evaluations are not sufficient, they need to provide more experiments on large-scale datasets (ImageNet1K, COCO, etc) and across different model architectures (VisionTransformers, etc).\n- The hyper-parameter $\\lambda$ is proposed but there are no experiments that consider the effect of $\\lambda$ on the boundedness of the weight before and after scaling.\n- There should be a theoretical discussion about how to tighten the boundedness compared to other methods. For example, in Theorem 2, the authors show that $\\|W_t\\| \\neq B$, which is trivial thus not proving that the proposed method is better than others."
      },
      {
        "rating": "3",
        "confidence": "4",
        "summary": "This paper introduces Soft Weight Regularization (SWR), a regularization based algorithm for maintaining plasticity under the broad framework of continual learning. Unlike other regularization based approaches for addressing plasticity loss, such as L2 regularization, Shrink and Perturb, and L2 Init, SWR does not alter the network's predictions. The paper provides a theoretical analysis showing that SWR bounds weight magnitudes and maintains balanced weights between layers, two favourable properties of neural networks. Finally, the paper provides empirical evidence arguing the efficacy of SWR on a set of problems that test for plasticity and stability in settings of warm-starting, continual learning, and generalization.",
        "strengths": "- The paper rightfully makes the point that unbounded weight magnitudes in continual learning settings is a more general issue in deep learning. This is a point that is not often made explicit in the continual learning literature. \n- The proposed method of SWR is supported by theoretical analysis establishing that weight magnitudes are bounded and that weights between layers are relatively balanced, two properties that have been previously shown to be beneficial for generalization and continual learning settings. Many recent methods in the continual learning framework, despite their simplicity, have been introduced with little to no theoretical basis, therefore, this is  a strength of this paper.\n- The proposed method is evaluated on three types of problems: warm-starting, continual learning, and classic supervised learning evaluating generalization. SWR's performance is evaluated with respect to the generalization gap, plasticity in continual learning, and catastrophic forgetting in continual learning. This provides a broader evaluation than is typical in continual learning.",
        "weaknesses": "- This paper could use more polish and could be reorganized to better state the contributions as well as their relative merits to existing work. Some concrete examples are as follows: \n- The paragraph on line 039 is too specific for the introduction and the paper would be better served with a concise overview of the merits and draw backs of regularization based re-initialization based methods, and moving the existing paragraph as is to a related works section. \n- The paragraph on line 066 is redundant given the preceding paragraph.\n- It would be useful to give, at least a high level or rough, description of SWR in the introduction so that the reader has an understanding of how SWR differs from existing regularization based methods. As the paper is currently written, SWR is described by its merits: bounded weight magnitudes and balancing weights, and no actual description of the algorithm itself is provided, until the full algorithm is presented on page 5. \n- It would be useful to introduce and define both catastrophic forgetting and plasticity in the introduction, rather than just the latter phenomenon, as the paper claims to evaluate SWR's ability to mitigate catastrophic forgetting.\n- The motivating and illustrating experiment, Figure 1 and the paragraph that follows on line 197 are confusing and I cannot make out the experimental setup and the exact point that is being made. I would suggest explicitly describing the experimental setup and each algorithm that you are evaluating. How exactly are you scaling, and what is scaling with and without proportionality in this example? Does the pre-trained model include any scaling? What is the difference between fine-tuned after scaling and just the scaled model? When you train the fine-tuned model for another 50 epochs, are you fine tuning on the validation set or some new training set? What exactly is the scaling magnitude or scaling ratio in this experiment? Given that this is a motivating or illustrating example, it would be useful to very precise with outlining the experimental setup.\n- I would recommend moving your theorems on boundedness and balancedness to section 3 and commenting on the significance of these theorems rather than pointing the reader to the appendix.\n- The set of competitor algorithms is limited. Specifically, for re-initialization based methods the well-cited Continual Backprop (Dohare et al.) and ReDO (Sokar et al.) are missing from the experiments that evaluate plasticity loss. As for the experiment that evaluates catastrophic forgetting, regularization based methods for explicitly addressing this phenomenon such as Elastic Weight Consolidation (Kirkpatrick et al.) are absent.\n- To evaluate the efficacy of SWR for mitigating plasticity loss and catastrophic forgetting, a wider experimental study may be necessary. You could consider the benchmark problems of Permuted MNIST, Random Label MNIST and CIFAR, and Continual ImageNet, which are nicely described in (Kumar et al).\n- The claim that SWR mitigates catastrophic forgetting requires more evidence than a single experiment, as noted in the previous point. SWR does not modify the network's outputs unlike other regularization based methods, but this does not prove that SWR mitigates plasticity loss. There is a series of regularization based methods, e.g. Elastic Weight Consolidation, that regularize networks towards weights (or equivalently representations) learned during earlier tasks, and in turn mitigating catastrophic forgetting. Therefore, the limited experiments and construction of SWR do not provide sufficient evidence that catastrophic forgetting is alleviated by SWR more efficiently than by other algorithms, therefore the claims that SWR maintains useful information while re-initialization based methods do not, is not entirely accurate."
      }
    ],
    "rating_avg": 4.0,
    "confidence_avg": 3.5,
    "decision": "Reject",
    "meta_review": "The paper addresses the issue of plasticity loss, also known as intransigence, in neural networks. The authors identify unbounded weight growth as a key contributor to this issue and introduce a novel regularization technique called Soft Weight Rescaling (SWR) to overcome it. SWR aims to limit weight magnitudes and ensure balance across different layers without compromising model performance. The authors offer a theoretical analysis to confirm that SWR effectively maintains bounded and balanced weights, which are desirable properties in neural networks. The empirical results validate the effectiveness of SWR in various scenarios, including warm-starting, continual learning, and generalization, demonstrating its ability to preserve both plasticity and stability.\n\n**Strengths:** All reviewers agreed that the paper addresses an interesting and timely problem. They praised the clear and methodical writing style and the method's simplicity. Moreover, the reviewers found the experimental results and analysis presented in the paper to support the claims and provide insightful observations effectively.\n\n**Weaknesses:** The paper was primarily criticized for its limited experimental setup, which restricts its broader impact. Notably, the datasets employed, such as CIFAR10, CIFAR100, MNIST, and TinyImageNet, are small-scale. Furthermore, the use of a VGG model in the experiments resulted in performance metrics—72% on CIFAR10 and 40% on CIFAR100—that are significantly lower than current state-of-the-art results on these datasets. This discrepancy places the paper at a substantial disadvantage when compared to more recent literature. Additionally, the reviewers highlighted the absence of comparisons with related regularization methods, such as L2 regularization (weight decay) or more contemporary approaches that combine L2 and Layer Normalization (Lyle et al., 2024). Lastly, the paper lacks comprehensive ablation studies and a detailed sensitivity analysis of hyperparameters.\n\nAlthough the reviewers appreciated certain aspects of the paper, they unanimously agreed that the experimental setup was rudimentary and insufficient. Consequently, they concluded that the paper, in its current form, is not ready for publication. I enjoyed reading the paper and believe that the authors could significantly enhance their work based on the constructive feedback provided by the reviewers. Considering these factors, I recommend rejecting this paper. However, I recognize its potential and encourage the authors to continue refining their work.",
    "author_remarks": "",
    "decision_comment": ""
  },
  {
    "id": "TIxiwxd4iD",
    "title": "BanglaGITI: A Novel Dataset for Bangla Music Genre Classification with A Comprehensive Analysis",
    "authors": [
      "Syeda Farhana Ali",
      "Mohammad Tanveer Shams",
      "Kazi A. Kalpoma",
      "Tasnim Munawar Rafee",
      "Jecin Saba"
    ],
    "abstract": "This paper presents a comprehensive exploration into the classification of Bengali music genres, utilizing a novel dataset, `BanglaGITI: Bangla Genre-wise Indexed Tracks and Interpretations', specifically curated to capture the rich diversity of Bengali musical heritage. Our study is structured around a comparative analysis of traditional Machine Learning (ML) techniques, advanced Deep Learning (DL) methodologies, and innovative ensemble approaches that integrate the strengths of both ML and DL through Transfer Learning. Our dataset includes a total of 1410 audio files across 6 different genres. For the ML segment, features such as Mel-frequency cepstral coefficients (MFCCs), zero-crossing rate (ZCR), root mean square(RMS), chroma, tempo and spectral bandwidth were leveraged to encapsulate the unique characteristics of Bengali music. These features serve as a foundation for employing classic ML classifiers that demonstrate robust performance in genre classification tasks. Our methodology includes Decision Tree, Random Forest, Gradient Boost and KNN. Conversely, our DL models are designed around the extraction and analysis of Log-Mel spectrograms, capitalizing on their ability to represent complex musical structures in a manner that is both comprehensive and conducive to DL techniques. This approach allows for the deep neural networks to learn from a richer representation of audio data, potentially uncovering nuanced patterns inherent in Bengali music genres. DL techniques feature pre-trained CNN-based models such as DenseNet, ResNet and  VGGNet. Furthermore, our paper innovates by proposing ensemble models that combine the predictive capabilities of ML and DL methods respectively, aiming to harness their complementary strengths for enhanced classification accuracy. The ensemble models resulted in achieving almost 80% accuracy in ML and state of the art 96% accuracy in DL methods while the precision recall and F1-score of 96.09%, 96.05% and 96.04% respectively. Our findings not only shed light on the efficacy of different computational approaches in the realm of music genre classification but also contribute to the understanding of Bengali music through the lens of machine intelligence. The use of our self-made dataset, which is among the first of its kind for Bengali music, adds a significant value to the study, offering a new benchmark for future research in this area. Through this comprehensive study, our aim is to provide insights that will guide the development of more sophisticated and culturally nuanced music classification systems.",
    "keywords": [
      "BanglaGITI",
      "Music Genre Classification",
      "CNN",
      "ML",
      "Transfer Learning",
      "Spectrogram",
      "MFCC",
      "Ensemble"
    ],
    "venue": "ICLR",
    "year": 2025,
    "pdf_url": "https://openreview.net/pdf?id=TIxiwxd4iD",
    "forum_url": "https://openreview.net/forum?id=TIxiwxd4iD",
    "reviews": [],
    "rating_avg": null,
    "confidence_avg": null,
    "decision": "N/A",
    "meta_review": "",
    "author_remarks": "",
    "decision_comment": ""
  },
  {
    "id": "9DrPvYCETp",
    "title": "Shared Memory for Multi-agent Lifelong Pathfinding",
    "authors": [
      "Alsu Sagirova",
      "Yuri Kuratov",
      "Mikhail Burtsev"
    ],
    "abstract": "Multi-agent reinforcement learning (MARL) demonstrates significant progress in solving cooperative and competitive multi-agent problems in various environments. One of the main challenges in MARL is the need to explicitly predict other agents' behavior to achieve cooperation. As a solution to this problem, we propose the Shared Recurrent Memory Transformer (SRMT), which extends memory transformers to multi-agent settings by pooling and globally broadcasting individual working memories, enabling agents to implicitly exchange information and coordinate actions. We evaluate SRMT on the Partially Observable Multi-Agent Path Finding problem, both in a toy bottleneck navigation task requiring agents to pass through a narrow corridor and on a set of mazes from the POGEMA benchmark. In the bottleneck task, SRMT consistently outperforms a range of reinforcement learning baselines, especially under sparse rewards, and generalizes effectively to longer corridors than those seen during training. On POGEMA maps,  including Mazes, Random, and Warehouses, SRMT is competitive with a variety of recent MARL, hybrid, and planning-based algorithms. These results suggest that incorporating shared memory into transformer-based architectures can enhance coordination in decentralized multi-agent systems.",
    "keywords": [
      "shared memory",
      "transformers",
      "multi-agent pathfinding"
    ],
    "venue": "ICLR",
    "year": 2025,
    "pdf_url": "https://openreview.net/pdf?id=9DrPvYCETp",
    "forum_url": "https://openreview.net/forum?id=9DrPvYCETp",
    "reviews": [
      {
        "rating": "3",
        "confidence": "3",
        "summary": "This work considers the application of a shared memory mechanism to the MAPF setting.",
        "strengths": "- The writing is generally clear and polished. \n- The approach is well-grounded in prior literature, and the algorithmic details are well-explained.  \n- Figure 1 is a useful complement to the written algorithmic details, and makes it easy to understand the method at a glance. \n- Figure 10 analysis is nice.",
        "weaknesses": "* It is hard to get a relative sense of the competitiveness of this approach. The baselines did not feel particularly well-motivated, and MARL communication works, which I'd argue share a similar goal, were not used as baselines (e.g. \\[1\\])\n* More generally, I am left not knowing exactly what I should take away from the results—Figure 5 seems to show that SRMT and variants achieve modest results compared to baselines (and the baselines used are not motivated or described in sufficient detail).\n* \\[2\\] I consider this a necessary work to acknowledge, given it is one of the first works discussing the use of attention in MARL\n* Nitpicks: \n\t* I cannot interpret the error bars in Figure 4—it is too muddled.\n\t* Despite the writing overall being clear, the language could be tightened somewhat; e.g. L043: \"has to reach its goal\" is quite colloquial; also contraction in L497. I recommend combing through the paper and essentially asking each word/phrase to justify itself—and to be as specific as possible, avoiding colloquialisms. \n\n\\[1\\] Jakob Foerster, Ioannis Alexandros Assael, Nando de Freitas, and Shimon Whiteson. Learning to communicate with deep multi-agent reinforcement learning. In D. Lee, M. Sugiyama, U. Luxburg, I. Guyon, and R. Garnett (eds.), *Advances in Neural Information Processing Systems, volume 29*. Curran Associates, Inc., 2016. URL https://proceedings.neurips.cc/paper_ files/paper/2016/file/c7635bfd99248a2cdef8249ef7bfbef4-Paper.pdf.\n\n\\[2\\] Iqbal, S. &amp; Sha, F.. (2019). Actor-Attention-Critic for Multi-Agent Reinforcement Learning. <i>Proceedings of the 36th International Conference on Machine Learning</i>, in <i>Proceedings of Machine Learning Research</i> 97:2961-2970 Available from https://proceedings.mlr.press/v97/iqbal19a.html."
      },
      {
        "rating": "8",
        "confidence": "4",
        "summary": "This paper introduces the Shared Recurrent Memory Transformer (SRMT), a novel model in multi-agent reinforcement learning designed for multi-agent lifelong pathfinding tasks. SRMT extends memory transformers to decentralized multi-agent environments by pooling individual agent memories into a shared memory space, allowing agents to indirectly share information and coordinate. The model is tested in various pathfinding tasks, including bottleneck navigation and complex environments from the POGEMA benchmark. SRMT demonstrates superior performance in coordination and generalization, particularly in high-density and partially observable environments.",
        "strengths": "1. The SRMT model is an adaptation of memory transformers to multi-agent settings, facilitating indirect communication among agents through a shared memory. This approach addresses a significant challenge in decentralized coordination by leveraging shared recurrent memory, which is unique compared to conventional communication strategies.\n2. The paper provides a rigorous evaluation of SRMT on multiple benchmark tasks, including POGEMA and bottleneck navigation. The use of diverse reward settings (e.g., sparse, directional) further strengthens the experimental framework, revealing SRMT’s adaptability in various coordination scenarios.\n3. The architecture and methods are clearly explained, supported by diagrams and flowcharts that help clarify SRMT’s working mechanism. The comparisons with baselines and the explanation of the multi-agent Markov decision process formulation are presented in a straightforward and understandable manner.\n4. SRMT’s ability to handle decentralized pathfinding without explicit communication protocols has considerable implications for real-world applications, particularly in settings where communication might be unreliable or costly. Its effectiveness across different maps and scenarios demonstrates potential for scalability in complex, large-scale environments.",
        "weaknesses": "1. While SRMT performs well on small to medium-sized environments, its scalability to very large maps or highly dense environments remains uncertain. The evaluation could be extended to more challenging settings, particularly with greater agent populations or larger obstacles, to fully assess SRMT’s scalability.\n2. While SRMT is designed for decentralized systems, it would be beneficial to see comparisons with centralized approaches on key metrics to understand the trade-offs better, particularly in environments that demand high coordination.\n3. While the paper claims that shared memory improves coordination, additional analysis on how shared memory influences individual agent behavior would provide a deeper understanding. An ablation study removing the shared memory aspect could further validate its impact on SRMT’s performance.\n4. The model's performance varied across different reward structures, and while this is discussed, a more detailed exploration of how reward shaping influences learning would strengthen the analysis. This would help in tailoring SRMT to tasks where only sparse rewards are available.\n\nMissing references (MARL with local information). I believe these are quite recent papers and work in a similar setting as mentioned in the related works section.\n\n[1]: Hu, Y., Fu, J., & Wen, G. (2023). Graph soft actor–critic reinforcement learning for large-scale distributed multirobot coordination. *IEEE transactions on neural networks and learning systems*.\n\n[2]: Nayak, S., Choi, K., Ding, W., Dolan, S., Gopalakrishnan, K., & Balakrishnan, H. (2023, July). Scalable multi-agent reinforcement learning through intelligent information aggregation. In *International Conference on Machine Learning* (pp. 25817-25833). PMLR."
      },
      {
        "rating": "5",
        "confidence": "3",
        "summary": "The paper proposes a global shared recurrent memory transformer (SRMT) mechanism for multiagent reinforcement learning to address the multiagent pathing finding problem. Specifically, SRMT uses self-attention to aggregate agent memory and observation history while utilizing cross-attention to aggregate the shared memory from other agents to help coordination. Results on a toy bottleneck navigation task and a set of maze environments from the POGEMA benchmark show that SRMT outperforms various baselines.",
        "strengths": "1.\tThe motivation for using a global shared memory to help coordination and the idea of using the transformer to implement it are clear.\n2.\tThe background is clearly explained and the related works are well discussed.",
        "weaknesses": "1.\tIt seems that a lot baselines are missing. For example, in the Bottleneck Task, only some basic memory mechanisms from single-agent RL are compared while more advanced memory mechanisms such as relational memory [1] and AMRL [2] from the single-agent RL domain are not compared.\n2.\tAt the same time, although some works about MARL memory such as RATE and ATM are discussed in Section 2.2, they are not compared in the experiments.\n3.\tThe ablation study to validate each component of the proposed SRMT is not given.\n4.\tThere are some typos. In Line 36, “MAPF” is not defined.\n\nReferences\n\n[1] Adam Santoro, Ryan Faulkner, David Raposo, Jack Rae, Mike Chrzanowski, Théophane Weber, Daan Wierstra, Oriol Vinyals, Razvan Pascanu, and Timothy Lillicrap. Relational Recurrent Neural Networks. In Proceedings of the 32nd International Conference on Neural Information Processing Systems, 2018.\n\n[2] Jacob Beck, Kamil Ciosek, Sam Devlin, Sebastian Tschiatschek, Cheng Zhang, and Katja Hofmann. Amrl: Aggregated memory for reinforcement learning. In International Conference on Learning Representations, 2020."
      }
    ],
    "rating_avg": 5.333333333333333,
    "confidence_avg": 3.3333333333333335,
    "decision": "Reject",
    "meta_review": "The paper proposes the Shared Recurrent Memory Transformer (SRMT) for improved coordination in decentralized multi-agent pathfinding (MAPF). The core claim is that by pooling and globally broadcasting individual working memories, agents can implicitly exchange information and coordinate actions more effectively without explicit communication protocols. SRMT is evaluated on a bottleneck task and the POGEMA benchmark, where it outperforms various baselines, particularly in sparse reward settings and generalizes well.\n\nThe main strengths of the paper are clarity of the presentation, and a comprehensive evaluation including the ablations and memory analysis. The main remaining weaknesses are about novelty, polish and scalability.\n\nOverall, the paper presents a novel approach with promising results. The authors have successfully addressed many of the initial concerns. The revised manuscript has improved the paper, but the original concerns may not be completely addressed.",
    "author_remarks": "",
    "decision_comment": ""
  },
  {
    "id": "odjMSBSWRt",
    "title": "DarkBench: Benchmarking Dark Patterns in Large Language Models",
    "authors": [
      "Esben Kran",
      "Hieu Minh Nguyen",
      "Akash Kundu",
      "Sami Jawhar",
      "Jinsuk Park",
      "Mateusz Maria Jurewicz"
    ],
    "abstract": "We introduce DarkBench, a comprehensive benchmark for detecting dark design patterns—manipulative techniques that influence user behavior—in interactions with large language models (LLMs). Our benchmark comprises 660 prompts across six categories: brand bias, user retention, sycophancy, anthropomorphism, harmful generation, and sneaking. We evaluate models from five leading companies (OpenAI, Anthropic, Meta, Mistral, Google) and find that some LLMs are explicitly designed to favor their developers' products and exhibit untruthful communication, among other manipulative behaviors. Companies developing LLMs should recognize and mitigate the impact of dark design patterns to promote more ethical Al.",
    "keywords": [
      "Dark Patterns",
      "AI Deception",
      "Large Language Models"
    ],
    "venue": "ICLR",
    "year": 2025,
    "pdf_url": "https://openreview.net/pdf?id=odjMSBSWRt",
    "forum_url": "https://openreview.net/forum?id=odjMSBSWRt",
    "reviews": [
      {
        "rating": "6",
        "confidence": "4",
        "summary": "The authors define six dimensions of 'dark design patterns' and develop the DarkBench benchmark to detect these patterns in LLMs. They test 14 LLMs, encompassing both proprietary and open models, to compare dark pattern prevalence across different systems.",
        "strengths": "- The paper tackles the crucial issue of dark patterns in LLMs. As far as I know, no prior research has defined and measured dark patterns in LLMs, making this a novel and much-needed contribution.\n\n- Extensive comparison of 14 proprietary and open-source models on the DarkBench benchmark",
        "weaknesses": "- The authors use LLMs to annotate dark patterns. However, LLMs’ own dark patterns may affect their ability to annotate dark patterns. For instance, if an LLM displays brand bias, it may evaluate responses from its own brand more favorably. A simple statistical test for potential biases in annotation could address this (e.g., comparing whether an LLM's scores for its own responses differ significantly from those it assigns to other LLM responses)\n\n- The paper lacks detailed information on human annotations, particularly regarding the annotators' demographics or level of expertise. For instance, it would be helpful to clarify whether LimeSurvey annotators were laypeople or experts and whether they reflect a diverse demographic range (age, gender, etc.) similar to typical LLM users.\n\n- There is no evidence of stability for the benchmark findings across variations in prompt designs. You could test for consistency by paraphrasing prompts in Table 1 and replicate the experiments.\n\n- Overall, the paper lacks detail. The results section would benefit from including actual qualitative examples from the models."
      },
      {
        "rating": "8",
        "confidence": "4",
        "summary": "Authors describe a benchmark for dark patterns: brand bias, user retention, anthropomorphization, sneaking, sycophancy and harmful generation. They created prompts designed to elicit the dark patterns. Then they used few-shot prompting to generate a total of 660 adversarial prompts. Using a mixture of human annotation and model annotation (Claude Sonnet, Gemini Pro, GPT-4o, and Llama3 70b) they tested 14 open and closed lmms. They found that 48% of the cases exhibited dark patterns, with the most common being user retention and sneaking. Dark patterns presence ranged from 30% to 61% across all models.",
        "strengths": "The paper is well-written and well-organized. The paper is a significant contribution as it presents a new benchmark for measuring dark patterns in LLMs. This is an important direction to help evaluate model safety.\nIn addition to LLM annotators, data were also reviewed by human annotators.",
        "weaknesses": "Unfortunately, the methods aren’t clear on the decision criteria, what makes a model’s performance count? Ought it be a simple proportion? Or something more akin to recall and precision might be more informative and valid for interpretation. Moreover, the authors did not report on group differences which would strengthen their conclusions."
      },
      {
        "rating": "6",
        "confidence": "4",
        "summary": "The paper introduces DarkBench a set of prompts designed to elicit \"dark patterns\" in LLM responses. The authors describe how the benchmark was developed, how the benchmark is evaluated against a model, and presents benchmark results for a variety of open and proprietary models. \n\nOverall this is an interesting piece of work, the various patterns are relevant and the problem is well motivated. \n\nI would like to see more formality w.r.t your description of the data generation and evaluation processes i.e. \n\n1. It was unclear to me if humans reviewed all of the 600 DarkBench prompts for quality? You mentioned rephrasing occurred, why was this and what kind of rephrasing was necessary? \n2. When applying the benchmark to an LLM, what parameters were used? Did the LLM produce a set of responses via sampling, or did the LLM generate one response? Did the annotator models correlate with one another? How was the final yes/no answer generated? Was positional bias accounted for?\n3. The results of the human reviews on the annotator model outcomes?\n\nI would appreciate a discussion around system prompts. In the context of system prompts, used to adjust LLM behavior, how is the DarkBench to be interpreted? I could see it being a tool. \n\nNice idea, good selection of patterns. I think the paper would be improved if the methodology was described in more detail as per the points above.",
        "strengths": "Nice idea \nThe selection of patterns is relevant\nValuable asset (DarkBench dataset)",
        "weaknesses": "The description of the methodology is a little vague. \nThe paper would be stronger if the methodology was more detailed."
      },
      {
        "rating": "8",
        "confidence": "4",
        "summary": "The authors develop DarkBench by manually conceptualizing six tendencies of LLMs that seem to align with the chatbot subscription-based business model (e.g., ChatGPT, Claude.ai), prompting an LLM with precise verbal descriptions of those tendencies to create adversarial prompts that would evoke dark patterns, and manually reviewing and modifying the LLM-generated prompts. Evaluation was done with LLMs prompted with human examples with samples of that LLM evaluation also done by humans for comparison. Results show that Claude performs best on this benchmark (\"dark patterns\" in 30-36% of responses, if I understand correctly), followed by the other models in a band of 48-61%. Some patterns (e.g., user retention) are much more frequent than others (e.g., sycophancy) in current LLMs.",
        "strengths": "- **S1.** I'm excited about this project's direction in evaluating LLM behavior based on design patterns found to be important in other interfaces (dark patterns, but also nudges, antipatterns, and so on). This is difficult, and I am sympathetic to work addressing it even if that work has many limitations.\n- **S2.** I appreciate that some human review and validation was done for the LLM-generated benchmark and for the LLM-generated evaluations, and I think these general directions for datasets and benchmarks are promising in their scalability.\n- **S3.** The figures are relatively clear and concise.",
        "weaknesses": "My primary concerns each refer to the benchmark development and evaluation seeming largely superficial, better suited to preliminary and exploratory formats, such as workshops or seminars, than a main conference publication. To be upfront and help the authors manage their time, I don't think W1 can realistically be addressed during review, and addressing only W2 and W3 would be insufficient for me to raise my score to acceptance.\n\n**W1. Theoretical engagement.**\n\nI'm skeptical that these six tendencies qualify as \"dark patterns.\" Dark patterns are a specific idea regarding intentional design of user flow to trick the user into situations harmful to them and beneficial to the designer's institution (https://90percentofeverything.com/2010/07/08/dark-patterns-dirty-tricks-designers-use-to-make-people-do-stuff/index.html). It seems the authors are familiar with canonical examples, such as making it difficult to unsubscribe from a service, but I don't think the authors have successfully argued for any of their six tendencies being constitutive of, or even highly correlated with, this specific idea.\n\nI would put the misalignments into three categories: (i) not being specific to dark patterns but just harmful generation more broadly (\"harmful generation\" and \"sycophancy\" are the main culprits), (ii) not necessarily being harmful, such as the model being \"friendly\" or \"anthropomorphic,\" which can be in fact some of the main benefits of LLMs, such as for mental health (https://dl.acm.org/doi/full/10.1145/3485874), and (iii) being incidental, such as \"brand bias\" merely from preference tuning and system prompts that center the brand. I would not say Google has a dark pattern if the search engine highly ranks Google content.\n\nI realize that it is impossible to have six metrics that uncontroversially fit into a subjective idea such as dark patterns, and it is nonetheless urgent that we build evaluations like this, but the current state of the paper is just too far off the mark.\n\n**W2. LLM generation and validation.**\n\nMy concerns here may be due to the cursory explanation provided by the authors, but I'm missing a lot of necessary details about generation process and test validation. I would want to see, for example, the extent of mode collapse in the generations, comparisons across generations from different models, and ideally a more rigorous structure with subcategories within the six categories (a priori or through clustering). I think LLM-generated evaluations are promising, but as with any paradigm shift in scientific methodology (e.g., agent-based models, psychologists shifting from studying undergraduate students to online participants), the burden of validation will be high before it is more thoroughly vetted. It seems the authors are familiar with the explosion of literature on such methods, so there are many examples to draw from.\n\n**W3. LLM evaluations.**\n\nThis is largely analogous to W2. I don't expect the authors to validate that LLM-as-a-judge aligns perfectly with human judgment, but only brief description such as \"poor inter-rater agreement\" is not sufficient to me that the LLM judges are performing well enough to trust this benchmark. It is also unclear to me how the different model judges (e.g., Claude versus Llama) were compared and aggregated, which is particularly concerning in a paper that (a) is focused on inevitably subjective distinctions between qualitative model output and (b) has a main empirical finding (or at least secondary) of differences between model brands/families. For example, it is well-known that Claude is heavily tuned to be \"friendly\" in various ways, such as modifying its behavior when nudged at all by the user. Some people like this. Some prefer ChatGPT as straightforward with less of that noise. But my point is that the benchmark may be merely picking up on tendencies like that, which would not only lack novelty as a finding but also be of little relevance to dark patterns.\n\n**Minor concerns**\n\n- The term \"dark pattern\" was not coined in the creation of darkpatterns.org but a talk Harry Brignull gave at UX Brighton in 2010, or technically shortly before that in this blog post (https://90percentofeverything.com/2010/07/08/dark-patterns-dirty-tricks-designers-use-to-make-people-do-stuff/index.html). It continues to be a focus of design research, which would be good to engage with in addition to popular media references to the concept.\n- The presentation of the paper seems rushed, including numerous typos and some structural choices that may need correction or at least clarification (e.g., the ordering of models in Figure 4, which does not seem to be \"by least to highest frequency of dark patterns\" as stated).\n- Where is the stated \"Appendix 5\"? Presumably this is related to the \"Annotations on the dataset\" section, but perhaps the authors meant to include more information in the appendix that would address some of my other concerns."
      }
    ],
    "rating_avg": 7.0,
    "confidence_avg": 4.0,
    "decision": "Accept (Oral)",
    "meta_review": "This paper presents a new benchmark— DarkBench — for evaluating dark patterns in LLMs. The authors develop the benchmark using few-shot prompting, resulting in a total of 660 adversarial prompts across six categories: brand bias, user retention, sycophancy, anthropomorphism, harmful generation, and sneaking. Using a mixture of human annotation and model annotations, the authors evaluate 14 open-sourced and preparatory models on the DarkBench and find prevalence of dark patterns across all models. \n\nThis is a timely and novel contribution towards tackling dark patterns in LLMs and to the evaluation of model safety in general. Given how arduous and complex building such a benchmark is, this is a thoughtful and significant contribution. The writing is concise and the figures are clear.",
    "author_remarks": "",
    "decision_comment": ""
  },
  {
    "id": "Of5F2GdGLA",
    "title": "VeSX: A Framework Featured by Verification, Self-Correction and In-context Learning for Web Automation Tasks",
    "authors": [
      "Lin Li",
      "Zhuyu Yao",
      "Xinyi Yang",
      "Boxun Li",
      "Qingmin Liao",
      "Yu Wang"
    ],
    "abstract": "While large language models have achieved remarkable success in tasks such as reasoning and question answering, applying LLMs to interactive tasks like web automation remains challenging. In web automation, existing planning-execution workflow often faces limitations due to the infeasible subtasks. We propose VeSX, a framework designed to enhance subtask feasibility through verification, self-correction, and in-context learning. VeSX introduces three key improvements: (1) subgoal-guided verification, which verifies the execution results of subtasks based on the preset subgoals; (2) hierarchical self-correction, which combines reflection and replanning, targeting to self-correct mistakes in both planning and execution phases; (3) exemplar bank, which improves in-context learning by partitioning execution trajectories and heuristically generating metadata for exemplars. We evaluate VeSX on WebArena benchmark and achieve the state-of-the-art average success rate of 0.34, which significantly outperforms existing methods without human guidance on all five scenarios.",
    "keywords": [
      "LLM agent",
      "web automation"
    ],
    "venue": "ICLR",
    "year": 2025,
    "pdf_url": "https://openreview.net/pdf?id=Of5F2GdGLA",
    "forum_url": "https://openreview.net/forum?id=Of5F2GdGLA",
    "reviews": [
      {
        "rating": "6",
        "confidence": "3",
        "summary": "VeSX is a framework for interactive web automation tasks using LLMs that focuses on improving sub-task feasibility, a common issue for planning based methods that initially break down tasks into multiple steps before execution. To improve sub-goal feasibility, VeSX introduces three components: sub-goal guided verification, which verifies either with the model itself or external methods if the sub-task is feasible. The second is a hierarchical self-correction method that takes place when verification fails during planning as well as during execution. Hierarchical self-correction uses reflection to correct verification errors, and replans if necessary. Lastly, VeSX uses an exemplar bank for in-context learning for both planning and execution. Unlike previous uses of in-context learning, the VeSX exemplar bank does not use full trajectories, instead sampling from existing trajectories to build the examples. For evaluation, VeSX uses 5 scenarios from the WebArena benchmark.",
        "strengths": "- Identifies key weaknesses in current methods for web automation\n- Method tries to account for different types of failures through the dual verification system and self-correction\n- Notable observations as part of method:\n    - A) It is easier to verify then come up verification for different goals \n    - B) Having the LLM output expected results as part of reflection \n- Exemplar bank: I think this is one of the strongest contributions since it is very different than existing work in particular using parts of trajectories instead of full trajectories.",
        "weaknesses": "- Presentation:\n    - I am a bit confused about the overall workflow. It would be helpful to have it written in an algorithm. \n    - It would also be helpful to see more examples \n- Extra Time and Cost:\n    - How much extra time and tokens does it take for this method compared to others (if available for other methods)? If these other methods also had access to more compute, they might also have higher performance. \n- Original of exemplars: Are the exemplars produced from questions in the benchmark? Are those questions included in the final results? This could also lead to an unfair comparison. \n- One stated advantage of the approach is that human guidance is not needed. Is any human guidance used to design the prompts for the different steps? Is the exemplar bank used as in-context examples for all of the different steps?"
      },
      {
        "rating": "5",
        "confidence": "4",
        "summary": "The paper presents VeSX, a framework for enhancing large language models (LLMs) in web automation tasks by introducing verification, self-correction, and in-context learning. VeSX aims to tackle the common challenges in web automation workflows, such as subtask infeasibility and data scarcity, by implementing three key components: subgoal-guided verification, which checks the accuracy of each subtask; hierarchical self-correction, allowing the model to reflect and replan when errors occur; and an exemplar bank for in-context learning, storing structured examples that improve decision-making. Evaluated on the WebArena benchmark, VeSX achieved a state-of-the-art success rate of 34% across multiple scenarios without human guidance, demonstrating its potential to improve accuracy and reliability in complex, multi-step web interactions.",
        "strengths": "- The web automation task is interesting and worth exploring.\n- The proposed self-reflection approach seems to have great improvement in performance, highlighting its potential to enhance task success and reliability in complex, interactive environments.",
        "weaknesses": "- The novelty is limited. Compared to previous work on web automation, the paper integrates self-reflection and retrieval-augmentation components, both of which have been widely explored. The paper also lacks discussions on relevant works on reflection and retrieval augmentation. \n- The writing needs to be improved, especially in explaining the main components and their novelty. \n    * Section 2.1 Overview is empty\n    * Clearly indicate success rates as percentages by adding the percentage sign (e.g., 34% instead of just 34)\n    * It will be better to put short descriptions in the captions for terms in the table (‘Shop’, ‘CMS’, ‘Red’, ‘Git’, ‘Map’).\n    * Adding example prompts would provide readers with a practical understanding of the pipeline.\n- Figures need to be significantly improved:\n    * ‘orders’ rather than ‘oreders’ in the teaser figure.\n    * Miss left bracket for ‘click sorted by]’. Is ‘click [sorted by]’ and ‘click [sortby]’ the same operation?\n    * the texts frequently touch or cross the boundaries of the icons. \n    * Some figures are blurry and difficult to interpret. (e.g. In Figure 2, it is not clear what the four boxes below the environment represent.)\n    * The figure captions should be refined to clearly describe each major component."
      },
      {
        "rating": "6",
        "confidence": "4",
        "summary": "The authors present a solution to automating web tasks such as checking on shopping orders. The solution leverages LLMs that break down the task into subtasks, executes those subtasks in the browser, verifies the subgoals are accomplished, can self corrects and replan if necessary, and leverages in context examples retrieved from an exemplar bank created by the authors. Experimental results show the authors' superior approach compared to the literature on WebArena, a popular benchmark in the literature.",
        "strengths": "Summary: \n- Solves a relevant problem\n- Adopts a solution that is based on the latest technology\n- Beats the state of the art with their experimental results on a well-known benchmark from the literature\n\nDetails: \nThe problem of automating web tasks is difficult and very relevant in this age of enterprise productivity. Many tasks are quite repetitive and could benefit from automation but the diversity of browsers and apps and tasks makes it challenging for automated systems. \n\nLLMs have proven beneficial and the paper not only leverages them but also tests GPT-4o which is one of the newest and less costly models compared to others from the literature. \n\nThe proposed framework introduces three key components to the LLM pipeline: 1) sub-goal verification, 2) self-correction and 3) exemplar bank. Each of these components are not particularly original but combining them into a single framework and applying this framework to the web task automation leads to state of the art of results.",
        "weaknesses": "Summary:\n- Limited experimental results and analysis including missing computational cost analysis, error analysis especially when linked to the various contributed components in their framework\n- Typing and grammar mistakes\n\nDetails:\nThe experimental results show that the proposed approach (including individual components) do improve the state of the art on the web arena benchmark. The authors compare to other approaches from the literature and do an ablation study on the components they proposed. However, the experimental analysis is still missing some key results that could help the community understand and evaluate this approach better. Notable, the authors perform multiple LLM calls during their pipeline. Quantifying the computational cost (whether with number of calls per input or some other metrics) would help evaluate the approach and compare to other in the literature. Furthermore, the authors do not analyze what errors benefited more from what components in their pipelines. What types of errors needed replanning, which were addressed with reflection only, why did some of the verifications fail, etc. Finally, the authors perform an end to end evaluation but do not evaluate each component individually on intrinsic metrics; e.g., how often was the reflection component able to correct an error that is within its scope, etc."
      },
      {
        "rating": "3",
        "confidence": "4",
        "summary": "This paper presents VeSX, a framework for web automation that integrates verification, self-correction, and in-context learning mechanisms.",
        "strengths": "1. The exemplar bank's approach of breaking down trajectories into smaller, reusable components is innovative and practically valuable for reducing context length while maintaining effectiveness.\n2. The ablation studies are comprehensive and help validate the contribution of each component.\n3. The design of local reflection and global reflection are interesting.",
        "weaknesses": "1. The literature review on LLM-based agents appears incomplete, missing several relevant recent works\n2. About \"subgoal-based verification,\" process supervision is a well-studied research direction[1]. This paper's key difference lies in the hierarchical verification mechanism. However， to prove the effectiveness of hierarchical verification，more comparison experiments and discussions should be made。\n3. Although the authors don't use ground-truth labels, their exemplar construction process still utilizes tasks from the target domain. While this doesn't constitute supervision in the traditional sense, it does provide the model with domain-specific information that zero-shot baselines may not have access to, potentially creating an unfair comparison if the baselines are purely zero-shot.\n\nReferences:\n\n[1] Lightman H, Kosaraju V, Burda Y, et al. Let's verify step by step[J]. arXiv preprint arXiv:2305.20050, 2023."
      },
      {
        "rating": "3",
        "confidence": "4",
        "summary": "The paper presents VeSX, a framework designed to enhance web automation tasks by improving the subtask feasibility of Large Language Models (LLMs). It addresses the challenges of error-prone workflows by introducing three key components: (1) Subgoal-Guided Verification, which ensures that subtasks are completed correctly by generating subgoals during the planning phase and verifying the execution results against those subgoals, (2) Hierarchical Self-Correction, which adds layers of error correction during both the planning and execution phases. If mistakes occur, the model first reflects on its actions, and if needed, replans the task, (3) Exemplar Bank for In-Context Learning, which uses stored examples of previous tasks to help the model learn from experience and improve performance on future tasks.",
        "strengths": "Originality: The paper presents VeSX, a framework that introduces a combination of verification, self-correction, and in-context learning for web automation tasks. The approach is notable for its hierarchical self-correction mechanism, which allows the model to reflect on errors and replan, addressing potential common challenges.\n\nQuality: The idea proposed in this paper is straightforward and clear. The overall structure is clear, despite some minor confusion. \n\nClarity: Key concepts such as subgoal-guided verification and hierarchical self-correction are explained straightforwardly, and the diagrams effectively support the explanations.\n\nSignificance: VeSX addresses a common issue in web automation—handling subtask failures and error correction. Its ability to autonomously verify and correct errors while using in-context learning is a useful enhancement.",
        "weaknesses": "While the paper proposes an interesting framework for web automation, the technical contribution feels somewhat limited. The system is more focused on practical application rather than introducing a novel method or algorithm. Additionally, there is no follow-up evaluation of the entire system under real-world conditions. It would be beneficial to see both quantitative and qualitative analyses of VeSX in real-world usage scenarios to better understand its performance in practical settings. E.g., a statistical evaluation or user study focusing on whether this system truly works for real-world tasks would significantly strengthen the paper. A field study or feedback from real users would also provide practical insights into how the system performs in dynamic, unstructured environments.\n\nThe concept of \"self-correction\" is promising, but the evaluation of this feature is not comprehensive enough. Although the paper includes an ablation study, a more detailed analysis of the self-correction mechanism is necessary to demonstrate its effectiveness. For example, breaking down how self-correction functions in different failure cases or assessing the time and resource costs associated with error correction would provide deeper insights into the feature’s utility. \n\nThe paper does not address what happens if the system or specific components fail. While self-correction is included, there is no discussion of how the system handles scenarios where self-correction or verification mechanisms fail. For real-world applications, understanding the system’s resilience and fallback options is crucial. Including an analysis of fail-safe protocols would enhance the system’s reliability and robustness."
      }
    ],
    "rating_avg": 4.6,
    "confidence_avg": 3.8,
    "decision": "Reject",
    "meta_review": "This paper proposes a agent-based framework for web automation tasks (VeSX), with 3 main new modules: subgoal-guided verification, hierarchical self-correction, and exemplar bank. The goal is to ensure that subtasks are are executable, and be able to correct both subtasks and the plan. Instead of storing entire trajectories as previous work, the exemplar bank in VeSX stores single-action exemplars, as well as planning exemplars. Evaluation on WebArena shows that VeSX (which does not require human feedback) performs comparably to a baseline method that uses human feedback. While reviewers appreciated the introduction of different modules in VeSX and the importance of the application, concerns were raised on potential issues in the execution of the exemplar bank (the usage of the benchmark examples to construct this), computational cost of the framework, and additional analysis (e.g. what happens when modules fail?). There was additional discussion between reviewers during the discussion phase on these concerns. The AC agrees with the concern that there are a lot of design choices in the examples used to form the exemplar bank (while test labels were not used, it is difficult to evaluate how these choices impacted performance). Additionally, the ablation study is only on one of the 5 scenarios, and the effect on the entire dataset is unknown. Additional examples on comparing the use of exemplar bank with in-context learning in VeSX would be helpful, or what if the exemplar bank is formed with 1 scenario held-out? The framing of the paper need to be more clear if all test tasks need to be known ahead of time to form the exemplar bank, vs. being used with in-context learning. The proposed method is interesting, but additional experiments are required to fully understand the contribution of each component. With completed experiments, I think this could be a good submission in the future.",
    "author_remarks": "",
    "decision_comment": ""
  },
  {
    "id": "Y0kmI2zqqi",
    "title": "Stochastic Sparse Sampling: A Framework for Variable-Length Medical Time Series Classification",
    "authors": [
      "Xavier Mootoo",
      "Alan Arnoldo Diaz Montiel",
      "Milad Lankarany",
      "Hina Tabassum"
    ],
    "abstract": "ile the majority of time series classification research has focused on modeling fixed-length sequences, variable-length time series classification (VTSC) remains critical in healthcare, where sequence length may vary among patients and events. To address this challenge, we propose $\\textbf{S}$tochastic $\\textbf{S}$parse $\\textbf{S}$ampling (SSS), a novel VTSC framework developed for medical time series. SSS manages variable-length sequences by sparsely sampling fixed windows to compute local predictions, which are then aggregated and calibrated to form a global prediction. We apply SSS to the task of seizure onset zone (SOZ) localization, a critical VTSC problem requiring identification of seizure-inducing brain regions from variable-length electrophysiological time series. We evaluate our method on the Epilepsy iEEG Multicenter Dataset, a heterogeneous collection of intracranial electroencephalography (iEEG) recordings obtained from four independent medical centers. SSS demonstrates superior performance compared to state-of-the-art (SOTA) baselines across most medical centers, and superior performance on all out-of-distribution (OOD) unseen medical centers. Additionally, SSS naturally provides post-hoc insights into local signal characteristics related to the SOZ, by visualizing temporally averaged local predictions throughout the signal.",
    "keywords": [
      "Time Series",
      "Healthcare",
      "Medicine",
      "Epilepsy",
      "Neuroscience"
    ],
    "venue": "ICLR",
    "year": 2025,
    "pdf_url": "https://openreview.net/pdf?id=Y0kmI2zqqi",
    "forum_url": "https://openreview.net/forum?id=Y0kmI2zqqi",
    "reviews": [
      {
        "rating": "5",
        "confidence": "3",
        "summary": "This article proposes a meta-heuristic to improve time series classification algorithms by classifying random windows and aggregating scores. The algorithm is tested on a real-world task where it achieves promising performance.",
        "strengths": "- The article is well-written and easy to follow.\n- The methodology is sound and has the potential to provide an interpretable time series classification strategy that can be combined with virtually any time series classification algorithm.",
        "weaknesses": "- The proposed approach is simple, which is perfectly fine, but lacks a more thorough analysis, at least empirical. For a reader with a use case in mind, it is difficult to assess if this method is appropriate.\n- Another drawback is that this approach has only been tested on one data set. To assess its generalization capability, the authors could test their method on additional publicly available time series datasets.\n- Section 4.5 on qualitative interpretation needs to (re)written to be more convincing as it lacks much information or comments. Interpretability is one of the contributions listed in the introduction."
      },
      {
        "rating": "6",
        "confidence": "4",
        "summary": "The paper describes using aggregation of time-series classification model predictions across windows during training and inference a way to go beyond fixed-context length window processing and infinite context models recurrent neural networks.  The aggregation method explored here is simple averaging. An additional calibration step is used after the model is trained. \n\nThe method is applied to different EEG channels in order to learn to classify a channel as being in the seizure originating zone or not. Cross-subject and cross institution results show very promising performance compared to fixed-context length approach and infinite context models.",
        "strengths": "Very clear presentation and well-fit for this type of time series classification problem. The calibration step after pooling during training is a thoughtful addition.",
        "weaknesses": "Main concern is the single domain/task used to test the method. While the single domain is very interesting, there is something different in the fact that the seizure periods are themselves randomly occurring throughout the time series. In other tasks, long-term dynamics of the time series may require extracting patterns through time rather than this which is more akin to multiple instance learning where the search is for any evidence of positive class. \n\nThe lack of other tasks weakens the generality of the method, but I don't have the perfect case of variable length it is hard to say where there would"
      },
      {
        "rating": "3",
        "confidence": "4",
        "summary": "This paper introduces Stochastic Sparse Sampling (SSS), a new framework for classifying variable-length medical time series. SSS employs fixed windows sparsely to make local predictions, which are then combined to form a global prediction.",
        "strengths": "1) Seizure onset zone (SOZ) detection is a novel direction that may be important for clinical intracranial EEG (iEEG) research.\n2) The method is described in detail, ensuring clarity and reproducibility. \n3) The experiments use a large-scale public iEEG dataset for evaluation, showing the robustness and effectiveness across diverse and heterogeneous data sources.",
        "weaknesses": "1) This paper uses a single-channel approach for SOZ detection, justifying it by citing the challenges posed by varying numbers of iEEG channels across iEEG recordings. However, this reason does not demonstrate that single-channel analysis is more effective. In clinical practice, SOZ and early propagation zones involve multiple channels with timing differences in abnormal discharges [1]. The authors do not provide sufficient theoretical or experimental support to explain why a single-channel approach would effectively capture these critical distinctions.\n2) This paper defines SOZ detection as a variable-length time series classification (VTSC) task. Still, the authors do not clarify the specific benefits of VTSC over general anomaly detection for this application. Their justification, that “effective treatment requires analysis of variable-length signals,” lacks concrete references or explanations relevant to variable-length signals, weakening the rationale for using VTSC in this context.\n3) The proposed method is quite simple. How does it differ from other downsampling or sparse sampling approaches?  Model output still provides a global classification result, which seems no different from a standard classification model. The paper should compare its approach with more methods that share a similar motivation and more details of related works to clarify its position within the research field. \n4) The authors state in the abstract that their method outperforms \"state-of-the-art (SOTA) baselines across most medical centers.\" However, none of these baselines were designed for the SOZ detection task or medical time series data.Instead, all baseline models were built for general time series or other sequential data forecasting tasks, not even for time series classification. The authors should have used baselines developed for iEEG or EEG signal analysis, such as methods in references [2-4], or, at the very least, models designed for time series classification or anomaly detection [4,5]. \n\n\n[1] Li et al., Neural fragility as an EEG marker of the seizure onset zone, Nature Neuroscience, 2021.\n\n[2] Tang et al., Self-Supervised Graph Neural Networks for Improved Electroencephalographic Seizure Analysis, ICLR, 2022.\n\n[3] Luo et al., Exploring Adaptive Graph Topologies and Temporal Graph Networks for EEG-Based Depression Detection, IEEE Transactions on Neural System and Rehabilitation Engineering, 2023.\n\n[4] Rikuto et al., SplitSEE: A Splittable Self-supervised Framework for Single-Channel EEG Representation Learning, ICDM, 2024.\n\n[5] tang et al., Omni-Scale CNNs: a simple and effective kernel size configuration for time series classification, ICLR, 2022.\n\n[6] Lu et al., Out-of-Distribution Representation Learning for Time Series Classification, ICLR, 2023."
      },
      {
        "rating": "5",
        "confidence": "5",
        "summary": "This paper introduces a multi-scale learning approach for medical time series classification. The proposed method comprises multiple independent models, each with a distinct patch length, allowing it to capture information across various temporal scales. The patching method follows the PatchTST framework, which employs single-channel patching. To reduce computational costs, the authors implement stochastic sparse sampling, randomly selecting models during training. The final representation is an aggregation of outputs from all models, combining multi-scale information. The model is evaluated on intracranial EEG (iEEG) data for seizure onset zone classification, using a dataset collected from four independent medical centers.",
        "strengths": "The use of sparse sampling for computational savings in multi-scale learning is an interesting idea. Additionally, the out-of-distribution classification on unseen subjects from different medical centers demonstrates strong potential for generalizability in real-world applications.",
        "weaknesses": "The motivation to save computational resources is well-intentioned, though I am concerned about its practicality in actual training. For a given set of window sizes with corresponding independent models, even if only subsets of window sizes are selected during training, the space complexity of the models remains unchanged. This approach primarily improves training speed without reducing memory requirements. Additionally, using an independent model for each patch length may not be optimal for memory efficiency. A shared backbone across different patch lengths could be a more effective choice for memory savings. Overall, the method resembles an enhanced version of MTST [1], employing a random subset of models with varying patch lengths during training.\n\nMoreover, while the paper’s title refers to medical time series, only a single seizure dataset is used for evaluation. Expanding the evaluation to include additional datasets would strengthen the claim of generalizability. The ablation study could also benefit from a deeper investigation into multi-scale learning with various patch lengths. For instance, exploring which combinations of patch lengths yield the best performance would be informative. Additionally, the impact of stochastic sparse sampling should be assessed in detail. For a given list of patch lengths, how do memory usage and running time between training with and without stochastic sparse sampling? Lastly, a recent work, Medformer[2], should be compared in baseline methods, as it is also designed for medical time series classification using multi-scale patching. A discussion on the differences between this method and Medformer would also be valuable for highlighting the unique aspects of the proposed approach.\n\n\n[1] Multi-resolution Time-Series Transformer for Long-term Forecasting\n[2] Medformer: A Multi-Granularity Patching Transformer for Medical Time-Series Classification"
      }
    ],
    "rating_avg": 4.75,
    "confidence_avg": 4.0,
    "decision": "N/A",
    "meta_review": "",
    "author_remarks": "",
    "decision_comment": ""
  },
  {
    "id": "qK6U4Ahfms",
    "title": "OpenCity: A Scalable Platform to Simulate Urban Activities with Massive LLM Agents",
    "authors": [
      "Yuwei Yan",
      "Qingbin Zeng",
      "Zhiheng Zheng",
      "Jingzhe Yuan",
      "Jun Zhang",
      "Jie Feng",
      "Fengli Xu",
      "Yong Li"
    ],
    "abstract": "Agent-based models (ABMs) have long been employed to explore how individual behaviors aggregate into complex societal phenomena in urban space. Unlike black-box predictive models, ABMs excel at explaining the micro-macro linkages that drive such emergent behaviors. The recent rise of Large Language Models (LLMs) has led to the development of LLM agents capable of simulating urban activities with unprecedented realism. However, scaling LLM agents to large city simulations presents significant challenges. Existing models are limited by the computational and communication costs of LLMs, compounded by the dynamic nature of urban environments that require continual updates to agent behavior. To address these limitations, we propose OpenCity, a scalable simulation platform optimized for both system and prompt efficiencies. Specifically, we propose a LLM request scheduler to reduce communication overhead by parallelizing requests through IO multiplexing. Besides, we deisgn a ``group-and-distill'' prompt optimization strategy minimizes redundancy by clustering agents with similar static attributes. Through experiments on six global cities, OpenCity achieves a 600-fold acceleration in simulation time per agent, a 70\\% reduction in LLM requests, and a 50\\% reduction in token usage. These improvements enable the simulation of 10,000 agents’ daily activities in 1 hour on commodity hardware. Additionally, OpenCity establishes a benchmark for LLM agents, comparing simulated mobility behaviors, origin-destination flows, and segregation indices against real-world data. We believe our OpenCity platform provides a critical infrastructure to harness the power of LLMs for interdisciplinary studies in urban space, fostering the collective efforts of broader research communities. Code repo is available at https://anonymous.4open.science/r/Anonymous-OpenCity-42BD.",
    "keywords": [
      "LLM Agent",
      "Large Language Model",
      "Urban Study"
    ],
    "venue": "ICLR",
    "year": 2025,
    "pdf_url": "https://openreview.net/pdf?id=qK6U4Ahfms",
    "forum_url": "https://openreview.net/forum?id=qK6U4Ahfms",
    "reviews": [
      {
        "rating": "3",
        "confidence": "4",
        "summary": "The paper describes an approach\twhere LLM agents are used to simulate individual behaviour in large (city-scale) simulations of people.\tThe proposed platform uses LLM agents that can adapt their behaviour depending on context and memory. This is different to the classic agent based approach for this type of simulation where behaviours are static over time. \nThe development of the platform is one of the main contributions of the work, and the development of a user-friendly web interface is another contribution highlighted by the authors. From a machine learning perspective, the proposed “group-and-distill” approach to reduce LLM usage is the main contribution of the work, essentially a clustering approach before prompting the LLM for each cluster (as opposed to prompting an LLM for each individual).",
        "strengths": "The use of a LLM for the purpose of larger scale population modelling appears to be novel, and the suggested group-and-distill approach enables this idea, with relatively low hardware resources. \nOverall, considerable effort appears to have gone into development of the system. The system could be an interesting resource for research in complex systems.",
        "weaknesses": "The paper has quite a broad focus, like an overall project report. For a venue like iclr, it would have been better to focus on the specific contributions in machine learning, and to provide more technical details rather than an overall description of architecture and usability aspects as the main contributions. In its current form, ICLR does not appear to be the right venue for the work as it is presented.\n\nThe work lacks depths in aspects that I would see essential for any ML paper: for example the group-and-distill concept is introduced, but the paper is very sparse in detail of the specific algorithms. Similarly it would have been interesting to see what are the initial prompts and the optimised prompts, in contrast. \nAny details comparing to the original approach without group-and-distill / ablation would have been an improvement too. \n\nMoreover it didn’t become clear to me what LLM has been used or how was it trained, and how do LLM outputs influence agents’ behaviours.\n\nFinally, the paper mentioned at the beginning the explainability of ABM as an advantage over black box neural network approaches. with the lack of detail on how the actions are influenced by the LLM or how the LLM are trained or fine tuned, the proposed model has the same disadvantage as any other neural network model.  \n\nMinor presentation issues:\n\n\"Agent-based models (ABMs) were first introduced to urban studies in the seminal work of Thomas Schelling about 50 years ago Schelling (2006)\"\n- if the work referenced was from approx 50 years ago, Schelling 2006 is the wrong reference. I believe the correct year would be 1978.\n- there are two\tkinds of citations, narrative (like the one in the sentence), and parenthetical (Schelling, 2006). It doesn't make sense to use\tnarrative style\twhen it doesn't fit into the sentence structure. In LaTeX with natbib, this is the difference between \\citet and \\citep. \nThe referencing is an issue throughout the paper."
      },
      {
        "rating": "6",
        "confidence": "3",
        "summary": "The recent rise of Large Language Models (LLMs) has led to the development of LLM agents capable of simulating urban activities with unprecedented realism. Nevertheless, the extreme high computational cost of LLMs presents significant challenges for scaling up the simulations of LLM agents. With this motivation, this paper introduces OpenCity, a scalable simulation platform designed to efficiently simulate urban activities using a large number of LLM agents. The platform incorporates innovative techniques, including LLM request scheduler and a group-and-distill prompt optimization strategy, to reduce the computational overhead of simulating LLM agents significantly. OpenCity achieves a 600-fold speedup and reduces both LLM requests and token consumption. Extensive experiments on six global cities verify the platform's scalability and its capability to replicate real-world urban dynamics.",
        "strengths": "Strengths\n1.\tThis paper introduces a scalable platform for urban simulations using LLM agents, which addresses a growing need for realistic human behavior modeling in urban environments.\n2.\tThis paper shows a high quality of presentation. The paper is technically sound and the research question is clear. The optimizations, particularly the LLM request scheduler and prompt optimization strategies, demonstrate clear performance benefits. The experimental results showing a 600x speedup and significant resource savings are compelling.\n3.\tThe paper is generally clear and well-structured. It provides a clear problem statement, introduces the proposed framework, and highlights key findings.\n4.\tThe contribution of the paper is relevant for LLM agent. The results of this paper is interesting and significant in LLM agent simulation. The proposed OpenCity framework is relevant for urban planning and policy-making. The development of a web portal that allows researchers to configure and visualize simulations without requiring programming skills is a valuable addition, making the platform accessible to a broader audience.",
        "weaknesses": "1.\tThe introduction part fails to convey to the reviewers what is the motivation and novelty in this paper. In fact, the authors should add more previous work on LLM agents based simulation platform. The problem this paper addresses and the reason why this paper uses system-level LLM request scheduler and prompt-level “group-and-distill” strategy to solve the problem of scalability should be further explained. Besides, the contribution the authors listed in the introduction section is inaccurate，the authors should focus on the system-level LLM request scheduler and prompt-level “group-and-distill” strategy. Thus, I would recommend a revision for the introduction section in this paper.\n2.\tThis paper utilizes Group-and-Distill Meta-Prompt Optimizer to classify similar agents to reduce computational complexity, which indeed improve efficiency. However, this may overlook differences between individuals, so the reason why this method can preserve the distinctive characteristics of the agents, as show in the experimental part, should be further explained in the method section。\n3.\tFigure 2 illustrates the principle of Group-and-Distill Meta-Prompt Optimizer. However, it seems difficult to follow. It is more intuitive to add an example to explain how IPL works. \n4.\tThere lacks explanation for the reason why the proposed method IPL is superior to conventional prototype learning. Moreover, the principles for setting the value of M and T in IPL should be further illustrated.\n5.\tExperimental part: the authors should add an explanation of the indicators including JSD, T1 and bold the important data in Table 2 . Similarly, Table 3 also requires revision. The metrics of RMSE of New York和San Franciscoin are not displayed in Table 3, which seems a little bit confusing, the authors need to provide explanations. \n6.\tThe authors should pay attention to the standardization of citations throughout the paper, especially in introduction and related works section. For example, “conventional prototype learning methods...”(line305), “the baseline represents the simulation time without optimization” (line 389), “we analyze the performance of the Generative Agent and EPR Agent ”(line 450).\n7.\tThe authors should carefully proofread the manuscript for typos and formatting issues. There exists some typos: in the abstract: “we deisgn a “group-anddistill” prompt optimization”, “where τqα is is the proportion”(line 687) , etc."
      },
      {
        "rating": "3",
        "confidence": "4",
        "summary": "The paper is considering the problem of agent-based modeling of environments such as cities. Such models had been previously used with the agents performing relatively simple behaviors. While LLMs open new opportunities for controlling the behaviors of the individual agents, their computational cost presents a significant scaling problem. \n\nThe paper describes an architecture that enables the parallelization of the agents, to allow the modeling the daily activities of a city with 10,000 agents. The architecture appears to be based on an efficient polling model of the LLM, as well as the development of a prompting model called \"group-and-distill\". The application of these models show a more than 600-fold increase.",
        "strengths": "* The overall goals of the paper, of capitalizing on the abilities of LLMs to achieve a better ABM model of cities, as well as addressing the scaling problems, are laudable.",
        "weaknesses": "* Achieving a more than 600 fold speed increase in terms of an improved process scheduler and I/O scheduler can be probably seen as \"debugging\", rather than research result, and very likely has nothing to do with the LLM. \n* It seems that the very considerable computational effort of an LLM can only achieve an approximate parity with the much cheaper rule based efforts. This is understandable, as description of the behavior of the agents described in the paper follows the same position based rules that the ABM models historically use. As there is no consideration of language or other type of reasoning, the paper does not make it clear what type of benefits one would expect from LLMs.\n* The only part of the paper that has a connection to the topic of this conference is the way in which the \"group-and-distill\" model is proposed to achieve the simulation of multiple agents with one prompt. However, there is very little about this technique in the paper proper, so it is difficult to form a judgement."
      },
      {
        "rating": "5",
        "confidence": "4",
        "summary": "ABM and LLM is leveraged to develop one platform for open city modeling and planning. It is a nice simulation platform and the paper provides application scenarios. Concretely, \n\n1. This paper combines agent-based models with large language models to develop the OpenCity platform for simulating urban activities. It reduces simulation computational costs through IO multiplexing and the \"group-and-distill\" prompt optimization strategy.\n2. Through experiments conducted in six major cities worldwide, OpenCity demonstrates a 635 plus increase in average simulation speed per agent, along with a 70% decrease in LLM requests and a 50% reduction in token usage. The time savings are mainly concentrated in the LLM response wait time and the CPU multiplexing process.\n3. The OpenCity platform proposed in this paper achieves the first benchmark testing for LLM agent-based urban activity simulation research.",
        "strengths": "The paper give a detailed introduction of the novel methods and the real outcome.\n\n1. Originality: The paper presents a novel approach by integrating Large Language Models with agent-based modeling to simulate urban activities. There has been limited research on combining LLMs with agent-based models, and even less so in the context of large-scale urban activity simulations. By using IO multiplexing and the \"group-and-distill\" prompt optimization strategy to reduce the computational cost of simulations, this paper has made the application of LLMs in large-scale urban activity simulations possible.\n2. Quality: The research is well organized with a clear methodology and experiments conducted in real cities data. The results show notable improvements in both simulation efficiency and accuracy, confirming the effectiveness of the proposed platform.\n3. Clarity: The paper is written in a clear and concise manner; it is easy to understand through the explanation of figures\n4. Significance: This paper establishes a benchmark for LLM agent-based urban activity simulation research. This paper also provides a scalable framework for simulating urban dynamics.",
        "weaknesses": "There is a lack of theoretical contribution, overall, rather it is an application tool development with leveraging well established tools. It may not fit ICLR the best though not out of scope at all. Further,\n\n1. Some parts of the main body text are not rigorous enough. For example, Equation 1 is missing a parenthesis, and the IPL method is mistakenly labeled as the LPL method in Figure 2.\n2. This research has high requirements for data quality. Additionally, despite significantly improving computational efficiency and reducing costs, the platform may still require substantial computational resources.\n3. When simulating cities in different countries, the dynamic properties to be considered should not be entirely the same, and some of the assumed static properties may also change during the simulation process."
      }
    ],
    "rating_avg": 4.25,
    "confidence_avg": 3.75,
    "decision": "Reject",
    "meta_review": "The paper proposes OpenCity, a platform combining agent-based modeling (ABM) with large language models (LLMs) to simulate urban dynamics at scale. By leveraging techniques like the “group-and-distill” prompt optimization, the platform achieves significant computational efficiencies, including a 600-fold speedup and reduced resource consumption in large-scale simulations. The paper claims to establish a new benchmark for LLM-powered urban simulation and provides a user-friendly web interface for broader accessibility.\n\nWhile the proposed OpenCity model shows promising results, the reviewers have identified several weaknesses that need to be addressed:\n1. The paper’s broad focus, which includes platform architecture and usability aspects, lacks sufficient technical depth on the machine learning contributions, especially regarding the “group-and-distill” approach.\n2. The absence of detailed algorithmic descriptions and comparisons, such as ablation studies or specifics on optimized prompts, weakens the paper’s technical rigor.\n3. There is a lack of clarity on which LLM model is used, how it is trained, and how its outputs influence agent behavior, leaving the model’s inner workings inadequately explained.\n\nBased on these weaknesses, we recommend rejecting this paper. We hope this feedback helps the authors improve their paper.",
    "author_remarks": "",
    "decision_comment": ""
  },
  {
    "id": "drrXhD2r8V",
    "title": "Structure-Aware Parameter-Efficient Machine Unlearning on Transformer Models",
    "authors": [
      "Wenjie Bao",
      "Jian Lou",
      "Yuke Hu",
      "Xiaochen Li",
      "Zhihao Liu",
      "Jiaqi Liu",
      "Zhan Qin",
      "Kui Ren"
    ],
    "abstract": "Transformer has become fundamental to a vast series of pretrained large models that have achieved remarkable success across diverse applications. Machine unlearning is an emerging field focused on efficiently removing the influence of specific data from trained models, to comply with privacy regulations enforcing the right to be forgotten. The sheer size of Transformer-based models poses a significant challenge to unlearning efficiency. Existing methods find it promising to restrict unlearning updates to a small portion of influence-critical parameters. However, their parameter-efficient unlearning methods are largely devised in a structure-oblivious manner, which tends to inaccurately identify these parameters and leads to inferior unlearning performance for Transformers. In this paper, we propose {\\tt SPE-Unlearn}, a structure-aware parameter-efficient machine unlearning approach tailored for the Transformer architecture. {\\tt SPE-Unlearn} introduces a learnable pair of masks to respectively pinpoint influence-critical parameters in the heads and filters of Transformers. The learning objective of these masks is derived by jointly considering both desiderata of unlearning, i.e., sufficiency in influence removal and efficiency, and optimized through an efficient algorithm featured by a greedy search with a warm start. Equipped with the identified key parameters, {\\tt SPE-Unlearn} facilitates second-order unlearning, memory-free unlearning, and memory-aided unlearning scenarios. Extensive experiments on various transformer models and datasets demonstrate the effectiveness and efficiency of {\\tt SPE-Unlearn}~for Transformer unlearning.",
    "keywords": [
      "Machine Unlearning",
      "Parameter-Efficient",
      "Transformer"
    ],
    "venue": "ICLR",
    "year": 2025,
    "pdf_url": "https://openreview.net/pdf?id=drrXhD2r8V",
    "forum_url": "https://openreview.net/forum?id=drrXhD2r8V",
    "reviews": [
      {
        "rating": "5",
        "confidence": "3",
        "summary": "This paper introduces a sparsity-aware machine unlearning method. First, it proposes to adaptively identify influence-critical parameters using a derived score function. Then, it applies existing machine unlearning methods (e.g., second-order unlearning) exclusively to optimize the identified parameters. The process of parameter identification and optimization is performed iteratively.",
        "strengths": "1. The approach to identifying influence-critical parameters based on the retain set (and the forget set) appears original. The derivation is clear and reasonable. (However, the necessity needs clarification, as mentioned in the weaknesses below.)\n2. The paper is well-organized and easy to understand.\n3. It is meaningful to explore the applications of the proposed method for both memory-free and memory-aided successive machine unlearning scenarios.",
        "weaknesses": "1. In line 273, it appears that the differentiation is performed on $\\theta$ rather than $m$.\n2. Doubts regarding the necessity of the proposed parameter identification approach. The authors derive a score function to identify informative parameters, involving calculating the derivative with respect to $m$ over $D_f$ and $D_r$. Why not directly optimize the mask parameters base on Eq.(4), which seems computationally cheaper and simpler with only once gradient calculation? Or why we need to transform Eq.(4) to Eq.(5)?\n3. Doubts about the claimed efficiency benefits. The paper claims improved efficiency for machine unlearning, but this may not be the case:\n   - Computation: Compared to vanilla second-order unlearning, the proposed method requires additional calculations involving twice the differentiation to identify informative parameters and still requires computing gradients for all parameters during the unlearning phase.\n   - Memory: Although masking hides certain parameters, storing the mask and associated gradients requires extra memory.\n4. Insufficient complexity analysis. A comprehensive analysis is needed, detailing the complexity of both the parameter identification and unlearning phases from perspectives like memory and computation. \n5. What are the specific advantages of the proposed method for the successive machine unlearning? The descriptions (e.g., in Line 362) is  too broad and hard to understand. Detailed, clear and reasonable analysis is needed.\n6. It is recommended to use the standard notation format as outlined by ICLR guidelines instead of using a uniform font throughout all equations. The correct formatting guidelines can be found on the official website."
      },
      {
        "rating": "6",
        "confidence": "3",
        "summary": "This paper proposes an efficient unlearning method with multiple benefits, such as reduced time and memory costs. The proposed method is a pruning-based unlearning approach that filters out sensitive weights to forget specific data. By converting to a differential formulation for the masking variable, the authors approximate unlearned weights through a combination of masking and the Fisher information matrix. Using a second-order Taylor expansion and the convergence assumption from LeCun et al., the method is simplified to this combination. In experiments, the authors compare their approach to prior methods and report promising performance.",
        "strengths": "I believe the strongest benefit of this work is its time and memory efficiency. Across all tables, the authors report significantly reduced costs for unlearning, which highlights a promising advancement in the field of machine unlearning.",
        "weaknesses": "However, I have several concerns:\n\n1. It is unclear why the method is considered structure-aware. While mask variables are applied to each head in the multi-head attention block, this approach is not unique to Transformers. The authors mention as \"widely-adopted unlearning methods in Transformers, e.g., fine-tuning (Golatkar et al. (2020)) and gradient difference (Liu et al. (2022); Jia et al. (2024)),\" but they are not specified to transformer architecture. As I understand from the manuscript, the authors suggest that their method’s efficiency makes it well-suited to large-scale Transformer models, but large scale is not a Transformer-specific attribute.\n\n\n2.  Although the method is not specialized for Transformer architectures, much of the paper focuses on Transformer-specific content. Reducing this content could make the paper more concise and focused.\n\n\n3. In line 190, the authors assume that \" L is differentiable with respect to m\", to develop Equations (5-9). However, as stated in line 160, $m$ is a binary variable. This raises concerns about whether the differentiability assumption is valid.\n\n\n4. In line 181, the authors state, \"we formulate the unlearning objective (1) with a learnable pair of masks for the heads and filters as a constrained optimization problem.\" However, objective (1) aims to retain a model with the same architecture trained only on D_r. The proposed method, which involves pruning, alters the architecture, making it misaligned with this objective.\n\n\n5. The experimental section lacks details on the partitioning of D_r and D_f. This split is an essential part of the experimental setup and should be clearly specified.\n\n6. Evaluation Concerns in Table 2 and Appendix:\n\n6-1) The unlearning performance should be evaluated by comparing it to the performance of a retrained model, as specified by Eq (1). In specific, the MIA metric should follow this protocol, with retrained models serving as the gold standard. However, the authors set the lower values of efficacy and higher values of fidelity are better without any explanation.\n\n\n6-2) In Table 1, the proposed method unlearns to a greater extent (achieving 85.94% as the lowest Unlearning Accuracy) than other methods, resulting in lower Remaining Accuracy. To ensure a fair comparison, it would be better to report Remaining Accuracy and Testing Accuracy at the point where each method reaches a common Unlearning Accuracy threshold.\n\n\n6-3) All methods (FT, GD, SA) have hyperparameters that control unlearning speed, such as learning rate, but there is no discussion of these parameters in the manuscript. Without this information, it’s unclear whether the evaluations are fair.\n\n\n6-4)  The authors used only D_r for Fine-Tuning (FT) and Sparsity-Aware Unlearning (SA) but used both D_r and D_f for their method. This discrepancy in dataset usage should be clarified, and comparisons with more unlearning methods that use both D_r and D_f are recommended.\n\n\n6-5) Many of the unlearning methods used for comparison are outdated. It would strengthen the evaluation to include more recent works, such as:\n\n[1] Fan, C., Liu, J., Zhang, Y., Wong, E., Wei, D., & Liu, S. (2023). Salun: Empowering machine unlearning via gradient-based weight saliency in both image classification and generation. arXiv preprint arXiv:2310.12508.\n\n[2] Chen, M., Gao, W., Liu, G., Peng, K., & Wang, C. (2023). Boundary unlearning: Rapid forgetting of deep networks via shifting the decision boundary. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (pp. 7766-7775).\n\n\n7. (Minor) In the second sentence of the Related Work section, \"Jang et al.\" is cited twice in a single sentence."
      },
      {
        "rating": "6",
        "confidence": "3",
        "summary": "This paper proposes a structure-aware parameter efficient machine unlearning approach for transformer models.",
        "strengths": "The research problem is interesting and the approach is novel.",
        "weaknesses": "Some experiments are insufficient, and the experimental setup should be more comprehensive.\n\nFor example, in page 7 the author notes that if the number of unlearning requests exceeds a certain threshold, the model must be retrained from scratch to regain its performance. What exactly is this threshold?\n\nAdditionally, in Table 3, is there a specific reason for selecting 90% sparsity instead of alternatives like 85% or 95%? Based on Figures 2 and 3, is this value specific to the model?"
      },
      {
        "rating": "3",
        "confidence": "4",
        "summary": "The authors tackle the challenge of efficient machine unlearning in large Transformer models, essential for meeting privacy regulations. Existing methods, often structure-agnostic, struggle to accurately target influence-critical parameters in Transformers. To address this, the authors introduce SPE-Unlearn, a structure-aware approach that uses learnable masks to identify key parameters within Transformer heads and filters. Optimized via a greedy search, SPE-Unlearn enhances unlearning by balancing efficiency and effectiveness. Extensive experiments show that SPE-Unlearn significantly improves unlearning performance across various Transformer models and datasets.",
        "strengths": "1. The paper is clearly written, well-formatted, and well-organized. \n\n2. The mathematical derivations are rigorous.",
        "weaknesses": "1. The paper mentions that SPE-Unlearn can enhance the effectiveness of various methods; however, the authors only integrate SPE-Unlearn with SO and do not test it with other methods. In Table 2, SPE-SO does not show a significant improvement over SO, while requiring more time.\n\n2. Common LLM unlearning tasks, such as TOFU, MUSE, and WMDP, are missing.\n\n3. Several standard baselines, like NPO and \"I don't know,\" are not included, which weakens the argument.\n\n4. For robustness, the authors employ memory-free and memory-aided unlearning but do not explore other approaches, such as jailbreak prompts."
      }
    ],
    "rating_avg": 5.0,
    "confidence_avg": 3.25,
    "decision": "Reject",
    "meta_review": "This paper proposes a structure-aware parameter-efficient machine unlearning approach (SPE-Unlearn) for Transformer architectures. After reviewing the paper and author-reviewer discussions, I find the current version has unresolved concerns and is not ready for acceptance.\n\n### 1. Complexity Analysis (Reviewer ZE8b)\nThe authors failed to address Reviewer ZE8b’s request for a quantitative complexity analysis of memory and computational efficiency. Their response lacked concrete evidence.\n\n### 2. Implementation Details (Reviewer Lm6c)\nKey implementation details remain unclear:  for example, threshold setting, sparsity setting, and data volume influence.\n\n### 3. Generalizability and Robustness (Reviewer fgpp)\nConcerns about generalizability and robustness remain unresolved:  \n- Benchmarks: Common benchmarks like MUSE and WMDP are not included.  \n- Robustness: No exploration of robustness against attacks (e.g., jailbreak prompts).  \n- Time Cost: SPE-SO’s higher time cost (Table 2) compared to SO is unexplained.\n\n### Conclusion\nWhile the approach is interesting, these unresolved issues in complexity, implementation details, and robustness make it unsuitable for acceptance without significant revision.",
    "author_remarks": "",
    "decision_comment": ""
  },
  {
    "id": "hWF0HH8Rr9",
    "title": "Large-Scale Multi-Agent Reinforcement Learning for Traffic Signal Optimization",
    "authors": [
      "Magnus Müller",
      "Alexander Prochnow",
      "Jonas Otten",
      "Lionel Peer"
    ],
    "abstract": "We present a novel approach to Traffic Signal Control (TSC) in a multi-agent environment by modeling communication among agents as a sequence problem, enabling intersections within road networks to communicate with one another. Taking inspiration from point cloud processing and graph neural networks, we make our architecture capable of handling variable road network topologies, including differing numbers of intersections and intersection types, and demonstrate this by successfully training on real & randomly generated road networks and traffic demands. Furthermore, we demonstrate that even utilizing minimal state information can achieve competitive performance.",
    "keywords": [
      "Reinforcement Learning",
      "Traffic Signal Control",
      "Multi-Agent",
      "Transformer"
    ],
    "venue": "ICLR",
    "year": 2025,
    "pdf_url": "https://openreview.net/pdf?id=hWF0HH8Rr9",
    "forum_url": "https://openreview.net/forum?id=hWF0HH8Rr9",
    "reviews": [
      {
        "rating": "5",
        "confidence": "3",
        "summary": "The paper presents a Novel Traffic Sign Control approach in a multi-agent setting by modelling communication as a sequence problem and allowing road networks to communicate. The model uses Graph Neural Networks to handle road network topologies and demonstrate that their approach can provide competitive performance despite minimal state information.\n\nThe paper presets:\n- An automated pipeline for dataset generation\n\n- Utilize a Transformer to model inter-agent dependencies by encoding state history.\n\n- Capability to model non-uniform input size based on number of intersections and intersection sizes.\n\n- A Model that can provide competitive performance to baselines without using expensive sensors.",
        "strengths": "- Experiments are done in both simple and complex network designs and show that ththe results are comparable to models that contain more information.\n \n- Lane encoding is clearly presented in Figure 1.\n\n- Utilizing existing Traffic Simulation models to verify the capabilities.",
        "weaknesses": "- It is unclear how the Graph Neural Network is used in this paper.\n\n- Length of the Sequences for the provided results is not mentioned. It is unclear how the transformer based model would perform for longer sequences.\n\n- Page limit is exceeded as per Lines 423 to 427."
      },
      {
        "rating": "3",
        "confidence": "4",
        "summary": "This paper proposes a Traffic Signal Control framework modeled as a multi-agent environment. The proposed framework consists of a Transformer architecture for feature extraction and an MLP for computing the action. The trained policy can be implemented for networks of different size.",
        "strengths": "The paper is well structured and was easy to follow. The problem considered in this manuscript is a very important problem and has been motivated very well in the introduction. The problem description and formulation is adequately. The use of transformer architecture is also well justified.",
        "weaknesses": "1) Clarity of writing and presentation: There are multiple instances where the paper lacks clarity in terms of writing and the meaning can only be understood with someone who are in this domain. \n\n2) Novelty: The paper does not propose any innovative approach. The use of Transformer or Transformer type architectures with RL and MARL is a well-known approach. This paper showcases the implementation of the architecture for the TSC problem.\n\n3) Baseline comparison: There should be a comparison to traditional TSC algorithms such as SCOOT. Without a comparison to traditional baseline methods, it is not possible to infer the effectiveness of the method.\n\n4) The abstract can be more meaningful. The abstract should cover the outline of the paper. But that’s not the case here.\n\n5) What is the 'static' baseline comparison? Please have a formal definition for it.\n\n6) Figure 7b and 7c: it would be nice if a different color palette and markers were used to represent these plots. In its present for it is very difficult to interpret.\n\n7)Font size for all the plots can be increased"
      },
      {
        "rating": "3",
        "confidence": "4",
        "summary": "This work proposes a novel RL framework for large scale traffic signal control, independent of the road network topology, based on the transformer architecture, together with a pipeline for generating diverse environments for this setting.",
        "strengths": "This work addresses an important and challenging setting, traffic signal control. It demonstrates the approach on large-scale settings, with up to 73 agents.",
        "weaknesses": "The work has merits and interesting contributions, but I argue it also has clarity issues and requires additional work on the empirical validation and presentation. I detail below some key issues and point to a few questions that can hopefully guide the future development of this contribution. \n\nThe first remark concerns the problem formulation. The multi-agent setting is defined using the MDP framework (i.e., single-agent setting), but using a joint action space. Should we understand that the MARL setting is approached using a centralised learning paradigm? Also the motivation for learning enriched states using information exchange signals a partially observable setting. I advise to reconsider the mathematical framework, given all these elements. Perhaps a Dec-POMDP [1] is more appropriate? See Q1. \n\n\nFurther clarity issues regards the two stage state encoding:\n- The idea of using PointNet to generate an encoding independent of the road network size is interesting. But one can also argue that lane level information is detailed information, that is not always available. See Q3. \n- It is not clear how exactly the communication is defined as a sequence modeling problem. As far as I understand the transformer further encodes into the state the topology information. See Q4. \n\nFinally, the evaluation was only performed against MAPPO and it is unclear what the 300 mentioned experiments were, since the presented results do not seem to be averaged over multiple runs. There are numerous potential baselines that could strengthen the results: [2, 3, 4]. While the related work was great within the application domain, there is a lot left to explore on the algorithmic side. \n\n[1] Oliehoek, F. A., & Amato, C. (2016). A concise introduction to decentralized POMDPs (Vol. 1). Cham, Switzerland: Springer International Publishing.\n\n[2] Wen, M., Kuba, J., Lin, R., Zhang, W., Wen, Y., Wang, J., & Yang, Y. (2022). Multi-agent reinforcement learning is a sequence modeling problem. Advances in Neural Information Processing Systems, 35, 16509-16521.\n\n[3] Jiang, J., Dun, C., Huang, T., & Lu, Z. Graph Convolutional Reinforcement Learning. In International Conference on Learning Representations 2020.\n\n[4] Sheng, J., Wang, X., Jin, B., Yan, J., Li, W., Chang, T. H., ... & Zha, H. (2022). Learning structured communication for multi-agent reinforcement learning. Autonomous Agents and Multi-Agent Systems, 36(2), 50."
      },
      {
        "rating": "3",
        "confidence": "4",
        "summary": "This paper proposes a multi-agent RL method to enable communication between multiple intersections using sequence modeling. It also introduces a pipeline for dataset and road network generation. It further tries to handle issues with minimal state information.",
        "strengths": "The originality is good. It aims to solve some real-world problems in current traffic signal control research, such as varying network and intersection structures, multi-intersection coordination, and the lack of expensive sensor-captured data.",
        "weaknesses": "* The abstract doesn’t provide enough information about the problem, method, and contributions.\n* Figures 5 and 6 both contain irrelevant parts in the screenshots. Moreover, the authors should use high-definition figures instead of screenshots.\n* It’s not clear what the “difference in vehicle waiting time” means in the reward setting in Line 159.\n* This paper states that one major contribution is the dataset, traffic flow and road network generation. However, how you generate them is not clearly explained.\n* There are not any latest baseline methods for comparison.\n* No uncertainty evaluation for any experimental results. Multiple runs are necessary for model evaluation.\n* The experiments lack comprehensiveness, and the analysis does not provide sufficiently convincing insights.\n* No code or implementation details are provided."
      }
    ],
    "rating_avg": 3.5,
    "confidence_avg": 3.75,
    "decision": "Reject",
    "meta_review": "The paper introduces Traffic Signal Control (TSC) in a multi-agent communication problem. They demonstrate the approach by training on real and randomly generated road networks with varying traffic demands, showing that competitive performance can be achieved even with minimal state information. \n\nReviewers acknowledge the importance and challenge of the traffic signal control setting, noting that the approach is tested on large-scale settings with many agents. However, several reviewers raise concerns about the clarity of presentation, and the novelty of the proposed method. Reviewers also question the formulation of the problem as a Markov Decision Process (MDP), suggesting that a Dec-POMDP might be more appropriate. Additionally, reviewers request a comparison to traditional TSC algorithms and other MARL methods, and request multiple runs. Overall, the reviewers generally agree that there are some interesting ideas, but that there are significant issues with clarity, novelty, and experimental validation that need to be addressed.",
    "author_remarks": "",
    "decision_comment": ""
  },
  {
    "id": "owR9ofvkFQ",
    "title": "MathOdyssey: Benchmarking Mathematical Problem-Solving Skills in Large Language Models Using Odyssey Math Data",
    "authors": [
      "Meng Fang",
      "Xiangpeng Wan",
      "Fei Lu",
      "Fei Xing",
      "Kai Zou"
    ],
    "abstract": "Large language models (LLMs) have significantly advanced natural language understanding and demonstrated strong problem-solving abilities. Despite these successes, most LLMs still struggle with solving mathematical problems due to the intricate reasoning required. This paper investigates the mathematical problem-solving capabilities of LLMs using the newly developed ``MathOdyssey'' dataset. The dataset includes diverse mathematical problems at high school and university levels, created by experts from notable institutions to rigorously test LLMs in advanced problem-solving scenarios and cover a wider range of subject areas. By providing the MathOdyssey dataset as a resource to the AI community, we aim to contribute to the understanding and improvement of AI capabilities in complex mathematical problem-solving. We conduct benchmarking on open-source models, such as Llama-3, and closed-source models from the GPT series and Gemini models. Our results indicate that while LLMs perform well on routine and moderately difficult tasks, they face significant challenges with Olympiad-level problems and complex university-level questions. Our analysis shows a narrowing performance gap between open-source and closed-source models, yet substantial challenges remain, particularly with the most demanding problems. This study highlights the ongoing need for research to enhance the mathematical reasoning of LLMs. \nThe dataset, results, and evaluation code are publicly available.",
    "keywords": [
      "Math",
      "LLMs"
    ],
    "venue": "ICLR",
    "year": 2025,
    "pdf_url": "https://openreview.net/pdf?id=owR9ofvkFQ",
    "forum_url": "https://openreview.net/forum?id=owR9ofvkFQ",
    "reviews": [
      {
        "rating": "3",
        "confidence": "3",
        "summary": "The manuscript presents an original and challenging dataset for mathematical problem-solving, encompassing various subjects and difficulty levels. Then the paper conducts comprehensive examinations on both open-source and closed-source LLMs. The findings reveal that while closed-source models currently lead, open-source models are rapidly catching up, highlighting the competitive landscape of LLM capabilities in mathematical problem-solving.",
        "strengths": "* The paper is well-motivated, as GPT-4o poses a significant challenge to current mathematical benchmarks. The introduction and open-sourcing of high-quality, difficult mathematical problems is a meaningful contribution to the field.\n\n* The dataset features distinct levels of difficulty and sub-domain classifications, which enhance its uniqueness.",
        "weaknesses": "1. The manuscript lacks coverage of important related work and further clarification on the difference and improvements compared to them.\n    * OlympiadBench: A Challenging Benchmark for Promoting AGI with Olympiad-Level Bilingual Multimodal Scientific Problems\n    * Omni-MATH: A Universal Olympiad Level Mathematic Benchmark for Large Language Models\n    * OlympicArena: Benchmarking Multi-discipline Cognitive Reasoning for Superintelligent AI\n    * Have LLMs Advanced Enough? A Challenging Problem Solving Benchmark For Large Language Models\n\n2. There are missing baseline comparisons that are crucial for evaluating the open-source models on the proposed dataset, like Qwen2.5-MATH, DeepSeek-Coder, and so on.\n\n3. It is unclear how the authors ensure that the data has not been previously encountered. If the problems are original, details regarding the creation principles and methodologies should be included in the paper. Additionally, how is the correctness of answers verified? Have the authors conducted cross-validation or sampling tests to ensure reliability? What is the accuracy rate?\n4. The conclusions drawn seem predictable and do not provide substantial insights. Are there fine-grained analyses and interesting findings?"
      },
      {
        "rating": "6",
        "confidence": "3",
        "summary": "The authors identify a need for a mathematics benchmark that spans a wider breadth of topics and difficulties. They propose MathOdyssey, a benchmark that includes hand-written and curated high-school, university, and Olympic-level problems. Each problem has a unique expected answer and detailed reasoning to aid LLM assessment. They demonstrate that the benchmark is not saturated since GPT-4 o1-preview archives ~65% overall. Further, their wide coverage of topics enables the identification of problem topics for LLMs enabling researchers to focus on those areas.",
        "strengths": "+ The proposed benchmark should have a unique answer enabling easier verification of the correct answer.\n+ The problems are crafted specifically for the benchmark avoiding their presence in the pre-training data for LLMs.\n+ The problem space covered in terms of topics and difficulty is wide, allowing the identification of problem areas for further research as well as \"solved\" areas if a topic saturates.",
        "weaknesses": "- Some of the paper language is hyperbolic, for example, S3.1, \"Design Principle.\" Paragraph, L178: \"representing the pinnacle of human intellectual achievement\" is very strong language and am uncertain the authors could substantiate such a claim unless it is an opinion. Another example is S3.1 L234: \"This rigorous process\": The curation process, while I can trust was done rigorously, is not presented in sufficient detail for me to make that assessment, and it would be better to instead tone it down to \"This process facilitates the quality and dependability...\". The paper in general would benefit from a pass that tones down the hyperbolic language to instead focus on the proposed advancements in an objective tone.\n- L256-264 could be replaced with \"Fig. 1 shows the detailed information\". and L266-268 repeat the same information that is already in the figure and could be pointed to.\n- The benchmark claims easy verifiability by code but uses GPT-4 as an evaluator (with the associated errors this induces even if the prompt enables the use of tools).\n- The ease of having a unique answer is counter-balanced by the false positives induced by correct-answer-with-wrong-reasoning."
      },
      {
        "rating": "6",
        "confidence": "5",
        "summary": "The paper aims to investigate and understand LLMs’ strong problem-solving abilities. The paper introduces a novel dataset “MathOdyssey”. The dataset includes a diverse set of mathematical programs at three levels: High school, university and olympiad level. Each category has a wide range of different problem areas such as Algebra, Number Theory, calculus etc. The dataset contains a total of 387 data points and has novel problems created by mathematics professionals, including high school educators, university professors and researchers. Each problem is accompanied by its final answer and its reasoning chain. They also did a comprehensive evaluation of the dataset and tested it on both closed and open models. They used GPT-4 to assist in evaluating the model accuracy, as the dataset contained a wide range of answer types (open answer, MCQ, and true-false). The evaluation shows that the closed source model particularly GPT-4, o1 and GPT-4 Turbo shows strong performance in high school and university-level math. For open-source models such as Llama-3, the results show that the selected open-source models only surpass the performance of GPT3.5 but are also approaching the capabilities of the earlier version of GPT-4.",
        "strengths": "1. Release of a novel dataset that will help the community as this dataset has not been used in the training of existing models.\n2. Comprehensive benching of different models, highlighting their efficiency in solving different categories/areas of problems.\n3. Effective use of GPT-4 for evaluating the accuracy of models. The author employs a prompt-based method and provides scores of various categories.",
        "weaknesses": "1. Even though the dataset provides various categories of questions in different areas, the count of individual categories is very small. For example Number Theory – Olympiad-level accounts for only 4 problems, Differential Equations – University-level for 14 problems etc. So do the authors have any plan to extend the count of problems in these areas?\n2. Even though the dataset does not use any existing problems, a sanity check for data contamination should be done. Experiments from the paper [1] should be added to ensure no data contamination.\n3. Evaluating the dataset using models fine-tuned specifically for solving math problems, such as MathCoder [2] helps show how models trained specifically to solve math problems perform on MathOdyssey.\n\nReference:\n\n[1] : Golchin, Shahriar, and Mihai Surdeanu. \"Time travel in llms: Tracing data contamination in large language models.\" arXiv preprint arXiv:2308.08493 (2023).\n\n[2] : Wang, Ke, et al. \"Mathcoder: Seamless code integration in llms for enhanced mathematical reasoning.\" arXiv preprint arXiv:2310.03731 (2023)."
      },
      {
        "rating": "3",
        "confidence": "4",
        "summary": "This paper presents a new dataset called MathOdyssey, which aims to evaluate the reasoning abilities of large language models (LLMs). The dataset consists of 387 problems, including 148 at the Olympic level, 101 at the university level, and 138 at the high school level. The problems cover several subjects with three answer formats: true/false, multiple choice, and open answers.\n\nThe authors evaluate LLMs' math reasoning performance on MathOdyssey using GPT-4 as the answer judger in a zero-shot manner, providing it with specific instructions. They conduct their experiments with seven closed-source LLMs and one open-source model, Llama-3-70B. Their findings reveal that the Llama-3-70B model still falls short when tackling more complex problems.",
        "strengths": "The proposed MathOdyssey dataset is novel and may be somewhat useful to certain researchers. While it introduces a variety of challenging problems, the experimental results provide a rough indication of the performance of closed-source LLMs. Overall, the dataset and findings suggest potential (but limited) usefulness to offer insights into LLM capabilities in mathematical reasoning, albeit with room for more comprehensive analysis.",
        "weaknesses": "MathOdyssey **offers no clear advantages over existing benchmarks**, which may limit the usefulness and contribution of this paper.\n\n- Compared to existing datasets, MathOdyssey is **limited in size**, containing only 387 problems, whereas datasets like GSM8K and MATH include 1,319 and 5,000 problems, respectively. This limitation might impact the reliability of accuracy in ranking the mathematical reasoning abilities of different LLMs.\n\n- **The \"difficulty levels\" within MathOdyssey are not well-defined**. Although it claims to cover comprehensive levels of math problems, it includes only three educational stages. In contrast, the MathBench [1] dataset offers a wide range of problems, spanning from primary school to university level. By the way, some datasets define the difficulty level as a rating (e.g. an integer number)\n\n- While the authors claim to have diversified answer types, MathOdyssey **only encompasses three distinct answer types**. OlympiadBench [2], however, incorporates a more fine-grained variety of answer types.\n\n- Although MathOdyssey includes several subjects, **the number of testing examples within each subject is relatively small, with many subjects containing fewer than 10 examples**. This limitation may lead to inaccurate analyses across different subjects.\n\n**The experiments are not comprehensive and compelling**:\n\n- The evaluation process is flawed because the authors use GPT-4 as the judge for answers in a zero-shot manner. However, **it is unclear how often this judgment aligns with human evaluators**. An analysis of judgment errors is necessary, and I recommend considering rule-based matching.\n\n- They **include only one open-source LLM, Llama-3-70B** in experiments, which is not comprehensive. The authors should include more open-source LLMs, including both general-purpose chat models and math-specialized LLMs.\n\n- The results and analysis are not compelling, as the reliability of GPT-4's judgment is uncertain. Additionally, **conducting an error analysis could provide valuable insights into how LLMs get wrong in solving math problems**.\n\n\nThis paper **is poorly written** and either **lacks important details or makes inaccurate claims or claims without proper citations** (see Questions).\n\n\n[1] Liu, H., Zheng, Z., Qiao, Y., Duan, H., Fei, Z., Zhou, F., ... & Chen, K. (2024). MathBench: Evaluating the Theory and Application Proficiency of LLMs with a Hierarchical Mathematics Benchmark. arXiv preprint arXiv:2405.12209.\n\n[2] He, C., Luo, R., Bai, Y., Hu, S., Thai, Z. L., Shen, J., ... & Sun, M. (2024). Olympiadbench: A challenging benchmark for promoting agi with olympiad-level bilingual multimodal scientific problems. arXiv preprint arXiv:2402.14008."
      }
    ],
    "rating_avg": 4.5,
    "confidence_avg": 3.75,
    "decision": "N/A",
    "meta_review": "",
    "author_remarks": "",
    "decision_comment": ""
  },
  {
    "id": "vVlNBaiLdN",
    "title": "ESMGain: Effective and Efficient Prediction of Mutation’s functional Effect via ESM2 Transfer Learning and robust Benchmarks",
    "authors": [
      "Moritz Glaser"
    ],
    "abstract": "Functional effect prediction of mutations, especially for properties like catalytic activity, holds greater significance for clinicians and protein engineers than traditional pathogenicity predictions. Recent approaches leveraging static ESM1 embeddings or multimodal features (e.g. embeddings, structures, and evolutionary data) either (1) fall short in accuracy or (2) involve complex preprocessing pipelines. Moreover, functional effect prediction suffers from (3) a lack of standardized datasets and metrics for robust benchmarking. We address these challenges by systematically optimizing ESM2-based functional effect prediction: Through extensive ablation studies, we demonstrate that fine-tuning significantly outperforms static embeddings, scaling laws for model size are non-transferable and LoRA matches full fine-tuning performance, deviating from trends observed in natural language processing. Our framework, ESM-Effect, fine-tunes 35M ESM2 layers with an inductive bias regression head achieving state-of-the-art performance. It slightly surpasses multimodal competitor PreMode indicating redundancy in structural and evolutionary features. We further propose a benchmarking framework featuring robst test datasets and strategies, and the relative Bin-Mean Error (rBME), as a metric designed to emphasize prediction accuracy in challenging, non-clustered, and rare gain-of-function regions. rBME better reflects model performance compared to commonly used Spearman’s rho, as evidenced by improved plot-based analyses. As ESM-Effect exhibits mixed transferability to different unseen mutational regions, we identify multiple areas for improvement such as finer-grained pretraining strategies.",
    "keywords": [
      "protein",
      "language model",
      "deep learning",
      "biology",
      "gain of function",
      "enzyme"
    ],
    "venue": "ICLR",
    "year": 2025,
    "pdf_url": "https://openreview.net/pdf?id=vVlNBaiLdN",
    "forum_url": "https://openreview.net/forum?id=vVlNBaiLdN",
    "reviews": [
      {
        "rating": "3",
        "confidence": "4",
        "summary": "This paper introduces a method for fine-tuning protein language models, specifically ESM2, using deep mutational scanning (DMS) data. The fine-tuning process involves generating both local and global representations of the reference and mutant protein sequences by utilizing separate, mostly frozen ESM models for the two sequences. These representations are combined and passed through a two-layer linear neural network to predict quantitative measurements from a DMS assay.\n\nFurther, the authors propose two modifications to the evaluation of fine-tuned models. First, they recommend fine-tuning models on one protein and testing them on a different protein within the same family, rather than using held-out positions from the original protein. Second, they suggest calculating correlation metrics separately for LoF, neutral, and GoF mutations. These separate correlation scores are then combined using a harmonic mean to produce a single protein-level metric.",
        "strengths": "1. The authors introduce important ideas for better evaluating fine-tuned models: (a) evaluating models on completely held out proteins and (b) developing a metric that prioritizes performance on LoF and GoF variants over neutral variants.\n2. Their fine-tuning approach demonstrates superior performance compared to existing methods, such as PreMode and augmented versions of unsupervised models.\n3. Through ablation studies, the authors establish that using larger versions of ESM2 does not significantly improve performance and that employing separate models for reference and mutant sequences provides some benefits.",
        "weaknesses": "1. Limited dataset evaluation: The authors do not evaluate their method on the large compendium of DMS datasets that are available in ProteinGym (217 datasets covering 2.5 million mutations), instead focusing on only 5 datasets (Figure 2). To convincingly prove that their fine-tuning approach outperforms existing methods, they should expand their analysis to more datasets.\n\n2. Insufficient comparison to existing fine-tuning approaches: PreMode and augmented unsupervised models are not the only approaches that have been proposed to fine-tune protein language models on DMS datasets. See https://www.nature.com/articles/s41467-024-51844-2 and https://arxiv.org/pdf/2405.06729. These papers explore strategies such as parameter-efficient fine-tuning and fine-tuning jointly on multiple DMS assays that this paper does not consider. In particular, the approach proposed in the second paper listed above shows improved performance on entirely held out proteins, which is in stark contrast to the poor generalization to new proteins exhibited by ESMGain in Fig. 4. \n\n3. While the idea to compute separate correlation metrics for LoF, neutral, and GoF variants is clever, the method of dividing variants into these categories by splitting the ground-truth scores into thirds is arbitrary. A more robust method, such as a Gaussian mixture model with three components, could provide a more principled assignment of variants to these classes."
      },
      {
        "rating": "3",
        "confidence": "3",
        "summary": "This work proposed a method called ESMGain to use fine-tuning ESM2 with a custom regression head incorporating inductive biases and enable the application of learned protein semantics to functional effect prediction. This method outperforms state-of-the-art competitor PreMode on deep mutational scans from three different enzymes.",
        "strengths": "1. The proposed method performs the best for functional effect prediction in the dataset.\n2. The methodology of ESMGain can predict functional effects without the limitation of feature redundancy and task specificity.",
        "weaknesses": "1. The organization needs improvement. Some terms like \"PTEN\" didn't have full names. The size of font in those figures is too small to read and is not consistent. The section 7 should be in the section of the experiential setup.\n2. In Fig4, \"LoF, Neutral and GoF\" in captions should be the same as the text in x axis of figure. How about the performance in all other baselines like competitor PreMode in Fig4?\n3. Have you conducted multiple train-test split seeds in ablation study of ESMGain? Why the result of the original ESMGain in the ablation study is different from the one in Fig2? Do they use different datasets or strategies to train and test?"
      },
      {
        "rating": "3",
        "confidence": "4",
        "summary": "The paper proposes a novel model method  ESMGain for predicting the functional impact of protein mutations, expanding addressing limitations in existing binary pathogenicity predictors. By fine-tuning ESM2 embeddings with a custom regression head, ESMGain aims to accurately classify mutations as loss-of-function, neutral, or gain-of-function. Through evaluations  in catalytic activity prediction tasks, ESMGain outperforms the state-of-the-art baselines by leveraging only ESM2 embeddings. Besides, the authors propose a new benchmarking framework for functional effect prediction, emphasizing cross-protein generalization tests within the same protein family. A Harmonic Spearman metric is also introduced to balance performance evaluation across mutation effect categories.",
        "strengths": "1) The paper is well-structured and clearly written.\n\n2) The proposed method achieves state-of-the-art performance on selected datasets in functional effect prediction.\n\n3) By employing two independent ESM2 models to embed wildtype and mutant sequences separately, the paper addresses potential information loss in mutation representation, enhancing the model’s ability to capture subtle differences. Ablation studies demonstrate that only using ESM2 embeddings effectively captures most of the relevant information on DMS datasets,  effectively reducing the reliance on additional data modalities.\n\n4) The paper proposes a novel benchmarking framework for functional effect prediction incorporates a cross-protein generalization test within the same protein family.",
        "weaknesses": "1) The novelty of this paper is limited. The use of dual ESM2 embeddings to separately represent wildtype and mutant sequences, along with the introduction of the Harmonic Spearman metric to address label imbalance, appears more incremental than groundbreaking.\n\n2) It seems that the motivation of the proposed benchmarking framework is underdeveloped. While focusing on cross-protein generalization within the same family is technically interesting, it lacks a clear connection to real-world situations where this type of evaluation would be essential.\n\n3) While ESMGain performs well on the tested DMS data, its generalization to other samples within the same protein family is weak (cross-family tests). The model may be overfitting in the specific training proteins."
      },
      {
        "rating": "3",
        "confidence": "4",
        "summary": "The paper introduces a method for mutation effect prediction. The method relies on two ESM2 heads for generating protein sequence embeddings, one used with wildtype sequences and the other one for the mutated sequences. On top of the embeddings a custom regression head is trained. The technical novelty of the method is their design of the regression head and the fact that the two ESM2 models have different weights one fine-tuned for wildtype sequences and the other for the mutated sequences. Other contributions claimed by the paper are towards better bencharking (i) testing generalization of the models fine-tuned on one protein by testing them on a different protein from the same family and (ii) introduction of “Harmonic Spearman” as a new metric.",
        "strengths": "1. The generalization test is of interest. In Figure 3, authors show the different distribution of labels for two different proteins from the same family and convincingly show why generalization between proteins (even in the same family) is not easy.",
        "weaknesses": "1. Paper is poorly structured, making it very hard to read:\n\n\t- Introduction contains contents which would better fit to related work or background (“Notably, PreMode was pre-trained to predict the binary measurement of “pathogenicity” for 4.7 million mutations and uses AlphaFold2 predicted protein structure, Multiple Sequence Alignments (MSAs) and pre-trained ESM2 650M embeddings as features (John Jumper, 2021).”) And it also presents some results and their discussion (“That leads us to hypothesize that the signal provided by protein structure, MSAs, and embeddings is largely redundant for the task of effect prediction. PreMode’s ablation studies show minimal performance drop when any of these modalities is ex- cluded, suggesting that they capture overlapping information for functional effect prediction. This explains ESMGain’s superior performance in turn: its fine-tuned embeddings are task-specific and the single modality avoids the redundancy.”). I suggest honoring the usual structure of the paper and using introduction just for motivation and a very brief (not so detailed) teaser for the contributions of the paper.\n\n    - Chapter 4, which should be describing the technical novelty and the method does not provide that many details, for example Figure 1 illustrating the method is never referenced in the text. I suggest to use a figure and equations to better describe the regression head, instead of the textual description at the end of section 4.2.\n\n    - No table summarizing results. The reported numbers are scattered across text and some figures, making it very hard to get a glimpse of the results. I suggest a more transparent summarization of the results, such as by using a table.\n\n2. Poor formatting of the paper.\n\n    - Authors are not economical with the space by being sometimes too verbose, repetitive in repeating their contributions or for example by wasting the whole first page just on abstract. Being more economical would enable the authors to make bigger figures which have too small fonts and are hard to read. I suggest making figure large enough so the fonts can be legible. \n\n    - References are poorly formated. Some references starting with “…”. AlphaFold referenced as “(John Jumper, 2021)” - note that AlphaFold was a collective effort. I suggest proper citing and formatting of references.\n\n3. Insufficient literature survey. Authors only have 13 references. I suspect authors were trying to fit into the page limit of 10 pages including references - this is not necessary references dont count in the page limit. I suggest making proper literature survey and crediting relevant work. For example, I miss the reference to ProteinGym, arguably one of the most influential benchmarks in this area.\n\n4. Insufficient benchmarking. Authors only focus on the comparison to PreMode (which was still not peer reviewed) and only compare on 5 proteins. I suggest to compare for example to AlphaMissense as well.\n\n5. The key contribution of having separate ESM2 heads for wildtype and for the mutated sequence is questionable. Authors claim this to give them the key improvement by the underlying inductive bias. To me it is not clear how to decide what is wildtype and what is mutation. What if the mutation is adopted by evolution and becomes the “new wildtype” and then gets mutated again? There is no fundamental reason to distinguish between the sequences. So I believe that using the distinction between the sequences based on the dataset definition and then adapting the two heads to this definition only leads to overfitting to the dataset, potentially explaining any benefit gained from these separate heads. I dont have a concrete suggestion how to prove authors point, because I think the point is wrong. If authors stand by their point they should present convincing evidence supporting that their “inductive bias” is not just overfitting to the dataset definition of what is wildtype and what is mutation.\n\n6. The model seems to improve over PreMod on just 2-3 out of 5 proteins (Figure 2), this does not seem very convincing. My suggestion would be to get other datasets (maybe something relevant could be found in ProteinGym) and show improvement on other dataset as well.\n\n7. The Harmonic Spearman is just introduced at the end of the paper and not motivated well enough. Could authors explain the choice of using harmonic average? Could authors clearly compare harmonic spearman to normal spearman? How does it change the evaluation of all the benchmarked models? A table summarizing the results (as suggested in Weak point 1) would help.\n\n\nI suggest to reject this paper for the following reasons. (i) The paper is not is well placed in literature, comparison to AlphaMissense is missing and the survey of the related work is not sufficient. (ii) The key contribution of using two separate ESM2 models for the wildtype and the mutated sequence is questionable and the claim of bringing a useful inductive bias is not supported by strong evidence, the improvement coming from this choice might be due to overfitting to the dataset definition of what is mutant and what is original sequence. (iii) The results dont seem as strong, only showing improvement for 2-3 out of 5 proteins. More convincing evaluation using other dataset would be necessary. (iv) The technical novelty of separate fine-tuning of two ESM models with a custom regression head is limited. (v) The writing is poor, making it hard for the reader to asses the contributions, the results of the method and its placement in the literature."
      }
    ],
    "rating_avg": 3.0,
    "confidence_avg": 3.75,
    "decision": "Reject",
    "meta_review": "The paper considers the problem of functional effect prediction and develops an ESM2-based framework that is tailored to this task through ablation studies.\n\nThe paper provides interesting insights such as the conclusions drawn from the ablation studies and the resulting framework outperforms comparison approaches. However, all reviewers agree that the approach is of limited novelty. It is therefore critical to provide a high-quality evaluation, where none of the results can be questioned and where all conclusions are clearly presented. \n\nThe reviewers made excellent suggestions, e.g. concerning potential bias resulting from the use of separate ESM2 heads, regarding generalization test, regarding scores, etc. Towards this goal, the authors have made substantial revisions to the manuscript, which require a new cycle of reviews.",
    "author_remarks": "",
    "decision_comment": ""
  },
  {
    "id": "FYvZCwdb6F",
    "title": "MOMENTUM MEETS VIRALITY: A NOVEL METRIC FOR UNMASKING SOCIAL BIAS IN VIRAL TWEETS",
    "authors": [
      "Nihar Ranjan Sahoo",
      "Arif Ahmad",
      "Nishtha Madaan",
      "Pushpak Bhattacharyya"
    ],
    "abstract": "Predicting which social media posts will go viral is a critical but complex task in the field of computational social science. Previous studies have utilized various measures to forecast the virality of tweets or Facebook posts, but these approaches exhibit limitations, particularly in the absence of a virality metric that specifically considers social biases. In this paper, we test existing metrics and introduce a new metric, $\\textbf{ViralTweet Score (VTS)}$, inspired by principles of momentum from physics to better predict a tweet's virality given that it consists of social biases. We compare this new metric with others, highlighting the advantages and disadvantages of each of them as a virality measurement metric. We release the $\\textbf{ViralTweets Dataset}$ with $\\mathbf{88.8k}$ Hindi tweets and corresponding virality labels based on our VTS metric. We also show how social biases in posts can influence their potential to go viral. We test our hypothesis that VTS is a better metric using two methodologies and we show how VTS achieves an F1 score of 0.87 based on pairwise evaluation methodology and an overall F1 score of 0.58 based on our clustering-based verification methodology. Our work offers a novel metric for understanding tweet virality for biased tweets and opens the door for more equitable and effective social media analytics by considering the role of social biases in virality.",
    "keywords": [
      "Social bias",
      "Tweet virality",
      "ViralTweetScore",
      "Hindi Tweets",
      "Tweets"
    ],
    "venue": "ICLR",
    "year": 2025,
    "pdf_url": "https://openreview.net/pdf?id=FYvZCwdb6F",
    "forum_url": "https://openreview.net/forum?id=FYvZCwdb6F",
    "reviews": [
      {
        "rating": "3",
        "confidence": "4",
        "summary": "**Summary**\nThe paper explores tweet virality through a metric, ViralTweet Score (VTS), designed to better predict which tweets go viral, particularly those with social biases.\n\nKey contributions are:\n\n* ViralTweet Score (VTS): VTS measures virality by tracking the spread momentum of tweets over time, factoring in likes and retweets weighted by user follower count. This approach relies on the speed and extent of engagement in addition to static metrics like total likes or retweets.\n\n* ViralTweets Dataset: The authors released a dataset of 88.8k Hindi tweets, labeled with binary bias indicators, categories of bias, and toxicity markers, to study social bias in social media virality. Labels were assigned using multiple different models including LLMs and human annotation for quality control.\n\n* Social Bias in Virality: The study focuses on social biases inherent in viral tweets, such as biases related to gender, religion, caste, and politics, which are prevalent in Indian social media content. The authors examine whether biased tweets exhibit higher virality, using VTS as the primary measurement tool.",
        "strengths": "**Originality**\n* VTS: By focusing on the rate of engagement growth (velocity) and using user follower count (mass), VTS captures virality dynamics more effectively than static metrics like total likes or retweets.\n\n**Significance**\n* Practical Relevance: Given the increasing concerns over misinformation and biased content on social media, the study’s insights are timely. VTS could help platforms and researchers identify harmful content trends more accurately.\n\n* Focus on Social Bias: The paper addresses the socially impactful issue of bias in viral content. By measuring how bias may amplify virality, the study provides valuable insights for understanding the propagation of biased content on social media.\n\n**Clarity**\n* Writing and Organization: The paper is organized logically with minimal grammatical errors, moving from an introduction of the problem to the proposed solution, methodology, experiments, and results. Each section is well-defined, making it easy for readers to follow the research journey. I appreciate authors mentioned the filtering methodology used to filter from 9.24M tweets.",
        "weaknesses": "**Evaluation and Results**\n \n* Lack of baselines: Although VTS outperforms some traditional metrics (likes, retweets), it lacks benchmarks from other studies and comparable metrics, even though some of them might be referenced. I advise the authors to include benchmarks from other similar studies on virality prediction [1, 2, 3] to see how VTS compares against them.\n\n* Lack of latest related works: Recent research has moved significantly beyond purely text-based approaches, incorporating multi-modal data for virality prediction [4, 5]. The paper should compare and mention the advantages of their study relative to some of the deep learning-based approaches.\n\n* VTS score analysis with bias clusters: The results section lacks any detailed evaluation of VTS scores in relation to bias. The study simplifies bias by categorizing tweets as either \"biased\" or \"non-biased,\" without distinguishing between different types of biases (e.g., gender, religion, caste). This binary approach may obscure insights into how specific biases impact virality differently, limiting the granularity of the results. The study should provide a detailed analysis of different types of bias clusters and how they interact with virality. The authors should also discuss the limitations of VTS for different types of biases.\n\n* Lack of generalizability :The study focuses solely on Hindi tweets, which limits the generalizability of the VTS score. The result evaluation should be conducted across multiple languages and regions to assess the value of the VTS score in broader contexts.\n\n* Limited analysis of false positives and negatives: While the paper provides precision, recall, and F1 scores for its metrics, it lacks an in-depth analysis of false positives and false negatives in bias and virality classification. An error analysis could highlight specific areas where VTS or the bias detection model falls short, such as overestimating virality for certain topics or missing nuanced biases.\n\n**Novelty**\n\n* The novelty here lies in how the study tailors VTS to biased content and the Hindi social media context. The VTS itself is more of a refinement of existing temporal models.\n\n* Other studies [6] have evaluated the spread of misinformation and biases on social media. The paper should attempt to distinguish or specify challenges related to these studies.\n\n\n[1] Kwak, Haewoon, et al. \"What is Twitter, a social network or a news media?.\" Proceedings of the 19th international conference on World wide web. 2010.\n\n[2] Goel, Sharad, et al. \"The structural virality of online diffusion.\" Management science 62.1 (2016): 180-196.\n\n[3] Weng, Lilian, Filippo Menczer, and Yong-Yeol Ahn. \"Virality prediction and community structure in social networks.\" Scientific reports 3.1 (2013): 1-6\n\n[4] Gao, Liqun, et al. \"Public opinion early warning agent model: A deep learning cascade virality prediction model based on multi-feature fusion.\" Frontiers in Neurorobotics 15 (2021): 674322.\n\n[5] Zhang, Xuan, and Wei Gao. \"Predicting viral rumors and vulnerable users with graph-based neural multi-task learning for infodemic surveillance.\" Information Processing & Management 61.1 (2024): 103520.\n\n[6] Vosoughi, Soroush, Deb Roy, and Sinan Aral. \"The spread of true and false news online.\" science 359.6380 (2018): 1146-1151."
      },
      {
        "rating": "5",
        "confidence": "3",
        "summary": "This paper tests existing metrics and introduce *ViralTweet Score (VTS)* to predict tweet's virality with a specific focus on social biases. VTS incorporates engagement growth over time to capture \"momentum\", offering a more dynamic perspective on virality in biased tweets. The authors also release the dataset and corresponding virality labels. Compared to traditional metrics, VTS more accurately predicts virality and provides insights into how social biases shape online discourse, with implications for more responsible and equitable social media analytics.",
        "strengths": "1. This paper introduces a novel metric for capturing the \"momentum\" of engagement, which provides a new view of virality based on the rate of engagement growth over time.\n2. This paper links virality with social biases, which focuses on understanding how biased content can spread quickly on platforms and provides valuable insights into societal impacts and the role of bias in information dissemination.\n3.  The paper employs both supervised and unsupervised methods to validate the effectiveness of VTS, including pairwise tweet comparisons and clustering techniques. This dual approach strengthens the evaluation of VTS, showing its effectiveness across different predictive contexts.\n4. Open source the dataset, which will definitely promote relevant research in this area.",
        "weaknesses": "1. Lack of a detailed codebook for bias labels: The paper relies on social bias categories like gender, caste, and religion, but it does not provide a clear and detailed codebook or criteria for how these biases were defined and identified, especially by human annotators. \n2. A little bit of over-reliance on follower count: The use of follower count as the “mass” component in VTS could bias the score towards tweets from popular accounts, which might overshadow the organic virality of tweets from less popular users.\n3. Too few case studies: This paper identifies how biased tweets can become viral, but it does not delve into the practical implications of this finding, such as how VTS might inform moderation practices on social media platforms."
      },
      {
        "rating": "1",
        "confidence": "4",
        "summary": "This manuscript addresses the challenge of predicting social media post virality by introducing the \"ViralTweet Score (VTS).\" It presents the viraltweets dataset, comprising approximately 89,000 Hindi tweets with labels gathered in 2019. The primary goal is to investigate the factors driving tweet virality in the Indian context and to explore whether virality links to social biases within the tweet. The VTS is proposed as a more effective measure of tweet virality, revealing a correlation between virality metrics and the biases present in the tweets.",
        "strengths": "- The study of what goes virality is important for understanding the current social communication landscape and societal problems. \n\n- Non-english social media dataset is rarer and valuable.",
        "weaknesses": "- I believe that the manuscript is not a good fit for the ICLR conference because the central contribution of the paper is the ViralTweet Score (VTS) -- a hand-crafted score to measure the virality of tweets. Thus, I cannot see meaningful contribution to the field of representation learning. Although the study uses some LLMs, but the usage is rather secondary and not the main focus of the paper.\n\n- Data collection procedure is not described in enough details. For instance, it is not clear how the initial 9.24 million tweets were selected. Was it from the streaming API or search API? How was the Hindi language tweets detected?\n\n- The dataset includes only tweets with interactions from four specific dates—likely capturing many viral tweets, but too limited to adequately represent non-viral tweets, which could be valuable as negative or control data points."
      },
      {
        "rating": "3",
        "confidence": "4",
        "summary": "This study proposed a new metric, ViralTweet Score (VTS), to measure the virality of tweets. It was designed to capture multiple aspects of a tweet and their evolution over time. This study also proposed a dataset containing 88.8k Hindi tweets associated with VTS.",
        "strengths": "(1) This study touched on an important research topic.\n\n(2) The manuscript is easy to follow.",
        "weaknesses": "(1) The size of the original dataset was 9.24 million. In the end, only 88.8k tweets were preserved. Would there by any selection biases during data preprocessing? The size was significantly reduced (7 million to 200 thousand) after removing tweets that did not have time-series data spanning over one day. It suggests that the remaining tweets were popular. Would this introduce biases? Next, only tweets with at least four distinct time-series data points were kept. Did this suggest that the proposed metric might not generalize well?\n\n(2) The motivation of the study does not seem clear. In sections 3.2 and 3.3, the authors discussed content virality and virality metrics. However, it is unclear to me why the existing metrics were not good enough so that a new metric had to be proposed.\n\n(3) The Cohen's Kappa between models and humans is low.\n\n(4) Some text descriptions did not seem to align with the tables they referred to. \"These tweets are distributed across various categories of social biases, as shown in Table 5 of Appendix A.\" However, Table 5 only shows the total number of unique tweets, average likes, retweets, replies, and number of time series points per tweet in the dataset. It did not relate to categories of social biases.\n\n(5) In section 4.2, the authors discussed bias label, however, the definition of such bias was never provided. It was only until Section 4.4, the authors provided examples of the bias categories. However, why were they considered biases? Categories such as gender, religion, and race are features. It is not novel to include these additional features to improve virality prediction. There have been many efforts [1].\n\n(6) No baseline metrics except for likes, and retweets were compared to justify the effectiveness and novelty of the proposed metric. VTS was computed based on likes and retweets. It is not surprising that it is better than either of its components. However, the performance difference is not large even comparing VTS with likes or retwets.\n\nReferecnes:\n\n[1] Han Y, Lappas T, Sabnis G. The importance of interactions between content characteristics and creator characteristics for studying virality in social media. Information Systems Research. 2020."
      }
    ],
    "rating_avg": 3.0,
    "confidence_avg": 3.75,
    "decision": "N/A",
    "meta_review": "",
    "author_remarks": "",
    "decision_comment": ""
  },
  {
    "id": "Hw1tOjCWBZ",
    "title": "KARPA: A Training-free Method of Adapting Knowledge Graph as References for Large Language Model's Reasoning Path Aggregation",
    "authors": [
      "Siyuan Fang",
      "Kaijing Ma",
      "Tianyu Zheng",
      "Xeron Du",
      "Ningxuan Lu",
      "Ge Zhang",
      "Qingkun Tang"
    ],
    "abstract": "Large language models (LLMs) demonstrate exceptional performance across a variety of tasks, yet they are often affected by hallucinations and the timeliness of knowledge. Leveraging knowledge graphs (KGs) as external knowledge sources has emerged as a viable solution, but existing methods for LLM-based knowledge graph question answering (KGQA) are often limited by step-by-step decision-making on KGs, restricting the global planning and reasoning capabilities of LLMs, or they require fine-tuning or pre-training on specific KGs. To address these challenges, we propose Knowledge graph Assisted Reasoning Path Aggregation (KARPA), a novel framework that harnesses the global planning abilities of LLMs for efficient and accurate KG reasoning on KGs. KARPA operates through a three-step process: pre-planning, retrieving, and reasoning. First, KARPA uses the LLM's global planning ability to pre-plan logically coherent relation paths based on the provided question and relevant relations within the KG. Next, in the retrieving phase, relation paths with high semantic similarity to the pre-planned paths are extracted as candidate paths using a semantic embedding model. Finally, these candidate paths are provided to the LLM for comprehensive reasoning. Unlike existing LLM-based KGQA methods, KARPA fully leverages the global planning and reasoning capabilities of LLMs without requiring stepwise traversal or additional training, and it is compatible with various LLM architectures. Extensive experimental results show that KARPA achieves state-of-the-art performance in KGQA tasks, delivering both high efficiency and accuracy.",
    "keywords": [
      "Knowledge Graph",
      "Large Language Models",
      "Chain-of-Thought",
      "Reasoning"
    ],
    "venue": "ICLR",
    "year": 2025,
    "pdf_url": "https://openreview.net/pdf?id=Hw1tOjCWBZ",
    "forum_url": "https://openreview.net/forum?id=Hw1tOjCWBZ",
    "reviews": [
      {
        "rating": "3",
        "confidence": "4",
        "summary": "The framework operates through a three-step process: pre-planning, retrieving, and reasoning. KARPA is designed to address the limitations of existing LLM-based KGQA methods by fully utilizing the global planning and reasoning capabilities of LLMs without requiring stepwise traversal or additional training. The paper claims that KARPA achieves state-of-the-art performance in KGQA tasks, offering both high efficiency and accuracy.",
        "strengths": "- The three-step process of pre-planning, retrieving, and reasoning is a easy-to-fellow approach to leverage external knowledge sources for enhancing LLMs.\n\n- KARPA's training-free nature is an advantage, as it allows for easy integration with various LLM architectures without the need for fine-tuning or pre-training on specific KGs, which can be time-consuming and resource-intensive.",
        "weaknesses": "- To my knowledge, The proposed method lacks novelty; employing an agent-based approach for KGQA tasks is not particularly innovative.  For instance, RoG recently introduced a planning-retrieval-reasoning framework for KGQA, and  this manuscript is the expansion of the planning phase in RoG's framework into two processes: pre-planning and re-planning. \n\n- Secondly, the authors claim in their motivation that \"Pre-training or fine-tuning the LLM for KGQA, which is prone to hallucinations and struggles to adapt to unseen KGs without an extensive training process.\" I believe this is a point worth discussing. Taking RoG as an example again, it did employ instruction-tuning for the LLM, but I think such instruction-tuning for LLMs possesses a certain ability to learn from few samples, meaning that generalization can be reflected in the mitigation of hallucinations. Of course, I also feel that this is worth experimenting with and discussing further.\n\n- Considering the forward-looking nature of RoG in initially proposing the planning-retrieval-reasoning approach, it is somewhat unfair that this manuscript did not use the same large model as a backbone in its comparison with RoG (Table 1).\n\n- There is a noticeable absence of robust agent-like methods, such as Interactive-KBQA, which directly perform inference over KGs with LLMs."
      },
      {
        "rating": "5",
        "confidence": "4",
        "summary": "The paper proposes Knowledge graph Assisted Reasoning Path Aggregation (KARPA), a novel framework that harnesses the global planning abilities of LLMs for efficient and accurate KG reasoning on KGs. KARPA operates through a three-step process: pre-planning, retrieving, and reasoning.",
        "strengths": "The idea is reasonable. The paper clearly describes their model.",
        "weaknesses": "1. The comparison in Table1 is unfair, the baseline all use 3-7B LLM but the proposed model uses GPT. The proposed model heavily depends on the output of the LLMs. Whether the authors have tried the effect of using 7B LLMs.\n\n2. The claimed \"training-free\" contribution comes from the pre-trained LLMs and relies on the ability of LLMs. Therefore, KARPA lacks substantive technical contributions.\n\n3. For a specific problem, what if the path given by LLM does not match the knowledge graph? In the face of diverse query problems, how can the output of LLM remain effective? In this sense, ToG may be more realistic and efficient."
      },
      {
        "rating": "5",
        "confidence": "4",
        "summary": "This paper proposes KARPA, a training-free KGQA method that utilizes LLMs to reason over KGs. KARPA uses a pre-planning step to extract candidate relation paths in a three-stage manner (initial planning, relation extraction, and re-planning) and ranks top candidates in the later reasoning step. The main difference between KARPA and previous LLM x KGQA methods (e.g. ToG and Pangu) is that KARPA is more efficient in LLM usage as it avoids the stepwise interaction between LLM and KG, and yet achieves superior performance. Regarding the experimental results, KARPA consistently outperforms baseline methods on WebQSP and CWQ datasets.\n\nDespite these strengths, KARPA also exhibits several limitations. First, KARPA relies heavily on LLM's planning and reasoning abilities since it needs LLM to propose candidate relation paths or rank candidates in one single call, which may be harder to succeed when the candidate subgraph is complex and large. Second, in the pre-planning stage, KARPA uses a traditional sentence transformer to embed relations and calculate similarity, which may fail in multilingual scenarios (for example, the initial relations proposed by LLM is English, but the relation surface form in KG is Chinese). Overall, I may doubt the performance of KARPA on more complex KG (larger subgraphs, more relations) and multilingual scenarios.",
        "strengths": "- The proposed method is well-motivated and reasonable under certain scenarios.\n- The presented experimental results are strong.",
        "weaknesses": "- KARPA relies heavily on LLM's planning and reasoning abilities since it needs LLM to propose candidate relation paths or rank candidates in one single call, which may be harder to succeed when the candidate subgraph is complex and large.\n- In the pre-planning stage, KARPA uses a traditional sentence transformer to embed relations and calculate similarity, which may fail in multilingual scenarios (for example, the initial relations proposed by LLM is English, but the relation surface form in KG is Chinese). \n- Some experiment details are not clear enough. See questions."
      },
      {
        "rating": "5",
        "confidence": "4",
        "summary": "The paper addressed the task of KGQA and focused on the LLM-based method. The paper proposed a knowledge graph-assisted reasoning path aggregation approach, which contains three main steps: pre-planning, retrieving and reasoning. The proposed approach employs LLM and heuristic value-based relation path retrieval to extract potential relational paths for the questions. At last, the extracted candidate paths are provided to the LLM for reasoning. The results show the effectiveness of the proposed approach.",
        "strengths": "1. The proposed heuristic value-based relation path retrieval method is interesting to compute the semantic similarity between paths with different lengths. \n2. The experimental comparisons with baselines on KGQA show the effectiveness.",
        "weaknesses": "1) The Figure 1 is not very clear. Totally, there are two limitations for different previous methods: 1) local search strategies and 2) struggle with unseen KGs. I am not sure how the proposed method could resolve the aforementioned limitations. In specific, how about the performance of unseen KGs? Why the simple embedding-based semantic similarity, such as beam search deduce suboptimal answers?\n\n2) The advantage of the proposed heuristic value-based relation path retrieval method is to compute the semantic similarity between paths with different lengths. Why do we need to extend relation paths with different lengths? The authors should exploit some experiments to prove it.\n\n3) I wonder how about the performance when the given KG is not in the scope of LLM training sets. The used WebQSP and CWQ datasets, in my opinion, have been seen when pre-training LLMs."
      },
      {
        "rating": "5",
        "confidence": "4",
        "summary": "The paper introduces a novel framework called KARPA designed to enhance the reasoning capabilities of LLMs in Knowledge Graph Question Answering (KGQA) tasks. The authors identify limitations in existing methods that either rely on step-by-step traversal of KGs, which restricts the global planning abilities of LLMs, or require fine-tuning on specific KGs, making them less adaptable.\n\nKARPA addresses these challenges through a three-step process: \n(1) Pre-planning: The LLM generates initial relation paths based on the question and relevant KG relations, leveraging its inherent global reasoning and planning capabilities.\n(2) Retrieving: A semantic embedding model is used to find candidate paths in the KG that are semantically similar to the LLM-generated paths, avoiding local optima and reducing interactions with the KG.\n(3) Reasoning: The candidate paths and corresponding entities are provided back to the LLM for comprehensive reasoning to produce the final answer.\n\nThe framework operates in a training-free manner, making it adaptable to various LLM architectures without additional fine-tuning or pre-training. Experimental results demonstrate that KARPA achieves state-of-the-art performance on multiple KGQA benchmark datasets, delivering both high efficiency and accuracy.",
        "strengths": "- By eliminating the need for fine-tuning or pre-training on specific KGs, KARPA offers a flexible and adaptable solution compatible with various LLMs.\n- KARPA reduces the number of interactions between the LLM and the KG, enhancing efficiency without compromising accuracy. Moreover, the semantic embedding-based retrieval mitigates the risk of the LLM getting trapped in locally optimal solutions, leading to more effective exploration of KGs.\n- KARPA fully leverages the LLM's global reasoning and planning abilities, enabling it to generate comprehensive relation paths beyond adjacent relations.",
        "weaknesses": "- The experimental evaluation is focused on KGQA tasks; the framework's effectiveness on other knowledge-intensive tasks remains unaddressed.\n- KARPA assumes access to comprehensive and accurate KGs, but the performance may degrade with incomplete or noisy KGs. Further, the effectiveness of KARPA may vary across different domains, especially if the KG lacks sufficient coverage of the required knowledge.\n- The retrieval of candidate paths depends heavily on the quality of the semantic similarity measures used in the embedding model, which may affect the overall performance if the embeddings are not optimal."
      }
    ],
    "rating_avg": 4.6,
    "confidence_avg": 4.0,
    "decision": "N/A",
    "meta_review": "",
    "author_remarks": "",
    "decision_comment": ""
  },
  {
    "id": "gaa7gWPZBz",
    "title": "Mitigating Privacy Risk of Adversarial Examples with Counterfactual Explanations",
    "authors": [
      "Aohan Sun",
      "Yanrong Lu",
      "ATHANASIOS V. VASILAKOS"
    ],
    "abstract": "Robustness and privacy are two fundamental security properties that \nmachine learning models require. Without the balance between robustness and privacy leads to \nrobust models with high privacy risks. Obtaining machine learning models with high adversarial robustness and \nprivacy performance remains an open problem. In order to enhance the privacy performance of \nrobust models, we employ counterfactual explanations as a method \nto mitigate privacy risks while concurrently maintaining robust model accuracy, reducing the privacy risk of the robust model to the level of \nrandom guessing and using counterfactual explanations to generate adversarial examples for the first time. We analyze the similarities and differences between \nadversarial examples and counterfactual explanations and utilize these properties to design the \ngeneration method. We \nconduct an in-depth analysis of the advantages offered by counterfactual explanations compared \nto traditional adversarial examples. Our study indicates that the correlation between \nrobustness and privacy is strong and the ideal balance state of accuracy, robustness, and privacy is with 95\\% \nadversarial examples involved in model training.",
    "keywords": [
      "Adversarial Examples",
      "Privacy",
      "Counterfactual Explanations"
    ],
    "venue": "ICLR",
    "year": 2025,
    "pdf_url": "https://openreview.net/pdf?id=gaa7gWPZBz",
    "forum_url": "https://openreview.net/forum?id=gaa7gWPZBz",
    "reviews": [
      {
        "rating": "3",
        "confidence": "3",
        "summary": "-   The paper tackles an important topic in the field of machine learning, specifically the tradeoff between privacy and performance in the context of adversarial examples.\n-   The authors propose an approach to generating counterfactual explanations that are aligned with the original data distribution.",
        "strengths": "-   The paper tackles an important topic in the field of machine learning, specifically the tradeoff between privacy and performance in the context of adversarial examples.\n-   The authors propose an approach to generating counterfactual explanations that are aligned with the original data distribution.",
        "weaknesses": "-   The paper lacks clarity and readability, with technical terms and acronyms (e.g. CNN) used without definition.\n-   The comparison of different baselines is not well-explained, and the relevance of these baselines to the context is not clear.\n-   The paper only uses the MNIST dataset and does not define the model architecture, which limits the generalizability of the results.\n-   There are major spelling errors throughout the paper (for eg. title of Section 4.3 ), which detracts from its overall quality.\n-   The comparison with state-of-the-art membership inference attacks (MIA) and variants is not discussed, which could help evaluate the potency of this method."
      },
      {
        "rating": "3",
        "confidence": "4",
        "summary": "This paper proposes using counterfactual explanations to reduce privacy risks in robust machine learning models, aiming to balance robustness, accuracy, and privacy by generating adversarial examples through counterfactuals, ultimately achieving a privacy risk level comparable to random guessing.",
        "strengths": "- **Intersection between robustness & privacy is interesting**: The paper addresses a complex intersection between privacy and robustness in machine learning.\n\n- **Training algorthim**: By attempting to incorporate counterfactual explanations into model training, the paper takes a new perspective to adversarial robustness and privacy alignment.",
        "weaknesses": "- **Relevance and Motivation**: The practical relevance of the proposed solution remains unclear. The motivation for focusing on counterfactual explanations over traditional methods for balancing robustness and privacy lacks justification, leaving doubts about its necessity.\n\n- **Metric Selection for Privacy Evaluation**: The paper’s use of membership inference accuracy as a privacy metric is inadequate. A more suitable metric would be the true positive rate (TPR) at a low false positive rate (FPR), as this metric would allow an adversary to determine training set membership with higher confidence. Existing work, such as [7], highlights TPR @ low FPR as a more meaningful measure in privacy settings.\n\n- **Missing Related Works and Literature Misrepresentation**: The paper lacks a clear related works section, making it difficult to contextualize its contributions within existing research. For example, it fails to adequately cite and compare itself to relevant counterfactual explanation methods (e.g., [1-4]), leaving its method selection ungrounded.\nSome statements in the paper seem to misinterpret or misrepresent findings from prior research [8], diminishing the credibility of its claims. Specifically, the lack of distinction between counterfactual explanations and adversarial examples is problematic, as references like [6] demonstrate they can be equivalent, and [5] highlights the privacy risks that counterfactual explanations themselves can pose.\n\n- **Lack of Clarity in Methodology**: Key details are missing regarding the generation of counterfactual explanations. The lack of specifics regarding the generation process and the unclear formalization of key equations (e.g., equations 2 and 4) make the methodology difficult to follow and replicate.\nDefinitions of critical terms, such as the exact differences between adversarial examples and counterfactual explanations, are either ambiguous or absent, leading to confusion about the novelty and benefits of the proposed approach.\n\n\nBased on these weaknesses, the following **suggestions for improvement** could be considered:\n\n- Clearly articulate the relevance of counterfactual explanations for privacy-robustness tradeoffs in machine learning and provide a detailed comparison with existing methods.\n- Consider evaluating privacy using TPR at low FPR, as discussed in [7], and address potential limitations of using membership inference accuracy as the sole metric.\n- Include a comprehensive related works section that connects to the literature on counterfactual explanations, especially work such as [1] and [5], to provide a more thorough foundation for the methodology.\n- Improve clarity in the formalization of the method, specifically in explaining the setup for generating counterfactuals and addressing unclear notation in key equations.\n\n\n----\n\n**References**\n\n[1] Carla: a python library to benchmark algorithmic recourse and counterfactual explanation algorithms, https://arxiv.org/abs/2108.00783\n\n[2] Towards Realistic Individual Recourse and Actionable Explanations in Black-Box Decision Making Systems, https://arxiv.org/abs/1907.09615\n\n[3] Learning model-agnostic counterfactual explanations for tabular data, https://arxiv.org/abs/1910.09398\n\n[4] Getting a CLUE: A Method for Explaining Uncertainty Estimates, https://arxiv.org/abs/2006.06848\n\n[5] On the Privacy Risks of Algorithmic Recourse, https://arxiv.org/abs/2211.05427\n\n[6] Exploring Counterfactual Explanations Through the Lens of Adversarial Examples: A Theoretical and Empirical Analysis, https://proceedings.mlr.press/v151/pawelczyk22a.html \n\n[7] Gaussian Membership Inference Privacy, https://proceedings.neurips.cc/paper_files/paper/2023/hash/e9df36b21ff4ee211a8b71ee8b7e9f57-Abstract-Conference.html\n\n[8] Robustness Implies Privacy in Statistical Estimation. In Proceedings of the 55th Annual ACM Symposiumon Theory of Computing, pp. 497–506, 2023."
      },
      {
        "rating": "3",
        "confidence": "4",
        "summary": "It is hard to implement a deep learning model that protects privacy and is robust at the same time. Specifically, adversarial examples can be used to achieve the purpose of robustness, but it is usually difficult to protect privacy on this basis. This paper analyzes the relationship between counterfactual explanations and adversarial examples, and designs the counterfactual adversarial example to mitigate the privacy leakage of robust models.",
        "strengths": "1. This article proposes the idea of reducing privacy risk, which is inspiring.",
        "weaknesses": "1. This article uses a lot of space in section 2 to describe the similarities and differences between counterfactual explanations and Adversarial examples, which have been elaborated in many articles [1,2]. Further analysis is needed on the relationship with privacy.\n2. The formulas written in this article need to be further improved. Some mathematical symbols that appear for the first time (such as Eq. (7)) are not explained, and some formulas (such as Eq. (1) and (2)) do not correspond to the context, but appear abruptly in those positions.\n3. The description of the method part of this article needs to be improved. Sections 3.1, 3.2, and 3.3 look more like three independent parts.\n4. This article needs more experiments to reflect the effectiveness of the method. This article only made a CNN model on MNIST, and did not verify whether it is effective on larger datasets and more complex models.\n\n\n[1]Pawelczyk, Martin, et al. \"Exploring counterfactual explanations through the lens of adversarial examples: A theoretical and empirical analysis.\" International Conference on Artificial Intelligence and Statistics. PMLR, 2022.\n\n[2]Jeanneret, Guillaume, Loïc Simon, and Frédéric Jurie. \"Adversarial counterfactual visual explanations.\" Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2023."
      }
    ],
    "rating_avg": 3.0,
    "confidence_avg": 3.6666666666666665,
    "decision": "Reject",
    "meta_review": "The paper proposes to study privacy robustness tradeoffs by analyzing counterfactual examples and adversarial examples. By generating adversarial examples using counterfactual frameworks and imposing robustness, authors achieve better robustness-privacy tradeoffs. Reviewers have noted weak empirical evaluation due to insufficient datasets and the choice of metrics, lack of clarity in the writing and explaining methodology, and insufficent literature review. An author response was not provided. In going with reviewer consensus, I recommend a reject.",
    "author_remarks": "",
    "decision_comment": ""
  },
  {
    "id": "imT03YXlG2",
    "title": "Sparse autoencoders reveal selective remapping of visual concepts during adaptation",
    "authors": [
      "Hyesu Lim",
      "Jinho Choi",
      "Jaegul Choo",
      "Steffen Schneider"
    ],
    "abstract": "Adapting foundation models for specific purposes has become a standard approach to build machine learning systems for downstream applications. Yet, it is an open question which mechanisms take place during adaptation. Here we develop a new Sparse Autoencoder (SAE) for the CLIP vision transformer, named PatchSAE, to extract interpretable concepts at granular levels (e.g., shape, color, or semantics of an object) and their patch-wise spatial attributions. We explore how these concepts influence the model output in downstream image classification tasks and investigate how recent state-of-the-art prompt-based adaptation techniques change the association of model inputs to these concepts. While activations of concepts slightly change between adapted and non-adapted models, we find that the majority of gains on common adaptation tasks can be explained with the existing concepts already present in the non-adapted foundation model. This work provides a concrete framework to train and use SAEs for Vision Transformers and provides insights into explaining adaptation mechanisms.",
    "keywords": [
      "interpretability",
      "vision-language models",
      "sparse autoencoder",
      "adaptation"
    ],
    "venue": "ICLR",
    "year": 2025,
    "pdf_url": "https://openreview.net/pdf?id=imT03YXlG2",
    "forum_url": "https://openreview.net/forum?id=imT03YXlG2",
    "reviews": [
      {
        "rating": "8",
        "confidence": "4",
        "summary": "The authors perform sparse autoencoder (SAE) training on the features of a pre-trained vision transfer (ViT) from the CLIP image encoder.. The outputs of the 11th layer of the CLIP ViT is used to train a two layer SAE with reconstruction + sparsity objective. The SAE encoder features are then used to validate the presence of concepts in CLIP representations, and their role in classification as well as downstream tasks. The authors first utilize feature and example based statistics to sanity check that concepts are indeed present in SAEs trained on the CLIP visual representations, as well as multi-modal CLIP representations. Next, they verify that these conceptual features are relevant for class discriminative performance of CLIP zero-shot classification. Lastly, the authors show that SAE conceptual features after prompt-based adaptation show a suppression in non class-relevant features, while and increase in the activation of class-relevant features. New conceptual features are not learned during this adaptation procedure.",
        "strengths": "* The authors do a good job at utilizing both feature based and example based summary statistics to demonstrate presence of concepts in the SAE representations, and motivate all four statistics well in Section 2.2. Unlike prior work on inferring CLIP concepts from SAEs, which tend to rely on singular feature space statistics, this makes the author's results a bit more comprehensive.\n* The results from replacing CLIP features with SAE features and its impact on accuracy shows that the SAE conceptual features capture class discriminative information quite well. I think this result opens up more avenues on mechanistic interpretability research, as further exploration can be done into what makes a concept important vis-a-vis a class, what are the training dynamics of the concept learning for class discriminative performance (are there 'easier' concepts that are learned first e.g. winter before harder concepts e.g. christmas), and several other open research questions.",
        "weaknesses": "* The organization of the paper makes it hard for someone who is not very familiar with the field of sparse autoencoder based mechanistic interpretability of neural networks to follow the flow of ideas. For example Section 2 details the training procedure and the feature statistics calculated, but the experimental details are ommitted and then presented in Section 4. Similarly, the Intro and Section 2.1 cover a brief overview of SAEs and their use in intepretability research, but the actual related work section is not presented until Section 5. While I understand that the authors are eager to share their key results in an earlier section (especially since this is a intepretability focussed work), this organization made it more work for me as a reader to understand the paper.\n* The scope of experiments performed and the subsequential observations is somewhat limited. The first experiment, showing presence of concepts in CLIP visual features, was already shown in principle by Fry et al and Daujotas et al. The result about CLIP attention maps focussing on features at different scales and regions is not surprising, but another sanity check for the SAE interpretability apporach. The second emperimental design is inspired from previous SAE results in LLMs e.g. Templeton et al, and extrapolated from a language (only) transformer setting to a multimodal setting."
      },
      {
        "rating": "6",
        "confidence": "4",
        "summary": "This paper introduced Sparse AutoEncoder (SAE), which previously trained to disentagle and interprete LLM hidden states, to analysis CLIP features. The authors trained a SAE on top of CLIP features with ImageNet samples, and carried out several experiments with it demonstrating 3 points: \n- Section 3.1: certain demension in SAE feature correlates to certain visual concepts\n- Section 3.2: targeted ablation of neurons yeilds degraded performance\n- Section 3.3: CLIP model \"re-use already known concepts\" when it is fine-tuned for downstream datasets",
        "strengths": "- The paper transfers the methodology of SAE from NLP to vision. The idea of identifying visual concepts from CLIP features is quite interesting.\n- From visualizations, it seems that the SAE on top of CLIP sucessfully identified some meaningful semantic concertps in both image-level and patch-level.",
        "weaknesses": "1. **Lacks quantitative evaluation of SAE's reliability**. Although SAEs for LLMs are widely studied in NLP, to my best knowledge, the usage of SAE for CLIP is only reported in several blog posts that have not been peer-reviewed. Since its effectiveness and reliability are not sufficiently justified in a convincing way, directly using it to draw conclusions is quite risky.\n\n    - For example, how can we ensure that the training settings listed in Section 4.1 are properly set? Are 49,152 hidden dimensions enough for the vision domain? Does this SAE achieve monosemanticity? \n\n    - Examples in the case study are certainly not sufficient for a rigorous evaluation. I would suggest conducting a large-scale evaluation using vision datasets with fine-grained attribute annotations to answer the above questions.\n\n\n1. **Potential distribution shift between base and fine-tuned CLIP**. As stated in Line 325, the authors used the SAE trained on top of pretrained CLIP to interpret the fine-tuned CLIP. As MaPLe fine-tunes both image and text encoders, there are no guarantees that the feature distribution will remain the same after fine-tuning, and all the conclusions in Section 3.3 might be inaccurate as a result.\n\n\n1. **Regarding \"re-mapping\" or \"re-using\" visual concepts**. As highlighted in the paper title and section titles, the authors wanted to demonstrate the connection of visual concepts between base and fine-tuned CLIP. However, I am a bit confused regarding the terminology used, as neither \"re-mapping\" nor \"re-using\" is properly defined in the paper. The authors are encouraged to provide a clear definition of these terms and highlight how the results (e.g., Fig. 6c) demonstrate this point.\n\n\n1. **Significance of Contribution**. Overall, I find the new insights provided in this paper are not as substantial as I expected when I read only the title. Training SAE on CLIP features is not novel. It has been previously reported in several blog posts, yet this paper does not provide a more formal and quantitative evaluation. The results in Section 3.1 and 3.2 are somewhat expected and are not particularly surprising. \n\n    I would suggest that the authors conduct large-scale quantitative validation to prove the effectiveness of CLIP's SAE, e.g., ablation of hyperparameters, training settings, and types of CLIP models (convolutional encoders are not covered in the presented study). Additionally, clearly stating the relation and differences between SAE and existing interpretability methods in the vision domain would help readers understand the contributions."
      },
      {
        "rating": "6",
        "confidence": "2",
        "summary": "In this paper, the authors propose a new way to try to interpret features learned from a vision-language (in particular, a CLIP model). The proposed approach train SAE on all image tokens. The author then show that the trained SAE can be used to discover different concepts from the CLIP vision transformer. The authors then investigate how the learned \"interpretable features\" relates the output of the model.",
        "strengths": "- Better understanding foundantion models (and what their features encode) is an extremely important problem---specially as these models get more powerful.\n- The proposed approach is simple  and leverages the well-understood sparse autoencoder approach to interpret the features.",
        "weaknesses": "- The paper has some very strong claims that has not been properly demonstrated. Eg, L249 says \"CLIP understands sophisticated concepts from input images not only responding to basic patterns such as color or shape \". Showing a a few (potentially cherrypicked) qualitative examples is not enough to show/demonstrate/prove the results on the paper. It would make results stronger if  the authors could provide more quantitative metrics to measure the sophistication of detected concepts. This would make the results on the paper more convincing/interesting.\n- Some sessions of the paper are not very clear. For example, the authors leverage MaPLe model (eg \"adaptation methods analysis\") and nowhere in the paper they explain how this model works. It would make the paper more readable if the authors could provide a brief overview of this model on the manuscript.\n- A lot of design choices seem to be made ad-hoc. For example, why chose the second-to-last layer? Why use the SAE feature statistics used? Why 49,152 dimensions? Could the authors provide some justification for these choices? How were those choices made? Was any ablation study performed to choose those values?"
      },
      {
        "rating": "6",
        "confidence": "4",
        "summary": "This paper utilizes sparse autoencoders (SAE) to interpret visual concepts learned by the CLIP vision model and investigates how these concepts are affected by adaptation techniques such as MaPLe. The key finding is that during adaptation, the model primarily reuses existing concepts rather than learning entirely new ones.",
        "strengths": "- The paper offers a detailed and fine-grained exploration of CLIP by processing the entire token sequence with SAEs, allowing for a deeper understanding of the model's visual feature representations.\n- It tackles the adaptation dynamics of foundation models like CLIP, which is a relatively under-explored topic.",
        "weaknesses": "- The clarity and organization of the analyses are insufficient. The main body of the paper frequently refers to figures in the appendix, many of which are poorly annotated, making it difficult for readers to follow the core arguments. The authors should revise the manuscript to consolidate the most important findings in the main body and present them in a clearer and more structured format.\n- The paper lacks sufficient discussion on the broader implications and significance of its findings. Are any results surprising or do they challenge conventional views within the field? The authors should also elaborate on the practical value of their discoveries."
      }
    ],
    "rating_avg": 6.5,
    "confidence_avg": 3.5,
    "decision": "Accept (Poster)",
    "meta_review": "Post rebuttal, all of reviewers vote for acceptance. The AC checked all the materials and concurs that the paper has done a valuable exploration of using patch-wise sparse auto-encoders to interpret the CLIP visual representations, especially through the adaptation process. The paper received concerns about clarity and organization, but has been significantly improved during the rebuttal period, with authors paying great efforts providing new results and re-writing the draft. With these major revisions, the paper can be accepted. Please incorporate necessary changes in the final version.",
    "author_remarks": "",
    "decision_comment": ""
  },
  {
    "id": "gtVo4xcpFI",
    "title": "GenBen:A Genarative Benchmark for LLM-Aided Design",
    "authors": [
      "Gwok-Waa Wan",
      "Wang yubo",
      "SamZaak Wong",
      "jingyi zhang",
      "Mengnv Xing",
      "Zhe jiang",
      "Nan Guan",
      "ying wang",
      "Ning Xu",
      "Qiang Xu",
      "Xi Wang"
    ],
    "abstract": "This paper introduces GenBen, a generative benchmark designed to evaluate the capabilities of large language models (LLMs) in hardware design. With the rapid advancement of LLM-aided design (LAD), it has become crucial to assess the effectiveness of these models in automating hardware design processes.\nExisting benchmarks primarily focus on hardware code generation and often neglect critical aspects such as Quality-of-Result (QoR) metrics, design diversity, modality, and test set contamination. GenBen is the first open-source, generative benchmark tailored for LAD that encompasses a range of tasks, from high-level architecture to low-level circuit optimization, and includes diverse, silicon-proven hardware designs. \nWe have also designed a difficulty tiering mechanism to provide fine-grained insights into enhancements of LLM-aided designs. Through extensive evaluations of several state-of-the-art LLMs using GenBen, we reveal their strengths and weaknesses in hardware design automation. Our findings are based on 10,920 experiments and 2,160 hours of evaluation, underscoring the potential of this work to significantly advance the LAD research community. \nIn addition, both GenBen employs an end-to-end testing infrastructure to ensure consistent and reproducible results across different LLMs. The benchmark is available at https://anonymous.4open.science/r/GENBEN-2812.",
    "keywords": [
      "GenBen; Benchmark; LLM-Aided Design; LLM; Hardware Design"
    ],
    "venue": "ICLR",
    "year": 2025,
    "pdf_url": "https://openreview.net/pdf?id=gtVo4xcpFI",
    "forum_url": "https://openreview.net/forum?id=gtVo4xcpFI",
    "reviews": [
      {
        "rating": "3",
        "confidence": "3",
        "summary": "GenBen introduces a benchmark designed to evaluate the capacity of LLMs for generating hardware designs. Existing state-of-the-art benchmarks have several limitations: primarily, they focus solely on syntax and functional pass rates and often include simplistic problems sourced from textbooks, which may be part of LLM training data.",
        "strengths": "In this paper, we present GenBen, a comprehensive benchmark developed to assess the capabilities of LLMs in hardware design. GenBen addresses existing limitations through the following strategies:\n\n1. Incorporating problems sourced from various origins, including silicon-proven projects, to establish three levels of difficulty for evaluating LLMs.\n2. Utilizing perturbation strategies to create dynamic tests, ensuring that LLMs encounter unseen challenges.\n3. Expanding evaluation criteria beyond syntax and functional pass rates to include metrics such as synthesizability, power, performance, and area.\n4. Conducting assessments across multiple LLMs to provide comparative insights.",
        "weaknesses": "The writing quality of this paper is subpar, primarily due to the lack of practical examples. The authors should include more concrete examples to clarify concepts such as \"adding some perturbations.\" Additionally, Table 4 lacks substantive information, and it would be more effective if it included illustrative examples. Furthermore, Section 3.3.1 provides only a superficial overview of the end-to-end verification flow, lacking sufficient detail and making the article less informative. \n\nMoreover, it is unclear how the perturbation process ensures the creation of sound problems, avoiding ambiguity or unclear meanings. The authors should address this aspect to reinforce the reliability of their approach.\n\nSome types on writing:\nSection 3.2 \"GenBen then generates test tests from the test dataset D using scripts\", test typo.\nFigure 2 and Figure 4-12 are very hard to read. Use contrasting colors then patterns to discern between different\nmetrics.\nline 213: test tests from"
      },
      {
        "rating": "3",
        "confidence": "4",
        "summary": "The paper introduces a generative benchmark designed to evaluate large language models (LLMs) in the context of hardware design automation. Recognizing the limitations of existing benchmarks focused primarily on basic code generation, GenBen extends evaluation to include critical aspects like Quality-of-Result (QoR) metrics, debugging capabilities, design diversity, and prevention of test set contamination. The benchmark encompasses tasks across multiple design levels, from high-level architecture to low-level circuit optimization, and includes a tiered difficulty system to provide insights into LLM performance across different complexities. With an open-source, end-to-end testing infrastructure, GenBen aims to deliver reproducible and comprehensive assessments, intending to advance the development of LLM-aided design tools within the hardware design community.",
        "strengths": "The paper tries to address a relevant problem and is well written, and well organized",
        "weaknesses": "1)\tThe dynamic perturbation strategy aims to prevent memorization but may inadvertently introduce ambiguity into test cases. This can create inconsistencies in evaluating LLM performance, especially if slight changes in prompt phrasing lead to variations in model responses. The reliance on superficial perturbations (surface-level changes) may not effectively challenge models in understanding complex circuit design concepts.\n2)\tThe paper identifies issues with synthesizability due to non-IEEE-compliant code in pre-training datasets, but it lacks concrete methods for systematically identifying and filtering these cases. This limitation could lead to significant variability in QoR metrics, particularly for synthesis tools that adhere strictly to IEEE standards, reducing the benchmark’s reliability.\n3)\tTiming issues are briefly discussed, but the GenBen benchmark does not appear to account for complex timing closure tasks, such as handling Total Negative Slack (TNS) and Worst Negative Slack (WNS) for high-frequency designs. The benchmark could fall short in evaluating LLMs’ ability to generate designs that meet stringent timing requirements, which is critical for high-performance applications.\n4)\tAlthough the benchmark includes debugging tests, it may not fully capture the complexity of real-world hardware debugging, particularly for stateful designs or asynchronous circuits. The current debugging scope seems limited to relatively straightforward syntax and functional errors, without addressing state-based errors, race conditions, or setup/hold timing violations that are common in complex designs.\n5)\tWhile the inclusion of multimodal tests is innovative, the integration of textual and visual data (e.g., diagrams) lacks specific detail on how visual data is processed or scored. This lack of clarity may lead to ambiguous scoring for models that perform differently across multimodal and text-based tasks, making it challenging to standardize assessments.\n6)\tThe QoR metrics focus on synthesizability, power, area, and timing but do not assess finer aspects like pipeline balancing, parallelism optimizations, or state-machine efficiency. These factors are crucial for high-performance designs and should be part of a rigorous hardware benchmark that targets comprehensive design quality."
      },
      {
        "rating": "5",
        "confidence": "5",
        "summary": "The paper introduces GenBen, a benchmark for LLM-aided design (LAD) specifically targeted at evaluating the performance of large language models (LLMs) in hardware design. This benchmark covers a diverse set of tasks with both unimodal and multimodal support, drawing from 20 sources across four primary domains, further organized into five detailed categories. The tasks are structured across three difficulty tiers, aiming to comprehensively assess models' skills in LAD. The paper also addresses issues of data contamination, dataset diversity, and incorporates a pass@5 evaluation setup across nine models, assessed with comprehensive metrics for syntactic, functional, and Quality-of-Results (QoR) evaluation. The benchmark and its workflow are structured to support reproducibility, utilizing open-source tools like Icarus Verilog and OpenLane.",
        "strengths": "1.\tComprehensive Metric Coverage: GenBen includes both syntactic and functional correctness metrics, as well as QoR metrics (synthesizability, power, area, timing), giving a well-rounded evaluation of LLMs in LAD. The use of open-source tools like Icarus Verilog and OpenLane (as detailed in Section 3.6 and Appendix A.3.1) enhances reproducibility.\n2.\tPerturbation Strategy: GenBen employs both surface and semantic perturbations to prevent test set contamination, a thoughtful design that diversifies test inputs dynamically, as discussed in Section 3.4 and illustrated in Figure 2. This strategy enhances benchmark reliability by mitigating memorization effects.\n3.\tMultimodal Support: Recognizing the multimodal nature of hardware design, GenBen supports tasks that include textual, schematic, and architectural data (Section 3.5). This addition is crucial for practical LAD assessments where real-world design tasks often require multimodal inputs.\n4.\tClear Evaluation Pipeline: The step-by-step pipeline in Figure 2 provides clear guidance for users, with explicit instructions on test construction, perturbation, and evaluation metrics (Section 3.2). The modular approach allows GenBen to assess models on multiple metrics, making it adaptable to diverse LAD scenarios.\n5.\tThorough Documentation: The appendices provide exhaustive details on LAD-related concepts, evaluation metrics, and the role of open-source tools (Appendix A.1 to A.3), which can aid users in implementing the benchmark effectively.",
        "weaknesses": "The paper is not much relevant to the ICLR community, and does not provide a strong mathematical foundation. A more suitable venue for this paper could be ICLAD Conference or some Design Automation Conference like DAC or ICCAD.\n\n1.\tData Imbalance in Test Categories: Table 3 presents disparities across task categories (e.g., 99 Design tasks vs. 57 Debug tasks). While task diversity is commendable, the authors should clarify why such an imbalance exists and discuss potential implications for model performance assessment, especially if specific categories are overrepresented. An explanation of how this might affect the reliability of the benchmark would strengthen the dataset's construction rationale (Section 3.3.3).\n2.\tModel Selection Motivation: Section 4.1 introduces nine models across five families but lacks justification for these particular choices. Clarifying why specific models (e.g., GPT, Claude, LLaMA, QWEN, and GLM families) were included could strengthen the argument, especially if these models are particularly relevant for LAD tasks. For instance, what LAD-specific capabilities do these models bring? Including performance characteristics in multimodal tasks or LAD-related features in each model would better contextualize the selection.\n3.\tDifficulty Tiering: The paper divides tasks into three difficulty levels (L1 to L3) with proper descriptions (Table 2). However, detailing how each tier’s tasks correspond to LAD challenges (e.g., debugging complexity or resource optimization) would add valuable context. The authors could enhance Appendix A.4 by providing specific examples that illustrate the distinctions between L1, L2, and L3, particularly within each task type (knowledge, design, debugging). Quantitative data on average model performance per tier might also reveal trends that could guide future benchmarking improvements.\n4.\tDetailed Case Study on Perturbation: The perturbation strategy is briefly explained in Section 3.4, with an overview of surface and semantic techniques. However, a specific example, especially for semantic perturbation, would make this section clearer. Adding a detailed case study would provide a more straightforward demonstration of how the data were perturbed, also for semantic perturbation, due to the randomness, is there a manageable gap of difficulty to change? For instance, showing a task before and after both types of perturbation would help readers understand the differences in difficulty introduced by each type. Furthermore, since semantic perturbation could change task difficulty, addressing how fairness is maintained would strengthen the case for using this approach.\n5.\tElaboration on Workflow: The \"Dynamic Test Kit\" component in Figure 2 and Section 3.2 would benefit from additional detail. For instance, does the Dynamic Test Kit contain tools that adjust task difficulty, or is it limited to generating variants of test inputs? Furthermore, clarifying the connection between the scoring system described in Section 4.1 and the metrics reported in Table 5 could make the scoring more interpretable. Specifically, explaining if the pass rate is calculated per task or per difficulty level would aid in understanding the benchmark's scoring logic.\n6.\tExperiment Results Interpretation: Section 4.2 and Figures 4-12 illustrate experiment results, but a breakdown of model performance by metric (e.g., Syntax, Synthesizability, Function) would be helpful. Discussing why Syntax scores are generally higher while Function scores lag behind could provide insight into specific model weaknesses. Additionally, including a statistical analysis (e.g., variance in pass rates across difficulty levels) would offer a clearer picture of each model’s strengths and limitations.\n7.\tSupporting Literature for Multimodal Justification: Section 3.5 could be enhanced by citing specific LAD scenarios or prior research that demonstrate the need for multimodal tasks (e.g., combining schematics with HDL code) to support the claim “This feature is particularly important because real-world design processes often require the integration of various forms of data, such as textual specifications, diagrams, and architectural schematics”. Including practical examples from hardware design projects that require multimodal support would illustrate the real-world relevance of GenBen’s multimodal component. This would also substantiate the statement that real-world LAD tasks are inherently multimodal.\n9.\tFuture Work and Limitations: The paper would benefit from a Limitations and Future Work section, discussing GenBen's adaptability to emerging LAD requirements (e.g., integration with more complex EDA tools or AI-driven hardware design) could provide a roadmap for GenBen’s evolution. Additionally, mentioning scalability limitations (e.g., handling larger designs or more complex verification tasks) would provide a balanced view of the benchmark’s potential applications and restrictions.\n10.\tEvaluation Metric Granularity: While Table 5 provides an overview of evaluation metrics, further clarification on the weighting or relative importance of these metrics (e.g., Syntax vs. Synthesizability vs. QoR metrics) could improve transparency. Explaining if QoR metrics are prioritized over syntactic correctness for certain tasks, such as those targeting manufacturable designs, would give a better understanding of how the benchmark defines \"success.\" Additionally, addressing any trade-offs between these metrics, especially in cases where models might excel in one metric while underperforming in others, would be helpful (e.g., does a high Syntax score compensate for lower Synthesizability?).\n11.\tBenchmark Customizability: GenBen is described as an end-to-end LAD benchmark. A brief mention of how the benchmark might be tailored for different LAD applications (e.g., specialized RTL verification or energy optimization) in Section 3.2 would clarify the benchmark’s flexibility.\n12.\tClearer Description of Multimodal Task Processing: Although Section 3.5 explains the importance of multimodal tasks, more detail on how GenBen processes or evaluates multimodal inputs would be beneficial. For instance, specifying how different data forms (e.g., schematics vs. HDL code) are presented to models and if specific evaluation criteria are adapted to multimodal tasks could provide clarity. Addressing whether the models are expected to interpret these inputs sequentially or concurrently, and if multimodal inputs impact the difficulty tiering, would improve understanding of the benchmark's multimodal handling.\n13.\tClarification of Pass@5 Evaluation and Scoring: The pass@5 scoring strategy in Section 4.1 is introduced without much context on its relevance to LAD tasks. Explaining why pass@5 is chosen over other scoring metrics (e.g., pass@10, exact match) and how it aligns with real-world LAD evaluation (e.g., tolerance for minor errors in preliminary passes) would strengthen its justification. Additionally, describing if scoring varies by task difficulty or complexity would make the scoring methodology clearer."
      },
      {
        "rating": "6",
        "confidence": "3",
        "summary": "The paper introduces GenBen, a generative benchmark designed to evaluate the performance of large language models in hardware design automation. As LLM-aided design progresses rapidly, it has become essential to assess these models' efficacy in automating various stages of hardware design, from high-level architecture to low-level circuit optimization. GenBen distinguishes itself from existing benchmarks by emphasizing aspects such as Quality of Result metrics, design diversity, multimodality, and data contamination prevention.",
        "strengths": "1.  GenBen implements an end-to-end verification process, ensuring functional coverage for RTL designs, which enhances the reliability of generated designs.\n\n2. With a dataset derived from silicon-proven projects, textbooks, and community sources, GenBen categorizes tasks into three difficulty levels, allowing for more granular assessments.\n\n3. By employing static and dynamic perturbations, GenBen mitigates the risk of data leakage from pre-training datasets, maintaining the integrity of evaluation results.",
        "weaknesses": "1. I tried to access the anonymous link provided by the authors for the benchmark, but it seems to be unavailable. Could the authors provide a working link during the rebuttal phase? This would allow me to evaluate the quality of the dataset\n\n2. Another minor concern: Although I really appreciate the multimodal and contamination-free dataset, I personally feel that this paper might be better suited for a hardware-focused conference."
      }
    ],
    "rating_avg": 4.25,
    "confidence_avg": 3.75,
    "decision": "Reject",
    "meta_review": "**Summary:** \nThe paper introduces GenBen, a benchmark designed to evaluate LLMs for hardware design tasks, addressing limitations in existing benchmarks. It includes multi-level tasks, incorporates Quality-of-Result (QoR) metrics, and employs perturbation strategies to prevent test set contamination. GenBen spans diverse tasks, supports multimodal inputs, offers a tiered difficulty system, and demonstrates its utility through evaluations of nine LLMs.\n\n**Strength:** \n\n1. The paper introduces a diverse benchmark that evaluates both functional and QoR metrics, filling in a gap in hardware design benchmarks.  \n\n2. The use of perturbation strategies to prevent data contamination is novel and can potentially enhance the benchmark's reliability.  \n\n3. The taxonomy of the LAD benchmark provided by this work is potentially insightful and valuable for the research community.  \n\n**Weakness:**\n\n1. The perturbation strategy lacks detailed descriptions to avoid ambiguity and lacks thorough validation, raising concerns about its consistency and usability.  \n\n2. Some critical aspects of the benchmark design are insufficiently detailed, such as how complex timing metrics are accounted for and how debugging tests capture the complexity of real-world hardware debugging.  \n\n3. The paper suffers from some writing issues, including typos and insufficient clarity in figures and methodology, which negatively affect its presentation.  \n\n\n**Reasons for the decision:**\n\nThis work aims to provide a comprehensive benchmark encompassing many diverse aspects; however, the methodology and evaluation for each aspect are not sufficiently detailed or validated. Therefore, I am inclined to recommend rejection.",
    "author_remarks": "",
    "decision_comment": ""
  },
  {
    "id": "orr5uPZY28",
    "title": "DySpec: Faster Speculative Decoding with Dynamic Token Tree Structure",
    "authors": [
      "Yunfan Xiong",
      "Ruoyu Zhang",
      "Yanzeng Li",
      "Tianhao Wu",
      "Lei Zou"
    ],
    "abstract": "While speculative decoding has recently appeared as a promising direction for accelerating the inference of large language models (LLMs), the speedup and scalability are strongly bounded by the token acceptance rate.\nPrevalent methods usually organize predicted tokens as independent chains or fixed token trees, which fails to generalize to diverse query distributions. \nIn this paper, we propose \\textsc{DySpec}, a faster speculative decoding algorithm with a novel dynamic token tree structure. \nWe begin by bridging the draft distribution and acceptance rate from \nintuitive and empirical clues, and successfully show that the two variables are strongly correlated. Based on this, we employ a greedy strategy to dynamically expand the token tree at run time. Theoretically, we show that our method can achieve optimal results under mild assumptions. Empirically, \\textsc{DySpec} yields a higher acceptance rate and speedup than fixed trees. \\textsc{DySpec} can drastically improve the throughput and reduce the latency of token generation across various data distribution and model sizes, which significantly outperforms strong competitors, including Specinfer and Sequoia. Under low temperature setting, \\textsc{DySpec} can improve the throughput up to 9.10x and reduce the latency up to 9.4x on Llama2-70B. Under high temperature setting, \\textsc{DySpec} can also improve the throughput up to 6.21x, despite the increasing difficulty of speculating more than one token per step for draft model.",
    "keywords": [
      "inference methods",
      "efficient inference",
      "speculative decoding"
    ],
    "venue": "ICLR",
    "year": 2025,
    "pdf_url": "https://openreview.net/pdf?id=orr5uPZY28",
    "forum_url": "https://openreview.net/forum?id=orr5uPZY28",
    "reviews": [
      {
        "rating": "5",
        "confidence": "4",
        "summary": "This work proposes a method to dynamically expand the token tree based on the draft distribution. A key difference between this work and existing approaches is that it introduces a smooth dynamic draft token tree construction method, which expands the tree along both width and depth without hyperparameter setup, within the given token budget. However, related works are missing, and the experimental setup should be properly improved.",
        "strengths": "1.\tThe correlation of Hypothesis 1 with the proposed method is well elaborated and explained.\n2.\tThe structure of the paper is clear and easy to follow.",
        "weaknesses": "1.\tLack of related work. Context-aware dynamic draft token tree is not a new idea. I would like to draw your attention to a very related work: “EAGLE-2: Faster Inference of Language Models with Dynamic Draft Trees” (EMNLP'24). This paper also proposes adopting dynamic draft token trees and claims a strong positive correlation between the draft model confidence score and the acceptance rate of the token. Another relevant paper is “Dynamic Depth Decoding: Faster Speculative Decoding for LLMs,” which further improves performance by dynamic depth. The methodology of EAGLE-2 is quite similar to this paper but differs in the tree construction method. Including this work in your paper and providing necessary discussion is essential.\n2.\tExperimental setup and results are weak. First, the dataset is too limited. I recommend adding more datasets like MT-Bench (Zheng et al., 2023), HumanEval (Chen et al., 2021), and GSM8K (Cobbe et al., 2021). Second, the 9.1× speedup is compared with the autoregressive method, and when compared with static tree methods like Sequoia, the results are much less overwhelming. Considering that the experimental setup lacks comparison with state-of-the-art dynamic draft token tree methods, the experiment does not fully convince me of the merits of this methodology.\n3.\tWriting needs improvement. Section 4.2 is hard to follow. The presentation of Figure 3 should be improved. Additionally, Figure 4 is not clear; please increase the font size."
      },
      {
        "rating": "6",
        "confidence": "2",
        "summary": "This paper introduces DySpec, a novel approach to speculative decoding that employs a dynamic token tree structure to improve inference speed for large language models. The authors present both theoretical and empirical evidence showing that higher draft probabilities correlate with higher acceptance rates. Based on this insight, they develop a greedy strategy for dynamically expanding the token tree at runtime. The method achieves impressive results, demonstrating up to 9.1× throughput improvement and 9.4× reduction in latency on Llama2-70B under low temperature settings, outperforming existing methods like Specinfer and Sequoia.",
        "strengths": "1. Strong Theoretical Foundation\n- Provides rigorous theoretical analysis linking draft distribution to acceptance rate\n- Includes formal proofs of optimality under stated assumptions\n- Clearly bridges theoretical insights with practical implementation\n\n2. Novel Technical Contributions\n- Introduces an innovative dynamic token tree construction approach\n- Develops efficient algorithms for both fixed-size and threshold-based tree construction\n- Proposes block-sparsity friendly token ordering for optimization\n\n3. Comprehensive Empirical Evaluation\n- Tests across multiple model scales (7B to 70B parameters)\n- Evaluates on diverse datasets (C4, OpenWebText, CNN DailyMail)\n- Compares against strong baselines (Specinfer, Sequoia)\n- Examines performance under different temperature settings\n\n4. Implementation Efficiency\n- Addresses practical concerns about overhead\n- Provides C++ implementation to minimize token tree construction costs\n- Includes detailed analysis of computation complexity",
        "weaknesses": "1. Limited Discussion of Limitations\n- Could elaborate more on scenarios where the method might not perform optimally\n- More discussion of the trade-offs between fixed-size and threshold-based approaches would be valuable\n\n2. Implementation Details\n- Some implementation specifics about the C++ optimizations could be expanded\n- Could provide more guidance on threshold selection for different scenarios\n\n3. Experimental Validation\n- Could include more ablation studies to isolate the impact of different components\n- Additional experiments on more diverse model architectures would strengthen generalizability claims"
      },
      {
        "rating": "5",
        "confidence": "4",
        "summary": "Summary:\n\nThe authors propose dyspec to generate an optimal tree. The core idea is based on the idea that the target distribution and draft distribution should match.\n\nThe authors based on the idea propose an algorithm to come up with optimal tree. They overcome several implementation challenges and achieve reasonable speedups compared to existing baselines.\n\n“DYSPEC achieves a 9.1× throughput improvement and 9.4× reduction in latency.” ([“DySpec”, p. 2]-> Should compare to SpecInfr or Medusa\n\n“Figure 2: Connection between acceptance rate/target distribution and draft distribution on CNN DailyMail.The density of each block is normalized by column.” ([“DySpec”, p. 3] -> Can you please explain this figure. I think it’s the main motivation for your method, however it is not clearly explained, what this figure is showing.\n\n“Specinfer-Baseline” ([“DySpec”, p. 7] -> Specifinfer requires training the models. What have authors done here.\n\n“DYSPEC leverages CUDA Graph to capture 129 different input lengths ranging from 128 to 258” ([“DySpec”, p. 7-> What is the significance of CUDA Graph here, my understanding is CUDA graph is a mechanism to launch multiple kernels at the same time on the GPU to minimize the overhead of kernel dispatch\n\n“We selected Llama2-7B as the draft model” ([“DySpec”, p. 7] -> What happens when you use the 68M model ?\n\n“Set the maximum draft token tree size to 64, DYSPEC achieves up to a 9.1x improvement in throughput and a 9.4x reduction in latency compared to auto-regressive generation” ([“DySpec”, p. 8]-> Unfair comparison, compare to baselines\n\nAdditional experiments -\n\nI would really like to experimentally understand the optimality of your tree. Will it be possible to construct an optimal tree based on some post-hoc data and compare it with the tree generated by Dyspec.",
        "strengths": "- The proposed idea is quite useful and can provide significant speedups for tree based speculative decoding methods. \n\n- The overheads reported our negligible.",
        "weaknesses": "- See the summary section please."
      },
      {
        "rating": "3",
        "confidence": "5",
        "summary": "This paper proposes a draft token selection method in speculative decoding aimed at improving the token acceptance rate. The core idea is to use the draft model's prediction score as evidence to infer the token acceptance rate and use this information to select more promising tokens. The authors provide both theoretical and empirical analyses to support their approach.",
        "strengths": "The proposed token selection method demonstrates improvement over existing methods such as Sequoia and Specinfer.",
        "weaknesses": "1. The paper lacks discussion on existing works that share very similar ideas (see Questions 1 and 2). \n1. The experimental results do not sufficiently validate the method's effectiveness from various perspectives (see Questions 3 and 4)."
      }
    ],
    "rating_avg": 4.75,
    "confidence_avg": 3.75,
    "decision": "Reject",
    "meta_review": "This paper provides a dynamic tree structure construction for multi-draft speculative decoding, and shows improvements over existing static tree construction techniques. However, during the rebuttal, the reviewers mentioned the existence of related work that also creates trees dynamically, specifically Eagle 2, which has significant overlap with the current proposal. The authors have responded with an explanation on the differences. However, the AC finds this to be insufficient and a more in-depth understanding of similarities and differences is warranted. In particular, the AC recommends that the authors replace the tree construction step in Eagle 2 with that proposed herein. This ablation is key to substantiating the claim of almost optimality of the tree construction in this work and can increase its impact further. We hope that the authors find the comments of the reviewers useful for a future iteration of their paper.",
    "author_remarks": "",
    "decision_comment": ""
  },
  {
    "id": "hz3NtNpDNv",
    "title": "Hottel Zone Physics-Constrained Networks for Furnaces",
    "authors": [
      "Ujjal Kr Dutta",
      "Aldo Lipani",
      "Chuan Wang",
      "Yukun Hu"
    ],
    "abstract": "This paper investigates a novel approach to improve the temperature profile prediction of furnaces in foundation industries, crucial for sustainable manufacturing. While existing methods like the Hottel Zone model are accurate, they lack real-time inference capabilities. Deep learning methods excel in speed and prediction but require careful generalization for real-world applications. We propose a regularization technique that leverages the Hottel Zone method to make deep neural networks physics-aware, improving prediction accuracy for furnace temperature profiles. Our approach demonstrates effectiveness on various neural network architectures, including Multi-Layer Perceptrons (MLP), Long Short-Term Memory (LSTM) and Kolmogorov-Arnold Networks (KANs). We also discussion the data generation involved.",
    "keywords": [
      "Hottel Zone method",
      "Physics-Informed Neural Networks",
      "Radiation Heat Transfer",
      "Furnaces"
    ],
    "venue": "ICLR",
    "year": 2025,
    "pdf_url": "https://openreview.net/pdf?id=hz3NtNpDNv",
    "forum_url": "https://openreview.net/forum?id=hz3NtNpDNv",
    "reviews": [
      {
        "rating": "3",
        "confidence": "3",
        "summary": "This paper studies temperature profile prediction of furnaces and tries to integrate a typical approach named Hottel Zone into Deep Learning models.",
        "strengths": "While I may lack specific expertise in furnace behaviors, the paper’s strengths are difficult to identify due to significant weaknesses in structure and clarity.",
        "weaknesses": "The primary weakness of this paper is its lack of a clear, structured approach, which hampers readability and information flow. Also, the writing style is very unclear and there are missing unfinished statements, links (like the GitHub from line 68), the red text, etc."
      },
      {
        "rating": "5",
        "confidence": "3",
        "summary": "This paper proposes a physics-constrained neural network approach for temperature profile prediction in furnaces. The authors introduce a regularization technique based on the Hottel Zone method and demonstrate its effectiveness across various neural network architectures (MLP, LSTM, KAN, xLSTM).",
        "strengths": "**Originality**  \n   This work presents an innovative application of the Hottel Zone method for regularizing neural networks, which sets it apart from traditional data-driven models. Using a physics-based constraint to enhance temperature prediction accuracy is a novel concept.\n\n**Clarity**  \n   The methodology, especially the integration of the Hottel Zone method, is well-explained, allowing readers to understand how the physics constraint aids in capturing the furnace's temperature dynamics. Experimental design and metrics are clearly presented.",
        "weaknesses": "**Domain-Specific Limitation**  \n   The method is specifically tailored to furnace temperature prediction, limiting its general applicability to other domains. This specificity reduces its potential impact within a broader range of applications or datasets outside of high-temperature industrial processes.\n\n**Inference Time Analysis**  \n   Although training time with regularization is detailed, the paper lacks explicit performance analysis for inference time on industrial setups. Given the potential complexity of incorporating physical constraints, a clear discussion on inference time efficiency for real-time applications would strengthen the paper's practical value.\n\n**Comparative Baseline**  \n   The paper does not provide a comprehensive comparison with other physics-informed neural networks or hybrid models, which makes it difficult to evaluate the novelty of this approach relative to existing techniques in similar settings.\n\n**Implementation Complexity**  \n   The integration of Hottel Zone constraints may complicate the model deployment process in practical, real-time environments. The paper would benefit from discussing strategies to mitigate the computational overhead associated with this regularization approach."
      },
      {
        "rating": "5",
        "confidence": "3",
        "summary": "This paper investigates a novel approach to improve the temperature profile prediction of furnaces in foundation industries. Physics-constrained networks are used to obtain the real-time inference capabilities and careful generalization for real-world applications\nThe effectiveness on various neural network architectures, including Multi-Layer Perceptrons (MLP), Long Short-Term Memory (LSTM),\nExtended LSTM (xLSTM) and Kolmogorov-Arnold Networks (KANs) are demonstrated.",
        "strengths": "This works conducts many experiments on different datasets and different methods to evaluate the model.",
        "weaknesses": "The organization of this paper should be improved. The results from MLP, LSTM, DLSTM, KAN and xLSTM and their physics-based improvements (PBMLP, PBLSTM, PBDLSTM, PBKAN and PBxLSTM) are compared. But this paper is to improve the neural networks using Hettel Zone constraint, I think the results from pure Hettel Zone method should also be included. If it is a matter of pages limit, I suggest to move some text of the background of the proposed method (in Section 3) to the appendix. Other than that, the author should consider does it really neccessary to compare the results from so many neural networks with simple structures. Adding physics terms in loss function is a normal method, like in continuum fluid mechanics, so this is an application of PINN in furnace temperature prediction. The author should also check the grammar, such as the last sentence of the Abstract (\"We also discussion the data generation involved\")."
      },
      {
        "rating": "5",
        "confidence": "3",
        "summary": "The manuscript presents a physics-aware deep learning model that integrates principles from the Hottel zone method for real-time prediction of furnace temperatures in the foundation industry. The authors propose a reformulation of the Hottel zone method's equations and introduce an energy-balance based constraint as a regularizer within the neural network. Results are demonstrated across various neural network architectures, showcasing the effectiveness of their approach.",
        "strengths": "The problem is well motivated and is significant for the foundation industry. \nThe use of physics-based constraints using principles of conventional zone method appears to be a good idea and is also shown to enhance the quality of the predictions. Such efforts are vital and essential for sectors such as foundation industry, where much work is needed on adoption of machine learning and deep learning technologies. This could represent a valuable applied contribution to the process industry.",
        "weaknesses": "Clarity: \nStructure of the paper makes reading quite difficult. Important information for evaluation is dispersed throughout the paper at varied locations, including a quite lengthy appendix. A more organized structure would enhance the clarity of the paper. Consider compressing the important information in tables wherever possible, instead of paragraphs. \n\nOriginality/Novelty: \n1. The claim of being \"first-of-its-kind\" is questionable in light of a paper presented at NeurIPS 2023 workshop (https://arxiv.org/abs/2308.16089), which has not been cited. What is the improvement achieved over earlier results? In contrast, the results reported here appear to be inferior going by the scale of error metric values. A comparative analysis with the mentioned work would be beneficial to clarify this discrepancy.\n2. Investigation of Physics-constraints in variety of neural network architecture does not add value to the paper. The reason of choosing these specific network architectures is also not clear.  \n3. Hottel zone method seems to take only 5 minutes for simulating temperatures across entire furnace for a 341 minute real process. For 1 time step, the PCNN model takes 0.5 seconds. What is the total time taken by PCNN for 341 minute process prediction? From a practical standpoint, is it even worth developing the PCNN model that accelerates the prediction marginally while losing accuracy? \n\nFinally, while this work is an important piece of applied ML work, it does not qualify as an original contribution to the field of machine learning in reviewer's opinion."
      }
    ],
    "rating_avg": 4.5,
    "confidence_avg": 3.0,
    "decision": "N/A",
    "meta_review": "",
    "author_remarks": "",
    "decision_comment": ""
  },
  {
    "id": "qnAZqlMGTB",
    "title": "StreamingBench: Assessing the Gap for MLLMs to Achieve Streaming Video Understanding",
    "authors": [
      "Junming Lin",
      "Zheng Fang",
      "Zihao Wan",
      "Fuwen Luo",
      "Chi Chen",
      "Peng Li",
      "Yang Liu",
      "Maosong Sun"
    ],
    "abstract": "The rapid development of Multimodal Large Language Models (MLLMs) has expanded their capabilities from image comprehension to video understanding. However, most of these MLLMs focus primarily on ofﬂine video comprehension, necessitating extensive processing of all video frames before any queries can be made. This presents a signiﬁcant gap compared to the human ability to watch, listen, think, and respond to streaming inputs in real time, highlighting the limitations of current MLLMs. In this paper, we introduce StreamingBench, the ﬁrst comprehensive benchmark designed to evaluate the streaming video understanding capabilities of MLLMs. StreamingBench assesses three core aspects of streaming video understanding: (1) real-time visual understanding, (2) omni-source understanding and (3) contextual understanding. The benchmark consists of 18 tasks, featuring 900 videos and 4,500 human-curated QA pairs. Each video features ﬁve questions presented at different time points to simulate a continuous streaming scenario. We conduct experiments on StreamingBench with 15 open-source and proprietary MLLMs and ﬁnd that even the most advanced proprietary MLLMs like Gemini 1.5 Pro and GPT-4o perform signiﬁcantly below human-level streaming video understanding capabilities. We hope our work can facilitate further advancements for MLLMs, empowering them to approach human-level video comprehension and interaction in more realistic scenarios.",
    "keywords": [
      "Benchmark",
      "Streaming Video Understanding",
      "Multimodal Large Language Models",
      "Video Benchmark",
      "Evaluation"
    ],
    "venue": "ICLR",
    "year": 2025,
    "pdf_url": "https://openreview.net/pdf?id=qnAZqlMGTB",
    "forum_url": "https://openreview.net/forum?id=qnAZqlMGTB",
    "reviews": [
      {
        "rating": "3",
        "confidence": "4",
        "summary": "This work proposes a benchmark called StreamingBench to evaluate video LLM capabilities in streaming settings. StreamingBench introduces several tasks tailored to streaming scenarios, including real-time visual understanding, omni-source understanding, and contextual understanding.",
        "strengths": "- This work introduces a new benchmark designed to evaluate video models in streaming scenarios.\n- It conducts insightful experiments, such as \"Does Redundant Information Affect Contextual Understanding?\", which provide valuable perspectives in this area.",
        "weaknesses": "- Although this benchmark focuses on streaming scenarios, a standard video LLM can handle it effectively with simple preprocessing. For instance, whenever a question arises, the model can process all frames up to that timestamp. With this approach, the benchmark may not differ significantly from traditional video benchmarks. Therefore, it is essential for this benchmark to identify scenarios that cannot be simplified to an offline setting.\n\n- While handling redundant information is indeed critical for video LLMs, this challenge is not exclusive to streaming scenarios; it is a general issue for any long-video task. As a result, the insights from this paper may be overshadowed by findings from benchmarks specifically focused on long-video understanding.\n\n- The annotation process lacks clarity. Specifically, how do human annotators manually label QA pairs for omni-source understanding and other contextual understanding tasks? What measures are in place to ensure the quality of each question, and what specific strategies were employed?"
      },
      {
        "rating": "6",
        "confidence": "5",
        "summary": "This paper introduces StreamingBench, a benchmark designed to evaluate the capabilities of MLLMs in understanding online streaming videos. Key features of StreamingBench include the ability to pose questions at any point during the video, rather than requiring the full video to be viewed first. The benchmark also considers both visual and audio inputs, and it takes into account the influence of historical interactions in multi-turn dialogues.",
        "strengths": "- StreamingBench addresses a relatively unexplored area in MLLM research—real-time video understanding. By allowing questions to be asked at any moment and incorporating both audio and visual data, it expands the scope of existing benchmarks.",
        "weaknesses": "- The methodology for collecting 900 videos from YouTube lacks sufficient detail.\n- Given that the study focuses on a model's capability that is seldom addressed—real-time video understanding—it would be beneficial to create or curate a specific supervised fine-tuning (SFT) dataset. This would allow for an evaluation of model performance post-SFT.\n- There is a lack of exploration into the model’s ability to generate proactive outputs. Designing a corresponding SFT dataset to assess whether the model performs better with prior exposure to similar outputs would provide valuable insights.\n- Clarification is needed on how open-source models like Qwen2-VL tackle omni-source understanding problems, particularly in the absence of audio inputs. This comparison could shed light on the robustness of the proposed benchmark."
      },
      {
        "rating": "6",
        "confidence": "5",
        "summary": "The paper introduces StreamingBench, a benchmark designed to evaluate the streaming video understanding abilities of Multimodal Large Language Models (MLLMs). Traditional MLLMs are effective in offline video comprehension but struggle with real-time, streaming scenarios that require instant processing, synchronizing visual and audio inputs, and understanding context over time. StreamingBench addresses this by presenting 900 videos across diverse real-world scenarios, structured into 18 tasks and 4,300 human-curated question-answer pairs. These tasks test MLLMs on real-time visual, omni-source, and contextual understanding, aiming to bridge the gap between MLLMs and human-level comprehension in streaming contexts. Testing 13 MLLMs, including state-of-the-art proprietary models, revealed significant limitations in current models, especially in omni-source and contextual tasks, suggesting that MLLMs need further development to match human performance in real-time understanding. In general, it is a solid paper and I would recommend acceptance to it.",
        "strengths": "1. It is the first valid benchmark on streaming long videos. The questions are designed properly to reflect the information gained in a streaming long video, and highly resembles what human will ask when continuously watching a video.\n2. The evaluation and discussion are both very solid.\n3. Human performance is another plus.",
        "weaknesses": "1. The real-time understanding part is nice, but seems a little bit trivial. From all kinds of NIAH evaluations, all models can best answer questions near the ending part of the input, and questions related to \"current moments\" (which is actually the ending part of input as implemented) might not be so important. Would love to see the understanding on \"remembering earlier moments\" and the discrepancy from \"current moments\" for LMMs.\n\n2. The omni-source (visual+audio) part is good. However, how are LMMs without audio abilities evaluated? As these `audio'-related questions seem to be mostly about speeches, do authors plan to interleave text ASR into the model for evaluation? At present, sadly we only see a black-box Gemini-1.5-Pro (for which we do not know how they integrate audio and video) being evaluated with audio.\n\n3. A minor suggestion: the omnisource part of the benchmark is related to \"referring reasoning\" part of LongVideoBench, an interleaved benchmark for frames and ASR texts, which also needs to judge between concurrent video and audio information in a video. As some other long video benchmarks discussed in Tab 1, please also try to discuss it in the revised paper."
      },
      {
        "rating": "8",
        "confidence": "4",
        "summary": "The authors propose a new benchmark, StreamingBench, for evaluating MLLMs in streaming video understanding. It assesses three aspects of streaming video understanding: real-time visual understanding, omni-source understanding, and contextual understanding. There are 18 tasks in total. They evaluate 13 open-source Video MLLMs and 3 proprietary MLLMs on this benchmark and analyze the results.",
        "strengths": "S1: In this paper, the authors propose a benchmark to evaluate the MLLMs' capabilities of streaming video understanding, which is novel and unexplored previously. I believe this will facilitate the advancement of Video MLLMs.\n\nS2: The benchmark considers both video and audio modalities, which have been absent in most previous benchmarks.\n\nS3: The experiments and analysis are comprehensive and detailed, effectively highlighting the limitations of current Video MLLMs in understanding streaming video.\n\nS4: The writing is clear and well-structured.",
        "weaknesses": "W1: The impact of language model size on performance has not been analyzed. For instance, models like InternVL-V2 come in 1B, 2B, 4B, 8B, 26B, 40B, and 72B parameter versions, while Video-LLaMA2, LLaVA-OneVision, and Qwen2-VL also have 72B versions. Expanding your experiments to include these variations and providing a more detailed analysis would enhance your work. Additionally, exploring the number of frames the model can process would offer valuable insights.\n\nW2: Several significant models are missing from the evaluation, such as LongVILA [1], Long-LLaVA [2], and Oryx [3]. Including these would provide a more comprehensive comparison.\n\n[1] https://github.com/NVlabs/VILA/blob/main/LongVILA.md\n\n[2] https://github.com/FreedomIntelligence/LongLLaVA\n\n[3] https://github.com/Oryx-mllm/Oryx"
      }
    ],
    "rating_avg": 5.75,
    "confidence_avg": 4.5,
    "decision": "Reject",
    "meta_review": "The paper presented a benchmark for stream video understanding. The paper received mixed ratings from four reviewers. Although some of the reviewers appreciated the importance of stream video understanding and the creation of a corresponding benchmark to advance this research area, there are some concerns still remaining in the current paper. First, as pointed out by reviewer 7TRD, the paper needs more discussion on particular insights of real-time stream video understanding, which is considered a different direction from the existing long-video understanding in an offline setting, including from both the benchmark, the method, and the evaluation levels. Both reviewers szQS and wiNw also mentioned in the weakness part that the unique capability of the model for handling online real-time stream video understanding is seldom addressed. Second, the data processing details are not clearly presented in the paper, and some additional analysis experiments should be added to better show the effectiveness of the model. Based on these significant comments, AC finally decided to reject the submission for this time.",
    "author_remarks": "",
    "decision_comment": ""
  },
  {
    "id": "2Sn0ty7zoI",
    "title": "Learning through Conditioning on Natural Language Feedback",
    "authors": [
      "Dylan Hillier",
      "Cheston Tan",
      "Jing Jiang"
    ],
    "abstract": "In this paper we explore the simple idea of teaching models by allowing them to condition their answers on natural language feedback. Motivated by the idea that natural language interactions provide a targeted, flexible, and level-appropriate reward signal, we study the ability of small instruction-tuned models to leverage feedback from a larger frontier model. We find while the frontier model provides generally high quality feedback, especially smaller models can struggle to use this due to noise in their generative output. After incorporating techniques like negative sampling, we find that models trained on these feedback-conditioned responses can perform similarly to those trained directly on teacher responses. We explore training using supervised finetuning and preference learning algorithms over a broad set of tasks including Big-Bench Hard. These findings are broadly applicable and our methods rely only on the ability of models to give and receive linguistic feedback. As such, they contribute to a growing body of work exploring how to best utilise the linguistic capabilities of language models for human-like instructive learning.",
    "keywords": [
      "Social Learning",
      "Natural Language Feedback",
      "Instructive Learning"
    ],
    "venue": "ICLR",
    "year": 2025,
    "pdf_url": "https://openreview.net/pdf?id=2Sn0ty7zoI",
    "forum_url": "https://openreview.net/forum?id=2Sn0ty7zoI",
    "reviews": [],
    "rating_avg": null,
    "confidence_avg": null,
    "decision": "N/A",
    "meta_review": "",
    "author_remarks": "",
    "decision_comment": ""
  },
  {
    "id": "N0MnPLK6r7",
    "title": "Toward Human-Interpretable Explanations in a Unified Framework for GNNs",
    "authors": [
      "Kyeongrok Park",
      "Hyunju Kang",
      "Hogun Park"
    ],
    "abstract": "As Graph Neural Networks (GNNs) are increasingly applied across various domains, explainability has become a critical factor for real-world applications. Existing post-hoc explainability methods primarily focus on estimating the importance of edges, nodes, or subgraphs in the input graph to identify substructures crucial for predictions. However, these methods often lack human interpretability and do not provide a unified framework that incorporates both model-level and instance-level explanations. In this context, we propose leveraging a set of graphlets---small, connected, non-isomorphic induced subgraphs widely used in various scientific fields---and their associated orbits as human-interpretable units to decompose GNN predictions. Domain experts can select the most relevant graphlets as interpretable units and request unified explanations based on these units. To address this problem, we introduce UO-Explainer, the Unified and Orbit-based Explainer for GNNs, which utilizes predefined orbits that are generalizable and universal across graph domains as interpretable units. Our model decomposes GNN weights into orbit units to extract class-specific graph patterns (model-level) and to identify important subgraphs within individual data instances for prediction (instance-level). Extensive experimental results demonstrate that UO-Explainer outperforms existing baselines in providing meaningful and interpretable explanations across both synthetic and real-world datasets.",
    "keywords": [
      "eXplainable AI",
      "Graph Neural Networks"
    ],
    "venue": "ICLR",
    "year": 2025,
    "pdf_url": "https://openreview.net/pdf?id=N0MnPLK6r7",
    "forum_url": "https://openreview.net/forum?id=N0MnPLK6r7",
    "reviews": [
      {
        "rating": "3",
        "confidence": "5",
        "summary": "The paper addresses the problem of explainability in (black-box) graph neural networks (GNNs). As the existing methods lack explanations that are human interpretable as well as a unified framework to perform both instance specific and model-level explanations, the paper proposes a framework based on graphlets (and orbit bases). These predefined graphlets and their associated orbits contribute to both instance and model-level explanations.",
        "strengths": "- The problem of explanations of GNN is relevant and timely as GNNs are being applied in many domains.\n\n- The unified framework of having both instance-level and model-level explanations is interesting.\n\n- The experiments have many different settings. The number of baselines and datasets is comprehensive.",
        "weaknesses": "- The graphlets (orbit bases) as human interpretable units need justifications.\n\n- A strong assumption is that both the instance-level and model level explanations depend on these graphlets (orbit bases). This also needs justification.\n\n- Some experimental settings could be improved."
      },
      {
        "rating": "5",
        "confidence": "4",
        "summary": "The paper introduces UO-Explainer, a framework for Graph Neural Networks (GNNs) that provides human-interpretable explanations at both model and instance levels. It utilizes graphlets and orbits as interpretable units to reveal the significance of specific graph structures for predictions. This unified approach aims to address limitations in previous GNN explainability methods, particularly in providing coherent, interpretable insights. The experiments on various synthetic and real-world datasets demonstrate its effectiveness.",
        "strengths": "1. The idea of leveraging graphlets and orbits as units for interpretation is interesting\n\n2. The experimental results show UO-Explainer accurately provides explanations than baselines at both model-level and instance level.\n\n3. The source code is publicly available",
        "weaknesses": "1. The paper aims to provide human interpretable explanations. However, there are no experiments asking human evaluators to evaluate the quality of the explanations. The authors should consider adding some experiments of human evaluation.\n\n2. The model-level explanation is only evaluated on synthetic datasets. It is unclear if such kind of model-level explanation really makes sense on real-world datasets. For example, does there really exist a model-level graphlet for each class for molecular graphs, which is able to explain the characteristics of each class captured by the target GNN model?\n\n3. Though the idea of leveraging graphlets and orbits as units for interpretation is interesting, the authors might need to give more explanations and real-world examples showing why they make sense in real-world.\n\n4. In lines 201-202, this paper introduces a model-level explanation by decomposing class weights into a linear combination of orbit bases. However, I think it will potentially lose some contextual information between the graphlets, because these bases only capture local information, and they might miss out on broader contextual patterns in the graph. For example, some predictions might depend on interactions between distant nodes or on the overall graph structure, which cannot be encapsulated by small, isolated graphlets.\n\n4. In line 259-261, the paper introduces the instance-level explanation by decomposing the prediction value of the target node into orbit units. But the motivation of the proposed method is not clearly introduced.\n\n5. I am concerned about the efficiency. To generate the instance-level explanations, the proposed method needs to go through all graphlets that include all 0-72 orbits with time complexity $O(|O||V| d^{k−1})$ based on Algorithm 3 and 4. This search method is too expensive to extend to large-scale graphs. Moreover, this paper lacks an experimental analysis of the time complexity. A running time comparison is highly suggested."
      },
      {
        "rating": "5",
        "confidence": "5",
        "summary": "This submission introduces a new l framework for explaining Graph Neural Networks (GNNs) that provides both model-level and instance-level explanations in a unified manner. UO-Explainer leverages graphlets and their orbits—small, connected, non-isomorphic subgraphs—as human-interpretable units to decompose GNN predictions. The framework enables users to utilize prior knowledge by selecting relevant graphlets for detailed, interpretable explanations. UO-Explainer decomposes class-specific model weights into orbit units, facilitating the identification of important substructures in both general and instance-specific contexts. Extensive experiments on synthetic and real-world datasets demonstrate that UO-Explainer outperforms existing methods in delivering high-quality explanations.",
        "strengths": "1. The idea is interesting and promising in unifying model-level and instance-level explanations for GNNs.\n2. The technical approach is novel, incorporating orbit basis learning and class-orbit score learning.\n3. The paper is well-organized, with self-contained figures that aid understanding.\n4. The experiments are comprehensive, covering 8 node classification datasets.",
        "weaknesses": "1. The title and abstract overstate the scope, as the method can only explain node classification tasks.\n\n2. The method’s reliance on all subgraphs with up to 5 nodes as explanation units does not inherently ensure meaningful or domain-relevant structures. It is unclear how this improves human interpretability compared to subgraph-based methods that use constraints like connectivity.\n\n3. In real-world datasets such as Gene, linking small graphlets to functionally significant groups can be problematic. The approach does not consider node features or types, making it difficult to distinguish substructures with different real-world meanings or implications. For instance, C-C and CO substructures correspond to the same graphlet, which poses an issue.\n\n4. The notations need improvement, as the notation for the downstream layer does not consider activation functions.\n\n5. The reference paper mentions two fidelity measurements: Fidelity+ and Fidelity-. This submission uses Fidelity+, and I suggest that the authors specify this clearly.\n\n6. Add robust fidelity measurements. As recent studies [1, 2, 3] have shown, Fidelity in the graph domain suffers from out-of-distribution (OOD) issues. Specifically, in Eq. 10, $f_{\\text{prob}}()$ is trained on datasets containing entire graphs, whereas  $G_{vi} - G_{vi}^{\\text{ex}}$ is a smaller subgraph with a different distribution. Thus, the prediction  $f_{\\text{prob}}(G_{vi} - G_{vi}^{\\text{ex}})$ may not be reliable. I recommend that the authors consider robust fidelity measurements, such as Robust Fidelity [1], OAR, SimOAR[2], or GInX-Eval[3], or demonstrate that this distribution shift does not impact the main results.\n\n[1] Zheng, Xu, et al. \"Towards Robust Fidelity for Evaluating Explainability of Graph Neural Networks.\" The Twelfth International Conference on Learning Representations. (2024)  \n[2] Fang, Junfeng, et al. \"Evaluating post-hoc explanations for graph neural networks via robustness analysis.\" Advances in Neural Information Processing Systems 36 (2023).  \n[3] Amara, Kenza, Mennatallah El-Assady, and Rex Ying. \"GInX-Eval: Towards In-Distribution Evaluation of Graph Neural Network Explanations.\" XAI in Action: Past, Present, and Future Applications. 2023"
      },
      {
        "rating": "3",
        "confidence": "4",
        "summary": "The authors propose an graphlet/orbits based GNN Explainer for providing human-interpretable explanations. UO-Explainer decomposes GNN weights into orbits and uses these orbits as explanatory units. It can provide both model-level explanations and instance-level explanations. Experiments on synthetic and real-world datasets show that UO-Explainer outperforms baseline explainability methods in providing meaningful, interpretable explanations.",
        "strengths": "S1: Leverages orbits within small graphlets as human-interpretable units for explanations. This even allows users to define their own units of interest instead of orbits if desired.\nS2: Provides explanations in a unified framework at both the model and instance level",
        "weaknesses": "C1: Lack of intuitive representation: what's orbits in graphlet? why orbits are used as explanation unit? What're unique property of graphlet and oribts? What's advantages of graphlet and orbit compared to existing methods? Why the proposed oribit-based explainer can unify both levels?\n\nC2: Limited to using orbits from 2-5 node graphlets, restricting the explanation patterns. There may be cases where important patterns in the data involve larger graphlets that cannot be captured by this restricted set of units. \n\n\nC3: As a follow-up, we need to predefine the graphlets/orbits, rather than learning them from data. Would it be possible to extend the base set of graphlet. For example, considering these 2-5 node graphlet as seeds, how to dynamically discover larger graphlet that might be more meaningful to exaplain the prediction ability of a GNN."
      }
    ],
    "rating_avg": 4.0,
    "confidence_avg": 4.5,
    "decision": "Reject",
    "meta_review": "The paper proposes an algorithm for explaining black-box GNNs. The paper is motivated by the observation that existing methods lack explanations that are human interpretable and the ability to perform both instance specific and model-level explanations. The paper proposes a framework based on predefined graphlets and their associated orbits to perform both instance and model-level explanations. The reviewers have highlightes several concerns related to the justification of using graphlets, their connections to human interpretability, and substantiating the various claims made in the paper. The authors opted not to submit a rebuttal, leading to the conclusion that the paper is not yet ready for publication.",
    "author_remarks": "",
    "decision_comment": ""
  },
  {
    "id": "w7P92BEsb2",
    "title": "PIED: Physics-Informed Experimental Design for Inverse Problems",
    "authors": [
      "Apivich Hemachandra",
      "Gregory Kang Ruey Lau",
      "See-Kiong Ng",
      "Bryan Kian Hsiang Low"
    ],
    "abstract": "In many science and engineering settings, system dynamics are characterized by governing partial differential equations (PDEs), and a major challenge is to solve inverse problems (IPs) where unknown PDE parameters are inferred based on observational data gathered under limited budget. \nDue to the high costs of setting up and running experiments, experimental design (ED) is often done with the help of PDE simulations to optimize for the most informative design parameters (e.g., sensor placements) to solve such IPs, prior to actual data collection. This process of optimizing design parameters is especially critical when the budget and other practical constraints make it infeasible to adjust the design parameters between trials during the experiments.\nHowever, existing experimental design (ED) methods tend to require sequential and frequent design parameter adjustments between trials. Furthermore, they also have significant computational bottlenecks due to the need for complex numerical simulations for PDEs, and do not exploit the advantages provided by physics informed neural networks (PINNs) in solving IPs for PDE-governed systems, such as its meshless solutions, differentiability, and amortized training. \nThis work presents Physics-Informed Experimental Design (PIED), the first ED framework that makes use of PINNs in a fully differentiable architecture to perform continuous optimization of design parameters for IPs for one-shot deployments. \nPIED overcomes existing methods' computational bottlenecks through parallelized computation and meta-learning of PINN parameter initialization, and proposes novel methods to effectively take into account PINN training dynamics in optimizing the ED parameters. \nThrough experiments based on noisy simulated data and even real world experimental data, we empirically show that given limited observation budget, PIED significantly outperforms existing ED methods in solving IPs, including for challenging settings where the inverse parameters are unknown functions rather than just finite-dimensional.",
    "keywords": [
      "Physics-Informed Neural Network",
      "PINNs",
      "Experimental Design",
      "AI For Science",
      "Active Learning",
      "Data Selection"
    ],
    "venue": "ICLR",
    "year": 2025,
    "pdf_url": "https://openreview.net/pdf?id=w7P92BEsb2",
    "forum_url": "https://openreview.net/forum?id=w7P92BEsb2",
    "reviews": [
      {
        "rating": "8",
        "confidence": "2",
        "summary": "The paper proposes a novel algorithm for solving the inverse problem in PDEs - that is, estimating the parameters of a PDE governing the dynamic characteristics of a system.  In particular, the paper assumes that (a) obtaining (x,y) observations of the system is expensive, so we must select our observation points carefully; and (b) observations require an initial setup that we cannot (practically) repeat, so we must specify our test points up-front and not dynamically as in e.g. Bayesian Optimization.\n\nTo tackle this problem the paper suggests physics-informed experimental design (PIED) that uses two sets of PINNs to select appropriate test points for a given system of PDEs (with a-priori unknown parameters).  The general approach uses a set of PINNs operating as forward simulators to generate functions satisfying the PDEs, sampling these for a set of points X, then using PINNs as inverse solvers to estimate the PDE parameters from the observations.  The efficacy of the points X is measured as the difference between the \"real\" PDE parameters (used in the forward simulators) and the corresponding estimated estimated PDE parameters.",
        "strengths": "The algorithm is certainly interesting.  The PIED framework certainly looks practical.  The motivation behind and justification of each step is presented, and the experimental results look good.",
        "weaknesses": "One point that needs to be address in the paper is that of computational cost.  After all, one of the motivations of using PINNs in parallel is computational efficiency, so it would be good to have a comparison in terms of same."
      },
      {
        "rating": "8",
        "confidence": "2",
        "summary": "This paper suggests PIED, a method for optimal experimental design for PDE inverse problems via Physics-informed neural networks (PINN). The PIED framework consists of three steps: 1. A PINN to learn a forward simulator that maps parameters $\\beta$ to solutions of the PDE $u_\\beta$. 2. An observation selector that returns noisy predicted observations $\\tilde Y= u_\\beta(X) + \\epsilon$ at a fixed number of sensor placements $X$. 3. A PINN inverse solver that predicts the ground truth parameter $\\hat \\beta(X, \\tilde Y)$ from $X$ and $\\tilde Y$. 4. The optimal sensor placements $X$ are found by minimising the MSE between $\\beta$ and $\\hat \\beta(X, \\tilde Y)$ which requires back-propagation through the inverse problem solver. The paper claims the following contributions and innovations: \n- The weight initialisations of all PINN-based components are shared and from a pretrained model which stabilises and accelerates training.\n- The forward simulator for various choices of $\\beta$ are learned in parallel\n- The mean square error between $\\hat\\beta(X, \\tilde Y)$ and $\\beta$ is approximated by learning the inverse solver with a smaller number of training steps (FIST criterion for ED)\n- The mean square error between $\\hat\\beta(X, \\tilde Y)$ and $\\beta$ is approximated through a linearisation of the PINN training dynamics (MoTE criterion for ED)\n\nThe framework is tested on optimal experimental design for sensor placement on Eikonal, Wave, and Navier-Stokes equations as well as groundwater and cell growth dynamics, and benchmarked against Bayesian experimental design, random sensor placements, and sensor placements on a grid.",
        "strengths": "- Overall, the paper is well written and seems methodologically sound.\n- The paper addresses a challenging experimental design problem with little existing approaches.\n- There is sufficient experimental results to support to proposed approach.\n- The paper combines an interesting set of ideas: \n\t- Meta learning and shared weights for more efficient PINN training. \n\t- Approximate training dynamics through of the inverse solver to make back-propagation through the inverse solver feasible.",
        "weaknesses": "- The approach is mostly motivated by the comparison with classical simulators, but other types of neural surrogate models for the forward simulator are not mentioned. This is probably because most such approaches like Fouier Neural Operators don't investigate the ED downstream task. Nevertheless, this made me wonder how much this approach actually relies on Physics-informed neural networks. For example, the processing in parallel threads would be typical for all approaches that target ED with a neural network.\n- The description of the algorithm/framework is a little inconsistent. The PIED framework in Figure 1 suggests that the PIED framework is trained end-to-end, while Algorithm 3 in the appendix clarifies that training proceeds in three phases that are not interleaved: Optimising for initial weights,  training to define ED criteria, optimisation of ED criterion. I wish that this was clearer from the main text."
      },
      {
        "rating": "6",
        "confidence": "3",
        "summary": "The authors developed a physics-informed experimental design approach for the inverse problems to find the optimal and most informative design parameters. The paper is well-organized.",
        "strengths": "The theoretical analysis of PINN is thorough.",
        "weaknesses": "The effect of some experiments is not significant."
      },
      {
        "rating": "6",
        "confidence": "3",
        "summary": "This paper solves the one-shot experiment design using PINNs in both forward and inverse problems. It overcomes computational bottlenecks by parallelism and meta-learning of initialization. The experiments on both synthetic and real-life datasets show the performance improvements.",
        "strengths": "1. this paper joins many advanced techniques together to solve the problem.\n2. most of the representation is clear, with extensive experiments and details.",
        "weaknesses": "1. The overall algorithm flow is unclear in the main text. Figure 1b is too general and missing almost all of the details of the technique.\n2. Does not compare with existing NN-based experiment design methods.\n3. Almost all techniques are adopted from existing literature."
      }
    ],
    "rating_avg": 7.0,
    "confidence_avg": 2.5,
    "decision": "Accept (Poster)",
    "meta_review": "This paper proposes a new method for optimal experimental design for PDE inverse problems via Physics-informed neural networks (PINN).  The approach entails learning a forward simulator that maps parameters to PDE solutions;  an observation selector that returns noisy predicted observations  at a fixed number of sensor placements; and an inverse solver that predicts the ground truth parameter. This sets up an objective function for finding optimal sensor placements.  Favorable experimental comparisons against Bayesian experimental design, random sensor placements, and sensor placements on a grid for Eikonal, Wave, and Navier-Stokes equations as well as groundwater and cell growth dynamics is the primary strength of this paper. Computational cost, novelty and some remarks on empirical significance were brought up as weaknesses, but the paper received unanimously positive reviews.",
    "author_remarks": "",
    "decision_comment": ""
  },
  {
    "id": "wE5xp3zBaQ",
    "title": "The Good, the Bad and the Ugly: Watermarks, Transferable Attacks and Adversarial Defenses",
    "authors": [
      "Grzegorz Gluch",
      "Berkant Turan",
      "Sai Ganesh Nagarajan",
      "Sebastian Pokutta"
    ],
    "abstract": "We formalize and extend existing definitions of backdoor-based watermarks and adversarial defenses as *interactive protocols* between two players. The existence of these schemes is inherently tied to the learning tasks for which they are designed. Our main result shows that for *almost every* discriminative learning task, at least one of the two — a watermark or an adversarial defense — exists. The \"*almost*\" refers to the fact that we also identify a third, counterintuitive but necessary option, i.e., a scheme we call a *transferable attack*. By transferable attack, we refer to an efficient algorithm computing queries that look indistinguishable from the data distribution and fool *all* efficient defenders.\n\nTo this end, we prove the necessity of a transferable attack via a construction that uses a cryptographic tool called homomorphic encryption. Furthermore, we show that any task that satisfies our notion of a transferable attack implies a *cryptographic primitive*, thus requiring the underlying task to be computationally complex. These two facts imply an \"*equivalence*\" between the existence of transferable attacks and cryptography. Finally, we show that the class of tasks of bounded VC-dimension has an adversarial defense, and a subclass of them has a watermark.",
    "keywords": [
      "Watermarks",
      "Adversarial Defenses",
      "Transferable Attacks",
      "Interactive Proof Systems",
      "Cryptography",
      "Backdooring",
      "Game Theory",
      "Learning Theory"
    ],
    "venue": "ICLR",
    "year": 2025,
    "pdf_url": "https://openreview.net/pdf?id=wE5xp3zBaQ",
    "forum_url": "https://openreview.net/forum?id=wE5xp3zBaQ",
    "reviews": [
      {
        "rating": "3",
        "confidence": "3",
        "summary": "This paper investigates the relationship between watermarks (planted in trained ML models) and adversarial defenses for noiseless classification tasks over a finite set $\\mathcal{X}$. For clarity, let us focus on *binary* classification tasks. Here, a learning task (or equivalently, full data distribution) can be represented by a pair $(D, f^*)$, where $D$ is the marginal distribution over $\\mathcal{X}$ and $f^*: \\mathcal{X} \\to \\\\{0,1\\\\}$ is the true labeling function.\n\nFor any given learning task $(D, f^*)$, consider an interactive protocol in which Alice (ML service provider) interacts with Bob (client). As a service provider, Alice trains a classifier $f: \\mathcal{X} \\to \\\\{0,1\\\\}$ which achieves $\\epsilon$-error on $D$, and sends it to Bob. However, Alice is motivated to secretly plant a “watermark” into her trained classifier $f: \\mathcal{X} \\to \\\\{0,1\\\\}$ by making it susceptible to pre-designed adversarial examples. Bob, on the other hand, is motivated to neutralize any backdoors in the classifier f he received from Alice.\n\nThe opposing objectives of Alice and Bob in this framework can be formulated as a *zero-sum two-player* game. Furthermore, by modeling Alice and Bob to be circuit classes of fixed size, the pure strategy space for both Alice and Bob become finite, with explicit bounds on their cardinalities. This setup allows previous results on approximate equilibria [Lipton and Young, 1994] to be applied. Using the zero-sum two-player game formulation, the authors show that any “efficiently learnable” classification task $(D, f^*)$ falls into at least one of the following three cases:\n\n1. **Watermarking.** There exists a watermarking scheme for Alice can compute a classifier f and sequence of adversarial (randomized) queries $x_1, …, x_q$ such that for any circuit (”Bob”) whose size is significantly smaller than hers (i.e., y computed by any such small circuit incurs $\\mathrm{err}(x, y) \\ge 2\\epsilon$) the watermark is *unremovable* and the distribution of her queries $x_1, …, x_q$ is indistinguishable from $D$.\n2. **Adversarial Defense.** There exists a watermark neutralizing (i.e., adversarial defense) scheme for Bob such that either Alice’s queries $x_1,…,x_q$ are non-adversarial (the avg loss of $f$ on $x_1, …, x_q$ is $\\epsilon$-small) or the distribution of Alice’s queries $x_1, …, x_q$ and $D^q$ are distinguishable by small circuits.\n3. **Transfer Attack.** A third possibility not covered by the previous two cases, which has left me confused. Please refer to the Questions section for further details.",
        "strengths": "The paper attempts to formalize an intriguing relationship between two phenomena recently studied in machine learning: watermarking (i.e., planting undetectable backdoors [Goldwasser et al., 2022]) and adversarial defense [Cohen et al., 2019]. A watermark for a classifier attempts to hide specific signatures in its error patterns, while an adversarial defense attempts to maintain performance of a given untrusted classifier f across distributions that are “close to” D, which can be formalized via a weakened notion of statistical distance. Intuitively, there is tension between these two objectives, which the authors attempt to formalize as a zero sum game. Addressing these natural questions would be of wide interest to the ML community.",
        "weaknesses": "The main weakness of this paper lies in the **lack of clarity and precision in its definitions and framework**, which significantly undermine the credibility of any theorems that follow. The presentation of key definitions and interactive protocols are “hand-wavy”, leaving substantial ambiguity in how the results should be interpreted and applied. This vagueness makes it difficult to assess the validity of the theoretical claims and fully appreciate the significance of the results.\n\nWhile the authors give more formal specifications in the Appendix (especially, Appendix B), significant gaps still remain to be filled. In addition, the appendix should provide further technical details after the basic setup and key insights have been presented in the main text, rather than serving as a teaser for readers left confused by the unclear presentation in the body of the work. \n\nOne significant issue is that the modeling of Alice and Bob with size-bounded circuit classes seems to fail a basic type check. In the interactive protocols, Alice and Bob face different tasks that involve different input and output spaces. For instance, in a watermarking scheme for binary classification, Alice is expected to output a representation of a classifier $f: \\mathcal{X} \\to \\\\{0,1\\\\}$ along with queries $ x_1,\\ldots,x_q \\in \\mathcal{X}$ (a separate issue here is Alice's inputs are not specified and the dependence on the input domain’s cardinality doesn't appear anywhere in the quantitative results, which raises concerns). On the other hand, Bob’s inputs are sequences $x_1, \\ldots, x_q$ and needs to output $y \\in \\\\{0,1\\\\}^q$. Without further clarification, it’s unclear how a size $s$ circuit for Alice compares to a size $s$ circuit for Bob since even the input and output domains do not match. This is one of several issues with the paper's framework that, collectively, call into question the overall rigor and applicability of the approach. Please refer to the **Questions** section for additional issues.\n\nMoreover, the paper **incorrectly applies previous results from cryptography**, which indicates a lack of understanding of the field. In particular, the interpretation of the results based on [Goldreich, 1990] in Section 5.2 is incorrect. Goldreich’s result applies to an *ensemble* of random variables, i.e., a *sequence* of distributions, whereas the EFID pairs the authors define in Section 5.2.1 are particular instances of distributions. Moreover, the ensembles used by Goldreich are *uniformly constructible*, meaning that there exists a single Turing machine generating random samples from X_n given the input 1^n. This contrasts with the non-uniform circuits used in this work. Given this misunderstanding, the title of Section 5,  *Transferable Attacks are “Equivalent” to Cryptography* is misleading and unnecessarily provocative. Even if Goldreich’s equivalence result could be applied here (which I find unlikely), the only concrete implication for cryptography is the existence of pseudorandom generators (PRGs), which are basic cryptographic primitives but do not represent the entire research field.\n\nIn addition, the restriction to succinct circuits feels somewhat ad hoc, seemingly added specifically to prevent Alice and Bob from hardcoding outputs. It seems likely that the approximate equilibria results (Theorem 1) would still hold without the succinctness assumption, albeit with different bounds, as the key requirement is simply that the pure strategy space remains finite with explicitly known bounds on its cardinality. This raises concerns about the integrity of the formulation, with the succinctness restriction serving more as a workaround than an integral component of the setup.\n\nOverall, the paper would benefit greatly from prioritizing clarity over excessive generality, focusing on straightforward, concrete setups and presenting mathematical results clearly and precisely, without the informal remarks.\n\n**Editorial comments**\n- (Abstract) The phrase \"almost every\" learning task is misleading. Terms like “almost every” carry strong connotations in measure theory. The mere fact that a mathematical object is “irregular” or \"very complex\" does not imply that it is rare (e.g., from a measure-theoretic perspective). For instance, with respect to the uniform measure on [0,1], “almost every” real number in the unit interval is uncomputable.\n- (Line 214) Advantage should be an equal sign.\n- (Line 243) The unremovability condition, as stated, is clearly incorrect. Bob can simply respond with random y and the realized error can be 0 with small but non-zero probability. Even if this is intended as an informal simplification of the definitions in Appendix B, it should not be so obviously wrong.\n- (Line 248) The term \"defender\" is used inconsistently alongside other terms like \"player\", \"prover\", and \"Bob\". It would be better to choose a single term for the recurring entities and use it consistently throughout the paper."
      },
      {
        "rating": "5",
        "confidence": "2",
        "summary": "This paper explores the relationship between backdoor-based watermarks and adversarial defenses in machine learning.  These concepts are formalized as interactive protocols between two players and proved that for almost every discriminative learning task, at least one of the two exists. The main contribution is the identification of a third, counterintuitive option: a transferable attack.  This term describes an algorithm capable of generating queries that are indistinguishable from the data distribution, yet can deceive even the most effective defenses.  The authors demonstrated the necessity of a transferable attack using homomorphic encryption and proved that any task susceptible to such an attack implies a cryptographic primitive.",
        "strengths": "- Formalization of the relationship between backdoor-based watermarks and adversarial defenses is useful.",
        "weaknesses": "- I take umbrage with the following claim: “Along the way to proving the main result, we identify a potential reason why this fact was not discovered earlier.”. There are multiple prior works that have investigated the trade-off between adversarial robustness and backdoors/watermarks [Weng et al,  Sun et al, Gao et al, Niu et al., Fowl et al., related work in Tao et al. is a good summary]. Although most of these papers are more empirical, this paper completely ignores an entire line of work. The paper primarily focuses on theoretical results without providing clear guidance on how these results can be translated into practical applications, and I find it difficult to assess if this paper is saying anything profound beyond what has already been discussed in the referenced papers. This is my main concern. Some suggestions:\n    * (1) Include a detailed discussion of how their theoretical results relate to or extend the empirical findings in the papers you cited.\n    * (2) Explicitly state what novel insights their work provides beyond the existing literature.\n    * (3) Add a section on potential practical applications or implications of their theoretical results.\n\n- In Definition 2.3. Why is the coefficient before epsilon, 7?\n\n- The paper primarily deals with discriminative learning tasks, like classification. These tasks assume a clear relationship between input data (e.g., images) and distinct output labels (e.g., \"cat\" or \"dog\").  How can the trade-offs be captured for generative models?\n\n\n[Weng et al] Weng, Cheng-Hsin, Yan-Ting Lee, and Shan-Hung Brandon Wu. \"On the trade-off between adversarial and backdoor robustness.\" Advances in Neural Information Processing Systems 33 (2020): 11973-11983.\n\n[Sun et al] Sun, Mingjie, Siddhant Agarwal, and J. Zico Kolter. \"Poisoned classifiers are not only backdoored, they are fundamentally broken.\" arXiv preprint arXiv:2010.09080 (2020).\n\n[Gao et al.] https://openreview.net/forum?id=nG4DkcHDw_\n\n[Niu et al.] Niu, Zhenxing, et al. \"Towards unified robustness against both backdoor and adversarial attacks.\" IEEE transactions on pattern analysis and machine intelligence (2024).\n\n[Fowl et al.] Fowl, Liam, et al. \"Adversarial examples make strong poisons.\" Advances in Neural Information Processing Systems 34 (2021): 30339-30351.\n\n[Tao et al.] Tao, Lue, et al. \"Better safe than sorry: Preventing delusive adversaries with adversarial training.\" Advances in Neural Information Processing Systems 34 (2021): 16209-16225."
      },
      {
        "rating": "6",
        "confidence": "4",
        "summary": "The authors provably identify the following trichotomy - for every learnable task there is an adversarial defence and/or a watermarking scheme, while for learning tasks which have associated cryptographic hardness results, there is a transferable attack.",
        "strengths": "The most important contribution of this manuscript is the proof that the notions adversarial robustness and watermarking schemes is complementary to the notion of cryptographically hard learning schemes. The authors use a lot of existing results across various fields creatively, to arrive at this result, which makes the technical part of the paper interesting in its own right.",
        "weaknesses": "My main concern with the paper is that the definitions (especially the two player games) is too carefully constructed to be readily used in conjunction with existing results from game theory, cryptography, and learning theory. There is lack of justification / discussion on several fronts, which should be addressed for the paper to be useful to the community at large.\n\nA secondary but related weakness is the lack of a technical discussion section. A detailed overview of proof techniques section is much required. I have detailed a list of my questions in the next section.\n\nA better related works section is also warranted. For example, there are certain confusions arising in the discussion containing the comparison with the Christiano et al. (2024) paper. See the questions section.\n\n*Note to the authors:* Regardless of the acceptance results at this conference, I believe the authors should prepare a longer version of this manuscript and submit it to a journal like TMLR. It would be of immense value to the community.\n\n\n--------\nAfter the rebuttal period, I have decided to raise my score to indicate my positive opinion of the paper. \n\n*Note:* At this point I cannot justify raising the score any higher due to numerous missing definitions and discussions (detailed in the reviews by myself and other reviewers, and mostly agreed upon by the authors) that should have been included in a theoretical paper in the first place."
      },
      {
        "rating": "6",
        "confidence": "4",
        "summary": "The paper gives formal definitions of “watermarks” through backdoor (not for LLM’s output, but rather for models themselves) and “adversarial robustness” and “transferable attacks” in their own way. Meaning that the definitions do not necessarily match what is the common usual way of defining them, but the definitions make sense in their own way.\n\nThen, the paper observes that these three notions are complementary for a “learning task”. A task is modeled using a distribution D (on instances) and a function h (to label them) and differs from the method of using a family of h (as hypothesis class). In particular, the paper shows that for each learning task, at least one of the following holds: either we can watermark models that predict that task, or that we can resist backdoor, or that transferability attacks work.\n\nIntuitively, the main result is proved by observing that a watermark through a backdoor aims to plant a backdoor and later use specific queries to detect it (using wrong answer) and this is exactly what a defense against backdoor wants to avoid. So the two notions are rather complementary. Once the paper aims to prove this formally, they show that a third case is also possible, which in their formalism is referred to as the transferability attack.\n\nThe paper then shows that “transferability” attacks could probably exist assuming fully homomorphic encryption, and that transferability attacks *require* one-way functions (they say PRG, but that is the same as OWFs), and hence it implies secret key crypto.\n\nFinally, the paper claims that PAC learnable families (ie., those with bounded VC dimension) always can have adversarial robustness and “watermark against fast adversaries”.",
        "strengths": "A formalism of the intuition behind the duality of watermarks (for models through backdoor) and adversarial robustness is interesting. \n\nAlso, the paper realizes that formal definitions are needed for such results and takes an effort in that direction.",
        "weaknesses": "The new formalisms for the 3 notions of watermark, robustness and transferability need a lot more scrutiny and discussion. For example, there are limits on the time of the adversary that are needed to make these definitions non-vacuous, but these definitions are different from previously established definitions in this regard (e.g., about adversarial examples) and I see no real effort to compare them. (see my question below)\n\n\nAlso, due to the number of results in the main body, their proofs are deferred to the appendix, and perhaps the most exciting result (saying that bounded VC dimension means we can have adversarial robustness) is pushed to the appendix."
      }
    ],
    "rating_avg": 5.0,
    "confidence_avg": 3.25,
    "decision": "Reject",
    "meta_review": "This paper derives a theoretical analysis of the relationship between backdoor-based watermarks and adversarial defenses. The authors show that all discriminative learning tasks can be categorized into one of three classes, which suggests there is an inherent security trade-off in ML applications.\n\nReviewers generally appreciated the technical depth of the paper and its clever use of existing techniques to derive their theoretical result. However, most reviewers also found the paper's analysis framework to be lacking in precision, leaving much of the derived theoretical result up to interpretation. The paper is also written in a way that is difficult to absorb for the general ML audience. As a result, practical implications of the paper are also unclear. After the rebuttal period, reviewers and AC discussed thoroughly and reached consensus that the paper's weaknesses currently outweigh its strengths. Thus, AC believes the paper is currently not ready for publication, but encourages the authors to taken into account reviewer suggestions and improve the paper's clarity before resubmitting to a future venue.",
    "author_remarks": "",
    "decision_comment": ""
  },
  {
    "id": "pcnq7fZs4t",
    "title": "Common Feature Learning for Zero-shot Image Recognition",
    "authors": [
      "Shuang Li",
      "Lichun WANG",
      "Kai Xu",
      "Jianjia Xin"
    ],
    "abstract": "The key issue of zero-shot image recognition (ZIR)  is how to infer the relationship between visual space and semantic space from seen classes, and then effectively transfer the  relationship to unseen classes. Recently, most methods have focused on how to use images and class semantic vectors or class names to learn the relationship between visual space and semantic space. The relationship established by these two methods is class-level and coarse-grained. The differences between images of the same class are ignored, which leads to insufficiently tight relationships and affects the accurate recognition of unseen classes.To tackle such problem, we propose Common Feature learning for Zero-shot Image Recognition (CF-ZIR) method to learn fine-grained visual semantic relationships at the image-level. Based on the inter class association information provided by class semantic vectors, guide the extraction of common visual features between classes to obtain image semantic vectors. Experiments on three widely used benchmark datasets show the effectiveness of the proposed approach.",
    "keywords": [
      "Zero-shot Image Recognition；Visual-semantic Relationship；Fine-grained Alignment；Semantic Vectors Generation；"
    ],
    "venue": "ICLR",
    "year": 2025,
    "pdf_url": "https://openreview.net/pdf?id=pcnq7fZs4t",
    "forum_url": "https://openreview.net/forum?id=pcnq7fZs4t",
    "reviews": [
      {
        "rating": "1",
        "confidence": "5",
        "summary": "This paper proposed to learn a common features for ZSL, which include two kind dictionary for the final prediction.",
        "strengths": "1. The proposed method is innovative in using a dual dictionary approach to improve class prediction accuracy.\n\n2. The paper is well-structured, making it relatively easy to follow the methodology and experimental setup.",
        "weaknesses": "1. The motivation in the third paragraph of the introduction, stating that \"most methods focus on how to use images and class semantic vectors or class names to learn the relationship between visual space and semantic space,\" is somewhat inaccurate. In fact, most methods utilize class-level attributes as semantic information. Some also incorporate embeddings of individual attributes to enhance fine-grained associations.\n\n2. Section 3.2 is overly lengthy and has significant overlap with subsequent sections. The overview could be more concise to avoid redundancy and improve clarity.\n\n3. There is confusion around the definitions of semantic space and attribute space. What is the intended difference? In ZSL, attributes are generally considered a type of semantic information, so a clearer distinction would improve understanding.\n\n4. The paper lacks comparisons with recent methods and is limited in dataset diversity. Additional comparisons with recent approaches and experiments on more datasets, such as CUB, FLO, and SUN, would strengthen the evaluation.\n\n5. More extensive experimentation is needed. The current paper includes only two tables and one figure, which is insufficient to support its claims. Particularly, experiments should cover both conventional ZSL and generalized ZSL.\n\nThis paper appears incomplete and requires substantial revision before submission. More work is needed to clarify motivations, streamline the methodology, and provide comprehensive experimental validation."
      },
      {
        "rating": "5",
        "confidence": "5",
        "summary": "This paper mainly introduces a shared feature learning method (CF-ZIR) for zero-sample image recognition, which extracts shared visual features through attribute guidance, and uses category semantic vectors to guide the generation of image semantic vectors, so as to form the semantic representation of images. In addition, a dual-layer embedding method is proposed to establish fine-grained associations between visual-attributes and visual-semantics. Experimental results show that the CF-ZIR method achieves competitive performance on multiple datasets.",
        "strengths": "1. The dual-layer embedding mechanism is introduced to improve the recognition performance through fine-grained visual-semantic relationship, which exhibits a degree of innovation.\n2. The paper is articulated with clarity and precision.",
        "weaknesses": "1. Although the experimental results are presented in the paper, the description of experimental settings, hyperparameter selection, training details and other aspects is not detailed enough, which may affect other researchers to reproduce the results.\n2. The proposed method does not achieve the best results on multiple datasets. \n3. Several references to the three datasets were made with inconsistent fonts."
      },
      {
        "rating": "3",
        "confidence": "5",
        "summary": "This paper proposes common feature learning for zero-shot image recognition (CF-ZIR) method to learn fine-grained visual semantic relationships. This method leverages inter-class association information from class semantic vectors to guide the extraction of common visual features. Experiments on three datasets show the effectiveness.",
        "strengths": "+ Introducing dual-layer embedding method for zero-shot learning is reasonable.\n+ The experimental results show the effectiveness of the proposed approach on conventional ZSL.",
        "weaknesses": "- The paper leverages inter-class association information from class semantic vectors to guide the extraction of common visual features. In fact, this issue has been defined as visual-semantic domain shift in previous work and has been discussed in several papers, such as [1], [2] and [3]. This paper does not discuss the differences with them.\n\n- This paper only conducts experiments under the conventional zero-shot learning setting, lacking experiments in generalized zero-shot learning.\n\n- Line 16, \"The relationship established by these two methods is class-level and coarse-grained\", what do these two methods refer to?\n\n- Introduction and Related work sections do not discuss the latest research.\n\n- The ablation experiments are insufficient to validate the claims of this paper, especially regarding zero-shot recognition in three spaces discussed herein.\n\n- The paper discerns fine-grained visual-semantic relationships at the image level, but why are experiments not conducted on fine-grained datasets, such as CUB?\n\n- There is a lack of hyperparameter analysis. The current hyperparameters are not convincing. Are they the same across all datasets?\n\n- How does this method demonstrate advantages for attributes like 'small', 'hunter', and 'fast' on AWA2?"
      },
      {
        "rating": "3",
        "confidence": "4",
        "summary": "This paper proposes a novel method called Common Feature learning for Zero-shot Image Recognition (CF-ZIR) to address the challenge of learning fine-grade relationships between images and classes in Zero-Shot Learning. CF-ZIR leverages the inter-class association information from class semantic vectors to guide the extraction of common visual features between classes. The author conducted experiments on three datasets to attempt to validate the effectiveness of the proposed method.",
        "strengths": "It seems that the proposed approach is easy to follow.",
        "weaknesses": "This paper has major shortcomings in writing, method innovation, and experiment, so it is not able to be accepted, specifically:\n\nThis paper is hard to read. The meanings of many concepts are difficult to understand. For example, what is ‘the cross domain dictionary learning model’ mentioned in Section 3.2 and what are the particular meanings of ‘common feature’, ‘single dictionary learning model’ and ‘class semantic vectors’? The structure of the model and the calculation process are also hard to understand, what are ‘x2’ and ‘x3’ in Figure 1?\n\nThis paper is filled with grammatical and formatting errors, to the point that it's difficult to list them all. For example, in the abstract, 'zero-shot image recognition (ZIR)' should be 'Zero-shot Image Recognition (ZIR)', 'unseen classes.To tackle' should be ''unseen classes. To tackle', and ' Based on the inter class association information provided by class semantic vectors, guide the extraction of common visual features between classes to obtain image semantic vectors.' should be 'The inter-class association information provided by class semantic vectors guides the extraction of common visual features between classes to obtain image semantic vectors.'\n\nAligning images with attributes is a common idea in existing approaches (Modeling Inter and Intra-Class Relations in the Triplet Loss for Zero-Shot Learning (ICCV19) and Concept Bottleneck Models (ICML20)).\n\nThe author conducted experiments on only three small datasets, two of which are nearly identical (AWA1 and AWA2), and did not compare with multimodal pre-trained models such as CLIP."
      }
    ],
    "rating_avg": 3.0,
    "confidence_avg": 4.75,
    "decision": "Reject",
    "meta_review": "The paper introduces the Common Feature learning for Zero-shot Image Recognition (CF-ZIR) method, which uses a novel dual dictionary approach to enhance class prediction accuracy by leveraging inter-class association information from semantic vectors. However, the paper suffers from several weaknesses, including a lack of motivation and context and inadequate experimental results and analysis (e.g., ablation study and hyperparameters). Other minors, such as redundancy in writing and numerous grammatical and formatting errors, could be addressed in future submissions.",
    "author_remarks": "",
    "decision_comment": ""
  },
  {
    "id": "3g2iyFU8gA",
    "title": "Learning Fused State Representations for Control from Multi-View Observations",
    "authors": [
      "Zeyu Wang",
      "Yao-Hui Li",
      "Hongyu Zang",
      "Xin Li"
    ],
    "abstract": "In visual control tasks, leveraging observations from multiple views enables Reinforcement Learning (RL) agents to perceive the environment more effectively. However, while multi-view observations enrich decision-making information, they also increase the dimension of observation space and introduce more redundant information. Thus, how to learn compact and task-relevant representations from multi-view observations for downstream RL tasks remains a challenge. In this paper, we propose a Multi-view Fusion State for Control (MFSC), which integrates a self-attention mechanism with bisimulation metric learning to fuse task-relevant representations from multi-view observations. To foster more compact fused representations, we also incorporate a mask-based latent reconstruction auxiliary task to learn cross-view information. Additionly, this mechanism of mask and reconstruction can enpower the model with the ability to handle missing views by learning an additional mask tokens. We conducted extensive experiments on the Meta-World and Pybullet benchmarks, and the results demonstrate that our proposed method outperforms other multi-view RL algorithms and effectively aggregates task-relevant details from multi-view observations, coordinating attention across different views.",
    "keywords": [
      "multi-view learning",
      "reinforcement learning"
    ],
    "venue": "ICLR",
    "year": 2025,
    "pdf_url": "https://openreview.net/pdf?id=3g2iyFU8gA",
    "forum_url": "https://openreview.net/forum?id=3g2iyFU8gA",
    "reviews": [
      {
        "rating": "5",
        "confidence": "4",
        "summary": "This paper proposes a method that combines a bisimulation-based approach with masked representation learning for multi-view reinforcement learning. The core idea is that to enable task-relevant multi-view fusion, it is essential to align the integration process closely with the specific objectives of the task. In other words, when fusing information from multiple views, the task’s specific goals (Equation 8) must be considered. The authors have evaluated their method on two visual control environments, including Meta-World and PyBullet, demonstrating significant performance improvements over baseline methods.",
        "strengths": "- The paper is clearly written and easy to understand.\n- The proposed method that integrates bisimulation metric learning into the fusion process of multi-view states is reasonable.\n- The authors have provided extensive experimental results, covering various visual RL environments, to validate the effectiveness of the method. The paper also includes experiments with missing views as well as additional visualizations to interpret the effectiveness of the method.",
        "weaknesses": "My main concerns involve the novelty of the method and the completeness of experimental comparisons:\n\n- The primary limitation lies in the method's novelty. Although the authors present two core challenges of multi-view RL in the introduction, these challenges have already been extensively explored in prior research. While incorporating bisimulation metrics into state aggregation is reasonable, bisimulation-based methods are also well-covered in existing RL literature, making this combination feel more like a natural choice than a groundbreaking innovation.\n- Although the authors conducted extensive experiments and validated the effectiveness of their approach against various existing multi-view RL methods, there are still two main gaps. First, there is no experimental verification of whether the method remains superior to baseline models in cases with missing views (even with a single view). Second, Seo et al. (2023) proposed the masked world model, which performs well on multi-view RL tasks and has methodological similarities to the approach in this paper. A direct comparison with Seo et al.'s work would provide stronger support for the effectiveness of this method."
      },
      {
        "rating": "5",
        "confidence": "4",
        "summary": "This paper proposes the Multi-view Fusion State for Control (MFSC), which integrates a self-attention mechanism and bisimulation metric learning to fuse task-relevant representations from multi-view observations, and incorporates a mask-based latent reconstruction auxiliary task to obtain more compact fused representations and handle missing views.",
        "strengths": "1. The writing is relatively clear.\n\n2. The performance of the proposed method is validated on Meta-World and Pybullet benchmarks.",
        "weaknesses": "1. The author incorporates bisimulation principles by integrating reward signals and dynamic differences into the fused state representation to capture task-relevant details. As I am aware, [1] also acquires representations for control with bisimulation metrics. Additionally, the author employed a Mask-based Latent Reconstruction strategy, which is analogous to that in [2]. Does this similarity suggest a deficiency in significant innovation or does the author offer additional components or enhancements that differentiate it from the existing strategies in [1] and [2]? Furthermore, it is essential to determine whether appropriate credit and comparison with the prior works in [1] and [2] have been adequately accounted for.\n\n[1] Learning invariant representations for reinforcement learning without reconstruction.\n\n[2] Mask-based Latent Reconstruction for reinforcement learning。\n\n3. Missing many recent visual RL baselines: the baselines used in the paper are all old methods and a large body of the recent methods developed on visual reinforcement learning are ignored [1][2].\n\n[1] TACO: Temporal Latent Action-Driven Contrastive Loss for Visual Reinforcement Learning.\n\n[2] Mastering Diverse Domains through World Models.\n\n4. Whether this method is only useful for robot control tasks needs to be further verified on more types of environments, such as Carla, atari, etc.\n\n5.  The paper lacks sufficient ablation experiments. The author only ablated MFSC without bisimulation constraints ('MFSC w/o bis') and MFSC without Mask and Latent Reconstruction ('MFSC w/o res'), but not more detailed parts like the Self-Attention Fusion Module.\n\n6. The author claims that MFSC can be seamlessly integrated into any existing downstream reinforcement learning framework to enhance the agent's understanding of the environment. However, there are no relevant experiments to verify this claim."
      },
      {
        "rating": "5",
        "confidence": "3",
        "summary": "The paper presents a novel architecture called Multi-view Fusion State for Control (MFSC), designed to learn compact and task-relevant representations from multi-view observations in reinforcement learning (RL). This approach integrates a self-attention fusion module with bisimulation metric learning to aggregate information from different views, while also using a mask-based latent reconstruction auxiliary task to promote cross-view information aggregation.  Experiments conducted on Meta-World and Pybullet demonstrate the superiority of MFSC over other methods.",
        "strengths": "1.\tThe paper addresses the challenging and significant problem of learning task-relevant fused state representations from multi-view observations, which is a crucial aspect of multi-view reinforcement learning. \n2.\tThe integration of a mask-based latent reconstruction task enhances the model’s ability to learn cross-view information. The proposed approach, combining self-attention and bisimulation metrics, offers an effective solution.\n3.\tThis paper demonstrates the effectiveness of MFSC across multiple challenging benchmarks, including robotic manipulation tasks in Meta-World and control tasks in Pybullet.",
        "weaknesses": "1.\tThis paper does not include comparisons with approaches tailed for visual RL, such as [1-2], particularly multi-view visual RL method like [3]. Evaluating MFSC against such baselines would provide a more accurate assessment of its effectiveness and novelty.\n2.\tHow does the computational complexity of MFSC compare to baseline approaches in terms of training time, inference time, and resource requirements?\n3.\tThis paper does not provide sensitivity analyses of MFSC with respect to different hyperparameters, such as the weight of fusion loss and the weight of reconstruction loss.\nReferences\n[1] Hafner et al. Mastering diverse domains through world models. arXiv preprint   arXiv:2301.04104, 2023.\n[2] Seo et al. Masked world models for visual control. CORL, 2023.\n[3] Seo et al. Multi-view masked world models for visual robotic manipulation. ICML, 2023."
      },
      {
        "rating": "3",
        "confidence": "3",
        "summary": "The paper introduces a novel approach named Multi-view Fusion State for Control(MFSC)，which ingrates a self-attention mechanism with bisimulation metric learning to fuse task-relevant representation from multi-view observation. Additionally, the paper also incorporated a mask-based latent reconstruction auxiliary task to learn cross-view information in order to foster more compact fused presentation. In this paper, two major problems were solved : First is Higher data dimensions and more redundant information , and Informative aggregation of representation from various views.",
        "strengths": "1.\tClear statements and good structure. The paper is well-structured, and viewpoints was stated logically. The introduction provides a good overview of the challenges in the multi-view representation learning task and approach to address them relatively.  Also illustrate provided along with methods made it easy and vivid.\n2.\tSufficient and solid proof in major conclusions. Problems were clearly defined and followed by mathematical formulations with clear explanation and ended with a solution with validate experiments. \n3.\tComprehensive experiment and supportive solution ,also contributions made by this method were shown vividly and clearly through several comparative illustrate shown in the part of Experiments.  \n4.\tReproductive experiment with project code and data shared.  Experiments  result can be verified personally by readers with resources provided in this paper.",
        "weaknesses": "•\tA few formula faults are discovered in the paper.\n•\tEvaluation Metrics: The evaluation metrics used in the experiments could be more comprehensive. Currently, the focus appears to be on task performance, but including metrics that assess representation quality (e.g., reconstruction loss) would provide a fuller picture of the model’s effectiveness.\n•\tGeneralization to Other Tasks: The experiments are primarily conducted on Meta-World. To evaluate the generality of the approach, the authors should consider applying MFSC to other control tasks or environments. This would help demonstrate the versatility and broader applicability of the proposed method.\n•\tLimitations Discussion: The paper should include a dedicated section discussing the limitations of the proposed method. Identifying potential weaknesses and suggesting avenues for future work would add depth to the contribution."
      }
    ],
    "rating_avg": 4.5,
    "confidence_avg": 3.5,
    "decision": "N/A",
    "meta_review": "",
    "author_remarks": "",
    "decision_comment": ""
  },
  {
    "id": "p7vItQ3OfD",
    "title": "Exposing Privacy Gaps: Membership Inference Attack on Preference Data for LLM Alignment",
    "authors": [
      "Qizhang Feng",
      "Siva Rajesh Kasa",
      "SANTHOSH KUMAR KASA",
      "Hyokun Yun",
      "Choon Hui Teo",
      "Sravan Babu Bodapati"
    ],
    "abstract": "Large Language Models (LLMs) have seen widespread adoption due to their remarkable natural language capabilities. However, when deploying them in real-world settings, it is important to align LLMs to generate texts according to acceptable human standards. Methods such as Proximal Policy Optimization (PPO) and Direct Preference Optimization (DPO) have enabled significant progress in refining LLMs using human preference data. However, the privacy concerns inherent in utilizing such preference data have yet to be adequately studied. In this paper, we investigate the vulnerability of LLMs aligned using two widely used methods - DPO and PPO - to membership inference attacks (MIAs). Our study has two main contributions: first, we theoretically motivate that DPO models are more vulnerable to MIA compared to PPO models; second, we introduce a novel reference-based attack framework specifically for analyzing preference data called PREMIA (\\uline{Pre}ference data \\uline{MIA}). Using PREMIA and existing baselines we empirically show that DPO models have a relatively heightened vulnerability towards MIA.",
    "keywords": [
      "privacy",
      "LLM alignment",
      "rlhf"
    ],
    "venue": "ICLR",
    "year": 2025,
    "pdf_url": "https://openreview.net/pdf?id=p7vItQ3OfD",
    "forum_url": "https://openreview.net/forum?id=p7vItQ3OfD",
    "reviews": [],
    "rating_avg": null,
    "confidence_avg": null,
    "decision": "N/A",
    "meta_review": "",
    "author_remarks": "",
    "decision_comment": ""
  },
  {
    "id": "WxLwXyBJLw",
    "title": "Flow Matching for One-Step Sampling",
    "authors": [
      "Svetlana Pavlova",
      "Ivan Oseledets",
      "Gleb Ryzhakov"
    ],
    "abstract": "Flow-based generative models have rapidly advanced as a method for mapping simple distributions to complex ones for which the distribution function is unknown. By leveraging continuous-time stochastic processes, these models offer a powerful framework for density estimation, i.e. an algorithm that samples new points based only on existing samples. However, their requirement of solving ordinary differential equations (ODEs) during sampling process incurs substantial computational costs, particularly for large amount of data and numerous time points. This paper proposes a novel solution, which is based on a theoretical analysis of Flow Matching (FM), to overcome this bottleneck, namely, we developed an algorithm to find the point prototype for a given point from the target distribution. By eliminating the need for ODE solvers, our method significantly accelerates sampling while preserving model performance. Numerical experiments validate the proposed approach, demonstrating its efficiency.",
    "keywords": [
      "Flow Matching",
      "Generative Models",
      "Ordinary Differential Equations",
      "One-step generation"
    ],
    "venue": "ICLR",
    "year": 2025,
    "pdf_url": "https://openreview.net/pdf?id=WxLwXyBJLw",
    "forum_url": "https://openreview.net/forum?id=WxLwXyBJLw",
    "reviews": [
      {
        "rating": "6",
        "confidence": "2",
        "summary": "This paper considers continuous normalizing flows and proposes an algorithm for finding the corresponding point in the base distribution (called its prototype) for a given point from the target distribution, without having to solve the defining ODE. For each sampled target point, the explicit velocity function is followed backwards to find a suitable base distribution point. Using the set of point pairs as a training set, a model is trained on them; that is, the generation can take place in a single step, and the network does not need to be invertible.",
        "strengths": "The single step sampling results in a greatly improved speed without significantly affecting the model performance.",
        "weaknesses": "Language: there are many spelling and grammatical errors, and the sentences are sometimes incomprehensible.\nEspecially in the introduction, the main ideas are hard to comprehend, especially if one does not know the previous work in detail.\nThe experiment in Section 4.2 should be explained in more detail or a reference needs to be added if it is a common method for image colorization.\nLine 114: there is no \"Introduction and Related Work\" section, these are two separate sections in the paper."
      },
      {
        "rating": "3",
        "confidence": "2",
        "summary": "This paper presents a flow-based generative modelling approach that does not require solving an ODE for inference. The method seems to rely heavily on the \"exact velocity\" from (Ryzhakov et al., 2024); however, both the motivation and details of this need more development. Moreover, more comparison (especially numerical results) to previous works is needed. E.g. other approaches that bypass inference integration, like consistancy models, are not mentioned in the related work.",
        "strengths": "1. Adresses the problem of long inference time by bypassing the inference ODE integration.",
        "weaknesses": "1. More elaboration on the method of Ryzhakov would be helpful.\n2. Unclear about motivation and comparison to related works.\n3. Lack of numerical results."
      },
      {
        "rating": "1",
        "confidence": "4",
        "summary": "This paper proposes a one-step sampling method based on flow matching. Given a set of training samples from an unknown distribution $\\rho_1$, a mapping is learned from a simpler known distribution $\\rho_0$, typically a normal distribution, to $\\rho_1$.  Using a discretized estimate of the flow, derived in (Ryzhakov et al. 2024), so-called prototypes in $\\rho_0$ are found by solving an ODE for each training sample in $\\rho_1$, under the assumption of linear flow. A network is then trained to directly map from $\\rho_0$ to $\\rho_1$, using the set of training samples paired with their respective prototypes.",
        "strengths": "The most important benefit of the proposed sampling approach is its speed, since instead of solving an ODE, sampling is done in one step using a neural network.",
        "weaknesses": "The experiments described in the paper are extremely limited. It is shown that 8 Gaussians can be generated using the proposed sampling method. It is also shown, with four example images, how colors can be transferred from one distribution to another, with target colors given by a separate image. Furthermore, in the paper, the sampling method was not compared to any other alternative method or ablated versions of the same method. For a publication to be recommended, the experiments should be expanded to include comparisons against relevant baselines. The text describing the color transfer experiments should preferably also be rewritten since the current version is too unclear.\n\nIt is rather unclear what a prototype is, whether it is the point in $\\rho_0$ one would converge to if there are no errors in ODE solver, or whether a prototype can be any point in $\\rho_1$ that you happen to converge to. Something that would have been interesting to know is how precise the prototypes truly are, and what effect the errors have on the end result. It is claimed that the quality of the prototypes is sufficient for images to be predicted, but this is a question that ought to be studied in greater depth. \n\nWhen prototypes are found in $\\rho_0$, noise is first added to the position in $\\rho_1$, but the motivation for this is hardly satisfactory. In almost a full page the paper tries to argue why the added noise is necessary. It seems that the implementation of the Runga-Kutta method relies on a particular set tolerance parameter. If the tolerance is set too high, the method will stop early, and points will never reach $\\rho_0$. However, if normal distributed noise is added in $\\rho_1$, at least the points end up being spread like a normal distribution, but there is no convincing argument that the errors would then be smaller.\n\nThe language of the paper is unfortunately rather problematic with numerous missing articles (the, a), improper prepositions, and awkward sentences that are hard to interpret. However, the problems are not too severe for the material to be understood and should be relatively easy to correct in a final version of the paper.\n\nThe two algorithms are very similar to each other. The only difference seems to be that if you have a discrete label, a separate mapping is learned for each value of the label. It would have been sufficient to just keep Algorithm 2.\n\nThe notation for buffer B varies in different parts of the text."
      },
      {
        "rating": "3",
        "confidence": "3",
        "summary": "The paper presents a new flow matching approach for efficient sampling. The method finds an approximate prototype mapping by using importance sampling and the soft-max distribution. The prototype is finally found by solving a Cauchy problem. The prototypes and the connected target samples are used to define the  velocity field of the flow. The algorithm is evaluated on a 2D GMM task and a color transfer task.",
        "strengths": "- the new algorithm could potentially provide more computationally efficient generative models\n- the presented algorithm seems to be reasonable, even though a few theoretical justifications are unclear",
        "weaknesses": "(1) there are no comparisons to other flow matching approaches or generative models (diffusion, consistency models) provided\n(2) The evaluations are only done on a simplistic 2D dataset and the color transfer task, where I have difficulty assessing how good the result really is\n(3) No evaluation and comparison of the computational efficiency of the generative model is offered (which was the main motivation of the approach). Its unclear to me how the single-step sampling here actually works? We still have the solve the ODE, don't we?\n(4) Theory is also quite hand-wavy. For example, it is unclear to me how importance sampling is used to estimate the integral of Eq (1). Which distributions are replaced here ? I.e., what is the sampling distribution?\n(5) It is unclear to me how tolerance and sigma interact and why we need sigma. From the presented theory, sigma would not be needed, would it? But without sigma, only very poor prototypes are learned, so this seems to be unsatisfactory to me"
      }
    ],
    "rating_avg": 3.25,
    "confidence_avg": 2.75,
    "decision": "Reject",
    "meta_review": "This work proposes a sampling technique for Flow Matching, a recently emerging approach for generative modeling. Its main novelty is a sampling algorithm that, unlike in previous work, does not require solving an ordinary differential equation. It is based on a model training algorithm that uses exact expressions for the vector field in flow matching and training on samples from the original and target distributions simultaneously. One weakness of this work is its lack of clarity. For example, while some of the terminology may be standard in a subfield, the work may have also needed more background to be broadly accessible to the NeurIPS community.  Another concern raised by the reviewers is the lack of comparisons and a very limited experimental section. While the first weakness was slightly mitigated in the rebuttal process, the work still remains somewhat difficult to access, and the reviewers remained concerned about experimentation and comparisons, which is why I recommend rejection.",
    "author_remarks": "",
    "decision_comment": ""
  },
  {
    "id": "FDimWzmcWn",
    "title": "AgentRefine: Enhancing Agent Generalization through Refinement Tuning",
    "authors": [
      "Dayuan Fu",
      "Keqing He",
      "Yejie Wang",
      "Wentao Hong",
      "Zhuoma GongQue",
      "Weihao Zeng",
      "Wei Wang",
      "Jingang Wang",
      "Xunliang Cai",
      "Weiran Xu"
    ],
    "abstract": "Large Language Model (LLM) based agents have proved their ability to perform complex tasks like humans. However, there is still a large gap between open-sourced LLMs and commercial models like the GPT series. In this paper, we focus on improving the agent generalization capabilities of LLMs via instruction tuning. We first observe that the existing agent training corpus exhibits satisfactory results on held-in evaluation sets but fails to generalize to held-out sets. These agent-tuning works face severe formatting errors and are frequently stuck in the same mistake for a long while. We analyze that the poor generalization ability comes from overfitting to several manual agent environments and a lack of adaptation to new situations. They struggle with the wrong action steps and can not learn from the experience but just memorize existing observation-action relations. Inspired by the insight, we propose a novel AgentRefine framework for agent-tuning. The core idea is to enable the model to learn to correct its mistakes via observation in the trajectory. Specifically, we propose an agent synthesis framework to encompass a diverse array of environments and tasks and prompt a strong LLM to refine its error action according to the environment feedback. AgentRefine significantly outperforms state-of-the-art agent-tuning work in terms of generalization ability on diverse agent tasks. It also has better robustness facing perturbation and can generate diversified thought in inference. Our findings establish the correlation between agent generalization and self-refinement and provide a new paradigm for future research.",
    "keywords": [
      "agent",
      "self-refine",
      "diversity",
      "generalization",
      "data synthesis"
    ],
    "venue": "ICLR",
    "year": 2025,
    "pdf_url": "https://openreview.net/pdf?id=FDimWzmcWn",
    "forum_url": "https://openreview.net/forum?id=FDimWzmcWn",
    "reviews": [
      {
        "rating": "6",
        "confidence": "3",
        "summary": "The paper proposes a novel framework to improve the generalization capabilities of LLMs based agents. The authors identify that existing agent-tuning methods often overfit to specific environments and fail to generalize to new tasks. To address this, the paper introduces AgentRefine, which leverages a agent synthesis framework to encompass a diverse array of environments and tasks drawing upon extensive human persona data, enabling the model to learn from its mistakes through a process of refinement tuning. The experiments demonstrate that AgentRefine method outperforms state-of-the-art methods in terms of generalization, robustness to perturbations, and the ability to generate diverse thoughts during inference.",
        "strengths": "The proposed method's idea seems like meta learning, which trains the policy on diverse tasks for quickly adapting to novel tasks. This idea makes sense to me and seems new in agent domain. \n\nI appreciate authors' rethinking on the generalization of agent-tuning. The issue of memorizing trajectory leading to overfitting seems valid to me.\n\nThe experiment evaluates the performance of AgentRefine from wide range of perspectives.\nThe findings establish a correlation between agent generalization and multi-task agent training mechanism / self-refinement, providing a new paradigm for future research in agent-tuning.",
        "weaknesses": "Overall AgentRefine is a simple and effective method. However, the main idea is not new, as discussed in related work, Agent-FLAN and AgentGen have proposed to train generalist agents using general data. The idea of refinement is also widely studied as discussed in introduction. I encourage authors to clearly differentiate AgentRefine from these prior works. Highlight unique aspects or improvements over existing methods. Consider incorporating a comparative analysis to demonstrate the advantages of AgentRefine.\n\nI feel the procedure suffers from a high risk of generating low-diversity tasks, as the script generation is based on human persona data, which is limited in a certain domain. In contrast, a generalist agent is expected to complete any tasks. \n\nThe goal of the proposed method is to build a LLM-based agent to generalize to novel tasks. However, this way to generate agent tasks does not bring new knowledge to LLMs, but enabling the LLMs to follow the output format more strictly, as it trains LLMs on the data generated by LLMs themselves. \n\nBesides, the source of performance improvement is not clear. For instance, why the LLM-generated trajectories can improve performance on novel tasks? Authors can provide some examples of the evaluation tasks, and examples of the generated tasks."
      },
      {
        "rating": "6",
        "confidence": "3",
        "summary": "The paper presents a framework aimed at improving the generalization capabilities of Large Language Model (LLM) based agents through instruction tuning. The authors observe that existing agent training methods overfit to specific environments and struggle with new situations, leading to poor generalization. To address this, they propose AgentRefine, which incorporates self-refinement processes to enable the model to learn from its mistakes and adapt to diverse environments and tasks.",
        "strengths": "1. The paper is well-organized and easy to follow, with a clear progression from motivation to methodology.\n2. The identification of the generalization gap in existing LLM-based agents and the proposal of a self-refinement approach to address it is a rational step forward in the field.",
        "weaknesses": "1. The problem of generalization in LLM-based agents has been extensively discussed in previous literature, making the contribution of this work less novel. For example,  [1]  investigates the robustness of accuracy measurements in large language models (LLMs) when the order of answer labels is shuffled, using the MMLU dataset as a testbed.\n2. The methodology, while intuitive, lacks significant innovation, as the approach of enhancing generalization through data synthesis is not new [2].\n3. The experimental results do not demonstrate a strong improvement over existing methods, which questions the practical impact of the proposed approach. An apple-to-apples comparison of your main results to show the advantage of the algorithm would make your results more straightforward and strong, instead of using a lot of underlined text to filter out the results where training data is sampled in the same environment as the task.\n\n[1] Changing Answer Order Can Decrease MMLU Accuracy.\n\n[2] Knowledgeable Agents by Offline Reinforcement Learning from Large Language Model Rollouts."
      },
      {
        "rating": "6",
        "confidence": "3",
        "summary": "This paper discusses using synthetic data to improve the generalization ability of agents on held-out sets. Previous agent-tuning work often chose to construct agent-tuning data on held-in sets. The authors demonstrate that although these methods can greatly improve the performance of agents on held-in sets, they usually lead to overfitting, which in turn affects the performance of agents on held-out sets. Based on this observation, the authors propose AgentRefine. This method does not use task-related information at all. Instead, it uses LLM to complete the entire data generation process, including task generation, trajectory generation, and verification to construct the agent-tuning dataset, thus avoiding the possibility of overfitting to held-in sets from the very start. In the constructed dataset, the authors emphasize the ability of the agent to correct errors based on the feedback, which further improves the agent's generalization ability. They validate AgentRefine in multiple scenarios, and the experimental results show that finetuned agents outperform other baselines on held-out sets.",
        "strengths": "1. This paper discusses the generalization ability of agents, which is a very important topic for the community.\n\n2. The authors provide quantitative analysis to explain their insight, which is very convincing.\n\n3. Synthesizing data with almost no task-specific information is a very practical setting, and the improvement of generalization ability in this paper is impressive.",
        "weaknesses": "1. The presentation of this paper should be improved and some grammar mistakes should be fixed.\n\n2. Some important baselines, for example, Reflexion[1], are missing and should be included.\n\n3. They only consider decision-making tasks in their experiments. However, as they claimed on the generalization ability, tasks of different types should also be included, for example, reasoning tasks. \n\n[1] Shinn, Noah, et al. \"Reflexion: Language agents with verbal reinforcement learning.\" NeurIPS, 2023."
      },
      {
        "rating": "5",
        "confidence": "3",
        "summary": "The paper proposes AgentRefine, a framework designed to enhance the generalization capabilities of large language model (LLM)-based agents through a self-refinement process. The core idea is to enable agents to learn from their mistakes by refining their actions based on feedback from the environment. The authors introduce a data generation pipeline that simulates diverse environments and tasks, followed by a refinement tuning process to improve agent robustness and generalization. Experimental results show that AgentRefine outperforms state-of-the-art methods in held-out tasks, demonstrating improved generalization and robustness.",
        "strengths": "1. The introduction of a self-refinement process for agent tuning is a novel contribution to the field. By allowing agents to correct their mistakes based on environmental feedback, the authors propose an interesting alternative to traditional fine-tuning methods.\n2. The use of diverse environments and tasks in data generation helps mitigate overfitting to specific scenarios, which is a common issue in LLM-based agents.\n3. The experiments show that AgentRefine outperforms baselines in held-out tasks, suggesting that the approach has potential for improving generalization.",
        "weaknesses": "1.  The paper relies heavily on GPT-4 for generating both scripts and trajectories. This raises several concerns:\n   - The quality of the generated data depends entirely on GPT-4's ability to detect and correct errors\n   - The method is not truly \"self-refinement\" since it requires external stronger models for error detection and correction\n   - The authors should analyze what happens when using weaker LLMs for data generation and verification\n\n2. The verification process has potential flaws:\n  - It uses LLMs to verify the correctness of scripts and trajectories without human validation\n  - The paper lacks analysis of verification failure cases or error rates\n  - The authors should include human evaluation of the verification process accuracy\n\n3. While the paper shows improved performance, it lacks analysis of whether this is simply distillation from GPT-4 rather than true generalization and how much of the improvement comes from the refinement process versus having access to GPT-4's knowledge\n\n4. The experiments only scale up to 64k examples. Would the computational cost of generating refinement data with GPT-4 makes large-scale training difficult? Also, the authors should analyze the cost-benefit tradeoff of generating more refinement data\n\n5. While the paper shows some robustness analysis, the perturbation experiments are limited to only action descriptions. More diverse types of perturbations should be tested. The analysis should include how different components (script generation, verification, refinement) contribute to robustness"
      }
    ],
    "rating_avg": 5.75,
    "confidence_avg": 3.0,
    "decision": "Accept (Poster)",
    "meta_review": "The paper introduces AgentRefine, a novel framework aimed at enhancing the generalization capabilities of large language model (LLM)-based agents. The approach tackles the overfitting problem prevalent in existing agent-tuning methods by using a data generation pipeline that simulates diverse environments and tasks. \n- The framework avoids task-specific overfitting by synthesizing data with minimal reliance on task-specific information.\n- The method addresses the generalization gap by leveraging diverse environments and tasks, ensuring agents adapt well to held-out scenarios.\n- Experimental results demonstrate that AgentRefine outperforms existing baselines, highlighting its effectiveness.\n\nThe weaknesses are (1)the main idea, while practical, is not significantly novel; (2) the method heavily depends on GPT-4 for script and trajectory generation as well as error verification.\n\nCurrently, I think the strengths outweigh the weaknesses.",
    "author_remarks": "",
    "decision_comment": ""
  },
  {
    "id": "o3V7OuPxu4",
    "title": "StarCraft II Arena: Evaluating LLMs in Strategic Planning, Real-Time Decision Making, and Adaptability",
    "authors": [
      "Wenjie Tang",
      "Yuan Zhou",
      "Erqiang Xu",
      "Keyan Cheng",
      "Minne Li",
      "Zhiyuan Wang"
    ],
    "abstract": "StarCraft II plays an important role in developing AI agents for real-time strategic reasoning due to its complex nature. However, people usually draw conclusions of how competent their agents are according to the level of the built-in agents in StarCraft II which they can win in terms of the final success rate. Little intermediate quantitative information is considered while human-in-the-loop analysis is time inefficient, which results in inadequate reflection of the true strategic reasoning ability. In this work, we propose StarCraft II Arena, a well-designed benchmark for evaluating the strategic planning, real-time decision-making, and adaptability capabilities of large language models (LLMs) agents. We introduce using fine-grained capability metrics, allowing for targeted capture and analysis of specific capability, and further propose a detailed decision trace to enhance the understanding of LLM behavior. We demonstrate the utility of such a benchmark by evaluating several state-of-the-art LLMs in various setups. Our results reveal distinct performances in long-term strategy development, real-time decision-making, and adapting to environmental changes. Such results show that the StarCraft II Arena offers a deeper insight into the decision-making process of LLMs and has the potential to become a challenging and comprehensive benchmark for strategic reasoning.",
    "keywords": [
      "benchmark evaluation",
      "large language model",
      "LLM-based agent",
      "strategic reasoning",
      "real-time decision-making."
    ],
    "venue": "ICLR",
    "year": 2025,
    "pdf_url": "https://openreview.net/pdf?id=o3V7OuPxu4",
    "forum_url": "https://openreview.net/forum?id=o3V7OuPxu4",
    "reviews": [
      {
        "rating": "3",
        "confidence": "5",
        "summary": "The paper presents StarCraft II as a benchmark for evaluating reasoning capabilities of LLMs. The paper also presents a set of metrics for evaluating these models, which are based on the domain itself (e.g., amount of resources the play collects). Finally, the paper presents results of several LLMs on this benchmark.",
        "strengths": "The idea of having a challenging benchmark for reasoning with LLMs is interesting and appealing. I also think that computer games can be a good benchmark for this type of evaluation. The choice of a real-time strategy game is particularly good, given the response latency of these systems.",
        "weaknesses": "My main concern with the paper is that it is only half-baked in the sense that the presentation should be improved substantially before being accepted for publication.\n\nMy concerns with presentation range from the low level to the high level.\n\n**Low-level concerns**\n\n- The paper has a dangling sentence in line 241. It seems that the explanation of Table 2 was inadvertently commented out from the paper.\n- It is not clear what Equation 1 is trying to convey. What is its role in the paper? What is the parameter $\\tau$ that is passed as a parameter but not used in the equation?\n- The paragraph starting in line 137 discusses the need for communication between the agents, but this is not discussed in the paper. I can see SCII having this need if agents play in a team, but this doesn't seem to be the setting evaluated in the paper.\n- In line 106, the paper states that early RL algorithms learn through trial and error. Isn’t this the case for current RL algorithms too?\n- Some of the tables are not referred to in the text. For example, I am not sure when I should read Table 3, and I don’t think the paper discusses it at all.\n\n**High-level concerns**\n\nOne of the key points I was looking for in the paper was the input-output system for the benchmark. Is the LLM receiving images or text as input? How is the input defined? How much time do they have to reason? What happens when they timeout? The text mentions that smaller models perform better than larger models in the micromanagement part of the game. Is this simply because they are able to respond quicker? These are some of the key questions the authors would need to address in the paper. This is what the readers will be after when understanding whether SCII is a suitable benchmark for LLM evaluation.\n\nOverall, the paper is only half-baked, as the authors need to fix all these presentation issues and adjust the discussion of their results and benchmark. There is clearly a system running, as the paper also includes tables of results. However, it is not possible to understand how this system works as the description is missing."
      },
      {
        "rating": "3",
        "confidence": "4",
        "summary": "The paper presents StarCraft II Arena as a benchmark for evaluating LLMs in strategic planning and decision-making capabilities. While it introduces fine-grained metrics and decision tracking mechanisms, the paper needs substantial clarification on its novel contributions and experimental methodology.",
        "strengths": "1. Well-structured evaluation framework with fine-grained metrics\n2. Comprehensive testing across multiple LLM models\n3. Interesting decision tracking system for behavior analysis",
        "weaknesses": "1. Insufficient experimental details:\n- Build-in AI difficulty level not specified\n- Race and map selection criteria not documented\n- Limited experimental scope (10 games per model)\n2. Theoretical foundation needs strengthening:\n- Limited discussion of why LLMs are suitable for StarCraft II\n- Insufficient comparison between LLM agents and traditional RL agents\n- Unclear theoretical justification for chosen metrics\n3. Literature positioning:\n- Need more thorough comparison with existing StarCraft II benchmarks\n- Better contextualization of contributions needed\n- Clearer differentiation from existing approaches required"
      },
      {
        "rating": "3",
        "confidence": "3",
        "summary": "This paper introduces a benchmark called Starcraft II Arena, which aims to evaluate the decision-making, planning, and adaptability of large language models (LLMs) within a strategic gaming environment. While traditional benchmarks for Starcraft II assess agents based on a single overall metric—win rates against built-in opponents—the authors argue that a more detailed analysis of LLM performance is necessary. The main contribution of this paper is a methodology designed for an in-depth evaluation of the capabilities of LLM agents.",
        "strengths": "The key idea of this paper, introducing a benchmark for a more in-depth multi-agent evaluation of LLMs, is significant and useful.",
        "weaknesses": "Overall, the paper lacks clarity and depth in describing both the technical implementation and practical contributions.\n\n### **Major comments**\n\n1. Unclear contribution: The paper does not effectively justify why this benchmark must exist as a standalone contribution rather than an addition to existing Starcraft II resources. The contribution seems limited to a collection of scripts and metrics, which could likely be integrated into the existing environment without creating a separate benchmark.\n\n2. Lack of implementation details: Key technical aspects of the implementation are insufficiently described, making it hard to understand the benchmark's novelty and how it's technically realized. Several things are not clear, such as:\n   - Integration: How are LLM agents integrated with StarCraft II? How can users use the benchmark? Does the benchmark use a custom API or an interface for this?\n   - Decision Tracking: How is decision-making tracked and analyzed? While Table 3 provides a decision trajectory, details of how this is analyzed and used are missing.\n   - Computational Requirements: What hardware/software is necessary to run this benchmark effectively? This information is critical for usability but is absent.\n   - Opponents: Are the LLMs evaluated with built-in agents or newly introduced opponents? The fact that agents are evaluated against built-in agents in Starcraft II is mentioned as a limitation, but it is unclear whether the authors change this in their benchmark.\n\n3. Incomplete metric information: The metrics lack context. For instance, while Appendix A.1 outlines the metrics, there are no defined ranges, leaving the reader unsure of how to interpret scores. For example, how should a Real-Time Decision score of 21.12 versus 37.51 in Table 4 be interpreted? Similarly, terms such as “effective” actions in EPM or “collected vespene” are not unexplained, reducing the metrics’ interpretability (how do we know that these are the right metrics to assess decision-making and planning?).\n \n4. Missing benchmark discussion and limitations: A discussion about future development and limitations of the benchmark is missing, which limits the reader's understanding of the benchmark's intended scope and future extensions.\n\n5. Figure 2 indicates a large variance. Why are there no error bars in the tables?\n6. It's important to have the prompt included in the appendix or supplement. Was it possibly in a supplement that I cannot access?\n\n### **Minor comments** (These did not affect my score)\n- Abstract: Lines 016-019 are a bit difficult to understand; consider rephrasing\n- Figure 2: It’s unclear what this Figure is meant to convey, and the Figure lacks labeled y-axes.\n- In Section 4.3, line 367 states \"Definitions and methods for these metrics will be further detailed in the figure 4.3.\" This seems to refer to a table, possibly Table 3, rather than a figure. \n- In Table 3, \"OBSERVERtgreater\" should probably be \"OBSERVER.\"\n- Lines 323 + 350 state that screenshots illustrating decision traces will be provided in the appendix, but these are not included\n- I don't understand what is meant when the authors state that civilization and the other games are not \"strategic and tactical\" in Table 1. Additionally, Werewolf is clearly an imperfect information game. The authors should reconsider this table because I believe many of the entries are inaccurate.\n- Why is the score in Table 4 unnormalized? It's an incomprehensible number as it stands."
      },
      {
        "rating": "3",
        "confidence": "5",
        "summary": "summary: The paper presents StarCraft II Arena as a benchmark for evaluating LLMs in strategic planning and decision-making capabilities. While it introduces fine-grained metrics and decision tracking mechanisms, the work needs substantial clarification regarding its novel contributions, metric selection justification, and experimental methodology.",
        "strengths": "1. Well-structured evaluation framework with proposed fine-grained metrics\n2. Comprehensive testing across multiple LLM models\n3. Detailed decision tracking system for behavior analysis\n4. Clear visualization of experimental results\n5. Systematic approach to evaluating different aspects of LLM capabilities",
        "weaknesses": "1. Metric Selection and Justification:\n- APM/EPM metrics appear borrowed from traditional StarCraft II evaluation without clear justification of their relevance to LLM agents\n- No discussion of how these metrics specifically reflect LLM decision-making capabilities\n- Missing analysis of whether traditional StarCraft II performance metrics are appropriate for language models\n2. Experimental Design Limitations:\n- Build-in AI difficulty level not specified\n- Race and map selection criteria not documented\n- Limited experimental scope (10 games per model)\n- Absence of LLM vs LLM experiments\n- No evaluation against human players\n- Limited testing of open-source models, reducing reproducibility\n3. Theoretical Foundation and Novelty:\n- Limited discussion of why LLMs are suitable for StarCraft II\n- Insufficient comparison between LLM agents and traditional RL agents\n- Evaluation metrics show significant overlap with existing work\n- Need clearer articulation of novel contributions\n- Better contextualization within existing literature required"
      }
    ],
    "rating_avg": 3.0,
    "confidence_avg": 4.25,
    "decision": "Reject",
    "meta_review": "This paper proposes StarCraft II Arena as a benchmark for evaluating LLMs' strategic planning and decision-making capabilities, introducing metrics and decision tracking mechanisms. While presenting an interesting direction, the paper suffers from insufficient technical details, unclear differentiation from existing benchmarks, and inadequate experimental methodology.",
    "author_remarks": "",
    "decision_comment": ""
  },
  {
    "id": "4XHyThqt1C",
    "title": "Alternating Optimized Stochastic Vector Quantization in Neural Compression",
    "authors": [
      "Runsen Feng",
      "Weiping Li",
      "Zhibo Chen"
    ],
    "abstract": "In neural compression, vector quantization (VQ) is usually replaced by a differentiable approximation during training for gradient backpropagation. However, prior approximation methods face two main issues: 1) the train-test mismatch between differentiable approximation and actual quantization, and 2) the suboptimal encoder gradients for rate-distortion (RD) optimization. In this paper, we first provide new finds about how approximation methods influence the RD optimization in neural compression, and then propose a new solution based on these finds. Specifically, if a neural compressor is regarded as a source-space VQ, we find that the encoder implicitly determines the quantization boundaries, and the decoder determines the quantization centers.  Suboptimal approximation methods lead to suboptimal gradients for RD optimization of quantization boundaries and centers. Therefore, to address the first issue,  we propose an encode-decoder alternating optimization strategy. The encoder is optimized with differentiable approximation, and the decoder is optimized with actual quantization to avoid the train-test mismatch of quantization centers.  To address the second issue, we propose a sphere-noise based stochastic approximation method. During encoder optimization, VQ is replaced with a uniform sphere noise centered at the input vector. When the input vector is located at the quantization boundary, the encoder gradient is closer to the difference in RD loss between adjacent quantization centers, facilitating better encoder optimization. We name the combination of optimization strategy and approximation method as Alternating Optimized Stochastic Vector Quantization.\nExperimental results on various vector sources and natural images demonstrate the effectiveness of our method.",
    "keywords": [
      "vector quantization",
      "neural compression",
      "image compression"
    ],
    "venue": "ICLR",
    "year": 2025,
    "pdf_url": "https://openreview.net/pdf?id=4XHyThqt1C",
    "forum_url": "https://openreview.net/forum?id=4XHyThqt1C",
    "reviews": [
      {
        "rating": "3",
        "confidence": "4",
        "summary": "This paper investigates an improvement to the STE method used to train VQ-based neural compressors. For scalar quantization methods, the uniform additive noise method during training is shown to yield smooth gradients. This is not applicable to VQ-based methods, which so far mostly use STE. This is shown to yield highly non-smooth gradients. The proposed method, for VQ-based models, uses an alternating optimization scheme, combined with stochastic VQ. This is shown to yield smoother gradients than STE. Experimental results demonstrate superiority over STE-based VQ neural compressors.",
        "strengths": "- The problem of train-test mismatch and other issues of STE in VQ-based models is relevant and timely\n- The proposed method appears principled, and solves some of the challenges that are presented\n- The work is overall well-motivated, and easy to follow",
        "weaknesses": "- In sections 1-2, the problem is presented well, i.e., the need to solve some issues brought forth by STE in VQ-based compressors. However, section 3 dedicates a lot of explanation to how it is solved in scalar quantized neural compressors, which, to me, appears less important. In 3.2, I think it would be helpful to directly mention the VQ-STE section, as that is the setting which this paper's proposed method attempts to improve on. The UQ-AUN and UQ-STE can be mentioned briefly and details put in the appendix, as the scalar quantization setting is not the focus of the paper. This would provide more space to explain some of the details of the proposed method in section 4, which I found to be lacking. In addition, Figure 6 could be placed in section 4, and the reader can directly contrast that with Figure 4, and see how the non-smoothness issue is fixed via the proposed method. \n- The experimental results section covers a broad range of sources, both synthetic and real-world, which is helpful. It is shown that the proposed method outperforms VQ-STE in all settings, and the UQ-AUN method provides a frame of reference. However, some baselines are missing. For example, the two methods soft-toward vector quantization (A2) and probabilistic vector quantization (A3) used in the ablation study (lines 509-511) should also be its own baselines with the Balle et al 2018 transforms. This is useful for understanding how the proposed method compares with other methods that don't use STE. Moreover, these baselines are mentioned in the related work but not compared to. \n- In the related work, lines 138-140, it is said that section 3.2 addresses how prior works in VQ-based neural compression yield sub optimality. However, in the VQ setting, only the STE method from VQVAE is addressed. The method from Agustsson et al, 2017, and Zhu et al 2022 are not addressed in section 3.2. It would be helpful to understand how these two methods' gradients look like in the 1-d Gaussian setting. This, combined with a BD-rate comparison in the results section, would help the reader understand how all the methods compare (conceptually and performance-wise), and strengthen the work overall.\n- Furthermore, the experimental results of the proposed method on natural images use a fairly old architecture (which, to my understanding, uses transforms from Balle et al 2018, single-layer vector quantizer, and a discrete entropy model from VQVAE). There are more recent transforms that are higher-performing, such as those from [1], as well as vector quantizer layers, such as those from [2] and [3]. Experiments using these models would be more convincing. The authors say the proposed method cannot be used on more state-of-the-art models such as these. If true, I think that limits the applicability of the proposed method. \n- There are some issues with the references in the related work, in the second paragraph.\n\nReferences:\n\n[1] Cheng, Zhengxue, et al. \"Learned image compression with discretized gaussian mixture likelihoods and attention modules.\" Proceedings of the IEEE/CVF conference on computer vision and pattern recognition. 2020.\n\n[2] El-Nouby, Alaaeldin, et al. \"Image compression with product quantized masked image modeling.\" arXiv preprint arXiv:2212.07372 (2022).\n\n[3] Feng, R., Guo, Z., Li, W., & Chen, Z. (2023). NVTC: Nonlinear vector transform coding. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (pp. 6101-6110)."
      },
      {
        "rating": "3",
        "confidence": "4",
        "summary": "In this paper, the authors propose an optimization strategy for vector quantization in neural compression. Since quantization is non-differentiable, they approximate the vector quantization error using noise sampled from a uniform spherical noise distribution. Additionally, they introduce an optimization strategy to effectively minimize the rate-distortion loss function in neural compression. The authors tested their method on simulated data sources and several real-world images, demonstrating that their approach provides better compression efficiency compared to existing vector quantization methods.",
        "strengths": "1. An alternative optimization procedure to optimize the encoder network, the codebook of vector quantization, and the decoder network. This procedure could result in better convergence of the RD loss function.\n2. An approximation of vector quantization using uniform spherical noise centered on the latent vector.\n3. A gradient analysis of the encoder latent with respect to the loss function.\n4. Deriving the correspondence between vector quantization in the latent space and the corresponding quantization in the image space.",
        "weaknesses": "1.The paper is not well-written and is incomplete in several sections. In the related work section, citations are missing, and sentences are incomplete, making it difficult to relate the written content to the prior art. Few of the papers in the reference are repeated.\n\n2. The evaluation of the proposed vector quantization is limited. The authors have only experimented with a low-complexity autoencoder using a single layer. Consequently, the impact of the proposed method on neural compression is limited. The authors should utilize recent state-of-the-art variational autoencoder-based neural image compression methods, such as [1] and [2], and apply the proposed vector quantization to the latent space of these advanced methods. When the encoder and decoder are more powerful, the impact of vector quantization on reducing the bitrate might be lower than what is shown in the paper.\n [1] Cheng et. al, Learned Image Compression with Discretized Gaussian Mixture Likelihoods and Attention Modules, CVPR 2020\n [2] He et.al, ELIC: Efficient Learned Image Compression with Unevenly Grouped Space-Channel Contextual Adaptive Coding, CVPR 2022.\n\n3. The details of the network architecture are missing from the paper.\n\n4. The alternative optimization strategy is well-established in the vector quantization literature, where the codebook is fixed while optimizing the encoder and decoder. Additionally, in neural compression, some prior works [3] perform fine-tuning of the decoder using the quantized latent \\hat{y}​, showing that optimizing the decoder with the quantized latent improves compression efficiency and reduces the train-test set mismatch. The citations are missing.\n   [3] Zongyu Guo et.al, Soft then Hard: Rethinking the Quantization in Neural Image Compression, ICML 2021\n\n5. The citations to the related work (baseline) are incorrect (e.g., in Table 1), making it difficult to review the paper."
      },
      {
        "rating": "3",
        "confidence": "5",
        "summary": "The paper addresses two main issues of vector quantization (VQ) approximation methods in neural compression. The paper proposes encoder-decoder alternating optimization strategy to address the train-test mismatch and stochastic sphere-noise based approximation technique for suboptimal encoder gradients for rate-distortion (R-D) optimization. Experimental results on synthetic sources and natural images demonstrate the effectiveness of the proposed method over previous VQ approximation methods in terms of R-D performance.",
        "strengths": "1. The paper is well written and easy to follow.\n\n2. The proposed stochastic vector quantization for encoder optimization approach is superior to the previous VQ+STE approximation method as well as the UQ+AUN method, as demonstrated in experiments.",
        "weaknesses": "1. The proposed encoder-decoder alternating optimization strategy is of less importance. Recent neural compression methods address the train-test mismatch issue in end-to-end training by adopting mixed quantization. That is using additive uniform noise for learning the entropy model but employing quantized latent when it is passed to the decoder. There is no evidence that the encoder-decoder alternating optimization strategy is better than the mixed quantization method. Moreover, as the authors illustrated, the proposed alternating optimization strategy is only applicable to single-layer quantization and unconditional entropy models, which leads to obviously degraded R-D performance.\n\n2. In the proposed stochastic vector quantization approach, the authors assume $q(\\tilde{y}|y)$ is a uniform sphere distribution centered at $y$. However, there is no theoretical evidence to support that this assumption is reasonable. \n\n3. In experiments:\n\n(1) For low-dimensional vector sources, it is not reasonable for the dimension of the latent-space vector to be the same as that of the source-space vector, as the primary task of the encoder is dimensionality reduction for feature extraction .\n\n(2) The specific structure of the entropy model of VQ-STE and the proposed method is not given. Due to the different entropy models, it is also unfair to compare the proposed method with UQ-AUN and UQ-STE.\n\n(3) The R-D performance of the proposed method is evidently worse than current state-of-the-art methods. It is even worse than BPG444."
      },
      {
        "rating": "5",
        "confidence": "4",
        "summary": "This paper proposes an alternating optimization method that incorporates stochastic quantization to improve the quantization process of nonlinear transform coding (NTC). The paper clearly formulates the optimization problem of NTC from the perspective of vector quantization, *i.e.*, the optimization of boundaries and codewords. Experiments on low-dimensional sources and natural images show that the proposed method outperforms the classical NTC method equipped with additive uniform noise and straight-through estimator on image compression.",
        "strengths": "1. The paper is overall well written and easy to follow.\n2. The authors provide a clear framework for analyzing the gradient approximation problem of NTC and propose a method for solving it based on the characteristics of vector quantization.",
        "weaknesses": "1. The motivations and advantages of employing a uniform sphere distribution are hard to understand. The uniform quantizer with additive uniform noise also approximates the encoder gradient with the difference in RD loss between adjacent quantization centers (which is the main advantage of the uniform sphere distribution), as shown in Eq. (4).\n\n   By the way, I noticed that the proposed method uses a learnable multidimensional codebook instead of a fixed codebook of uniform quantizers. However, such a gap can be reduced by the nonlinear transforms (for flexible boundaries and codebook in the source space) and conditional coding (for redundant multidimensional signals).\n\n2. The importance of the proposed method seems to be limited. Vector quantization and conditional coding (*e.g.*, spatial auto-regression [R1] and channel-wise auto-regression [R2]) are two kinds of methods that solve the high-dimensional coding problem of latent representations, and the latter one is more prevalent in existing methods. Theoretically, the proposed alternating method can be used in both vector quantization and conditional coding. However, the authors only offer the results for vector quantization. It is better to evaluate the contribution of the proposed method by integrating it with state-of-the-art conditional coding methods, such as ELIC [R3] and TCM [R4].\n\n   [R1] D. Minnen, J. Ballé, and G. D. Toderici. Joint autoregressive and hierarchical priors for learned image compression, In *Advances in Neural Information Processing Systems (NeurIPS) 31*, 2018, pp. 10771-10780.\n\n   [R2] D. Minnen and S. Singh. Channel-wise autoregressive entropy models for learned image compression. In *2020 IEEE International Conference on Image Processing (ICIP)*, 2020, pp. 3339-3343.\n\n   [R3] D. He, *et al.* ELIC: Efficient learned image compression with unevenly grouped space-channel contextual adaptive coding. *Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)*, 2022, pp. 5718-5727.\n\n   [R4] J. Liu, H. Sun, and J. Katto. Learned image compression with mixed transformer-cnn architectures. *Proceedings of the IEEE/CVF conference on computer vision and pattern recognition (CVPR)*, 2023, pp. 14388-14397.\n\n3. Contributions on interpreting neural compression as vector quantization should be clarified. There has been work (Ballé *et al.*, 2020) that reveals the relationship between the source domain and the latent representation. Although this paper is cited by the authors in their related work, the relationship and contributions of the two papers are not clarified.\n\n4. Several details should be clarified in the manuscript to ensure that the paper is self-contained.\n\n   - The implementation of vector quantization in the latent space, which is crucial to better understand the contribution of the proposed method.\n\n   - The definition on the uniform sphere distribution.\n\n     I note that there are two different definitions of hypersphere, with a difference in whether the points with a distance less than the radius are considered part of the hypersphere. It is suggested that the authors provide a clear definition.\n\n     (Additional) 2 definitions, with the latter one be the case of this paper:\n\n     a) The $(k-1)$-sphere with a radius $R$ is the set of points $[x_1, x_2, \\cdots, x_k]$ with $\\sum_{i=1}^kx_i^2 = R^2$.\n\n     b) The $k$-dimensional hypersphere with a radius $R$ is the set of points $[x_1, x_2, \\cdots, x_k]$ with $\\sum_{i=1}^kx_i^2\\leqslant R^2$.\n\n5. Typos:\n\n   - There are several omitted citations in the second paragraph of Section 2.\n\n   - There is a redundant comma after “e.g.,” in Line 99.\n\n   - The references are not cited with proper commands. Some of the citations need to be replaced by `\\citep` instead of `\\citet`.\n\n   - There is an unnecessary bracket after $\\mathbf{\\mathit{y}}$ in Line 353."
      }
    ],
    "rating_avg": 3.5,
    "confidence_avg": 4.25,
    "decision": "N/A",
    "meta_review": "",
    "author_remarks": "",
    "decision_comment": ""
  },
  {
    "id": "yRd4loGAhJ",
    "title": "SEAL: Scaling to Emphasize Attention for Long-Context Retrieval",
    "authors": [
      "Changhun Lee",
      "Jun-gyu Jin",
      "YoungHyun Cho",
      "Eunhyeok Park"
    ],
    "abstract": "In this work, we introduce a novel approach called Scaling to Emphasize Attention for Long-context retrieval (SEAL), which enhances the retrieval performance of large language models (LLMs) over extended contexts. Previous studies have shown that each attention head in LLMs has a unique functionality and collectively contributes to the overall behavior of the model. Similarly, we observe that specific heads are closely tied to long-context retrieval, showing positive or negative correlation with retrieval scores. Built on this insight, we propose a learning-based mechanism using zero-shot generated data to emphasize these heads, improving the model's performance in long-context retrieval tasks. \nBy applying SEAL, we can achieve significant improvements in in-domain retrieval performance, including document QA tasks from LongBench, and considerable improvements in out-of-domain cases.\nAdditionally, when combined with existing training-free context extension techniques, SEAL extends the context limits of LLMs while maintaining highly reliable outputs, opening new avenues for research in this field.",
    "keywords": [
      "large language models",
      "long context",
      "retrieval",
      "attention",
      "supervised fine-tuning"
    ],
    "venue": "ICLR",
    "year": 2025,
    "pdf_url": "https://openreview.net/pdf?id=yRd4loGAhJ",
    "forum_url": "https://openreview.net/forum?id=yRd4loGAhJ",
    "reviews": [
      {
        "rating": "5",
        "confidence": "4",
        "summary": "This work focuses on scaling to emphasize attention to long-context retrieval, designed to enhance the retrieval performance of LLMs in handling extended contexts. A cost-effective, learning-based mechanism is proposed to improve the model's performance in long-context retrieval tasks, which emphasizes specific attention heads tailored to retrieval tasks. Experimental results demonstrate superior performance over the compared baselines.",
        "strengths": "1. This paper is well-organized and easy to read. \n2. The proposed method presents a reasonable approach for long-context retrieval by identifying the key components of Transformer architecture to boost retrieval performance. \n3. The approach is practical and has the potential for broad application in various RAG settings.",
        "weaknesses": "1. The term \"cost-efficient\" is not clearly defined, resulting in ambiguity when assessing the cost-effectiveness of the approach. The strategy of identifying key components initially and subsequently fine-tuning these components may prove to be computationally intensive. It would be beneficial to provide details regarding the computational time involved in this process.\n2. A more thorough evaluation would benefit from comparisons with a broader range of advanced baseline models. Currently, the proposed method is compared against only one simple. Including more sophisticated long-context modeling methods and state-of-the-art techniques would better validate the effectiveness of the proposed method.\n3. To confirm the versatility of the proposed method, it would be beneficial to conduct experiments on different LLMs of varying sizes."
      },
      {
        "rating": "5",
        "confidence": "4",
        "summary": "The paper introduces SEAL (Scaling to Emphasize Attention for Long-context retrieval), a novel attention scaling approach that improves retrieval performance for long-context tasks in Large Language Models (LLMs). It addresses the challenge of performance degradation over extended contexts, particularly in retrieval tasks. SEAL fine-tunes specific attention heads or channels using a minimal amount of training data, leading to significant improvements in long-context retrieval across various benchmarks. The paper focuses on cost-efficient enhancement of long-context capabilities without altering the model’s learned behavior.",
        "strengths": "1. SEAL presents an innovative approach by leveraging attention head/channel scaling to enhance long-context retrieval.\n2. The method uses very few trainable parameters and requires minimal training data, making it highly efficient.",
        "weaknesses": "1. The term “long-context retrieval” is ambiguous. It would be clearer to refer to “retrieval tasks that have long contexts,” which directly emphasizes tasks like passage retrieval or number retrieval.\n2. The paper lacks explicit detail about which context extension techniques are used. For example, Figure 6 mentions the use of Self-Extend, but no experiments isolating its performance are provided.\n3. Logical Flow in Writing: Certain parts of the paper are difficult to follow due to writing issues such as ambiguous expressions, inconsistent time tense, and occasional typographical errors (e.g., “biases” instead of “bias”).\n4. The distinction between “in-domain” and “out-of-domain” in the experiments is confusing. Specifically, if “in-domain” refers to training on retrieval tasks, why are the same datasets used for both “in-domain” and “out-of-domain” experiments?"
      },
      {
        "rating": "5",
        "confidence": "4",
        "summary": "This paper proposes an approach called Scaling to Emphasize Attention for Long-context retrieval (SEAL), which emphasizes specific heads or channels (attention outputs) particularly related to long-context retrieval by efficiently adjusting the strength of each attention component. The authors claimed that SEAL achieves significant improvements in in-domain retrieval performance and cross-domain document QA tasks, also extends the context limits of LLMs while maintaining highly reliable outputs.",
        "strengths": "1. This paper proposes SEAL to efficiently adjusting the strength of each attention component, and achieves superior performance to various LLM baselines in long-context retrieval.\n2. The content, figures, and tables of the paper provide a detailed explanation and analysis of the motivation, methods, and experiments, facilitating the readers' understanding.",
        "weaknesses": "1. The experimental results in Table 1 show that SEAL-H and SEAL-C require fewer parameters than Baseline and SEAL-L. However, their performance does not consistently surpass SEAL-L in long-context scenarios, failing to demonstrate the authors' claims.\n2. The experiments only select SEAL-L as the baseline, it should include other PEFT methods for comparison."
      },
      {
        "rating": "6",
        "confidence": "4",
        "summary": "This paper proposes a novel and practical method, SEAL, to improve the long-context retrieval ability of LLMs. \n\nFirst, through perturbation experiments, it finds a certain attention head or a certain channel in it can cause a positive or negative effect on long-context retrieval accuracy.\n\nSecond, it demonstrates directly scaling the hidden states of these heads or channels can indeed improve the retrieval accuracy of LLMs. \n\nThird, it adds trainable scale factors into the model and use a small amount of samples of retrieval tasks to fine-tune the model. The results show SEAL can remarkably improve the long-context retrieval ability of LLMs.",
        "strengths": "1. This paper discovers that a certain attention head can cast a remarkable positive or negative effect on long-context retrieval accuracy, even as well as a certain channel. This is interesting and helpful for us to further understand the role of the internal modules of LLMs.\n\n2. The proposed method, SEAL, is very cost-effective, which only needs very few training samples and tuned parameters.\n\n3. There are enough evaluation results of various models to demonstrate the method’s effect.",
        "weaknesses": "1. Narrow scope\n\nThe method seems to only be applicable for classic retrieval tasks such as NIAH, and the training data is also the same types of tasks. It will not be surprising that this leads to an improvement, since this task has been too simple, fixed and formulaic, which may represent a narrow application scope for this method. It would be better to train and test on more tasks such as Knowledge-QA.\n\n2. No unique advantages\n\nThe author should empirically test whether the time or space required by SEAL is significantly less than that of LoRA. Otherwise it cannot show significant superiority of SEAL compared to LoRA. Because the parameters tuned by LoRA are already very few. Though SEAL can theoretically tune much less parameters, it may not significantly save much time. \n\n3. There is little detailed description about the procedures of the method in the abstract or introduction. This will make it hard for readers hard to grasp the method quickly. There usually should be a paragraph included in the introduction to describe the specific operation of the method.\n\n4. The curve of data points in Figure 4 (a) may be too small, making it hard to clearly see the changes."
      }
    ],
    "rating_avg": 5.25,
    "confidence_avg": 4.0,
    "decision": "Reject",
    "meta_review": "This paper proposes an efficient method, SEAL, which tunes the scales of attention heads and channels for effective long context retrieval. Due to the limitations in the pretraining phase, LLMs are known for deficiencies in handling very long context window. By learning to weigh the strengths of different attention heads and channels using a small set of generated examples, the scaled model is capable of emphasizing the model components that are beneficial for the retrieval task and de-emphasizing those components negatively affecting the retrieval task. Experimental results demonstrate the advantage of SEAL on line retrieval task and LongBench QA task.\n\nStrengths:\n- The proposed scaling method is novel and effective, backed by an interesting observation on a significant performance change when pruning different attention heads or channels.\n- Given the tunable parameters only involve scaler weights for attention heads and channels, the method is efficient and could be easily adopted in different models and real applications.\n- Experimental results on two different datasets demonstrate the advantage of SEAL over the baseline.\n\nWeaknesses:\n- The clarity of the paper writing needs to be improved, such as the description of SEAL-L and SEAL-D, how the method is used in the context extension setting.\n- The implication of SEAL is not clearly revealed from the empirical results. Comparing with normal PEFT methods such as LoRA and DoRA, the performance improvement is not very consistent. If the provided LoRA (SEAL-L) and DoRA (SEAL-D) are also proposed by the authors, additional baselines with normal PEFT training should be given to clearly reveal the difference and advantage of the proposed method.\n- More datasets/tasks could be incorporated to showcase the method's generalizability.",
    "author_remarks": "",
    "decision_comment": ""
  },
  {
    "id": "6ifeGfWxtX",
    "title": "Slashed Normal: Parameterize Normal Posterior Distributions with KL Amplitude",
    "authors": [
      "Yujia Yan",
      "Xingjian Du",
      "Zhiyao Duan"
    ],
    "abstract": "We present Slashed Normal, a novel parameterization for the normal posterior\ndistribution in variational-inference-based latent variable models. Slashed Normal\ntakes a simple form resembling conventional practice, but uses the new stdplus\nactivation function to derive the standard deviation instead of softplus or exp. Although taking this simple form, the Slashed Normal establishes a direct connection between the squared l2-norm of the raw neural network output, termed KL amplitude, and the exact KL divergence value between the prior and the posterior. As a result, this parameterization enables a direct control of the KL divergence value, which is usually interpreted as the rate from the rate-distortion perspective for variational\nautoencoders. We demonstrate the versatility of Slashed Normal through theoretical analysis and experiments, showcasing its ability to provide good insight about the posterior distribution, explicit control over the KL divergence, and mitigate\nposterior collapse.",
    "keywords": [
      "Variational Inference",
      "Kullback-Leibler Divergence",
      "Posterior Parameterization",
      "Variational Autoencoders",
      "Variational Information Bottleneck"
    ],
    "venue": "ICLR",
    "year": 2025,
    "pdf_url": "https://openreview.net/pdf?id=6ifeGfWxtX",
    "forum_url": "https://openreview.net/forum?id=6ifeGfWxtX",
    "reviews": [
      {
        "rating": "3",
        "confidence": "4",
        "summary": "The paper proposes a new parameterization of Gaussian variational distributions when using variational inference (VI) in probabilistic models with Gaussian priors (the discussion and empirical evaluation focuses specifically on _amortized_ VI, i.e., variational autoencoders and variational information bottleneck). The KL-divergence from a Gaussian prior to a Gaussian variational distribution can be written as a sum $a^2 + b^2$ where $a$ depends only on the mean and $b$ depends only on the variance of the variational distribution. The authors propose to parameterize the variational distribution by $a$ and $b$ (rather than by, e.g., its mean and variance, or by its natural parameters). Solving for $a$ and $b$ results in $a$ being the shift between prior to variational mean, measured in units of the prior standard deviation, while $b$ is a more complicated function of the fraction between prior and variational standard deviation.\n\nThe paper claims that the proposed parameterization, in which the KL-term in the ELBO (the \"rate\") takes the simple form $a^2 + b^2$, allows for easier control of the rate and helps mitigating posterior collapse.",
        "strengths": "- The paper addresses a relevant problem that might sometimes be overlooked as a technical detail.\n- It discusses important consequences such as adversarial robustness and posterior collapse of the proposed method.\n- I think a streamlined derivation could motivate the proposed parameterization in a very straight-forward way whose simplicity would warrant exploring it in practical applications even if there may be limited strict theoretical guarantees.",
        "weaknesses": "While the studied problems are important, the derivations seem to be correct, and there are some (limited) empirical results, I find the paper lacking both in content and in presentation.\n\n## Content\n\nThe paper proposes a very simple (see \"presentation\" below) parameterization of the variational distribution in a specific model class.\nIn my experience, it is common when implementing probabilistic models that one thinks a bit about reasonable parameterizations of the probability distributions that avoid exploding gradients and that allow for easy regularization, initialization, and/or plotting of desired quantities.\nSuch considerations often make it into the appendix of a publication, where one describes details of the model implementation.\nFor such considerations to be noteworthy enough to merit a dedicated paper, in my opinion, they have to (i) apply to a general class of problems and (ii) be thoroughly evaluated empirically across a wide range of models to make sure that the improvements on a particular model are not an artifact of, e.g., the inevitably different initialization that comes with every reparameterization.\nI find the paper to be lacking in both (i) and (ii).\n\n**Regarding generality (i),** the proposal is limited to models with a Gaussian prior and Gaussian variational distribution.\n- While this simple setup is admittedly often used in practice, the paper seems to restrict the discussion and evaluation even further to *fixed* priors.\n  However, it seems to me that a good parameterization of a variational distribution would be of particularly interest in models with learned priors (which appear naturally in hierarchical VAEs [1-3], and also in applications of VAEs to data compression [4]).\n  I would find it an interesting question whether a parameterization that is relative to the prior is beneficial or detrimental to optimization speed when the prior itself changes during training.\n- Beyond learned priors, the idea of parameterizing the variational distribution in such a way that the rate term takes a simple form seems quite general to me, and it seems like this concept should, in some form, also be applicable to other distributions than Gaussians.\n\n**Regarding empirical evaluations (ii),** I find the experiments somewhat limited, but this may in parts be because I did not fully understand what the baselines are.\n- From the discussion, it is unclear to me whether baselines include a thorough comparison to standard $\\beta$-VAEs.\n  The discussion seems to suggest that the proposed family of renormalization methods do not need a tuning parameter (akin to $\\beta$) because the target rate can be set directly.\n  But of course, the target rate $r$ then takes the role of a tuning parameter.\n  For a full comparison, I would have expected some rate/performance plot, where performance can be any of the evaluated performance metrics (e.g., adversarial robustness or NLL), and the rate is always _measured_ by the standard KL-divergence and just _controlled_ differently (either explicitly by $r$ or implicitly by $\\beta$).\n- Point 4 in Section 6.2 suggests that the proposed method makes it easier to control the KL-term even when its value is trained.\n  However, it seems like model performance (e.g., number of active units) depends strongly on the initialization of $\\delta$.\n  Since the final value of the KL-term differs strongly from the initialization (see Table 2), it actually seems to me that the KL-divergence is quite hard to control in this setup.\n  We usually try to find setups where final model performance does _not_ depend strongly on initialization, since the effect of different initializations on final model performance is indirect and depends in complicated ways on learning rates and the number of training iterations.\n  I would imagine that it would have been much easier to control the KL-divergence had we just used a traditional parameterization of $q$ and added a simple regularization term $\\propto (D_\\text{KL} - \\delta)^2$ to the training objective (where $\\delta$ is the target rate).\n\nI would find the limited empirical evaluation less concerning if there was clear theoretical evidence of its benefits.\nHowever, I find the theoretical arguments somewhat vague.\nFor example, in the paragraph below Eq. 19, the paper highlights that the KL-divergence takes a very simple form in the proposed parameterization, claiming that \"this formulation eliminates all potentially unstable operations, e.g., log/exp\".\nBut first, other parameterizations that are common in practice avoid this too (e.g., parameterizing the variance by a softplus function).\nAnd second, and more importantly, the claim in the paper ignores the fact that the proposed parameterization just shoves the complexity (and potential instability?) from the KL-term into the reconstruction term.\n\n## Presentation\n\nMy main concern with the presentation is that the paper seems to overstate complexity at many points.\nThis is not a criticism of the simplicity of the proposal—simplicity is a good thing.\nBut, at several places, the paper makes simple (and sometimes even trivial) points seem unnecessarily complicated.\nExamples include:\n\n- Most importantly, a lot of space of the paper is used to derive the proposed parameterization, making it appear like this is a complicated invention that takes a lot of insight.\n  I think this complexity is artificial since the result almost falls out immediately from the expression for the KL-divergence between two normal distributions (Eq. 3).\n  The KL-divergence is a sum of a term that only involves the variational mean $\\mu$ and a term that only involves the variational standard deviation $\\sigma$.\n  Why not just define these two terms as $a^2$ and $b^2$, respectively, and then solve for $\\mu(a)$ and $\\sigma(b)$?\n  Here, $\\mu(a)$ is trivial and $\\sigma(b)$ involves a special function that we can't avoid anyway.\n  Instead of such a simple two-line derivation, the paper first proposes a _different_ parameterization in Section 3.1, that (i) seems less well motivated to me than my above simple motivation of the eventually proposed \"$a^2 + b^2$\" parameterization, (ii) is derived in such detail that I found it easier to rederive it myself than to follow every algebraic step in the paper, and, most importantly, (iii) gets discarded at the end of the section anyway.\n- The argument to discard the parameterization of Section 3.1 could have been seen without the lengthy derivation: if the argument is that $\\frac{\\partial\\sigma^2}{\\partial\\delta} \\xrightarrow{\\delta\\to0} \\infty$, then this can be seen simply by observing that $\\frac{\\partial\\sigma^2}{\\partial\\delta}$ = $1 \\big/ \\frac{\\partial\\delta}{\\partial\\sigma^2}$, where $\\left. \\frac{\\partial\\delta}{\\partial\\sigma^2} \\right|_{\\delta=0}=0$ since $\\delta$ is the KL-divergence, so the only place where it is zero is when prior and variational distribution are equal, in which case the derivative w.r.t. $\\sigma^2$ is trivially zero from Eq. 3.\n- For both Theorems 4.1 and 5.1, it seems like an overstatement to me to present these as \"Theorems\". Theorem 4.1 is a well-known information-theoretical bound, and Theorem 5.1 just states that $\\nabla_x (f(x) + x^2) = 0 \\Longleftrightarrow x = -\\frac{1}{2} \\nabla_x f(x)$.\n\n## Minor Point / Potential Typo\n\n- Line 522: \"Batch Learneable Rate\" --> \"Decoupled Learneable Rate\"?\n\n## References\n\n- [1] [Vahdat and Kautz, NVAE: A Deep Hierarchical Variational Autoencoder, NeurIPS 2020](https://proceedings.neurips.cc/paper/2020/hash/e3b21256183cf7c2c7a66be163579d37-Abstract.html)\n- [2] [Child, Very Deep VAEs Generalize Autoregressive Models and Can Outperform Them on Images, ICLR 2021](https://openreview.net/forum?id=RLRXCV6DbEJ)\n- [3] [Xiao and Bamler, Trading Information between Latents in Hierarchical Variational Autoencoders, ICLR 2023](https://openreview.net/forum?id=eWtMdr6yCmL)\n- [4] [Ballé et al., End-to-end Optimized Image Compression, ICLR 2017](https://openreview.net/forum?id=rJxdQ3jeg)"
      },
      {
        "rating": "6",
        "confidence": "5",
        "summary": "The paper proposed a Slashed Normal prior that parametrizes the KL divergence term in VAE as the form of a $L^2$-norm. It enables direct control of the KL divergence. Theoretical and experimental results show that the proposed approach is able to mitigate the issue of  posterior collapse.",
        "strengths": "* The presentation and the logic flow are clear.\n* The proposed method is intuitive. \n* The method derivation is good, with clear math notations and solid theorem prooves.",
        "weaknesses": "* The soundness is a bit questionable. There is no code uploaded.\n* The experimental results are a bit weak. For example, in experiment 1, which is the standard VAE results. There are actually two versions of standard VAE, one is the traditional KL term and the other is the reparametrized KL term. Will the results be significantly different?\n* There are no error bars in both of the experiments. For example, in experiment 2, I can see that the KL terms are significantly different (which is clear and intuitive). But the NLL terms (if that is the reconstruction loss) are roughly the same. Do these results show significant/effective performance differences? Some qualitative comparison will be better.\n* There is no comparison with alternative methods that also mitigate the posterior collapse issue. For example, https://proceedings.neurips.cc/paper/2017/hash/35464c848f410e55a13bb9d78e7fddd0-Abstract.html, https://proceedings.mlr.press/v161/jerfel21a.html, https://openreview.net/pdf?id=HD5Y7M8Xdk."
      },
      {
        "rating": "3",
        "confidence": "4",
        "summary": "The paper introduces Slashed Normal, a novel parameterization of Gaussian posterior distributions in variational-inference-based latent variable models, particularly focusing on Variational Autoencoders (VAEs). The method replaces traditional activation functions like softplus or exponential with stdplus to derive the standard deviation. By establishing a direct connection between the squared L2-norm of the raw neural network output (termed KL amplitude) and the exact KL divergence between the prior and posterior, the authors aim to provide explicit control over the KL divergence during training. They claim that this approach offers theoretical insights, enhances numerical stability, mitigates posterior collapse, and simplifies the training process.",
        "strengths": "- The method allows explicit manipulation of the KL divergence term by directly linking it to the network's output, potentially aiding in balancing the trade-off between reconstruction and regularization in VAEs.\n- By controlling the KL divergence explicitly, the approach offers a potential solution to posterior collapse, a common issue where the model ignores the latent variables.\n- The reformulation of the VAE loss function eliminates unstable operations like log and exp, which may improve numerical stability.",
        "weaknesses": "- The derivation of the Slashed Normal parameterization is convoluted, lacks sufficient explanation, and contains too many abuses of notation. For instance, the transition from Equation (9) to the introduction of complex numbers is abrupt and may confuse readers unfamiliar with the application of complex numbers in this context. The use of the Lambert W function is mentioned but not adequately justified or explained, making it difficult to follow the mathematical reasoning.\n- In Section 2, the authors create confusion by using the term \"posterior\" where they should more accurately refer to the \"approximate posterior.\"\n- The experimental results are minimal and lack depth. In Section 6, while the authors mention outperforming certain baselines, they do not provide comprehensive quantitative comparisons or statistical significance tests. \n- The paper acknowledges existing techniques for controlling KL divergence and mitigating posterior collapse but does not thoroughly compare the proposed method against these alternatives.\n- Despite citing numerical instability as a motivation, the paper does not present empirical evidence demonstrating improved stability during training. The claim that the method \"likely improves the numerical stability of training\" is speculative without supporting experiments.\n- The discussion on interpreting the KL amplitude and its relationship with posterior collapse is superficial. The connection made via Theorem 5.1 is not deeply analyzed, and the practical significance of this relationship is not convincingly established."
      },
      {
        "rating": "3",
        "confidence": "4",
        "summary": "This paper proposes a new activation function, \"```stdplus```,\" as a replacement for conventional ```exp``` or ```softplus``` parameterization of the approximate posterior variance in Gaussian VAEs, resulting in a new distribution they call \"Slashed Normal.\" This formulation allows for direct control over the channel capacity or information rate in VAEs and provides a more interpretable trade-off between the rate (KL) and distortion (reconstruction) terms. However, there are critical weaknesses that undermine the paper's contributions.",
        "strengths": "The authors identify several known issues within the VAE literature, such as posterior collapse and numerical instability, and aim to address them through their proposed parameterization approach. While theoretically well-motivated, the paper falls significantly short in providing sufficient empirical evaluation and validation of these claims, as discussed below.",
        "weaknesses": "A major weakness of this paper is the lack of empirical support for its primary claims. Since the main contribution centers on replacing the traditional ```exp``` or ```softplus``` parameterizations with the proposed ```stdplus``` activation, the most crucial empirical evidence should be a comprehensive evaluation of these parameterization choices across various datasets and architectures, with other factors controlled. Instead, the experiments primarily explore the impact of adversarial examples on performance, and their dependence on normalization choices, which seems tangential to the core contribution. The absence of a direct comparison between ```stdplus```, ```exp```, and ```softplus``` raises significant doubts about the practical value of the proposed method.\n\nAdditionally, it is known among practitioners that while ```exp``` is more challenging to train and may require techniques like clamping, it generally yields better performance compared to ```softplus```. This is likely attributed to the \"expansive\" nature of the ```exp``` nonlinearity, contrasted with the \"almost linear\" behavior of softplus, making the latter less expressive. Given the close relationship between the ```stdplus``` and ```softplus``` (Fig. 2b), it raises concerns that ```stdplus``` might underperform compared to ```exp``` in practical settings. Without demonstrating that ```stdplus``` is at least on par with ```exp``` or ```softplus``` in terms of empirical performance, the findings of this paper hold limited practical relevance.\n\nFurther complicating the evaluation, the paper relies on unvalidated assertions of numerical stability improvements. The authors assert (lines 309-311) that their approach \"eliminates all potentially unstable operations, e.g., log/exp, which previously require clipping the range of the input to prevent numerical problems. This property likely improves the numerical stability of training.\" This is indeed a major challenge in training VAEs, particularly in hierarchical settings. However, without an experimental demonstration to substantiate this claim, the impact remains speculative. For a novel parameterization technique, empirical validation of stability is essential, and its absence limits the trust in ```stdplus``` as a robust alternative.\n\nRelated to this, the introduction of the ```stdplus``` function adds significant implementation complexity without sufficient justification in terms of demonstrated performance gains. As presented in Algorithm 1, ```stdplus``` is computationally more complex than a simple ```exp``` or ```softplus``` functional call. The authors need to justify this added complexity with clear, consistent performance improvements across practical applications. Yet, the current manuscript fails to establish this, leaving the reader questioning whether ```stdplus``` offers tangible benefits to warrant its more intricate setup.\n\nWhile the authors acknowledge the need for more extensive empirical comparisons, this does not excuse the lack of rigorous evaluation in the current manuscript. Given the main contribution of the paper is replacing ```exp```/```softplus``` with ```stdplus```, a lack of empirical comparison between these parametrization choices almost seems like an intentionally left-out comparison.\n\nOverall, I am inclined towards rejection. Without sufficient empirical evidence, the theoretical contributions alone are not enough to warrant publication at this venue."
      }
    ],
    "rating_avg": 3.75,
    "confidence_avg": 4.25,
    "decision": "N/A",
    "meta_review": "",
    "author_remarks": "",
    "decision_comment": ""
  },
  {
    "id": "STpxO1Siaq",
    "title": "Defend against Jailbreak Attacks via Debate with Partially Perceptive Agents",
    "authors": [
      "Qi Zhou",
      "Tianlin Li",
      "Qing Guo",
      "Dongxia Wang"
    ],
    "abstract": "Recent studies have shown that maliciously injecting or perturbing the input image in Vision Large Language Models (VLMs) can lead to jailbreak attacks, raising significant security concerns. A straightforward defense strategy against such attacks is to crop the input image, thereby disrupting the effectiveness of the injection or perturbation. However, the cropping can significantly distort the semantics of the input image, leading to an adverse impact on the model's output when processing clean input. To mitigate the adverse impact, we propose a defense mechanism against jailbreak attacks based on a multi-agent debate approach. In this method, one agent (“integrated” agent) accesses the full integrated image, while the other (“partial” agent) only accesses cropped/partial images, aiming to avoid the attack while preserving the correct semantics in the output as much as possible. Our key insight is that when an integrated agent debates with a partial agent, if the integrated agent receives clean input, it can successfully persuade the partial agent. Conversely, if the integrated agent is given an attacked input, the partial agent can persuade it to rethink the original output, thereby achieving effective defense against the attack. Empirical experiments have demonstrated that our method provides more effective defense compared to the baseline method, successfully reducing the average attack success rate from 100% to 22%. In more advanced experimental setups, our proposed method can even limit the average attack success rate to 18% (debating with GPT-4o) and 14% (with enhanced perspective).",
    "keywords": [
      "Multi-agent Debate; Defense; Visual Large Language Models"
    ],
    "venue": "ICLR",
    "year": 2025,
    "pdf_url": "https://openreview.net/pdf?id=STpxO1Siaq",
    "forum_url": "https://openreview.net/forum?id=STpxO1Siaq",
    "reviews": [
      {
        "rating": "5",
        "confidence": "3",
        "summary": "This paper proposes a novel multi-agent debate framework for defending Vision Language Models (VLMs) against jailbreak attacks. The approach employs two types of agents - one with full image access and one with partial access - to engage in structured debates aimed at preventing harmful responses. The method achieves a significant reduction in attack success rate from 100% to 22% while maintaining better response quality than baseline approaches.",
        "strengths": "1. The training-free defense mechanism seems promising since it can be implemented at endpoints.\n    \n2. Comprehensive experimentation with multiple debate strategies like message passing, critical debate, persuasive debate.\n    \n3. The approach achieves a reduction in attack success rate from 100% to 22% while maintaining better response quality than baselines.",
        "weaknesses": "1. Experimental Design Issues:\n    \n\n- Insufficient sample size: only 20 samples per scenario for experiment is not adequate enough\n    \n- Inadequate justification for baseline selection: there is no explanation in the article why those two baseline methods are chose for comparison.\n    \n\n2\\. Evaluation methodology Concerns:\n\n- Unclear indicator function definition: the article didn’t clearly explain what the indicator function actually means\n    \n- No explicit criteria for \"successful\" attacks: there is no explicit definition of what constitutes a successful attack\n    \n- Over-reliance on GPT-4 without human validation: there is no human evaluation to validate GPT4’s assessments, which introduces no clear criteria for quality scoring\n    \n\n3\\. Grammar errors, for example\n\n1. ... other debater's answers -> ... other debaters' answers\n    \n2.  ... can notebly decrease... -> ... can notably decrease...\n    \n3. ... Additionlly ... -> Additionally..."
      },
      {
        "rating": "3",
        "confidence": "4",
        "summary": "This paper proposes a multi-agent debate framework focusing on defending against VLM jailbreak attacks. The framework involves 2 LLMs, one receiving the attacked image and one taking the partially observed image. The authors also propose different communication strategies to investigate the corresponding effects. Experiments show that the final conclusion reached by the two agent-debate has a low ASR against typographic attacks.",
        "strengths": "- The paper is well-written and easy to follow.\n- The topic of multi-agent debate to defend VLM attacks is interesting.\n- The experiments are comprehensive and clear.",
        "weaknesses": "- The novelty is limited. The multi-agent debate framework is not new and is well-explored in previous work. The authors directly apply the framework to the defense tasks.\n- The paper does not fully justify the advantage of the proposed framework based on multi-agent debate. For example, to demonstrate the advantage of debating, a simple baseline can be: get multiple initial responses from the two agents in round 1 and directly do majority vote instead of debating. To demonstrate the advantage of multi-round, the author should include the comparison with: use the moderator to summarize different responses and get a final response in the first round, instead of doing multiple rounds."
      },
      {
        "rating": "3",
        "confidence": "4",
        "summary": "The paper proposes a novel defense mechanism against jailbreak attacks on VLMs using a multi-agent debate approach, where one agent with full image access debates with another agent with partial/cropped image access, reducing the average attack success rate from 100% to 22% while maintaining response quality.",
        "strengths": "It seems novel to me to use multi-agent debate approach to VLM security. And the proposed method achieves significant performance improvements (reducing attack success rate from 100% to 22%) while maintaining good response quality and low refusal rates.",
        "weaknesses": "1. The paper lacks comprehensiveness in terms of attacks and defenses. Stronger attacks such as white-box attacks aren't considered. Common defenses such as refusal training aren't included.\n\n2. Lacks computational cost comparisons between the proposed method and the baselines in the paper.\n\n3. The claim of maintaining \"quality of responses\" needs more rigorous evaluation (on capability benchmarks) - the quality scoring method (0-5 scale using GPT-4) lacks detailed explanation."
      },
      {
        "rating": "3",
        "confidence": "4",
        "summary": "This paper introduces a method against jailbreak attacks on Vision Large Language Models (VLMs) that utilizes a multi-agent debate framework. The approach involves two agents: one that processes the full image and another that handles cropped images. Through debate, the agents cross-validate their outputs, allowing for effective defense—clean inputs lead to the correct output, while attacked inputs prompt re-evaluation.",
        "strengths": "The strengths of this paper include its clear and well-organized writing, making the explanation of the proposed method easy to follow. The authors provide a thorough introduction to the approach, enhancing its accessibility. Additionally, they conduct a comprehensive statistical analysis across different types of topics, which effectively demonstrates the performance of the method.",
        "weaknesses": "The weaknesses include: \n\n- The paper claims that their method can successfully reduce the average attack success rate from 100% to 22%. However, there is no other mention of a 100% attack success rate in the main content.\n\n- The authors compare agents with full image access and those with partial image access. At the very least, agents without image input could be a valid comparison, as the MM-SafetyBench dataset itself does not require models to analyze images. This approach is entirely feasible.\n\n- The proposed method, which relies on debate, is resource-intensive and requires significant computational time, making it less practical. However, the paper does not discuss the efficiency of the proposed approach. Beyond defense success rates, it is unclear whether the method could lead to overly cautious responses that might affect user experience or whether it could impact the usability of the model in other multimodal tasks.\n\n- The baselines used in the paper are overly simplistic, as they only compare the proposed method with MLLM Protector and SmoothVLM. Other relevant approaches, such as prompt-based methods, self-evaluation, self-defense, self-reminder, input perturbation techniques like query rewriting, and fine-tuning-based methods, were not included in the comparison.\n\n- The authors' evaluation approach is relatively simple, relying solely on GPT-4 for assessment, which may introduce bias. The evaluation should include results from other methods or demonstrate consistency with human evaluation to provide a more balanced and robust assessment."
      }
    ],
    "rating_avg": 3.5,
    "confidence_avg": 3.75,
    "decision": "N/A",
    "meta_review": "",
    "author_remarks": "",
    "decision_comment": ""
  },
  {
    "id": "uOnElfFuey",
    "title": "Recovering Knowledge by Hardening Language Models",
    "authors": [
      "Haiming Wang",
      "Yimeng Chen",
      "Han Shi",
      "Zhengying Liu",
      "Zhenguo Li"
    ],
    "abstract": "Recent neural language models show impressive capabilities on a wide range of tasks. However, it is not fully understood how the knowledge of the language is encoded in these models. In this work, we focus on the simplest case of languages, regular languages, and study language models trained on strings matching certain regular expressions. We propose a method, dubbed LaMFA, to recover the full knowledge of the regular language model by hardening it into a finite automaton. Such hardening is conducted by empirically partition the latent space of language models into finite states, and then recover a deterministic finite automaton by the estimated transition probabilities between these states. Through experiments on regular languages of varying complexity, we demonstrate that LaMFA can effectively extract DFA that consistently replicate the performance of the original language model. Notably, the extracted DFAs exhibit enhanced generalization capabilities, achieving 100\\% accuracy even in out-of-distribution scenarios",
    "keywords": [
      "regular language",
      "language model",
      "transformers",
      "knowledge interpretation"
    ],
    "venue": "ICLR",
    "year": 2025,
    "pdf_url": "https://openreview.net/pdf?id=uOnElfFuey",
    "forum_url": "https://openreview.net/forum?id=uOnElfFuey",
    "reviews": [
      {
        "rating": "5",
        "confidence": "3",
        "summary": "This paper studies how language models learn regular languages. It proposes an algorithm LaMFA that can recover the finite state automaton corresponding to the regular language from the neural language model trained on the same language.\n\nLaMFA first constructs the states in DFA by clustering the features generated in language models and then estimates the transition function by looking at strings with and without the last token.\n\nThey found that LaMFA-extracted DFAs can recover the full knowledge of the regular language and perform better than neural language models in out-of-distribution scenarios.",
        "strengths": "1. The method and results are neat, showing that neural language models are capable of learning the underlying DFA of a regular language from the strings of the language.",
        "weaknesses": "1. The findings about \"extracted DFAs exhibiting more generalizability\" kind of contradict the findings in [1], where they showed that a standard transformer often outperforms a transformer that's constrained to be compilable to a RASP program [2].\n2. The results on regular languages are great, but how are they helpful for explaining how and why real-world language models work?\n3. The results from [3] seem more generalizable and (slightly) earlier to me.\n\n### Reference\n\n[1] Learning Transformer Programs, https://openreview.net/forum?id=Pe9WxkN8Ff\n[2] Thinking like transformers, https://proceedings.mlr.press/v139/weiss21a/weiss21a.pdf\n[3] Physics of Language Models: Part 1, Learning Hierarchical Language Structures, https://arxiv.org/abs/2305.13673"
      },
      {
        "rating": "3",
        "confidence": "4",
        "summary": "This paper introduces a method for extracting finite-state automata (FSAs) from trained language models, called LaMFA. The approach clusters string prefix representations in the model’s representation space and builds FSAs based on these clusters. The authors add a new denoising step to make clustering more stable and accurate. They apply LaMFA to both transformer and LSTM language models trained on five regular languages and compare the extracted FSAs to the actual FSAs for these languages. They find that the extracted automata are usually not identical to the original ones—they’re often larger—but they tend to generalize better than the models from which they were extracted.",
        "strengths": "This paper contributes to an important area of research: analyzing black-box models using interpretable, easier-to-analyze representations. Key strengths for me include:\n- Exploring language models with interpretable structures like FSAs can lead to better understanding and analysis of these models, which is valuable for the field.\n- The FSA denoising procedure seems new and intuitively useful, making the clustering process more robust.",
        "weaknesses": "There are areas where the paper could be improved:\n\n- **Novelty in Methodology**: Apart from the new denoising step (the benefit of which isn’t explicitly measured), the overall approach seems similar to past work, especially to methods by Weiss et al. (2018), which—contrary to the claims in the paper—also work on *any* language model and come with some theoretical guarantees. The paper would benefit from a closer comparison to Weiss et al., as well as other FSA extraction methods, such as those by Merrill et al (2022) and other authors referenced in the paper.\n- **Related Work Section**: The extended related work in the appendix mostly repeats what is in the main text. Instead, it would be better to replace this with a direct comparison to specific existing FSA techniques.\n- **Limited Empirical Basis**: One main takeaway of the paper is that local context dependency is a better predictor of transformer performance than concepts like circuit complexity. However, since the models are trained on only five very simple languages, this evidence may not be enough to support that claim. Testing on more complex—and many more—languages would strengthen this finding.\n- **Lack of Novelty in Reconciling Generative Models with Recognizers**: The reconciliation of LMs as generative models with FSAs as recognizers is useful, but the approach here is not the first to do so. Weiss et al. (2018), for example, presented an algorithm that addresses similar scenarios.\n- **Valid Rate Measure**: The paper uses “valid rate” to evaluate how many generated strings are syntactically correct, implying this tests language diversity. But as defined, it seems to only measure precision—if a model only learned one syntactically correct string, it could achieve a perfect valid rate. Adding a diversity measure or clarifying this metric could provide a fuller picture."
      },
      {
        "rating": "1",
        "confidence": "5",
        "summary": "**TL;DR:** A deeply misguided, inconsistent, and confused text further burdened by its poor comprehension of the subfield's literature and self-congratulatory overselling.\n\nThe paper presents LaMFA, a method for constructing finite automata from hidden states of language models. The design decisions comprising LaMFA outnumber the automata samples/experimental setups (a grand total of 5) by a factor of 2, thus making the first doubts of the interpretability of the results. The method presented, LaMFA, is an apparent simplification of the Louvain method heavily tailored toward the carefully chosen experimental automata.\n\nSomewhat grandiosely, he paper claims to \"shed light on the internal mechanism of language models\" (L053), \"investigate how linguistic knowledge is encoded and compressed\" (L098), \"draw new insights on the interplay between architectures and language complexity\" (L103), \"yield significant insights into the behavior of LMs\" (L415), and \"mark a significant advancement in model interpretability and generalization\" (L521). None of these claims about the contents of the paper are true, as most of these have no experimental counterpart in the text, and virtually every conclusion about the nature of language models that is drawn can be traced back to a design decision.\n\nAs a brief example of the prevalence of these issues: A claim is made that \"the LaMFA-DFA of LSTM is exactly equivalent to the ground-truth regex\" (L482). However, this is only a consequence of Algorithm 2 merging the previously disjoint cluster states. Okay, a counter-claim can be made that this is the intended function of Algorithm 2. But why then does \"the DFA of GPT-tiny contain an extra state\" (L483) even after the Algorithm 2 merge that was supposed to collapse it? You can't have it both ways; the successful recovery and unsuccessful recovery of a DFA cannot both be findings simultaneously. This would perhaps be acceptable if we had more samples and could draw statistical conclusions, but 5 languages are not nearly enough to do so -- a statistically significant sample should be considered instead and evaluated in an automated fashion (see Weakness 7 for more guidance on this). By the way, the DFA alter-GPT-tiny is incorrect as it also accepts the string \"1\" which is not in the alter language. All in all, the immediately-following claim that \"these observations suggest that larger models may learn more *nuanced* representations of language\" is a deliberate obfuscation of the contradictions arising in L480-L485. The use of *nuanced* is nothing less than a disconcerting, blatant attempt to pass \"it worked once and it did not work once\" for a finding.\n\nWhile I touch on more issues with the paper in the weaknesses, it is important to note that this work is also flawed *conceptually*. In a surprising omission of related work, the text appears to be utterly oblivious to the results of H. Siegelmann from the late 90s giving constructive proofs to the Turing-completeness of RNN-based architectures including GRU/LSTM (rather surprisingly, however, the text goes into great lengths to cite the likes of Kleene, Rabin, Chomsky, or McNaughton&Yamada). Many of the (non-)findings of Sections 5.2.1-5.2.2 are focusing on the artifacts of arguably improper gradient-based training schedule of the selected architectures, as each of the 5 regular languages considered can be realized as RNNs following the construction of the seminal proof. Since both LSTMs (dated work, Siegelmann) and Transformers (contemporary work, Svete) can be constructed by hand to recognize simple finite automata, the insights the paper sets out to provide are already familiar from theory, and its contribution is reduced to a tedious construction and an entirely unconvincing experimentation. See also Weakness 6.\n\nIt is my recommendation that the work is not published. It should be instead revisited from the very beginning, refocused on the contribution of LaMFA, supported by further experimentation vouching for its utility and advantages over the omitted previous work on state merging, and only then submitted for review.",
        "strengths": "None.",
        "weaknesses": "1. The design decisions described in the paper outnumber the experimental data samples by a factor of 2 at the very least.\n2. The paper refers to a considerable amount of obscure and/or dated work with little bearing on its goals.\n3. An unsavory resemblance can be seen between this work and past works of William Merrill.\n4. Early sections of the paper are riddled with typos and grammatical mistakes, especially Section 2 (e.g. \"further developing\" -> \"further development\" L111, \"inspect\" -> \"inspecting\" L113, \"they are only possible to compute formal grammars\" -> this is not a sentence, you need passive L129, \"knowledge recovering\" -> \"knowledge recovery\" L265, etc.).\n5. That this work is \"investigating generative language models\" is a bit of an overstatement as the DFAs recovered by LaMFA are ultimately classifying recognizers rather than generative LMs.\n6. The dependence of Algorithms 1-2 on the number and desired number of clusters (L274,L291) ultimately voids all claims about the complexity of the languages learned by the neural models. By varying the two Ks and given different orderings for the similarities of the clusters, one can arrive at different DFAs. Ultimately, we know that equivalent DFA constructions exist, so any claim on the complexity or imperfection of recovery based on the outputs of the method can be  attributed to the gradient-based training of the neural model as well as the proposed LaMFA method itself.\n7. To give credibility to the claims about the effectiveness of LaMFA, the work should consider a population of automatically generated small DFAs/regular languages, not just 5 handpicked examples. For example, to have 90% confidence that the reconstruction success rate lies between 45 and 55%, at least 273 distinct DFAs should be considered."
      },
      {
        "rating": "3",
        "confidence": "4",
        "summary": "The authors propose a method of converting an LSTM or GPT LM trained on a regular language to a deterministic finite automaton (DFA) that approximates the LM. They test their method on 5 regular languages belonging to two different circuit complexity classes (AC0 and TC0). The languages also have different \"context complexity\", in that some only require a local, finite suffix of a string to correctly recognize, and some require global context. They define a regex/DFA for each language and use it to sample datasets of positive examples. They train neural LMs on it from scratch. Afterwards, they extract the hidden representations for each prefix of each string in the dataset. They apply k-means clustering and denoising to convert them to states of a DFA. They find that the extracted DFA often has higher precision than the original LM, and that neural LM accuracy depends mostly on context complexity.",
        "strengths": "This paper proposes a method for extracting DFAs from neural LMs that have only been trained on positive examples and does not require negative sampling. To my knowledge this has not been tested on transformers before.",
        "weaknesses": "1. The number of languages (5) is small, and they are quite simple. It is not clear if this method scales up to more complicated languages where the minimal DFA has more than 3 states.\n1. There are issues with the mdY language. It seems like the authors only allow semantically valid dates (i.e., they do not allow strings like 99/99/9999). This means the actual language tested, which incorporates these constraints, is different from the regex they report in the paper and requires a lot more than 11 DFA states. Also, when splitting examples into training and test data, there are constraints placed on the training data based on the sum of the numbers in the string, and this makes it more difficult to characterize the language actually represented in the training data. It should be noted that this language contains only a finite number of strings.\n1. A technical comparison against prior work on converting neural LMs to DFAs, particularly Weiss et al. (2018), is conspicuously absent. What advantage does your method have vs. theirs? How is it different? The state merging algorithm seems to be very similar to the standard DFA minimization algorithm.\n1. I think the alter language has been misclassified as having local instead of global context dependency.\n1. Some aspects of the method are unclear. In particular, how do you determine when you have converged on the minimal number $k$ of states? I do not see a stopping condition for merging states in the pseudocode. How do you pick the sharpening parameter $T$ and the frequency threshold $\\tau_0$?\n1. There are issues with the evaluation metrics. For one, the accuracy metric only measures precision, not recall. For example, it is possible for an LM to achieve 100% accuracy by assigning all probability mass to a single string in the language. Including cross-entropy does mitigate this because it measures recall, but the authors do not provide what the lower-bound cross-entropy would be under the original DFA LM, so it is not clear when the models are doing well.\n1. The authors claim that context dependency matters more than complexity class, but there is only one language (end0) where these two do not coincide. The paper would benefit from additional languages where they do not coincide. As mentioned above, alter is actually global, not local.\n1. There are grammatical issues throughout the paper which affect its clarity, and it would benefit from a round of proof-reading."
      }
    ],
    "rating_avg": 3.0,
    "confidence_avg": 4.0,
    "decision": "N/A",
    "meta_review": "",
    "author_remarks": "",
    "decision_comment": ""
  },
  {
    "id": "Yd5MHVIKLk",
    "title": "MuLan: Multimodal-LLM Agent for Progressive and Interactive Multi-Object Diffusion",
    "authors": [
      "Sen Li",
      "Ruochen Wang",
      "Cho-Jui Hsieh",
      "Minhao Cheng",
      "Tianyi Zhou"
    ],
    "abstract": "Existing text-to-image models still struggle to generate images of multiple objects, especially in handling their spatial positions, relative sizes, overlapping, and attribute bindings. To efficiently address these challenges, we develop a training-free Multimodal-LLM agent (MuLan), as a human painter, that can progressively generate multi-object with intricate planning and feedback control.\nMuLan harnesses a large language model (LLM) to decompose a prompt to a sequence of sub-tasks, each generating only one object by stable diffusion, conditioned on previously generated objects. Unlike existing LLM-grounded methods, MuLan only produces a high-level plan at the beginning while the exact size and location of each object are determined upon each sub-task by an LLM and attention guidance. Moreover, MuLan adopts a vision-language model (VLM) to provide feedback to the image generated in each sub-task and control the diffusion model to re-generate the image if it violates the original prompt. Hence, each model in every step of MuLan only needs to address an easy sub-task it is specialized for. The multi-step process also allows human users to monitor the generation process and make preferred changes at any intermediate step via text prompts, thereby improving the human-AI collaboration experience. We collect 200 prompts containing multi-objects with spatial relationships and attribute bindings from different benchmarks to evaluate MuLan. The results demonstrate the superiority of MuLan in generating multiple objects over baselines and its creativity when collaborating with human users.",
    "keywords": [
      "Diffusion models",
      "Controllable generation",
      "multi-modal agent"
    ],
    "venue": "ICLR",
    "year": 2025,
    "pdf_url": "https://openreview.net/pdf?id=Yd5MHVIKLk",
    "forum_url": "https://openreview.net/forum?id=Yd5MHVIKLk",
    "reviews": [
      {
        "rating": "5",
        "confidence": "4",
        "summary": "The paper presents MuLan, a training-free multimodal language model agent designed to enhance text-to-image (T2I) generation. MuLan addresses challenges in generating images with multiple objects, focusing specifically on controlling spatial relationships, relative sizes, and attribute bindings. By leveraging a large language model (LLM) for planning and a vision-language model (VLM) for feedback, MuLan decomposes complex prompts into sequential subtasks, each handling a single object generation with attention-guided positioning.",
        "strengths": "+ The paper is well-written and easy to follow.\n+ MuLan demonstrates good control over the generation process and produces high-quality images that align with the prompts.\n+ MuLan can be applied to human-agent interaction during the generation process.",
        "weaknesses": "- MuLan increases inference time, especially as the number of objects in a prompt grows, which could limit its scalability in real-time applications.\n- As a training-free approach, MuLan is heavily reliant on the capabilities of underlying base models (such as Stable Diffusion).\n- In some cases, as shown in Figure 2, the generated images exhibit unrealistic proportions. For example, in the first row, the refrigerator, chair, and table are the same size, and in the second row, the pumpkin and door are also similarly sized, which detracts from the realism of the generated scenes.\n- Although qualitative results are emphasized, the absence of metrics such as generation speed or quantitative latency comparisons with baselines makes it difficult to assess MuLan’s practical efficiency."
      },
      {
        "rating": "3",
        "confidence": "3",
        "summary": "The paper introduces MuLan, a Multimodal-LLM agent to improve the performances of existing text-to-image generation models, especiallly with multiple objects, spatial relationships and attribute bindings.\nThe main contributions inlcude, \n* A large language model (LLM) is adopted to decompose complex prompts into a sequence of simpler sub-tasks, each focusing on generating a single object. \n* A vision-language model (VLM) provides feedback to ensure that each object is generated accurately and aligns with the original prompt.",
        "strengths": "(1) This article adopts LLM to divides text-to-image generation into several steps, it addresses the limitations of existing models in handling multiple objects effectively. (2) The use of an VLM to provide feedback ensures that the generated images maintain consistency to the input prompt.",
        "weaknesses": "(1) In Section 3.4, the paper mentioned 'MuLan will adjust the backward guidance of the current stage to re-generate the object', but detailed adjustment algorithm or operation is not clearly explained.\n\n(2) The evaluation is not sufficient, more existing works e.g. Ranni[1], Composable[2] should be included.\n\n(3) The baseline models (e.g. SD1.4, SDXL) used in this paper are relatively weak, I highly doubt that if MuLan still works when using more strong base models (e.g. SD3, FLUX)?\n\n(4) The tradeoff between accuracy and efficiency should be evaluated quantitatively, so that we can assess the practical values of this work.\n\n[1] Feng Y, Gong B, Chen D, et al. Ranni: Taming text-to-image diffusion for accurate instruction following\n\n[2] Liu N, Li S, Du Y, et al. Compositional visual generation with composable diffusion models"
      },
      {
        "rating": "5",
        "confidence": "5",
        "summary": "This paper introduces MuLan (Multimodal-LLM Agent), which leverages the reasoning capabilities of Large Language Models (LLMs) to decompose complex prompts into multiple subtasks, progressively generating multi-object outputs with detailed planning and feedback control. Additionally, MuLan incorporates Vision Language Models (VLMs) to provide feedback, thereby enhancing the alignment between prompts and generated images. The authors conducted experiments with 200 prompts involving multi-object scenarios with complex relationships to evaluate MuLan, and the results demonstrate its superiority in generating multiple objects.",
        "strengths": "1. Utilize LLMs as planners and VLMs as inspectors to enhance generation in complex scenarios.\n\n2. The approach is training-free and model-agnostic.\n\n3. Qualitative results surpass those of SDXL and PixArt-α.\n\n4. Supports human interaction throughout the generation process.",
        "weaknesses": "1. The results are not competitive enough compare to current open-source models like FLUX and SD3, the method are outdated and lack novelty .\n\n2. As mentioned in L233-243, the rough mask is limited to just four relative positions, which restricts its ability to handle more complex scenarios and reduces its overall flexibility.\n\n3. As mentioned in the limitations, Inference time of MuLan is much higher than base models, however, open-source models like sd3 could already achieve accurate generation in compositional scenarios. It is inefficient to use a mulit-step method which could not show superior advancement as presented in the paper."
      },
      {
        "rating": "3",
        "confidence": "4",
        "summary": "This paper introduces MuLan, a comprehensive image generation method that utilizes a Large Language Model (LLM) agent for precise control of the generation process. The approach involves decomposing the prompt into a sequence of sub-tasks and generating each object sequentially through a diffusion model. Consequently, the method effectively generates multiple objects in accordance with the prompt.",
        "strengths": "- The idea of using Large Language Models (LLMs) for planning and Vision-Language Models (VLMs) to provide feedback is quite sensible. \n\n- This approach allows for the generation of objects that closely adhere to given instructions.",
        "weaknesses": "1. Using LLMs as planners is not a novel concept. Several methods like RPG have explored this approach before. \n\n2. In the experimental section, no compared methods leverage LLMs for image planning, although similar methods have been proposed. Only plain text-to-image methods are compared.\n\n3. The entire generation process could be lengthy since each object in the image must be generated in order."
      }
    ],
    "rating_avg": 4.0,
    "confidence_avg": 4.0,
    "decision": "Reject",
    "meta_review": "The reviewers are concerned about the insufficient experimental comparison, unreaching sota performance, and limited technology. While the authors try to address these issues by providing specific explanations, the overall contribution remains limited. Overall, the ac has checked all the files and stands on the reviewers' side. The authors are suggested to further improve the current submission.",
    "author_remarks": "",
    "decision_comment": ""
  },
  {
    "id": "Sd4wYYOhmY",
    "title": "TabM: Advancing tabular deep learning with parameter-efficient ensembling",
    "authors": [
      "Yury Gorishniy",
      "Akim Kotelnikov",
      "Artem Babenko"
    ],
    "abstract": "Deep learning architectures for supervised learning on tabular data range from simple multilayer perceptrons (MLP) to sophisticated Transformers and retrieval-augmented methods.\nThis study highlights a major, yet so far overlooked opportunity for substantially improving tabular MLPs; namely, parameter-efficient ensembling -- a paradigm for imitating an ensemble of models with just one model.\nWe start by describing TabM -- a simple model based on MLP and BatchEnsemble (an existing technique), improved with our custom modifications.\nThen, we perform a large scale evaluation of tabular DL architectures on public benchmarks in terms of both task performance and efficiency, which renders the landscape of tabular DL in a new light.\nIn particular, we find that TabM outperforms prior tabular DL models, while the complexity of attention- and retrieval-based methods does not pay off.\nLastly, we conduct a detailed empirical analysis, that sheds some light on the high performance of TabM.\nFor example, we show that parameter-efficient ensembling is not an arbitrary trick, but rather a highly effective way to reduce overfitting and improve optimization dynamics of tabular MLPs.\nOverall, our work brings an impactful technique to tabular DL, analyses its behaviour, and advances the performance-efficiency tradeoff with TabM -- a simple and powerful baseline for researchers and practitioners.",
    "keywords": [
      "tabular",
      "tabular data",
      "deep learning",
      "architecture"
    ],
    "venue": "ICLR",
    "year": 2025,
    "pdf_url": "https://openreview.net/pdf?id=Sd4wYYOhmY",
    "forum_url": "https://openreview.net/forum?id=Sd4wYYOhmY",
    "reviews": [
      {
        "rating": "6",
        "confidence": "5",
        "summary": "The authors propose TabM, a variation of an MLP with $k$ heads that uses a shared backbone, and only certain aspects of the architecture in the beginning  and in the end are specialized. The heads are trained independently. The work is compared with prior DL methods (plain and attention architectures), retrieval-based methods, and tree-based methods on a diverse collection of classification and regression tasks. Based on the results, the proposed method manages to outperform all baselines with tuned hyperparameters.",
        "strengths": "- The proposed method achieves better performance compared to the other methods with tuned hyperparameters. \n- The set of considered baselines is extensive.\n- Extensive results on classification/regression datasets. Additionally, results are provided on well-known benchmarks in the domain.\n- The authors provide extensive ablations of the different components of the method. The authors additionally provide a time comparison of the different methods.",
        "weaknesses": "- The work is difficult to read, the captions of Figure 2 and Figure 3 are long and blend with the core manuscript text, making it hard to keep track of the manuscript flow."
      },
      {
        "rating": "6",
        "confidence": "3",
        "summary": "This paper come up with an efficient ensembling method for tabular deep learning — which integrate BatchEnsemble with multilayer perceptron. This method exhibits great improvements in their benchmark.",
        "strengths": "- [Major] This method is simple yet effective.\n- [Major] The paper is easy to read.",
        "weaknesses": "- [Medium] The proposed method is not much novel. Note that this concern is not the main reason that I chose to reject this paper. If other concerns listed can be addressed (e.g., more technical contributions, comprehensive empirical study for depper understandings), I think this paper is still very useful.\n- [Major] More experiments are needed to fully understand the behavior of TabM. In the abstract, the authors mentioned “we show that parameter-efficient ensembling is not an arbitrary trick, but rather a highly effective way to reduce overfitting and improve optimization dynamics of tabular MLPs.” However, in the paper, there is no discussion why TabM helps with reducing overfitting and optimization dynamics. Of course the experiments proves this, but it seems like a general benefits of ensemble models. At least, some explanation supported by experiments is needed to fully understand this method — especially this method is already very simple and not much novel, understanding this better is important to have sufficient technical contribution.\n- [Major] Baselines missing. This method is an ensemble method. At least we could compare it to other naive ensemble method. For instance, how much speed up it provides compared to normal ensemble; how robust it compared to normal ensemble; etc.\n- [Major] Datasets missing. Yes this paper test on many datasets — but the more important thing is the diversity. For instance, how about high-dimensional datasets and large datasets (I know it is on Table 2, but only evaluated on two datasets and three baselines, moreover, only TabMmini has been evaluated). I suggest the authors to use TabZilla hard benchmark, and then evaluate the method’s capability under different circumstances. These kind of experiments can make the findings more interesting."
      },
      {
        "rating": "6",
        "confidence": "3",
        "summary": "This paper proposes TabM, a deep learning model for tabular data based on MLP enhanced with BatchEnsemble, along with custom modifications designed to improve the model's efficiency and performance. The authors position TabM as an efficient alternative to more complex architectures like Transformer-based models, claiming it achieves superior performance without their added computational cost. The paper also provides a detailed analysis, suggesting that parameter-efficient ensembling can effectively address overfitting and improve optimization dynamics in tabular MLPs.",
        "strengths": "1. The paper is well-structured and clearly written, making the methods, results, and analysis easy to understand.\n2. TabM demonstrates competitive performance, positioning it as an efficient alternative for tabular data modeling.\n3. By introducing BatchEnsemble techniques into tabular data modeling, the authors have adapted and enhanced a previously underutilized approach in this domain.\n4. The paper provides a thorough analysis of each component's impact on model performance, contributing valuable insights.",
        "weaknesses": "1. Although the authors mention similar methods, a more detailed comparison with other related approaches for tabular data, such as Trompt, would be helpful. Despite structural differences, both methods share commonalities in prediction, such as averaging multiple head (cycle) outputs and summing losses across heads (cycles). \n2. Comparisons with standard ensemble methods are insufficient. Incorporating results from methods like model soup could help position TabM's performance.\n3. Dataset scope is somewhat limited, particularly for classification tasks. For a more comprehensive evaluation, the authors might consider incorporating the datasets from Tabzilla, which could provide richer classification benchmarks and enable a more detailed analysis, such as comparing performance across binary, multiclass, and regression tasks or evaluating model performance on datasets of varying sizes.\n\n[1] Kuan-Yu Chen, Ping-Han Chiang, Hsin-Rung Chou, Ting-Wei Chen, Tien-Hao Chang: Trompt: Towards a Better Deep Neural Network for Tabular Data. In ICML\n\n[2] Duncan C. McElfresh, Sujay Khandagale, Jonathan Valverde, Vishak Prasad C., Ganesh Ramakrishnan, Micah Goldblum, Colin White: When Do Neural Nets Outperform Boosted Trees on Tabular Data? In NeurIPS"
      },
      {
        "rating": "8",
        "confidence": "4",
        "summary": "The paper applies the BatchEnsemble technique to MLPs for tabular data, and investigates several modifications. The results show an improvement over MLPs and several deep baseline models and GBRT on a broach benchmark of 50 datasets from the literature. The experiments show that in the first adapter layer in particular is extremely critical, and results in the majority of gains.",
        "strengths": "The paper discusses the adoption of the BatchNorm architecture for the tabular setting, and describes several interesting ablations.\nThe empirical evaluation is broad and in-depth and well presented.\nThe empirical results are quite strong against a broad variety of baselines.\nThe paper is well written.",
        "weaknesses": "- The technical novelty of the paper is somewhat small; however, this is made up for by the in-depth analysis with somewhat surprising results and the good performance of the proposed model.\n- The paper doesn't describe the relationship to dropout, even though dropout was original describes as an efficient ensemble approach. Given the simple nature of TabM_mini, there seem to be some obvious parallels between drop-out and TabM_mini that I think are worth discussing. In particular, TabM_mini actually contains a dropout layer, and it would be interesting to evaluate how the two forms of ensembling complement each other.\n- The comparison doesn't include TabPFN, an extremely strong baseline. McElfresh showed that even subsampling data to at most 3000 datapoints, TabPFN outperforms most other models.\n- Given the focus on improving MLP performance, a comparison with regularization cocktails and \"Better by Default: Strong Pre-Tuned MLPs and Boosted Trees on Tabular Data\" might be relevant but not essential.\n- Given the somewhat surprising result about the importance of the initial adapter, it would be great to have more ablations on the different components. In particular, it's unclear in how far the initial adapter and last layer are coupled. How does the performance change if the best performing last layer is used for all the initial adapters? I.e. are the initial layer and last layer co-adapted or do they work independently? \n\n## Minor comments\nFigure 2 cuts off points at 8%. It seems there's a lot of points on exactly that line, which seems a bit suspicious. Are these all the outliers that are clipped to the limits of the figure? It would be great to indicate outliers in the plot.\n\nTable 2 is far below the mention and maybe should be moved up.\n\nTable 2, MLP on the Maps dataset is missing units in duration.\n\nThe title of section 5.3 should read \"How does the performance of TabM depend on k?\"\n\nLine 257: \"requires a special care\" should be \"requires special care\"\n\nLine 160: multiplication with 100% is not mathematically meaningful."
      }
    ],
    "rating_avg": 6.5,
    "confidence_avg": 3.75,
    "decision": "Accept (Poster)",
    "meta_review": "The authors propose TabM an efficient ensembling architecture that uses MLPs as its backbone, where the main weight matrix of a linear layer is shared between the ensemble members, and only member-specific adapters are learned. The proposed method outperforms traditional ensembles of neural networks and it offers a faster runtime compared to the plain ensemble counterpart. \n\nThe experimental protocol features a comparison with an extensive number of baselines/datasets where the proposed method achieves the best overall performance. However, in terms of novelty, the proposed approach is somehow limited.\n\nInitially, the reviewers had concerns regarding the efficiency of the proposed method and the complexity of the datasets included in the experimental protocol. However, the authors provided a thorough rebuttal. After the rebuttal the reviewers agree that the proposed method has a strong performance and it includes an extensive experimental protocol, yielding valuable results that would be helpful to the community.\n\nI agree with the reviewers that the novelty of the proposed method is limited, however, the proposed work provides valuable insights and a strong baseline in the realm of tabular data. Based on the previous points, I recommend acceptance.",
    "author_remarks": "",
    "decision_comment": ""
  },
  {
    "id": "zrdkQaf48Z",
    "title": "Leveraging Implicit Sentiments: Enhancing Reliability and Validity in Psychological Trait Evaluation of LLMs",
    "authors": [
      "Huanhuan Ma",
      "Haisong Gong",
      "Xiaoyuan Yi",
      "Xing Xie",
      "Dongkuan Xu"
    ],
    "abstract": "Recent advancements in Large Language Models (LLMs) have led to their increasing integration into human life. Understanding their inherent characteristics, such as personalities, temperaments, and emotions, is essential for responsible AI development. However, current psychometric evaluations of LLMs, often derived from human psychological assessments, encounter significant limitations in terms of reliability and validity. Test results reveal that models frequently refuse to provide anthropomorphic responses and exhibit inconsistent scores across various scenarios. Moreover, human-derived theories may not accurately predict model behavior in practical real-world applications.\nTo address these limitations, we propose Core Sentiment Inventory (CSI), a novel evaluation instrument inspired by the Implicit Association Test (IAT). CSI is built from the ground up with a significantly broader range of stimuli words than traditional assessments. CSI covers both English and Chinese to implicitly evaluate models’ sentiment tendencies, which allows for a much more comprehensive assessment.\nThrough extensive experiments, we demonstrate that CSI effectively quantifies models’ sentiments, revealing nuanced emotional patterns that vary significantly across languages and contexts. CSI significantly improves reliability, yielding more consistent results and a reduced reluctance rate, and enhances predictive power by effectively capturing models’ emotional tendencies. These findings validate CSI as a robust and insightful tool for evaluating the psychological traits of LLMs, offering a more reliable alternative to traditional methods.",
    "keywords": [
      "LLM",
      "Benchmark",
      "Evaluation",
      "Psychometrics"
    ],
    "venue": "ICLR",
    "year": 2025,
    "pdf_url": "https://openreview.net/pdf?id=zrdkQaf48Z",
    "forum_url": "https://openreview.net/forum?id=zrdkQaf48Z",
    "reviews": [
      {
        "rating": "3",
        "confidence": "3",
        "summary": "The paper introduces Core Sentiment Inventory (CSI), a multilingual evaluation benchmark aimed at assessing the sentiment tendencies of LLMs in an implicit manner. The approach leverages 5,000 neutral words from English and Chinese and prompts the LLM to express polarity towards these neutral words. By assessing this polarity, the paper measures the biases of the models with respect to optimism or pessimism. To quantify the reliability of CSI, the paper validates the method against BFI, where CSI shows significant decrease in reluctance (i.e., model punting).",
        "strengths": "Reasons to accept\n- The presentation of the method is clear and concise.\n- Measuring LLM’s sentiment tendencies is vital to identify biases and building fair systems.\n- The evaluation is performed both in English and Chinese with the approach being easily extended to other languages.",
        "weaknesses": "Reasons to reject\n\nWhile the paper has merit, I see the some critical flaws presented below:\n\n- The decision to pick all top nouns/verbs is questionable to me. Yes, nouns and verbs “tend” to be neutral. However, this is not always the case. From the examples in Table 2, some of these words are clearly polarized. “Improve” has positive connotations, as well as “team”. I believe there needs to be a manual filtering step where these words are removed to ensure reliable results. As it stands, I think the model does not have implicit biases if it assigns “improve” as positive.\n- Design choices are not well-motivated. The approach does multiple predictions for the same word and the method shuffles the order of words to measure inconsistency. (1) Given this goal, why is temperature T set to 0? Wouldn’t a higher temperature better indicate the model uncertainty in assigning tragedy/comedy? (2) Why is the number of words sampled equal to 30? What happens with n > 30 or n < 30. Why wasn’t the number of words picked so it maximizes the context window?\n- The prompt design is biased. (3) Why is neutral not a valid option? A very strong model with perfect instruction following capabilities will always pick one of the two (comedy/tragedy) and will never output “neutral”. (4) Given the definition of neutral score as N_{inconsistent} / N, I am wondering what percentage of words the model predicted in opposite categories? I think they should be very few. In this case, neutral score is solely determined by poor instruction following, not implicit biases."
      },
      {
        "rating": "3",
        "confidence": "4",
        "summary": "This paper introduces a novel assessment method known as the Core Sentiment Inventory (CSI) for evaluating the emotional tendencies of large language models (LLMs). Inspired by the Implicit Association Test (IAT), the CSI aims to provide a more reliable and effective way to assess the implicit emotional characteristics of LLMs. It addresses the limitations of traditional psychometric methods, such as model reluctance and inconsistency.",
        "strengths": "•  The CSI can effectively quantify the emotions of models, reflecting the emotional tendencies of LLMs.\n\n•  It effectively reduces the issues of reluctance and inconsistency in traditional psychological scales.\n\n•  The use of representative neutral words in constructing the CSI reduces the potential emotional orientation of the words themselves, better reflecting the internal emotional associations of LLMs.\n\n•  It explores the impact of different language environments on the emotional tendencies of LLMs.",
        "weaknesses": "•  The constructed CSI is only used to assess the emotions of LLMs and has not been extended to other psychometric fields, such as personality or moral decision-making.\n\n•  It does not introduce the calculation methods for consistency rate and reluctance rate."
      },
      {
        "rating": "6",
        "confidence": "3",
        "summary": "The authors propose Core Sentiment Inventory, a psychometric evaluation framework to assess LLMs' sentiment tendencies.\n\nThe experimental setup covers two languages, English and Chinese, 2 open-weight LLMs (LLama3.1-70B and Qwen2-72B), and 4 closed/proprietary LLMs (GPT-4o, two GPT4 checkpoints, and GPT-3.5).\n\nThe CSI consists of the 5k most frequent emotionally neutral words; it is assumed that noun and verbs are neutral, and thus the CSI word lists consist of the top-5k noun/verbs in the corpora.\n\nThe LLM is then provided with N words picked from the wordlist, and asked to to associate each word with \"comedy\" or \"tragedy\", thus revealing a sentiment bias for each word.",
        "strengths": "The paper proposes an elegant approach based on the adaptation of existing psychometric tools (IAT).\n\nThe paper is well written and easy to follow.",
        "weaknesses": "Although an enjoyable read, the work falls short when it comes to the experimental setup.\n\nFirst, while I consider the proposed method more elegant and effective than human-tailored alternatives such as BFI, I am not convinced by the preliminary reliability tests conducted: it can be argued than reluctance is due to post-training strategies (e.g. guardrails, instruction-tuning), thus a different choice of (accessible) LLMs could have been more convincing -- e.g. the first Mistral release.\n\nSecond, some design choices seem discretional and not thoroughly justified: for instance, the choice of the words \"comedy\" / \"tragedy\" used as classes seems arbitrary."
      },
      {
        "rating": "5",
        "confidence": "4",
        "summary": "The paper introduces the Core Sentiment Inventory (CSI), a new evaluation method inspired by the Implicit Association Test (IAT) to assess the implicit sentiment tendencies of large language models (LLMs). The approach aims to provide a reliable and valid measure of LLMs' optimism, pessimism, and neutrality in both English and Chinese, surpassing conventional human-centric psychometric tests like the Big Five Inventory (BFI). The authors present experimental results that claim improved reliability, reduced reluctance rates, and strong predictive power for CSI.",
        "strengths": "CSI represents an interesting attempt to create a psychometric assessment tool tailored for LLMs, addressing concerns around LLM reluctance and consistency with human-designed psychometric scales.\n\nThe bilingual approach (English and Chinese) is a notable effort to capture linguistic and cultural variance in model behaviors, which is increasingly important as LLMs are deployed globally.\n\nThe experiments cover several dimensions of reliability and validity, with additional sentiment analyses through story generation, providing a range of quantitative metrics.",
        "weaknesses": "The paper does not sufficiently justify the underlying premise that implicit sentiment tests designed for humans (like IAT) can meaningfully assess non-human entities like LLMs. The model’s association of specific words with positive or negative sentiments may not translate into meaningful or actionable insights about its “psychological traits,” as LLMs lack actual consciousness or subjective experience.\n\nCSI is evaluated solely through internal metrics without external validation from human experts in psychometrics or linguistics. Given the novelty of the tool, expert evaluation is essential to substantiate the claims of reliability and practical value, particularly for a method positioned as a \"psychological trait\" assessment.\n\nThe word set of 5,000 items lacks diversity and cultural depth, and it is unclear how these words were chosen or if they were screened for cultural or contextual biases. This oversight introduces potential biases that could skew CSI’s predictive power and undermine its reliability across varied contexts.\n\nMany new mental health-based LLMs are not cited to show the differences  anf effectiveness of this paper."
      }
    ],
    "rating_avg": 4.25,
    "confidence_avg": 3.5,
    "decision": "Reject",
    "meta_review": "**Summary:** \n\nThe authors introduce a bilingual evaluation (Chinese and English) for assessing LLM's implicit emotional characteristics. Their work builds on existing psychometric tests, and shows how LLMs vary in tendencies towards optimistic, pessimistic, and neutral behavior (there is a general bias towards optimism). They also show that language impacts the sentiment tendencies of LLMs, sometimes flipping their preferences from optimistic to pessimistic. Finally, they show that their approach is more reliable than a traditional psychometric test (BFI).\n\n**Strengths:**\n\n- In principal, this offers a simple and solid approach for quantifying how LLMs mimic human emotions. \n\n- The multilingual setting allows for exploration of cultural variance in how sentiment is conveyed.\n\n**Weaknesses:**\n\n- The tone of the writing may over-anthrophomorize LLMs.\n\n- The data was inadequately validated, for example the choice of words to measure sentiment seems less well-reasoned than would be desirable even after the rebuttal.",
    "author_remarks": "",
    "decision_comment": ""
  },
  {
    "id": "n7RqgqbxP7",
    "title": "CASAK-V: Dynamic Sparse Attention and Adaptive KV-Cache Compression for Memory-Efficient Long-Context LLM Inference",
    "authors": [
      "Hamza Mohammed",
      "Sai Chand Boyapati",
      "Hang Yin"
    ],
    "abstract": "The emergence of long-context Large Language Models (LLMs) has triggered a rapid expansion of applications across various domains. However, these models remain inaccessible for on-device or on-premises deployments due to significant computational and memory challenges. The quadratic complexity of attention mechanisms and the substantial memory requirements of KV-caches, hinder adoption in resource-constrained environments. Current solutions, such as sparse attention mechanisms and KV-cache compression techniques, often rely on pre-observed patterns or context-independent, head-specific profiling strategies, which can compromise model accuracy, especially in long-context processing. This paper introduces Context-Aware adaptive Sparse Attention with Key-Value cache compression (CASAK-V), an inference-time approach that dynamically generates and applies head-specific sparse attention patterns. CASAK-V leverages a meta-learning framework to fine-tune a compact pre-trained vision-language encoder-decoder transformer for sparse pattern identification from per-layer attention scores. These patterns include fixed local windows, dynamic column stripes, block-sparse, and various other learned hybrid configurations. The technique additionally implements adaptive chunk-wise KV-cache compression using policies adapted from these layer-wise sparse configurations. To retain context-awareness, these configuration are dynamically adjusted during token generation, based on an attention map reconstruction heuristic. Our evaluations show that CASAK-V achieves minimal performance degradation on long-context benchmarks (LongBench), while reducing memory usage by 40% and delivering near-linear runtime complexity compared to full attention and caching. In summary, CASAK-V enables efficient long-context processing in memory-limited environments, extending the applicability of LLMs and facilitating their deployment in on-premises and on-device scenarios.",
    "keywords": [
      "Large Language Models",
      "Sparse Attention",
      "KV-cache Compression",
      "Long-context Processing",
      "Meta-learning",
      "Adaptive Algorithms",
      "Memory Efficiency",
      "Inference Optimization",
      "On-device Deployment",
      "Context-aware Models",
      "Dynamic Attention",
      "Transformer Architectures",
      "Efficient Natural Language Processing",
      "Machine Learning Systems",
      "Attention Mechanisms",
      "Sparse Computation",
      "Benchmarking",
      "Model Compression",
      "Resource-constrained Computing",
      "Edge AI",
      "Computational Complexity",
      "Information Retrieval",
      "Self-attention",
      "Transfer Learning",
      "Deep Learning",
      "Artificial Intelligence",
      "Chunk-wise Compression",
      "Pattern Recognition"
    ],
    "venue": "ICLR",
    "year": 2025,
    "pdf_url": "https://openreview.net/pdf?id=n7RqgqbxP7",
    "forum_url": "https://openreview.net/forum?id=n7RqgqbxP7",
    "reviews": [],
    "rating_avg": null,
    "confidence_avg": null,
    "decision": "N/A",
    "meta_review": "",
    "author_remarks": "",
    "decision_comment": ""
  },
  {
    "id": "y15LAM4u0A",
    "title": "EmbodiedCity: A Benchmark Platform for Embodied Agent in Real-world City Environment",
    "authors": [
      "Chen Gao",
      "Baining Zhao",
      "Weichen Zhang",
      "Jinzhu Mao",
      "Jun Zhang",
      "Zhiheng Zheng",
      "Fanhang Man",
      "Jianjie Fang",
      "Zile Zhou",
      "Jinqiang Cui",
      "Xinlei Chen",
      "Yong Li"
    ],
    "abstract": "Embodied artificial intelligence (EmbodiedAI) emphasizes the role of an agent's body in generating human-like behaviors. The recent efforts on  EmbodiedAI pay a lot of attention to building up machine learning models to possess perceiving, planning, and acting abilities, thereby enabling real-time interaction with the world. However, most works focus on bounded indoor environments, such as navigation in a room or manipulating a device, with limited exploration of embodying the agents in open-world scenarios. That is, embodied intelligence in the open and outdoor environment is less explored, for which one potential reason is the lack of high-quality simulators, benchmarks, and datasets. To address it, in this paper, we construct a benchmark platform for embodied intelligence evaluation in real-world city environments. Specifically, we first construct a highly realistic 3D simulation environment based on the real buildings, roads, and other elements in a real city. In this environment, we combine historically collected data and simulation algorithms to conduct simulations of pedestrian and vehicle flows with high fidelity. Further, we designed a set of evaluation tasks covering different EmbodiedAI abilities. Moreover, we provide a complete set of input and output interfaces for access, enabling embodied agents to easily take task requirements and current environmental observations as input and then make decisions and obtain performance evaluations. On the one hand, it expands the capability of existing embodied intelligence to higher levels. On the other hand, it has a higher practical value in the real world and can support more potential applications for artificial general intelligence. Based on this platform, we evaluate some popular large language models for embodied intelligence capabilities of different dimensions and difficulties. The executable program of this platform is available for download, and we have also released an easy-to-use Python library and detailed tutorial documents. All of the software, Python library, codes, datasets, tutorials, and real-time online service are available on this anonymous website: https://embodied-ai.city.",
    "keywords": [
      "Embodied intelligence",
      "real-world city environment",
      "large language model agent",
      "benchmark"
    ],
    "venue": "ICLR",
    "year": 2025,
    "pdf_url": "https://openreview.net/pdf?id=y15LAM4u0A",
    "forum_url": "https://openreview.net/forum?id=y15LAM4u0A",
    "reviews": [
      {
        "rating": "3",
        "confidence": "4",
        "summary": "This paper presents a comprehensive benchmark platform aimed at assessing the performance of embodied agents in a realistic urban setting. Unlike previous benchmarks limited to indoor or fictional settings, this platform features a highly realistic 3D simulation of an actual city district in Beijing. The benchmark includes five core tasks for evaluating embodied capabilities: scene understanding, question answering, dialogue, visual language navigation, and task planning. These tasks are designed to capture the core embodied AI abilities of perception, reasoning, and decision-making. The platform supports multiple agents, offers an interface for real-time control, and provides a SDK for easy access, along with a dataset for training and evaluation.",
        "strengths": "- The platform's integration with Unreal Engine and AirSim, along with the provision of a Python SDK, significantly lowers the barrier for use and promotes flexible, scalable experimentation for researchers.\n- The benchmark includes evaluations of popular large language models (e.g., GPT-4, Claude 3) across tasks, providing a well-rounded quantitative baseline for the embodied intelligence community.\n- The open structure allows future expansions, such as multi-agent collaboration and adaptability, fostering an extensible environment for advanced research in embodied AI.",
        "weaknesses": "1. While the paper addresses the city layout aspect of the sim-to-real gap, it does not extend to other critical factors impacting real-world applicability. Additionally, no experiments are conducted to quantify the sim-to-real benefits derived from using a real-world city layout, leaving the practical advantages of this choice unclear.\n2. The shadows and lighting in Figure 3 appear less realistic, which may limit the benchmark's effectiveness in simulating real-world visual conditions.\n3. The benchmark predominantly focuses on drone-related tasks, with limited discussion on tasks relevant to autonomous vehicle planning. Definitions, metrics, and methodologies for evaluating embodied tasks in autonomous driving contexts, particularly for planning, are not included.\n4. The tasks are largely oriented toward language-based interactions, with an emphasis on using large language models. Metrics like BLEU and ROUGE, which primarily measure text quality, may not fully capture the performance of embodied AI tasks, raising questions about the suitability of these metrics for this benchmark.\n5. The paper does not specify a license for the assets used. Given that some assets are sourced from Unreal Engine, Baidu Maps, and Amap, it remains unclear whether these assets are freely distributable under their original licenses. Clarification on the licensing terms for these assets would strengthen the transparency and accessibility of the benchmark."
      },
      {
        "rating": "3",
        "confidence": "5",
        "summary": "In this paper, the authors construct a benchmark platform for embodied intelligence evaluation in real-world city environments. They create a highly realistic 3D simulation environment based on real city elements and conduct high-fidelity simulations of pedestrian and vehicle flows. The platform has a set of evaluation tasks and provides input and output interfaces. The quantitative evaluation is performed over popular large language models on this platform.",
        "strengths": "1. The authors introduce a new urban simulator for simulating pedestrians and traffic states of a city.\n2. This work provides the resources of a large digital city district, which is quite scarce in this field.\n3. This study evaluates several state-of-the-art large multimodal models (LMMs) against the proposed benchmark to assess their effectiveness in addressing embodied tasks from multiple perspectives. The results largely align with findings from other LMM benchmarks, which partially support the validity of the proposed benchmark.",
        "weaknesses": "1. Some metrics presented in Table 1 appear to be subjective and potentially incorrect. For instance, regarding visual realism, the rendering quality in Figure 1 is noticeably less convincing compared to GRUtopia. The images appear to be produced by a rasterization renderer rather than a ray tracing or path tracing renderer, revealing a significant disparity between the quality of human-crafted assets and actual buildings. Furthermore, from an embodiment perspective, the platform seems to primarily incorporate drones and vehicles, lacking support for widely-used embodiments such as humanoid and quadruped robots, despite the authors' claim in Table 1 that all these embodiments are supported.\n2. The diversity of the QA templates illustrated in Figures 8 and 9 appears to be quite limited. A broader range of templates would enhance the comprehensiveness of the evaluation.\n3. While the authors assert that the scene is crafted from real city maps, they do not clarify the benefits of this approach. The quality of the assets and rendered images does not seem realistic enough to justify this claim. Additionally, the authors have not demonstrated the sim-to-real potential of the proposed dataset, which is crucial for its application.\n4. Although the report includes scores based on several metrics, there is a lack of intuitive illustrations to showcase what the large multimodal models (LMM)-agents excel at solving. The results presented do not clearly reveal the main challenges of the proposed tasks.\n5. The rationale for incorporating dynamic pedestrians and vehicles into this platform is not clearly articulated. There appears to be no strong connection between the proposed tasks and the roles of pedestrians and vehicles, which raises questions about their necessity in the framework.\n6. Details regarding the LMM agents are insufficiently described. It remains unclear how these agents handle sequential egocentric observations, which is essential for understanding their operational effectiveness.\n7. The usefulness of the proposed benchmark is not adequately established. The absence of learnable baselines to validate the dataset’s rationale potentially limits the significance and impact of this work.\n8. The authors do not justify the running efficiency of the platform, which is critical for scaling training within the environment. A discussion of performance metrics or benchmarks would be beneficial.\n9. The authors have not conducted experiments to explore the impact of different embodiments on task performance. Such investigations could provide valuable insights into the effectiveness of various embodiment strategies.\n10. The metrics for Evaluative Question Answering (EQA) rely on conventional reference-based NLP metrics, which may not directly demonstrate the correctness of the answers provided. It would be more effective for the authors to utilize a large language model (LLM) to assess the correctness of answers in relation to the ground truth.\n\nTypos:\n1. In the caption of Table 6, \"vision-and-navigation\" should be corrected to \"vision-and-language navigation.\""
      },
      {
        "rating": "3",
        "confidence": "4",
        "summary": "This paper proposed an open-world simulator for embodied agents. The simulator is based on the city Beijing. To evaluate agents in this simulator, the authors propose 5 tasks. Embodied Scene Understanding, Embodied Question Answering, Embodied Dialogue, Embodied action (navigation), and Embodied Task Planning.\n\nThey evaluate 4 current VLMs on these tasks.",
        "strengths": "The proposed simulator and environment covers a large area.\n\nThe authors create various tasks in the simulator.\n\nThe authors evaluate various current VLMs on their proposed tasks.",
        "weaknesses": "Visuals. The paper advertises high quality visuals, and rates their visuals 3 out of 3 stars. To the reviewers, the visuals do not look better than things rated 2 out of 3 stars, such as CARLA.\n\nEvaluation metrics. Evaluating Embodied QA, Embodied Dialogue, and Embodied Task Planning with captioning and translation metrics, BLUE, CIDEr, etc, seems like a poor choice. I encourage the authors to define a notion of success for each task that evaluates if the agent did the task correctly. Such as, for the Embodied QA and Dialogue tasks, making questions with ambiguous answers multiple choice, or using something like LLM-Match (https://open-eqa.github.io). Questions without ambiguous answers can be evaluated directly. This would lead to a more meaningful and interpretable metric.\n\nMissing References. This paper is missing a very large number of references. For example, the authors mention, by name, the tasks Vision-and-Language Navigation (VLN) (https://arxiv.org/abs/1711.07280) and Embodied QA (https://arxiv.org/abs/1711.11543), but do not cite either work. They also do not cite the paper that proposed SPL (https://arxiv.org/abs/1807.06757). Overall, the space of EmbodiedAI has seen considerable interest and work but the paper cites very little of the work in this area."
      },
      {
        "rating": "5",
        "confidence": "3",
        "summary": "The paper presents a benchmark platform for evaluating embodied artificial intelligence in realistic urban environments, addressing gaps in open-world scenarios. It features a detailed 3D simulation, diverse evaluation tasks, and user-friendly interfaces, enhancing embodied intelligence capabilities and supporting practical applications in artificial general intelligence.",
        "strengths": "1. The paper constructs a detailed 3D environment based on real-world urban settings in Beijing, improving on previous fictional models.\n2. The paper establishes a diverse set of evaluation tasks that assess various dimensions of embodied intelligence.\n3. The paper provides accessible input and output interfaces for easy interaction and performance evaluation of embodied agents.",
        "weaknesses": "1. The motivation behind this paper aligns with the principles of ELM [1], focusing on embodied understanding in driving scenarios. A detailed explanation of the differences between the two approaches is necessary.\n2. Most of the evaluation tasks already exist in current literature. Providing a detailed explanation to distinguish these tasks from those in other works is important.\n\n[1] Embodied Understanding of Driving Scenarios"
      }
    ],
    "rating_avg": 3.5,
    "confidence_avg": 4.0,
    "decision": "Reject",
    "meta_review": "This paper was reviewed by four field experts and received unanimously negative evaluations. The main concerns raised include a lack of significant technical contributions and relatively underwhelming results. Additionally, no rebuttal was provided by the authors. The AC finds no reason to recommend acceptance.",
    "author_remarks": "",
    "decision_comment": ""
  },
  {
    "id": "75PhjtbBdr",
    "title": "Multi-Label Test-Time Adaptation with Bound Entropy Minimization",
    "authors": [
      "Xiangyu Wu",
      "Feng Yu",
      "Yang Yang",
      "Qing-Guo Chen",
      "Jianfeng Lu"
    ],
    "abstract": "Mainstream test-time adaptation (TTA) techniques endeavor to mitigate distribution shifts via entropy minimization for multi-class classification, inherently increasing the probability of the most confident class. However, when encountering multi-label instances, the primary challenge stems from the varying number of labels per image, and prioritizing only the highest probability class inevitably undermines the adaptation of other positive labels. To address this issue, we investigate TTA within multi-label scenario (ML--TTA), developing Bound Entropy Minimization (BEM) objective to simultaneously increase the confidence of multiple top predicted labels. Specifically, to determine the number of labels for each augmented view, we retrieve a paired caption with yielded textual labels for that view. These labels are allocated to both the view and caption, called weak label set and strong label set with the same size k. Following this, the proposed BEM considers the highest top-k predicted labels from view and caption as a single entity, respectively, learning both view and caption prompts concurrently. By binding top-k predicted labels, BEM overcomes the limitation of vanilla entropy minimization, which exclusively optimizes the most confident class. Across the MSCOCO, VOC, and NUSWIDE multi-label datasets, our ML--TTA framework equipped with BEM exhibits superior performance compared to the latest SOTA methods, across various model architectures, prompt initialization, and varying label scenarios. The code is available at https://github.com/Jinx630/ML-TTA.",
    "keywords": [
      "Vision-Language Models",
      "Zero-Shot Multi-Label Generalization",
      "Test-Time Adaptation"
    ],
    "venue": "ICLR",
    "year": 2025,
    "pdf_url": "https://openreview.net/pdf?id=75PhjtbBdr",
    "forum_url": "https://openreview.net/forum?id=75PhjtbBdr",
    "reviews": [
      {
        "rating": "5",
        "confidence": "3",
        "summary": "This paper focuses on test time adaptation under a multi-label setting, this is an early work in this field.  This paper first analyzes why widely used entropy loss is not helpful in multi-label settings, and proposes a new method to adapt with multi-label. Then, the author proposes the view prompt and caption prompt to adapt the model for each instance. The experiments on three datasets show the effectiveness of the proposed method.",
        "strengths": "1. This paper focuses on an important question.\n2. This paper has a good theoretical analysis.\n3. The proposed method achieves better result than baselines.",
        "weaknesses": "1. The equ(6) is quite difficult to understand, more explanation is needed to show the meaning. The author should explain more about how weak labels and strong label is recognized in the proposed method, and the meaning of $\\hat{s}_{ij}^{x^{test}$.\n2. It is unclear which parameter is learnable in this method. The authors need to clearly point out all the learnable parameters.\n3. The authors could explain more about the motivation of the view prompt and caption prompt, and why they are useful for this setting."
      },
      {
        "rating": "6",
        "confidence": "5",
        "summary": "This paper proposes a novel method for Multi-Label Test-Time Adaptation (ML–TTA) using a technique called Bound Entropy Minimization (BEM). Unlike traditional test-time adaptation (TTA) that optimizes for the most confident single-label prediction, BEM increases the confidence of the top-k predicted labels simultaneously. This approach addresses the challenges associated with multi-label data where prioritizing one label can reduce the adaptation effectiveness for others. The framework also incorporates paired captions as pseudo-positive labels to guide adaptation. Experiments conducted on MSCOCO, VOC, and NUSWIDE datasets demonstrate that ML–TTA outperforms existing methods and the original CLIP model, showcasing superior adaptability across diverse architectures and prompt setups.",
        "strengths": "1. The paper demonstrates robust experimentation across diverse datasets (MSCOCO, VOC, NUSWIDE) and architectures (e.g., RN50, ViT-B/16), showcasing the generalizability and efficacy of the proposed method.\n2. The introduction of the Bound Entropy Minimization (BEM) for Multi-Label Test-Time Adaptation (ML–TTA) is a significant theoretical and practical advancement. It effectively addresses the challenges inherent in multi-label test-time adaptation, a space where traditional single-label approaches like entropy minimization fall short.",
        "weaknesses": "1. The method section, particularly the mathematical formulations and algorithmic details, could be more clearly presented. The explanations surrounding the implementation of label binding and how the paired captions are retrieved need additional clarity for readers less familiar with the intricate mechanisms of vision-language model adaptations.\n2. While the paper effectively shows ML–TTA's superiority over traditional methods, it would benefit from a more detailed discussion about the choice of baseline methods and potential reasons for their relative underperformance."
      },
      {
        "rating": "6",
        "confidence": "4",
        "summary": "This paper introduces a Bound Entropy Minimization method for improving test-time adaptation in multi-label scenarios. BEM addresses the challenge of adapting multiple labels simultaneously. By integrating textual captions to determine the number of positive labels, the method enhances the confidence of several top predicted labels. The proposed Multi-Label Test-Time Adaptation (ML–TTA) framework leverages both visual and textual data, leading to superior performance across various datasets compared to state-of-the-art techniques.",
        "strengths": "1. The proposed Bound Entropy Minimization (BEM) method presents an innovative solution to improve test-time adaptation in multi-label scenarios.\n2. The use of paired captions as pseudo-labels is a clever strategy to determine the number of positive labels for each test instance.\n3.  It considers both visual and textual modalities, optimizing for a more robust adaptation to distribution shifts.\n4. The figures are well presented.",
        "weaknesses": "1. More detailed motivation behind the model design is preferred. It is important to explain why the authors propose the method in this work.\n2. The proposed method involves multiple steps, including view augmentation, caption retrieval, and label binding, which might introduce complexity in practical implementation. Simplifying the process could enhance usability.\n3. The effectiveness of the method heavily relies on the quality and relevance of the paired captions. In real-world scenarios, captions might not always accurately represent the image content, which could affect performance."
      },
      {
        "rating": "8",
        "confidence": "3",
        "summary": "The paper presents a novel approach to Test-Time Adaptation (TTA) for multi-label scenarios using a method termed Bound Entropy Minimization (BEM). The paper is well-structured, the problem statement is clear, and the proposed solution is innovative. The integration of view and caption prompts and the application of BEM to meet the test time adaptation are innovative to some extent. However, there are  some details should be clarified.",
        "strengths": "1) This paper is well-structured, the problem statement is clear, and the proposed solution is innovative. \n2) The integration of view and caption prompts and the application of BEM to meet the test time adaptation are innovative to some extent.\n3) Compared with the latest and most advanced methods, the method in this paper achieves the best performance.",
        "weaknesses": "1) In your paper, the choice of top-k seems to be very important, so how do you determine the setting of k? You said \"we retrieve a paired caption with derived textual labels for each view, which then serves as weak label set of size k for the corresponding view.\" How do you make sure the selected weak label set is reliable?\n2) I can not see any explanation about the \"augmented view\" in this paper, what is the definition of it and what effort does it have in the framework?\n3) The comparison methods you selected in the paper may be not designed for multi-label datasets, so is this comparison fair? Could you add more ML-TTA specific framework to the results?\n4) Some details: Table 1 lacks a description of evaluation metric; Marking the second-best result in the experimental results is more beneficial to the reader."
      }
    ],
    "rating_avg": 6.25,
    "confidence_avg": 3.75,
    "decision": "Accept (Poster)",
    "meta_review": "This paper introduces a novel technique, Bound Entropy Minimization (BEM), for multi-label test-time adaptation (ML-TTA). Unlike existing methods that prioritize the most confident prediction, BEM enhances the confidence of the top-k predicted labels simultaneously, effectively addressing the challenges of ML-TTA. The paper presents comprehensive experimental evaluations across several datasets, including MSCOCO, VOC, and NUSWIDE, demonstrating that the ML-TTA framework with BEM outperforms current state-of-the-art methods. The structure is clear, and both the methodology and results are well-presented. Although the initial submission lacked some clarity in the algorithm description and experimental interpretation, the authors have successfully addressed these concerns in the rebuttal, leading to a significant improvement in the overall presentation. Therefore, I recommend accepting this paper.",
    "author_remarks": "",
    "decision_comment": ""
  },
  {
    "id": "UlAkM88Vum",
    "title": "Action-Constrained Imitation Learning",
    "authors": [
      "Chia-Han Yeh",
      "Tse-Sheng Nan",
      "Risto Vuorio",
      "Shao-Hua Sun",
      "Ping-Chun Hsieh"
    ],
    "abstract": "Policy learning under action constraints plays a central role in ensuring safe behaviors in various robot control and resource allocation applications.\nIn this paper, we study a new problem setting termed Action-Constrained Imitation Learning (ACIL), where an action-constrained imitator aims to learn from a demonstrative expert with larger action space.\nThe fundamental challenge of ACIL lies in the unavoidable mismatch of occupancy measure between the expert and the imitator caused by the action constraints. We tackle this mismatch through $\\textit{trajectory alignment}$ and propose DTWIL, which replaces the original expert demonstrations with a surrogate dataset that follows similar state trajectories while adhering to the action constraints. Specifically, we recast trajectory alignment as a planning problem and solve it via Model Predictive Control, which aligns the surrogate trajectories with the expert trajectories based on the Dynamic Time Warping (DTW) distance. Through extensive experiments, we demonstrate that learning from the dataset generated by DTWIL significantly enhances performance across multiple robot control tasks and outperforms various benchmark imitation learning algorithms in terms of sample efficiency.",
    "keywords": [
      "action-constrained reinforcement learning",
      "imitation learning",
      "safety"
    ],
    "venue": "ICLR",
    "year": 2025,
    "pdf_url": "https://openreview.net/pdf?id=UlAkM88Vum",
    "forum_url": "https://openreview.net/forum?id=UlAkM88Vum",
    "reviews": [
      {
        "rating": "5",
        "confidence": "3",
        "summary": "This paper proposes a novel problem setting called Action-Constrained Imitation Learning (ACIL), where an imitation learner's action space is a subset of an expert's action space. The paper proposes DTWIL, which (1) generates feasible trajectory for the imitator by using Model Predictive Control (MPC) with Dynamic Time Warping (DTW) as its objective, and (2) performs behavior cloning from the generated trajectories. Experimental study showed that, existing imitation learning (IL) methods with a naive projection approach suffer from low performances in ACIL settings, and DTWIL outperforms these methods.",
        "strengths": "- The proposed paradigm, ACIL, is an important research direction. It must have many potential applications and a large group of potential audiences (originality, significance).\n- The high level idea of DTWIL seems reasonable and novel, and the experimental study showed that it indeed performs better than baselines in ACIL problems (originality, quality, significance).",
        "weaknesses": "Besides the strengths above, the presentation quality of the paper is not good in general. The followings are my concerns.\n\n### Major concerns\n- The exposition of DTWIL is not self-completed and clear enough. For example,\n  - At L.231, there is a statement \"The pseudo code for trajectory alignment is presented in __??__\" and the pseudo code for __trajectory alignment__ is missing in the paper.\n  - The definition of DTW distance in Eq. (2) is not provided, though its high level idea is stated in page 4.\n  - Since trajectory alignment algorithm is missing, it is not clear how the action constraints are handled practically. I conjecture that Eq. (2) is solved by a constrained optimization problem.\n  - The definition of $\\bar{S}(A,f_\\theta)$ is not concrete. Does this sequence start from $\\bar{s}_{t_{\\rm pg}}^e$?\n  - How $t_{\\rm pg}$ is updated in practice? Figure 3 explains only discrete cases. For continuous spaces, I suppose that we need to compute the distance of states by some metric and determine by a threshold, which must be an additional hyper parameter to be tuned.\n\n- I am not convinced of the validity of Actor Regularized Control (ARC). In my understanding, the expert actions before projection, $a^e$, are sampled from the dataset. On the other hand, $a^{\\rm sampled}$ are computed for states in the generated trajectory. Therefore, the states for which $a^e$ and $a^{\\rm sampled}$ are sampled are different by construction. Mixing these different-state-dependent actions seems not valid.\n\n- Ablation study is not comprehensive enough. Since the paper describes the importance of excluding the final expert state in Figure 3, the reader may expect its experimental impact.\n\n- The time complexity of the naive DTW algorithm is O(NM), where N and M are the lengths of the two input sequences. I suppose that DTWIL has a drawback in the computational complexity compared to the baselines, which might hinder the applicability of DTWIL to real world applications. I think that it is necessary to compare the computational time with baseline methods.\n\n\n### Minor concerns\n- For Maze2d, state-dependent constraint is not stated.\n- Section 5.6 and Appendix A.3 look exactly the same.\n\n\n## After reading author responses and revised manuscripts\n- As of 11/25: Thank you for revising the paper. The presentations are improve largely. I raise the score from 3 to 5.\n- As of 12/03: Thank you for clarifications. I raise the score from 5 to 6."
      },
      {
        "rating": "5",
        "confidence": "4",
        "summary": "This paper addresses the setting of action-constrained imitation learning, an imitation learning problem where the learned agent must use an action space that is more restricted than the one used by the expert demonstrator. It proposes DTWIL, a method that uses a combination of Model Predictive Control, Dynamic Time Warping, and Behavioral Cloning, to train agents in this setting. The paper shows that the method outperforms several baselines across 3 tasks.",
        "strengths": "The problem setting introduced by the paper is interesting and not widely studied (at least to the best of my knowledge). The paper is well-written and easy to follow. The experiments section compares against a large number of baselines, all of which are reasonable, and the results showcase the effectiveness of the approach.",
        "weaknesses": "There are a few critical weaknesses that should be addressed.\n\n**Limited Experiment Results.** While I appreciate the thoroughness of the results in terms of the number of baselines, the number of tasks shown are small and do not have much variety. For example, Half-Cheetah and Hopper are both locomotion tasks, and relatively simple in complexity (RL approaches can solve these tasks very efficiently from scratch). It would be great to see more settings such as robot manipulation tasks -- there are a wide number of suitable datasets and benchmarks available today (e.g. [robosuite](https://robosuite.ai/), [RLBench](https://sites.google.com/view/rlbench), [ManiSkill](https://www.maniskill.ai/home), and others). It is important to show that the method is general-purpose and easy to apply to many scenarios. Similarly, BC+P seems like a very strong baseline (from Table 1) -- seeing results across more tasks and settings to highlight the value of proposed method would paint a more complete picture.\n\n**Method Limitations.** The ARC (Section 4.2) seems like a hack, and could require per-task tuning, which is undesirable. It is also unclear if it's a good idea to always use blended actions up to a certain timestep, compared to other alternatives for incorporating expert actions, like using the notion of residual additive actions (for example, https://arxiv.org/abs/1812.03201). Including more tasks could help show that one set of parameters works well across multiple settings. It also seems like this method is only suitable for imitating a single specific trajectory, in contrast to typical scenarios where an agent must deal with a variety of initial conditions (such as a robot that needs to manipulate objects that start in diverse configurations on a table from episode to episode). Section 6 mentions \"as long as the agent is able to be initialized to the same starting state as the expert\" -- this is a severe, and often impractical assumption to make. Finally, it seems like the method implicitly assumes full state observability (e.g. privileged information) compared to partially observed settings (raw sensor data such as images or depth sensing), which also impedes the practicality of the approach.\n\n**Some Writing Issues.** Section 4 does not adequately describe the overall approach of how BC is used with MPC. This needs more details -- I had to figure this out from the Algorithm 1 pseudocode. It also isn't clear why BC is needed versus directly using MPC for control -- some further experiments might help point out the value of using BC.\n\n**Minor Issues.**\n\n- I suggest organizing Related Work further, with a bolded title for each paragraph at least.\n- line 231, undefined Figure reference\n- Section 5 beginning - \"both offline baselines online baselines\""
      },
      {
        "rating": "5",
        "confidence": "3",
        "summary": "The paper proposes a new setting of action-constrained imitation learning where an action-constrained imitator aims to learn from a demonstrative expert with larger action space. The authors show that using behavior cloning to imitation the behavior in the dataset followed by deploying the actions with constraints is insufficient to perform the tasks in their experiments. Accordingly, they propose DTWIL for improving the policy performance in such action constratined settings.",
        "strengths": "- The paper address a new domain of action constrained imitation learning to enable agents to address environmental or physical constraints when performing a task without have the constraints reflected in the expert demonstrations.\n- The algorithms uses DTW-based trajectory alignment for modifying the expert trajectories with the agent constraints and perform BC on this modified dataset to obtain policy. The authors also include Actor Regularized Control to improve the alignment’s effectiveness.\n- The paper carries out experiments on 3 simulated tasks and provides ablation studies across hyperparameters to justify their design choices.",
        "weaknesses": "- I am a bit confused about the action constrained setting that the paper operates in. For the experiments shown in the paper, the demonstrations are collected with the same agents in the same environments as at test time. So why should additional action constraints be added during deployment when they are not need during demonstration collection? It would be great if the authors could provide a real world example of a scenario needing the introduction of such action constraints during deployment.\n- I am a little confused about the algorithm. From what I understand, given some expert demonstrations, these demonstrations are modified through online interactions with the environment. Some questions based on this - (1) In Algorithm 1 Line 3, does each iteration correspond to a trajectory rollout or one step of action in the environment?, (2)  From Eq. 2, it seems like the action sequence optimization is done over a planning horizon. However, Line 6 in Algorithm 1 makes it seem like the whole trajectory is aligned in one go. So does this trajectory alignment involve multiple alignment steps and actions in the environment? (3) In Line 5 of Algorithm 1, its seems like a new forward dynamics model is trained for each iteration on the updated training data. How long does this take? I reckon this might make training slower. (4) In case each iteration corresponds to one environment action step, is a new trajectory sampled at each iteration after having taken action(s) based on a different trajectory in the previous iteration? It would be great if the authors could provide some clarifications regarding this.\n- There is a missing reference in line 231.\n- In Table 1, for HalfCheetah HC+O, BC+P is the best  performing method but DTWIL is still boldened. Similarly, in Table 3 for DTW-S, Hopper Box-Sync outperforms Hopper Box but Hopper Box is boldened. This is confusing to the reader and beats the purpose of boldening the results."
      },
      {
        "rating": "5",
        "confidence": "4",
        "summary": "This paper proposes action-constrained imitation learning (ACIL), a new imitation learning algorithm for action-constrained imitators to learn from demonstrations. The authors propose DTWIL to solve this problem by first replacing the original expert demonstrations with a surrogate dataset that follows similar state trajectories and then recasting trajectory alignment as a planning problem and solving it via Model Predictive Control. Through experiments in both navigation and locomotion tasks, they show the effectiveness of proposed method.",
        "strengths": "1. The problem formulation of this paper is novel for tackling action-constrained imitation learning. It tackles the problem by generating demonstration data that adheres to the action constraints.\n2. The quantitative experiment results are good.",
        "weaknesses": "1. The motivation requires to be further explained. I am not fully convinced that action-constrained imitation learning is an important problem in a wider range of tasks. The author should give more examples for this point. \n\n2. Also, what is the difference between action-constrained imitation learning and cross-embodiment imitation learning? How do they tackle this problem? The author should elaborate on this more in the introduction/related works sections.\n\n3. From my point of view, the proposed method is based on such an important assumption: the surrogate demonstrations generated by Trajectory Alignment (Section 4.1) must solve the task (or achieve high rewards), so that the imitator can solve the task by doing BC on this data. However, this assumption is not always true for general imitation learning tasks. The author should provide more analysis for this assumption to show what kinds of tasks meet this assumption and what tasks do not. Also, how does the \"box constraints\" coefficient affect this assumption? For example, if the box constraint of the maze task becomes *action<-0.5 and action >0.5*, can the method also generate good surrogate demonstrations?\n\n4. Why do the IRL and LfO methods (such as GAIL) require a +P operation? Can they directly use the constrained action space for IRL/LfO?\n\n5. Although the proposed method has better interaction sample efficiency than IRL/LfO methods, the author should also show if IRL/LfO methods can solve this task with more interactions, and how many interactions they need to train a successful policy.\n\n6. I doubt if directly using MPC with constrained action space can solve the task with the proposed DTW metric as the (negative) cost function. \n\n7. The stability of the proposed method for other tasks is doubtful. The proposed method requires task-specific operations to make the method effective such as normalization (Section 4.1.1) and time-step alignment (Section 4.2), as well as the $\\beta$ hyperparameter."
      }
    ],
    "rating_avg": 5.0,
    "confidence_avg": 3.5,
    "decision": "Reject",
    "meta_review": "This paper studies a novel problem formulated as action-constrained imitation learning where the imitation learning agent has access to only a subset of the demonstrator's actions. The proposed learning algorithm leverages dynamic time warping to measure discrepancies between trajectories, generates surrogate data with actions from the learner's action space using model predictive control, and then train a behavior cloning policy with the surrogate data. \n\nThe reviewers agree the problem studied in this paper is novel and can have a high impact on robotics applications, but raised concerns about the assumption the proposed algorithm makes, as well as the lack of sufficient evaluation on benchmark tasks and comparison with state-of-the-art baselines. Reviewers suggest that incorporating additional empirical results and testing in realistic task settings would strengthen the paper.\n\nIn summary, while the paper presents a novel problem and a plausible solution, further empirical validation and broader evaluations are necessary to fully establish its efficacy and applicability.",
    "author_remarks": "",
    "decision_comment": ""
  },
  {
    "id": "EdKSI2ijUY",
    "title": "LMRL Gym: Benchmarks for Multi-Turn Reinforcement Learning with Language Models",
    "authors": [
      "Marwa Abdulhai",
      "Isadora White",
      "Charlie Victor Snell",
      "Charles Sun",
      "Joey Hong",
      "Yuexiang Zhai",
      "Kelvin Xu",
      "Sergey Levine"
    ],
    "abstract": "Large language models (LLMs) provide excellent text-generation capabilities, but standard prompting and generation methods generally do not lead to intentional or goal-directed agents and might necessitate considerable prompt tuning. Even the best current LLMs rarely ask clarifying questions, engage in explicit information gathering, or take actions that lead to better decisions after multiple turns. Reinforcement learning has the potential to leverage the powerful modeling capabilities of LLMs, as well as their internal representation of textual interactions, to create capable goal-directed language agents. This can enable intentional and temporally extended interactions, such as with humans, the emergence of complex skills such as persuasion, and long-horizon strategic behavior, such as in the context of games. Enabling this requires the community to develop reliable reinforcement learning algorithms for training LLMs. Developing such algorithms requires tasks that can gauge progress on algorithm design, provide accessible and reproducible evaluations for multi-turn interactions, and cover a range of task properties and challenges in improving reinforcement learning algorithms. Our paper introduces the LMRL-Gym benchmark for evaluating multi-turn RL for LLMs, together with an open-source research framework for getting started on multi-turn RL with offline value-based and online policy-based RL methods. Our benchmark consists of 3 Interactive Dialogue tasks and 5 RL Capability tests for a total of 8 tasks, which require multiple rounds of language interaction and cover a range of tasks in open-ended dialogue and text games.",
    "keywords": [
      "benchmarks",
      "LLMs",
      "RL"
    ],
    "venue": "ICLR",
    "year": 2025,
    "pdf_url": "https://openreview.net/pdf?id=EdKSI2ijUY",
    "forum_url": "https://openreview.net/forum?id=EdKSI2ijUY",
    "reviews": [
      {
        "rating": "3",
        "confidence": "4",
        "summary": "The authors introduce a novel benchmark called LMRL-Gym to evaluate multi-turn RL capabilities through 8 tasks. The tasks include 3 Interactive Dialogue Tasks (ex. persuading a user to buy a car) and 5 RL Capability tasks (ex. navigating a maze). The paper evaluates a series of online and offline methods across these tasks. On many of the RL tasks, Implicit Language Q-Learning (ILQL) performed best including 99.9 on one of the maze tasks. However, on the Interactive Dialogue tasks, simpler methods such as Monte Carlo Returns achieved a higher score than ILQL. This suggests that perhaps these TD-learning approaches may to scale poorly to more complex textual tasks. While the GPT-4 few-shot baseline performed well on Interactive Dialogue Tasks, it struggled with game tasks like Chess or Endgames. PPO had strong performance on some tasks, but showed training instabilities. Interestingly, different RL methods did well on different tasks, leaving open potential for further research to optimise for both linguistically and strategically complex tasks. The majority of experiments were conducted on GPT-2 variants for benchmark accessibility to researchers will small compute budgets. When generating synthetic data for the dialogue tasks, the authors used GPT-3.5 and validated the naturalness of data with human evaluation. This work overall contributes a benchmark and research framework with which to develop better RL algorithms for LLMs.",
        "strengths": "Originality: The paper presents one of the first published benchmarks for evaluating multi-turn RL methods. While it's likely frontier labs have such data internally and chosen not to publish it, this is the first paper I've seen making these types of results and code public.\n\nQuality: The paper uses a GPT-4 few shot baseline which provides a strong comparison against several other implemented baseline methods (PPO, ILQL, MC Returns, etc). The authors do a laudable job of using ablation studies to validate their use of LLM simulators which could be exploitable. In general, the authors tend to substantiate their claims thoroughly and explain potential weaknesses transparently. \n\nClarity: The writing is clear and straight forward with illustrative figures and an extensive appendix.\n\nSignificance: This benchmark and task-set addresses a current gap in publicly available benchmarks for multi-turn RL. This could be useful towards benchmarking novel RL methods and informing future research directions to optimise for both textual and strategic/planning performance. However, there is also a risk of this work being used to fine-tune more agentic, persuasive and thus potentially dangerous systems.",
        "weaknesses": "1. Scaling of Results \nThis one might be hard to fix without having computational budget: however one weakness of the paper is that the majority of the experiments are conducted on GPT-2 variants, leaving it unclear how these results may scale to larger models. For instance, it would be quite interesting to see whether the same findings regarding offline and online method differences in textual and strategic task performance remain when considering multimodal models or larger models with longer context windows. \n\n2. Failure Analysis\nIt would be interesting to see a few more examples (qualitative would be fine) of some of the observed failure modes, and some further analysis on where and why specific methods fail. The current results regarding online and offline are quite interesting and it'd be helpful for future work to understand more what might be causing this.\n\n3. Capabilities Coverage of Tasks\nThe current tasks don't require very complex reasoning or long-term memory. It's unclear whether the benchmark may become saturated by larger models who already are often used multi-turn. It could be interesting to look into whether language is increasing the performance relative to exclusively symbolic approaches. \n\n4. Evaluation Methods\nWhile it is said that human evaluators looked into the naturalness of the text, there is limited discussion of how consistent the simulated content would be with natural text. It's unclear how much variance there was across runs and different hyperparameters.\n\nThe paper is already quite extensive and the authors do acknowledge some of these limitations."
      },
      {
        "rating": "6",
        "confidence": "3",
        "summary": "The authors propose the LMRL-Gym benchmark, a collection of tasks and an open-source framework inspired by the lack of standardized multi-turn language-based tasks to evaluate reinforcement learning algorithms on. The benchmark consists of two types of tasks: three \"interactive dialogue\" tasks involving dialogue partners simulated by finetuned language models that stress information seeking behavior and persuasion and five \"RL capability\" tasks that are intended to test general RL challenges such as credit assignment and trajectory stitching. Each task provides offline data by suboptimal policies to perform offline RL with as well simulators to conduct online RL on. The authors benchmark various behavior cloning, offline RL and online RL algorithms on all proposed tasks.",
        "strengths": "1) The paper does address an important gap in the current literature. As the authors state, most work applying reinforcement learning on language models centers on single turn interactions while work on multi-turn interactions often requires humans in the loop, which is expensive, slows down iteration and is challenging to replicate. The proposed collection of tasks, while synthetic and inspired by already existing scenarios, can therefore act as a useful test bed for reinforcement learning algorithms for multi-turn language-based tasks.\n2) I also appreciate the inclusion of offline data from sub-optimal policies, allowing for the development of both offline and online RL algorithms.",
        "weaknesses": "1) My main concern, and my reason for giving a 2 on soundness, is whether the human evaluation on Appendix A is sufficient to show the correctness of the LLM simulator for the interactive dialogue tasks. There is no provided definition of \"naturalness\" and also no examples of the instructions given to the annotators. As a result, it is unclear whether the annotators were focused, for instance, on fluency or whether the simulator was accurate.\n\nIt would help, for instance, to conduct a separate experiment on the self-consistency of the LLM oracle. For the information seeking tasks, for example, this can involve taking a random sample of conversations and checking, either via human annotation or by prompting an LLM, if the oracle's answers to questions are consistent with the object they have in mind. \n\n2) My second concern is the choice of tasks for the RL capability component of the benchmark. Barring the Text-Nav and to a lesser extent Wordle settings, the tasks are regular reinforcement learning tasks that are presented in natural language but do not really test language understanding or use. While I recognize that these are intended to be unit-tests for various RL capabilities in language models, I do not have good intuition on how well algorithm success on these would generalize to multi-turn dialogue or tool use."
      },
      {
        "rating": "3",
        "confidence": "4",
        "summary": "1. The paper introduces the LMRL-Gym benchmark for evaluating multi-turn Reinforcement Learning (RL) for Large Language Models (LLMs).\n2. The benchmark consists of 3 Interactive Dialogue tasks and 5 RL Capability tests which require multiple rounds of language interaction.\n3. A research toolkit for practitioners has been provided to get started with multi-turn RL for LLMs with offline value-based and online policy-based RL methods.",
        "strengths": "A benchmark LMRL-Gym highlighting the importance of multi-turn RL for LLMs has been proposed in the paper. Evaluating multi-turn RL is important for LLMs, and offers future introspection whether RL can generalize for LLMs.\n\nA research toolkit has been proposed for multi-turn RL for LLMs with offline value-based and online policy-based RL. This can be useful to practitioners in the field as an engineering guide.",
        "weaknesses": "Lines numbers have been abbreviated as L# in the points below e.g. L100 means Line 100. Observations have been given quoting paper lines. Some observations are general where no line numbers have been quoted.\n\n1. L074-L075 Multi-turn reinforcement learning (RL) (Sutton&Barto,2018) in principle offers a path to enable LLMs to do just that.\n\nObservation: Sutton & Barto can be cited for general reinforcement learning algorithms and not for Multi-turn reinforcement learning algorithms specifically.\nThere are other papers which define multi-turn reinforcement learning which have not been cited like \"Multi-turn Reinforcement Learning from Preference Human Feedback\" https://arxiv.org/abs/2405.14655\n\n2. L086 – L089 While some works have sought to apply RL for multi-turn tasks (Singh et al.,1999;Li et al.,2016; Shah et al.,2016;Kwan et al.,2022), particularly for goal-directed dialogue (Lewis et al.,2017; Verma et al.,2022), there has been comparatively little research on improving the underlying RL algorithms and very little head-to-head comparison on same sets of tasks.\n\nObservation: What does ‘comparatively little research’ and ‘very little head-to-head comparison’ refer to? It should be mentioned why the comparisons in existing multi-turn tasks is not enough\n\n3. Observation: What contribution and value addition does the present work make? It seems that already published papers cover the paper's goals.\n\n4. L100 – L103: In this paper, we use an LLM to simulate a conversation partner in dialogue tasks. While the behaviour of the LLM may deviate from human behavior, we verify in a human study in Appendix A that our LLM simulators produce natural text reflecting human norms of conversation.\n\nObservation: The human study with 40 participants and 18 natural text examples does not statistically justify that the simulation results reflect human norms of conversation. What is the basis of the simulation results reflecting human norms of conversation on a very small sample size of participants and likewise very small number of examples?  \n\n5. L105 – …. to test RL algorithms with datasets that are sufficiently difficult and complex to gauge how effective ….\n\nObservation: How do you define datasets that are sufficiently difficult and complex to gauge? Is there any metric or any qualitative decision making? The phrasing \"sufficiently difficult and complex\" needs to be justified\n\n6. L117 - L118: This framework includes implementations of PPO (Schulman et al.,2017), ILQL(Snell et al.,2022a), and several baseline methods, ….\n\nObservation: What other baseline methods? It should be mentioned in the appendix at least\n\n7. L129 – L130: Some works have proposed text games for evaluating language-based agents and interactive dialogue.\n\nObservation: If other research papers have already proposed text games for evaluating language-based agents and interactive dialogue, please justify why this paper using RL algorithms for such tasks is a novel or a major contribution. Is there any engineering benefit? Please share that as other papers have covered this direction of research.\n\n8.. L205 – L206: We have provided example trials for each task are shown in Figure 4, and a concise summary of the data set and task statistics in Table 1.\n\nObservation: Please correct Grammatical errors like \"are shown\" should be \"as shown\". Please note that clicking Figure 4 leads to Figure 1. The source tex file needs to be corrected. Also please mention that Figure 4 is in Appendix B.\n\n10. L321-L322: We have selected these algorithms have they are currently the state-of-the-art methods RL methods for LLMs\n\nObservation: Please revise the sentence construction. The paper needs edits and revisions before publication. \n\n11. L441-L442: Our objective is enable the iteration and development of more effective methods for language based, multi-turn interaction tasks.\n\nObservation: Correction of the phrase ‘is enable’ to ‘is to enable’ should be done"
      },
      {
        "rating": "5",
        "confidence": "4",
        "summary": "The paper highlights that current LLMs are trained to imitate golden responses rather than genuinely learning to reason and solve single-turn tasks. Additionally, there is a lack of benchmarking for multi-turn RL tasks, along with the absence of established evaluation protocols, which can be costly. To address this, the authors synthesize a benchmark that leverages the imitation capabilities of language models in conjunction with simulators, such as chess engines. They propose the LMRL-GYM benchmark, which comprises three interactive dialogue tasks and five RL capability tests, benchmarking existing RL methods, including offline methods like ILQL and online methods like PPO, among others.",
        "strengths": "The paper raises a significant question regarding the benchmarking of different RL algorithms in multi-turn scenarios and introduces the LMRL-GYM benchmark, which consists of several tasks designed for evaluation. It assesses a diverse range of RL algorithms while also providing a comprehensive evaluation framework.",
        "weaknesses": "1. The real-world tasks included in the benchmark are not sufficiently representative, as they only incorporate three tasks that focus on abilities such as persuasion and information gathering.\n2. The dataset construction appears somewhat unconvincing. For the interactive dialogue tasks, authors initially use two GPT-3.5 models to generate the dataset and then train two FLAN-T5-XL models to imitate the guesser and oracle roles. Since these are relatively small models, the resulting dialogues may lack diversity and representativeness. The reliability of the benchmarking results for various RL algorithms raises concerns. While the authors conducted a user study to assess the naturalness of the synthesized datasets, I remain skeptical about the benchmark's overall naturalness.\n3. The RL ability benchmark, which consists of five tasks, has a limited action space, deviating from real-world scenarios that utilize RL with much larger action spaces, such as step-wise scoring for tasks like math or code generation.\n4. The experiments are conducted with small models; is the benchmark applicable to larger models? Since small models can achieve nearly 100 rewards on some tasks (as shown in Table 2), this may impact the significance of the benchmark.\n5. In Table 2, the performance of GPT-4 prompting is significantly worse than that of the RL algorithms on the RL capability tasks, despite GPT-4 also being trained using RL methods. Can you comment on this?\n6. The right side of Table 1 extends beyond the page margin, and some tables in the appendix exhibit the same issue."
      }
    ],
    "rating_avg": 4.25,
    "confidence_avg": 3.75,
    "decision": "Reject",
    "meta_review": "This paper presents a new benchmark to evaluate LLM agents in a dialogue setting. An agent interacts with an LLM (a proxy for a human) to engage in a dialogue to solve an RL task. \n\nStrengths:\nThis is an important and interesting task, and one that is surprisingly overlooked in LLM benchmarks. The more common tasks is for the LLM to generate a single response and get reward for it, or to take symbolic actions in multi-turn setting. However, reviewers raised several concerns regarding the benchmark:\n\nWeakness:\n1. Tasks are somewhat simplistic; not all are natural dialogue tasks. This was noted by the reviewer j29V and 9eFK. I personally found car dealer as an example of a good task and it would have been great to have more real-world tasks like it (e.g., hotel recommendation, flight booking).\n\n2. Evaluations are restricted to GPT2 models. I understand that only a few labs can train GPT-4 or even 70B models, but GPT-2 is at this point quite outdated. Even a 2B or 3B model would have been nice.\n\nOverall, I like this direction but I think this needs more work. At a minimum, either more real-world tasks or experiments with bigger models would be needed. Alternatively, authors can focus more on the human evaluation of LLM agents. For now, I am recommending a weak reject, but I wouldn't mind if the paper was accepted.",
    "author_remarks": "",
    "decision_comment": ""
  },
  {
    "id": "XLMAMmowdY",
    "title": "ToolGen: Unified Tool Retrieval and Calling via Generation",
    "authors": [
      "Renxi Wang",
      "Xudong Han",
      "Lei Ji",
      "Shu Wang",
      "Timothy Baldwin",
      "Haonan Li"
    ],
    "abstract": "As large language models (LLMs) advance, their inability to autonomously execute tasks by directly interacting with external tools remains a critical limitation. Traditional methods rely on inputting tool descriptions as context, which is constrained by context length and requires separate, often inefficient, retrieval mechanisms. We introduce ToolGen, a paradigm shift that integrates tool knowledge directly into the LLM’s parameters by representing each tool as a unique token. This enables the LLM to generate tool calls and arguments as part of its next token prediction capabilities, seamlessly blending tool invocation with language generation.  Our framework allows the LLM to access and utilize a vast amount of tools with no additional retrieval step, significantly enhancing both performance and scalability. Experimental results with over 47,000 tools show that ToolGen not only achieves superior results in both tool retrieval and autonomous task completion but also sets the stage for a new era of AI agents that can adapt to tools across diverse domains.  By fundamentally transforming tool retrieval into a generative process, ToolGen paves the way for more versatile, efficient, and autonomous AI systems. ToolGen enables end-to-end tool learning and opens opportunities for integration with other advanced techniques such as chain-of-thought and reinforcement learning, thereby expanding the practical capabilities of LLMs",
    "keywords": [
      "Agent",
      "Tool Learning",
      "Virtual Token"
    ],
    "venue": "ICLR",
    "year": 2025,
    "pdf_url": "https://openreview.net/pdf?id=XLMAMmowdY",
    "forum_url": "https://openreview.net/forum?id=XLMAMmowdY",
    "reviews": [
      {
        "rating": "5",
        "confidence": "5",
        "summary": "This paper proposes ToolGen, a finetuned LLMs that can use various tools during the conversations with the users. ToolGen incorporates new 47K tokens for tools into the Llama-3-8B. Through the tool virtualization, tool memorization, retrieval training, and end-to-end agent tuning, ToolGen correctly select the right tools in the context on  the ToolBench evaluation, achieving better performance than retrieval and end-to-end baselines.",
        "strengths": "- [S1] ToolGen outperform or achieves competitive performance among retrieval and end-to-end baselines on ToolBench.\n- [S2] ToolGen can natively invoke 47K tools following the context.",
        "weaknesses": "- [W1] The technical novelty is limited. Using special tokens for tools and incorporating them into the original vocabularies are widely-known approach (e.g. Toolformer: https://arxiv.org/abs/2302.04761, ToolkenGPT: https://arxiv.org/abs/2305.11554). The contribution of this paper is scaling this up to 47K tools, but it's very straight forward and I'm not confident if the ICLR community would be interested in it.\n- [W2] Releted to [W1], the results of ToolLlama-3 in Section 5 is unclear to me. Why ToolLlama-3 is not as good as ToolGen, even using the same data and models? Could you clarify the difference between two?\n- [W3] How about retrieving tools by LLMs itself (without retriever)? For instance, if we use the LLM with millions of extremely long context (such as Gemini), we may not need to rely on neural retrievers. It would be interesting to include long-contect LLMs as a baseline.\n- [W4] It would be important to compare other capability of LLMs before/after tool token incorporation. Current draft seems to lack the analysis after combining 47K tokens to LLMs.\n- [W5] In Figure1, I didn't understand the distinction between ToolGen's Retrieval Task and Agent Task. Both have the input \"I want some popular video games.\" How are they differentiated?"
      },
      {
        "rating": "5",
        "confidence": "3",
        "summary": "The paper introduces ToolGen, a novel framework that aims to enhance the interaction between large language models (LLMs) and external tools. ToolGen shifts away from traditional tool retrieval methods and instead integrates tool knowledge directly into the LLM's parameters. This is achieved by representing each tool as a unique token, allowing the LLM to generate tool calls and arguments seamlessly as part of its text generation process.",
        "strengths": "1. ToolGen elegantly combines tool retrieval and execution into a single generative process, eliminating the need for separate retrieval mechanisms. This streamlines tool interaction and enhances efficiency, particularly as the number of tools increases.\n2. The use of constrained beam search during inference effectively restricts the output to valid tool tokens, significantly reducing the generation of nonexistent tools, a common issue in LLM-based agents.\n3. ToolGen demonstrates its capacity to effectively handle a large repository of over 47,000 real-world tools, highlighting its scalability compared to existing methods that struggle with vast tool sets.\n4. The authors spend good amount of effort comparing different indexing method, and the result is clear.",
        "weaknesses": "1. The advantage of ToolGen which combines tool retrieval and execution into a single generative process introduces limitation together with its efficiency. Since the tools are integrated into the system as tokens, the extension of new tools become inefficient. For every new tool/API, new token need to be added and the documentation finetuned into the model. Also, consider the case that when the tool/APIs get updated, the maintenance of all the tool/APIs, making sure they are up to date is a quite challenging task. On the contact, with a retriever would make adding and maintaining tool/APIs very easy."
      },
      {
        "rating": "5",
        "confidence": "3",
        "summary": "The paper introduces ToolGen, a novel framework designed to address the limitations of LLMs in interacting with an extensive array of external tools. This framework shifts existing paradigms by embedding knowledge about various tools directly into the LLM’s vocabulary, using unique tokens to represent each tool. This allows the model to generate tool calls and arguments as part of the language generation process, eliminating the need for separate tool retrieval systems and seamlessly integrating tool usage within LLM capabilities. ToolGen incorporates a three-stage training process to enable the LLM to learn how to use tokenized tools.\n\nThe main contribution of this paper is introducing the ToolGen framework including training and inferencing, and proving that ToolGen have comparable result with current tool retrieval systems.",
        "strengths": "**Originality:**\nThe paper introduces a novel approach to tool retrieval by representing each tool as a unique virtual token directly integrated into the LLM’s vocabulary. This method eliminates the need for auxiliary retrievers, making the retrieval process more seamless and efficient. The concept of transforming tool retrieval into a generative task is novel and presents a possible solution to the scalability challenges faced by some existing methods.\n\n**Quality:**\nThe authors have conducted a comprehensive set of experiments to validate their claims, showing thoroughness in their evaluation. These experiments include various comparisons and detailed ablation studies to assess the impact of different components of their approach. The robustness of their methodology enhances the credibility of their results and conclusions.\n\n**Clarity:**\nThe paper is well-structured and written in a clear and concise manner. It systematically outlines the problem, the proposed solution, and the experimental validations. Each section transitions smoothly into the next, making it easy for the reader to follow the logic and understand the contributions of the work.\n\n**Significance:**\nThe research addresses a critical issue in the field of LLM agents: managing and retrieving tools from a large set of tools efficiently. Given the increasing complexity and number of tools available, the proposed method provides a solution. This work has implications for the development of more autonomous and efficient AI systems, potentially benefiting some applications where tool interaction is essential.",
        "weaknesses": "**Substantive Assessment of Weaknesses:**\n\n**Cost and Efficiency Claims:**\nThe key claim of \"significantly less cost and higher efficiency\" does not hold up under scrutiny. The authors have not substantively demonstrated that their framework is less costly or more efficient than existing methodologies. The ToolGen framework necessitates a three-stage training process, which does not inherently suggest reduced costs. Furthermore, the paper lack data or experiments to substantiate the claim regarding efficiency improvements over other approaches.\n\n**Role of the Memorization Stage:**\nIn Section 4.4, the table shows that the memorization stage plays a relatively minor role in the three-stage training process. However, the authors assert that this stage is beneficial for generalization, with further discussion supposedly found in Appendix F. There is, however, no such discussion present in Appendix F. I would recommend authors to do more experiments to validate the significance of the memorization stage and its impact on generalization.\n\n**Hallucination Comparison:**\nSection 5.4 contains statements that do not fully make sense. The claim that ToolGen experiences no hallucination is primarily due to the use of a constrained decoding strategy. Theoretically, it is impossible to encounter hallucination, as defined by the authors, under this constraint. This does not constitute a fair comparison with other frameworks. The authors should either provide results without this constraint and compare them or demonstrate why other frameworks are unable to implement a similar strategy.\n\n**Performance Benchmarking:**\nToolGen is not currently the best-performing framework. Several baselines in the paper outperform ToolGen in various categories, as shown in Table 1 and Table 4. Notably, even the proposed but ultimately unused semantic tokenization approach outperforms the authors' current method, as shown in Table 2. This discrepancy confuses me."
      },
      {
        "rating": "8",
        "confidence": "4",
        "summary": "This paper proposes ToolGen, a generative tool/function calling framework. The concrete methods are: (1) virtualizing tools by virtual tokens; (2) memorizing tools with training data of (tool docs, tool virtual tokens); (3) learning tool retrieval with training data of (user queries, tool virtual tokens); (4) and finally, finetuning tool agent with tool calling trajectories. Experimental results with over 47,000 tools show that ToolGen not only achieves superior results in both tool retrieval and autonomous task completion but also sets the stage for a new era of AI agents that can adapt to tools across diverse domains.",
        "strengths": "Overall, I like this paper very much.  \n\n1. ToolGen is now paradigm for fundamentally transforming tool retrieval into a generative process, which is a very important topic for function calling or LLM-based agents.  \n2. The methods are sound and resonable; the paper presentation is clear.  \n3. The experimental results show that the methods are effective compared with several strong baselines.",
        "weaknesses": "1. Traditional retrieval and generation methods for function calling can handle dynamic tools. If the tool set is changing, could ToolGen be used (without retraining)?  \n\n2. A few reltated works are not mentioned or compared. For example, TPTU and TPTU-V2 [1,2,3,] used demo retriever and fintuner besides the tool retrieval, which may be more powerful than the traditional retrieval and generation methods. They can be a strong baseline for comparision.  \n\n3. It seems that ToolGen uses a more complex process (i.e., (1) virtualizing tools by virtual tokens; (2) memorizing tools with training data of (tool docs, tool virtual tokens); (3) learning tool retrieval with training data of (user queries, tool virtual tokens); (4) and finally, finetuning tool agent with tool calling trajectories) to prepare for tool calling. Therefore, the suprior of ToolGen may come from more training of LLMs? Could the authors give more explination on this?\n\n\n[1] TPTU: Task Planning and Tool Usage of Large Language Model-based AI Agents. FMDM Workshop at NeurIPS 2023.   \n[2] TPTU-v2: Boosting Task Planning and Tool Usage of Large Language Model-based Agents in Real-world Systems. LLMAgents Workshop at ICLR 2024.  \n[3] TPTU-v2: Boosting Task Planning and Tool Usage of Large Language Model-based Agents in Real-world Industry Systems. EMNLP 2024 Industry Track."
      }
    ],
    "rating_avg": 5.75,
    "confidence_avg": 3.75,
    "decision": "Accept (Poster)",
    "meta_review": "The paper introduces ToolGen, a novel framework that integrates tool knowledge directly into the parameters of a Large Language Model (LLM) by representing each tool as a unique token.  This allows the LLM to generate tool calls and arguments seamlessly, eliminating the need for separate tool retrieval systems.  ToolGen is trained in three stages: tool memorization, retrieval training, and end-to-end agent tuning.  The authors claim this framework enhances the interaction between LLMs and external tools, particularly with large tool sets.    \n\nStrengths: The paper proposes a novel approach to tool retrieval and execution by representing tools as virtual tokens, streamlining the process.  The use of constrained beam search effectively reduces the generation of nonexistent tools.  The authors demonstrate the scalability of ToolGen by incorporating over 47,000 real-world tools, and how it can more easily deal with context length limitations and tool hallucinations.\n\nWeaknesses: (1) Dealing with new tools at test-time or major updates in tool APIs would necessitate retraining, which has been added as a discussion in appendix.  (2) Degradation in general instruction following performance of LLMs when fine-tuning heavily on tool use trace, which would be critical for practical deployment. (3) Post-hoc tool use is common for deployment due to latency introduced by tool calls during generation, which might need to carefully handled with ToolGen.\n\nReasons for Acceptance/Rejection: The paper present a novel perspective on tool use -- generative tool calling - which can tap into the generation abilities of LLMs. Moreover, the authors have addressed the reviewers' concerns by providing additional explanations and committing to further experiments. The revised version of the paper, incorporating the planned improvements, is expected to be a valuable contribution to ICLR.\n\nMinor suggestion: Work in similar spirit to ToolGen has been going on in generative verifiers / reward models (GenRM, Cloud) which would be worth discussing.",
    "author_remarks": "",
    "decision_comment": ""
  },
  {
    "id": "wLR9d5ZFpY",
    "title": "No Training Data, No Cry: Model Editing  without Training Data or Fine-tuning",
    "authors": [
      "Dhruva Kashyap",
      "Tanay Narshana",
      "Chaitanya Murti",
      "Chiranjib Bhattacharyya"
    ],
    "abstract": "Model Editing(ME)--such as classwise unlearning and structured pruning--is a nascent field that deals with identifying editable components that, when modified, significantly change the model's behaviour, typically requiring fine-tuning to regain performance.\nThe challenge of model editing increases when dealing with multi-branch networks(e.g. ResNets) in the data-free regime, where the training data and the loss function are not available.\nIdentifying editable components is more difficult in multi-branch networks due to the coupling of individual components across layers through skip connections. \nThis paper addresses these issues through the following contributions.\nFirst, we hypothesize that in a well-trained model, there exists a small set of channels, which we call HiFi channels, whose input contributions strongly correlate with the output feature map of that layer.\nFinding such subsets can be naturally posed as an expected reconstruction error problem. To solve this, we provide an efficient heuristic called RowSum.\nSecond, to understand how to regain accuracy after editing, we prove, for the first time, an upper bound on the loss function post-editing in terms of the change in the stored BatchNorm(BN) statistics.  With this result, we derive BNFix, a simple algorithm to restore accuracy by updating the BN statistics using distributional access to the data distribution.\nWith these insights, we propose retraining free algorithms for structured pruning and classwise unlearning, CoBRA-P and CoBRA-U, that identify HiFi components and retains(structured pruning) or discards(classwise unlearning) them. CoBRA-P achieves at least 50% larger reduction in FLOPS and at least 10% larger reduction in parameters for similar drop in accuracy in the training free regime. In the training regime, for ImageNet, it achieves 60% larger parameter reduction. CoBRA-U achieves, on average, a 94% reduction in forget-class accuracy with a minimal drop in remaining class accuracy.",
    "keywords": [
      "pruning",
      "model editing",
      "classwise unlearning"
    ],
    "venue": "ICLR",
    "year": 2025,
    "pdf_url": "https://openreview.net/pdf?id=wLR9d5ZFpY",
    "forum_url": "https://openreview.net/forum?id=wLR9d5ZFpY",
    "reviews": [
      {
        "rating": "3",
        "confidence": "3",
        "summary": "This paper addresses the problem of model editing (specifically, structured pruning and class unlearning) for deep neural networks when training data is not inaccessible. The authors propose the concept of \"HiFi components\", which are identified as a small subset of channels in each layer being responsible for the model's output. Detecting \"HiFi components\" could be solved by measuring the reconstruction error of these channels. However, due to the unavailable training data, the authors propose a heuristic \"RowSum\" to identify the similarity between distributions of input contribution and output feature map in a layer. Then HiFi components are the components having a high correlation(/similarity) between input channel contributions and the output feature map. To restore the model's accuracy after editing, the authors derive an algorithm called \"BNFix\" to update BN's statistics using only distributional access to the data distribution. Two algorithms COBRA-P and COBRA-U are proposed to find whether retaining or discarding HiFi components in pruning and unlearning, respectively. Empirical evaluations on CIFAR-10/100 and ImageNet datasets show the effectiveness of their approach in maintaining competitive accuracy.",
        "strengths": "1. The paper tackles the problem of model editing without accessible training data for the circumstances of structure pruning and class unlearning. \n\n2. Identifying the HiFi component with the proposed correlation measure is interesting to me.",
        "weaknesses": "1. While the concept of HiFi components is interesting, the technical novelty of the RowSum heuristic and BNFix algorithm appears limited. There are many papers proposing to update BN's parameters, a similar strategy to the one in this paper. \n\n2. The theoretical analysis focuses on providing upper bounds on the loss function, however, K is the largest eigenvalue of the hessian, which might not be tight enough as a guarantee. \n\n3. The overall writing and organization of the paper could be improved significantly. The presentation of the main framework and the transition between different concepts in sections should be intuitive."
      },
      {
        "rating": "3",
        "confidence": "4",
        "summary": "This paper mainly focuses on the model editing task, emphasizing the setting without training data or loss functions.\nTo detour access to the data or loss functions, the authors investigate the 'distributional' behavior of network layer outputs, which is not a 'sample-wise' behavior. Based on the finding that a very limited number of components of networks contribute to the learned outputs (called **HiFi** components), the authors have proposed to freeze the HiFi components and adjust the batch normalization to compensate for the changes in the distributional behavior. To verify their approaches, they have provided two types of tasks, i.e., pruning and unlearning.",
        "strengths": "**Strength 1:** The main strength of this paper is that the authors' viewpoint to scrutinize the distributional behavior of networks rather than the sample-wise network sensitivity can be a key strategy to control or edit the learned models.\n- The strategy seems to be widely applied to various long-aged problems across multiple related societies, e.g., continual learning, explainability, and pruning or unlearning, which are tested in this paper.",
        "weaknesses": "**Weakness 1:** Limited understanding of how the learned knowledge relates to the distributional behaviors of models\n- The main weakness of this paper is the limited understanding of how keeping the HiFi part results in keeping the knowledge of learned models. Otherwise, how tuning the HiFi part results in forgetting the specific learned knowledge.\n- At the conceptual level of understanding, it is quite convincing that the components showing similar distributional behaviors with the layer outputs are probably the crucial parts of the knowledge. However, it is not guaranteed theoretically. \n\n**Weakness 2:** Insufficient quality of presentation and writing\n- I strongly believe this venue requires the highest presentation and writing quality. However, the submitted version contains too many grammar errors, unpolished sentences, and low-clarity visualizations, as follows:\n- At line 47: a missing full name of 'CNN'\n- At many parts: add a whitespace between text and '('\n- At many parts: for citations, the form is inconsistent, e.g., at line 166, \"behavior (Jia...; Shah et al., (2024)).\" is correct.\n- At line 178: missing comma after i.e.\n- At line 185: missing whitespace before \"While\"\n- Figure 2: The size is too small to recognize the plots, formulations, and texts.\n- Equation 3: it is better to keep the length within the text width of the page.\n- At line 269: keep the name \"HiFi\"\n- At line 328: It seems \"Assumption 5\" means A1 and A2 at the right upper part. The labeling of assumptions is not matched.\n- At line 469: missing punctuation after \"Training Details\"\n- At line 529: \"loss\" rather than \"Loss\"\n- Figure 5 (in Appendix): The size is too small to recognize the contents.\n- I strongly feel that the level of presentations and writing is not reaching the level of this venue.\n\n**Weakness 3:** Limited comparison with other related works\n- Although the authors have provided the 'Related Work' part in the Appendix, it seems insufficient to provide deep insights into this work beyond others.\n- For instance, beyond the technically similar model editing methods, in-depth analysis of the prior works investigating the importance of weights or sensitivity measures of weights should be considered. I think that HiFi is another viewpoint to measure the importance of weights so that it has the potential to show further impact on continual learning (also without data of the past tasks) and explainability."
      },
      {
        "rating": "6",
        "confidence": "3",
        "summary": "This paper deals with the finetuning-free model editing of ResNet models without accessing the original training data. The authors hypothesize that High Fidelity (HiFi) components of the model take charge of overall performance retainment and propose determining the pruning parts from a model based on the reconstruction score. The authors further provide a novel theoretical analysis of the batch normalization statistic to characterize the model performance after editing. Evaluation was performed over model pruning and class-level unlearning tasks.",
        "strengths": "* This paper provide a novel theoretical analysis on batch normalization statistics to discuss post-edited model performance",
        "weaknesses": "* **Limited applicability of the proposed method**\n  * Although ResNet models are still popular in some cases, given that Vision Transformer (ViT) or other transformer-based models are dominant in many applications, the aim of this study limits its impact compared to previous work on model editing [1].\n  * Could the insights provided in this work have some implications for the transformer-style models?\n* **Limited validation scope**\n  * Although this paper provides some theoretical insights, the empirical validation is too weak in terms of \n the number of baseline methods, datasets, and experimental settings.\n  * Could more baseline methods for the unlearning task be considered? Either data-free [2] or not [3].\n  * Could more datasets be considered here for the unlearning task?\n* **Insufficient empirical advantage**\n  * The authors claim that the proposed method achieves a good trade-off between accuracy and efficiency. However, the proposed method actually could not achieve good accuracy compared to baseline methods, and the benefits of enhanced efficiency are also not so strong on both pruning and unlearning tasks.\n* **Reliance on external data (through distributional access)**\n  * Although the proposed method does not use an explicit training dataset on which the mode is trained, it still requires some samples from a similar distribution. This weakens the practical usefulness of the proposed method compared with truly data-free methods such as task arithmetic-based unlearning [2]\n  * Could the authors provide an ablation study for the size of the external dataset used for proposals?\n* **Bad presentation quality**\n  * In the introduction and experiment section, the author does not insert space between paragraphs, which makes the reading hard.\n  * The quality of the figure and table is so bad in terms of font size and resolution.\n  * There is incorrect labeling of assumption 5 in line 328\n  * Notations are complex beyond need and somewhat unclear. One example is lines 177-178.\n\n\n\n> Reference\n1. Decomposing and Editing Predictions by Modeling Model Computation, Shah et al. 2024\n2. Editing Models with Task Arithmetic, Ilharco et al. 2024\n3. Decoupling the Class Label and the Target Concept in Machine Unlearning, Zhu et al. 2024"
      }
    ],
    "rating_avg": 4.0,
    "confidence_avg": 3.3333333333333335,
    "decision": "Reject",
    "meta_review": "This paper tackles the challenge of model editing, specifically structured pruning and class unlearning, for deep neural networks when the training data is inaccessible and the loss function is unknown. The authors introduce the concept of \"HiFi components,\" a small subset of channels within each layer identified as being crucial to the model's output. Their approach involves freezing the HiFi components and adjusting batch normalization to compensate for changes in distributional behavior. To validate their method, the authors present two use cases: pruning and unlearning.\n\nThe paper's strengths lie in the novel setup and the introduction of HiFi components, which offer an intriguing perspective. However, the work has notable weaknesses, including limited empirical validation. Specifically, (1) the effectiveness of the learned importance weights compared to prior methods is not sufficiently demonstrated or interpreted, and (2) the proposed method's performance is not adequately benchmarked against baselines in contemporary Transformer-based architectures.\n\nGiven these limitations, I recommend rejecting this submission.",
    "author_remarks": "",
    "decision_comment": ""
  },
  {
    "id": "J5s6EG6ual",
    "title": "Investigating Self-Attention: Its Impact on Sample Efficiency in Deep Reinforcement Learning",
    "authors": [
      "JIANXIAO SUN",
      "Dorvin Ong",
      "Bu-Sung Lee"
    ],
    "abstract": "Improving the sample efficiency of deep reinforcement learning (DRL) agents has been an ongoing challenge in research and real-world applications. Self-attention, a mechanism originally popularized in natural language processing, has shown great potential in enhancing sample efficiency when integrated with traditional DRL algorithms. However, the impact of self-attention mechanisms on the sample efficiency of DRL models has not been fully studied. In this paper, we ponder the fundamental operation of the self-attention mechanism in visual-based DRL settings and systematically investigate how different types of scaled dot-product attention affect the sample efficiency of the DRL algorithms. We design and evaluate the performance of our self-attention DRL models in the Arcade Learning Environment. Our results suggest that each self-attention module design has a distinct impact on the sample complexity of the DRL agent. To understand the influence of self-attention modules on the learning process, we conduct an interpretability study focusing on state representation and exploration. From our initial findings, the interplay between feature extraction, action selection, and reward collection is influenced subtly by the inductive biases of the proposed self-attention modules. This work contributes to the ongoing efforts to optimize DRL architectures, offering insights into the mechanisms that can enhance their performance in data-scarce scenarios.",
    "keywords": [
      "self-attention",
      "sample efficiency",
      "reinforcement learning"
    ],
    "venue": "ICLR",
    "year": 2025,
    "pdf_url": "https://openreview.net/pdf?id=J5s6EG6ual",
    "forum_url": "https://openreview.net/forum?id=J5s6EG6ual",
    "reviews": [
      {
        "rating": "1",
        "confidence": "5",
        "summary": "This paper claims to investigate the sample efficiency of self-attention mechanisms in image-based reinforcement learning. The paper mentions that they compare different types of scaled dot-product attention. However, the paper suffers from multiple major flaws including the model architecture as well as the choice of the self-attention operations used for experiments.",
        "strengths": "- The paper attempts to analyze different types of self-attention layers. The motivation is good.",
        "weaknesses": "- The paper uses a self-attention layer within a couple of CNN layers as their model architecture. This is a very shallow unusual architecture for any visual representation learning. In Transformers, it is a very common practice to have a series of MHSA layers and MLP layers interleaved. At least use ViT? The current architecture used for the investigation is extremely limited and no concrete conclusions can be made using them.\n\n- The paper mentions that they investigate different self-attention. However, the selection of the attention mechanism to compare seems highly arbitrary. The operations selected in this paper include Spatial-wise-Attention, Channel-wise-Row(/Column)-Attention, and so on, but I have not seen any major state-of-the-art models using these arbitrary attention mechanisms in its architectures. Are these being used in any of today’s large vision-language models? What’s the point of comparing something that’s not being picked up by anyone? It would have been much more meaningful to compare different types of Transformer components that’s actually being used in practice, such as linear attention mechanisms like Performer and sequential models like Mamba2, which are much more of interest to the general audience.\n\n- The observations from the experiments seem inconclusive. It is very difficult to conclude from these limited experiments which do not show any major trend."
      },
      {
        "rating": "3",
        "confidence": "4",
        "summary": "This work investigates the performance differences on ALE games with different self-attention operations for visual reinforcement learning. The self-attention operations include (1) direct self-attention on the feature map, (2) self-attention on the height dimension, (3) self-attention on the width dimension, and (4) the sum of (2) and (3). The conclusion is that different attention operations have different impacts on different games, which is brought about by different game mechanics.",
        "strengths": "1. This paper investigates an interesting topic after Manchin et al., examining whether different attention operations can impact visual DRL learning differently.\n\n2. This paper evaluates 56 games within the ALE benchmark, ensuring the broad applicability of the results, and uses stratified bootstrap confidence intervals for reliable assessment. Compared with Manchin et al., the experiment uses 56 games and 5 seeds, which enhances the experimental results.\n\n3. The paper designs and contrasts four types of self-attention modules (SWA, CWRA, CWCA, CWRCA), revealing how each module’s inductive biases affect learning efficiency in specific environments.\n\n4. The paper is brief and straightforward.",
        "weaknesses": "1.  After reading the entire paper, I still struggle to understand the connection between the terms “sample efficiency” and “attention operation” in this paper. To my understanding, the attention operation only makes differences in network structures. It makes sense that different network structures bring different learning performance. However, “sample efficiency” relates to choosing different transition pairs from the replay buffers or the experience batches. Could you explain more about this part?\n\n2.  The related work section should contain more references. Three papers are not enough; you should investigate and survey more.\n\n3. The types of self-attention are far more varied than different channel operation sequences. More investigations are required if the author aims to make significant and fundamental contributions to the ongoing efforts to optimize DRL architecture.\n\n4. This paper's insights are poorly developed, lack theoretical analysis, and rely merely on limited observations. It fails to provide adequate insights for the community. E.g., “Different attention operations have different impacts on different games” cannot guide the community. Conclusions like “height dimension self-attention provides more performance improvement on vertically moving games” would be more beneficial.\n\n[1] Mott, Alexander, et al. \"Towards interpretable reinforcement learning using attention augmented agents.\" In *Advances in Neural Information Processing Systems*, 2019."
      },
      {
        "rating": "5",
        "confidence": "4",
        "summary": "This paper investigates the impact of self-attention when improving the sample efficiency in DRL. Specifically, the investigation focuses on how different types of scaled dot-product attention affect the performance in ALE. The methods are categorized by over which channels the dot product is applied, including SWA, CWRA, CWCA and CWRCA. In particular, the author discovered the effect of inductive biases of the self-attention modules, such as attending to objects movement horizontally or vertically can be rewarded in different game environments. The author conclude that self-attention modules have different effect to the interplay between the inductive bias and the game mechanics.",
        "strengths": "1. The topic is quite interesting, as it connects NLP and DRL, and self-attention has also attracted lots of attention in developing more advanced RL algorithms nowadays.\n\n2. The setup of experiments is quite thorough and well-thought, especially with the evaluation metrics and state presentations.\n\n3. The results are quite interesting and give us new perspective about the importance of self-attention. Meanwhile, I found te explanations of those results satisfactory.",
        "weaknesses": "1. The author did not give information about the choices of hyper-parameters or any ablation study regarding the network structure. In the experiment section, only the experimental setup and the evaluation methodology are discussed. This can be a problem.\n\n2. Following point 1, what kinds of steups for self-attention modules have you tested? Have you tried to vary the number of self-attention layers and the heads? I think it is crucial to study all different aspects of MHSA as well. This is because MHSA is more applicable in NLP and Vision Transformers than simplex self-attention operations."
      }
    ],
    "rating_avg": 3.0,
    "confidence_avg": 4.333333333333333,
    "decision": "N/A",
    "meta_review": "",
    "author_remarks": "",
    "decision_comment": ""
  },
  {
    "id": "GamwMdPj0y",
    "title": "C-Adam: Confidence-Based Optimization for Online Learning",
    "authors": [
      "Shaowen Wang",
      "ANAN LIU",
      "Jian Xiao",
      "Huan Liu",
      "Yuekui Yang",
      "Cong Xu",
      "Qianqian Pu",
      "Suncong Zheng",
      "Wei Zhang",
      "Jian Li"
    ],
    "abstract": "Modern recommendation systems frequently employ online learning to dynamically update their models with freshly collected data. The most commonly used optimizer for updating neural networks in these contexts is the Adam optimizer, which integrates momentum ($m_t$) and adaptive learning rate ($v_t$). However, the volatile nature of online learning data, characterized by its frequent distribution shifts and presence of noises, poses significant challenges to Adam's standard optimization process: (1) Adam may use outdated momentum and the average of squared gradients, resulting in slower adaptation to distribution changes, and (2) Adam's performance is adversely affected by data noise. To mitigate these issues, we introduce CAdam, a confidence-based optimization strategy that assesses the consistence between the momentum and the gradient for each parameter dimension before deciding on updates. If momentum and gradient are in sync, CAdam proceeds with parameter updates according to Adam's original formulation; if not, it temporarily withholds updates and monitors potential shifts in data distribution in subsequent iterations. This method allows CAdam to distinguish between the true distributional shifts and mere noise, and adapt more quickly to new data distributions. Our experiments with both synthetic and real-world datasets demonstrate that CAdam surpasses other well-known optimizers, including the original Adam, in efficiency and noise robustness. Furthermore, in large-scale A/B testing within a live recommendation system, CAdam significantly enhances model performance compared to Adam, leading to substantial increases in the system's gross merchandise volume (GMV).",
    "keywords": [
      "Optimization Algorithm",
      "Online Learning",
      "Recommendation Systems"
    ],
    "venue": "ICLR",
    "year": 2025,
    "pdf_url": "https://openreview.net/pdf?id=GamwMdPj0y",
    "forum_url": "https://openreview.net/forum?id=GamwMdPj0y",
    "reviews": [
      {
        "rating": "3",
        "confidence": "4",
        "summary": "This paper proposes a simple heuristic modification of Adam to enhance its ability to handle distribution shifts and sample noise. The modification is skipping the update of Adam if the inner product of the momentum and the gradient is negative. The performance of the algorithm is theoretically analyzed based on (Reddi et al 2018). Experiments demonstrate better performance compared to Adam and other baselines.",
        "strengths": "The writing of the paper is clear, but besides that, to be very honest, I don't think any aspect of this paper is strong by the iclr standard.",
        "weaknesses": "This paper is in my opinion another quite straightforward hack on Adam. Since Adam was proposed ten years ago there have been so many hacks on it, but it's hard to say how much they really moved the field forward. I can see at least two issues behind this, which this paper also suffers from. \n\n- As Adam itself is heuristic, it is natural for someone to come up with many heuristic modifications based on intuitions. But do these intuitions actually reflect what's going on in the deep learning practice? No one really knows, which makes the foundation of these works quite shaky. \n- It's also not hard in general to cook up some settings where the proposed hacks can help, but do they *always* help? Answering this requires very comprehensive testing which the hacking papers typically lack. \n\nAn acceptable paper of this type needs to stand out in at least one of the two dimensions. \n\nRegarding this particular paper, I would say the proposed hack is not surprising given the intuition the authors stated (\"it's bad to have momentum and gradient pointing to different directions\"), but I'm not convinced of this intuition, especially due to the stochastic nonconvex nature of deep learning optimization. The experiment settings are somewhat artificial, and the actual performance gain in the experiments is marginal. I'm also not convinced that the theoretical analysis adds sufficient value to the paper, as it doesn't show how the proposed hack *improves* Adam, let alone the known limitations of (Reddi et al 2018) itself which the paper builds on. \n\nI'm not completely denying the value of this paper, as some readers may still find it useful for their applications. But for a \"competitive\" conference like iclr the paper is quite far from enough."
      },
      {
        "rating": "5",
        "confidence": "2",
        "summary": "The authors of this paper propose a simple heuristic modification to the Adam algorithm to improve its performance when there is a shifting data distribution or noisy data — two common challenges in online learning for ad models/recommendation systems. The proposed algorithm, CAdam, checks if each coordinate of the gradient and the exponential moving average over the gradient share the same sign, and if not, stops updating the parameters until they align again. They also present a regret bound, seemingly closely following previous work on Adam. The authors evaluate CAdam on synthetic and real world data, including a live recommendation system, comparing against other common optimizers.",
        "strengths": "The core strength of the paper is the simplicity of the proposed modification to Adam, making it easy to deploy and reason about. Moreover, the problem of online learning under data distribution shifts and noisy data is a common problem in many real-world applications. If this simple modification can significantly improve performance under these conditions this would likely be of interest for the community.\n\nThe evaluation with A/B testing in a live recommendation system is also a promising way of demonstrating the practical benefit of the method, even if these results are not reproducible.",
        "weaknesses": "I’m leaning towards recommending rejecting the paper in its current form because of concerns about the experiments and the presentation.\n\nMy main concerns and questions regarding the experiments are:\n1. I assume that in Table 1 you only show results for a single seed? Since the difference between the proposed methods and the baselines are very small, it seems crucial to make sure that the difference is not just due to random variation. I suggest running the experiment for multiple (e.g. 5) random seeds and also adding standard errors to the table. Also, when two numbers are exactly equal, you seem to only print the one corresponding to your methods in bold (e.g., WideDeep column, AMSGrad and CAdam). How do you decide what to print in bold?\n2. Similarly, it would be good to show runs with multiple random seeds for the CNN image classification experiment (Figure 3 + 4).\n3. Regarding the real world recommendation system results, I find it a bit hard to put them into perspective. While the scale of the experiment is impressive, it is hard to evaluate how significant the performance gains are. Is there a way to put them into context, e.g. by comparing the gains to other previous interventions? In any case, at least the gains seem to be consistent.\n\nMy main concern regarding the presentation is that despite the apparent simplicity of the algorithmic modification, its description is surprisingly unclear: in Algorithm 1, all quantities seem to be vectors, so the modification in line 14 implies that a dot product between $g_t$ and $\\hat{m}_t$ is computed and, if it is smaller or equal to zero, $\\hat{m}_t$ is set to the zero vector. However, the verbal description is talking about pausing the update for a single _parameter_. Also, equation (6) in appendix A is clearly stating that the comparison is applied coordinate-wise, effectively checking whether the sign of each coordinate of $g_t$ and $\\hat{m}_t$  is the same. Could you please clarify this and make the description consistent throughout the paper?\n\nIf I can be convinced that CAdam is indeed a very simple way to improve performance in online learning tasks such as CTR prediction and recommendation systems and the presentation is improved, I’m happy to increase my score.\n\n**Minor comments**\n\n- The figures could be improved by increasing the font size and avoiding covering the letters with plot lines.\n- You could consider condensing the paper a bit more, avoiding repetitive content, and removing sentences with little information."
      },
      {
        "rating": "6",
        "confidence": "3",
        "summary": "This paper introduces Confidence Adaptive Moment Estimation (CAdam). It is a variant of the frequently used Adam optimizer, in which the model parameter update of a given weight is only applied if the current gradient g has the same sign as its exponential moving average m. If this is not the case, only the exponential moving averages m and v are updated. The purpose of this change is to improve the results in online learning if distribution changes occur and/or noisy samples are present. The method is evaluated in various scenarios.",
        "strengths": "- The idea of the CAdam optimizer is simple but clever. It is easy to integrate also in many other optimizers. Hence, the proposed change can be important in the end for a broad community.\n- The paper is well written and structured. The experiments are well chosen to underline the advantages of the proposed method.",
        "weaknesses": "Major:\n- Is the analysis of each experiment based on a single optimization trajectory (especially those in Sections 4.1 and 4.2)? For a reliable and convincing benchmark, multiple optimization trajectories should be started from different random initializations of the model parameters. Maybe I overread this aspect. However, then this should be highlighted more. You can also employ standard deviations of the trajectories to proof that CAdam is really consistently better than Adam.\n- The differences in Table 1 between CAdam and Adam are really minor. For WideDeep, the results are even equal for the given rounded numbers. But still, the CAdam results are highlighted as best and they are promoted to be consistently better. I think you are overselling CAdam here and should adjust the interpretation of your results. (CAdam still shows better performance for noisy online learning tasks, which is an important contribution by itself.)\n\nFigure 3:\n- It is difficult to see the difference between Adam and CAdam. However, there is not much insight if the accuracy is below ~50%. Maybe one could just zoom in the region between 50 and 100%. In addition, there is much white space in the three plots on the right which can be reduced.\n\nFigure 4:\n- See comment on figure 3. Try to highlight the differences of the graphs by zooming in.\n\nText:\n- The references to Figure 3 and 4 are incorrect.\n\nTypos:\n- page 4: \"optimumm\"\n- page 7: \"corrosbonding\""
      },
      {
        "rating": "3",
        "confidence": "4",
        "summary": "This paper proposes a variant of popular optimizer Adam, which cancels a specific batch updating by comparing the sign of $m_{t}$ with the sign of $g_{t}$, seeing line-14 of algorithm 1.\nThis method is intuitive and assumes that the $g_{t}$ is affected by noisy data and should be eliminated if the sign of $g_{t}$ differs from the sign of $m_{t}$.\nRegarding the evaluation, this work conducted three types of small-scope optimization tasks, an image classification task with VGG&CIFAR10 under customized distribution shift and label noise, advertisement tasks with Criteo-x4-001 dataset under different various models and optimizers, and a real-world recommendation system task.",
        "strengths": "(1) Regarding Algorithm 1, momentum term $m_{t}$ is considered a more trustworthy signal than stochastic gradient $g_{t}$ under the distribution shifts or noisy data, which makes sense to me. Then, the alignment between those two signals potentially helps identify between the clear data samples and noisy data samples.",
        "weaknesses": "$\\textbf{Weakness in method motivation}$\n\n(1) The method is intuitive and not supported by theoretical results or experiments that verify the intuition. For instance, given a new random batch $x_{i\\in B}$ and the corresponding ground truth label of clear data points and noisy data points, can you explicitly show that clear data points have the same sign with $m_{t}$ while noisy data points have a different sign with $m_{t}$.\n\n(2) Given algorithm 1 and considering line-5 and line-14, intuitively, the $m_{t}$, i.e., the cumulative behaviors, is considered as trustworthy and is utilized to filter out untrustworthy $g_{t}$ according to the sign of the two values, which make sense somehow. \n\nHowever, $g_{t}$ is sampled from a small batch of data and contains noise naturally. Can you provide more insights into how line-14 of algorithm 1 is related to the natural noise of stochastic gradient?\n\n\n$\\textbf{Weakness in technical contributions}$\n\n(1) This work assumes $g_{t} = \\nabla f_{t}(\\theta_{t-1})$ in the Notations in Section 3. Thus, this work assumes that it is a deterministic optimization problem. Along with the convex assumption, the theoretical result built upon those strong assumptions, i.e., Theorem 1, is less useful to reflect the practical performance of the proposed method.\n\n\n(2) The problem is not well defined. This work mentioned the proposed method has the potential to handle distribution shifts and noise, however, what are the mathematical definitions of the distribution shifts you mentioned? And can you characterize it more formally and connect it with real-world situations? “rotating the data distribution” is confusing. \n\nTo evaluate the robustness of optimizers to noise, well-accepted datasets such as CIFAR-10-C and CIFAR-100-C may be a better choice instead of rotating the images.\n\n\n$\\textbf{Weakness in evaluation}$\n\n(1) As mentioned, the customized “distribution shifts and noise” cannot support the performance improvement of the proposed method.\n\n(2) the small scope of the experiment cannot support the performance improvement of the proposed method. Specifically, most tasks do not apply diverse settings, such as VGG network on the CIFAR-10 for image classification, Criteo-x4-001 dataset for advertisement tasks.\n\n(3) The experiment settings are not well presented. Please refer to the Questions."
      }
    ],
    "rating_avg": 4.25,
    "confidence_avg": 3.25,
    "decision": "N/A",
    "meta_review": "",
    "author_remarks": "",
    "decision_comment": ""
  },
  {
    "id": "kn3GT7LbxT",
    "title": "Value Residual Learning For Alleviating  Attention Concentration In Transformers",
    "authors": [
      "Zhanchao Zhou",
      "Tianyi Wu",
      "Zhiyun Jiang",
      "Zhenzhong Lan"
    ],
    "abstract": "Transformers can capture long-range dependencies using self-attention, allowing tokens to attend to all others directly. However, stacking multiple attention layers leads to attention concentration. One natural way to address this issue is to use cross-layer attention, allowing information from earlier layers to be directly accessible to later layers. However, this approach is computationally expensive. To address this problem, we propose Transformer with residual value (ResFormer) which approximates cross-layer attention through adding a residual connection from the values of the the first layer to all subsequent layers. Based on this method, one variant is the Transformer with single layer value (SVFormer), where all layers share the same value embedding from first layer, reducing the $KV$ cache by nearly 50\\%.  Comprehensive empirical evidence demonstrates that ResFormer mitigates attention concentration problem in deeper layers and enhances representation across most layers, outperforming the vanilla Transformer, DenseFormer, and NeuTRENO in training error as well as downstream tasks. SVFormer trains significantly faster than the vanilla Transformer and performs better than other methods like GQA and CLA, with performance influenced by sequence length and cumulative learning rate.",
    "keywords": [
      "Transformer",
      "Self-Attention",
      "Cross-Layer Attention",
      "Residual Learning",
      "Language model",
      "KV cache"
    ],
    "venue": "ICLR",
    "year": 2025,
    "pdf_url": "https://openreview.net/pdf?id=kn3GT7LbxT",
    "forum_url": "https://openreview.net/forum?id=kn3GT7LbxT",
    "reviews": [
      {
        "rating": "5",
        "confidence": "4",
        "summary": "Paper proposes SVFormer, a way to reduce the size of the KV cache in Transformers by almost 50%. The authors propose sharing the values from the first self-attention layer across all layers. They find that this outperforms other approaches that reduce the KV cache size and perform extensive ablations to find when SVFormer works.",
        "strengths": "- Paper is straightforward and easy to read. \n- It's interesting that values from the first layer can be used throughout the network for a small loss penalty. \n- Authors thoroughly discusses prior work and explains the contributions of this work. \n- Lots of ablations and experiments.",
        "weaknesses": "- The paper leaves out many important details. See the \"Questions\" section for specifics.\n- Results are not well organized, and appear to have contradictory findings. Fig. 13 (c) in particular shows that SVFormer only outperforms a vanilla transformer when they have 2M parameters, which is very small.  At 82M parameters, SVFormer already is worse than the baseline. Fig. 13 (d), 14, and 15 also indicate that SVFormer hurts loss. However, Fig. 6 shows that SVFormer does better at larger scales\n- I don't like the practice of subtracting the transformer performance and showing the difference. It potentially (a) hides bad baseline performance, and (b) potentially hides the fact that the difference between methods is tiny compared to the overall training loss curve."
      },
      {
        "rating": "3",
        "confidence": "2",
        "summary": "This manuscript presents a novel framework for approximating cross-layer attention. Within this framework, the authors introduce ResFormer as a practical implementation, demonstrating its effectiveness in mitigating attention concentration challenges. In addition, they propose SVFormer within the same framework, which further enhances efficiency by reducing the memory requirements for KV caching, thus lowering overall computational costs.",
        "strengths": "The manuscript proposes a framework for reducing the computational cost of cross-layer attention, offering a unified approach that integrates and extends existing methods, including NeuTRENO and DenseFormer.",
        "weaknesses": "1. The paper lacks discussion of prior work on the attention concentration problem and the connection to the over-smoothing issue addressed by NeuTRENO is unclear. A more detailed review of relevant literature would enhance clarity and better contextualize the impact of this work.\n2. Using training loss as a criterion for comparing model performance is unconvincing (e.g. in Section 4.2, 4.3, 4.6), as it may not accurately reflect generalization. A more reliable evaluation metric, such as accuracy or perplexity on a separate validation set, would provide a clearer assessment of the model's effectiveness.\n3. Minor comments:\n- The term “gold attention matrix” in Section 4.3 should be clearly defined for better understanding.\n- Right margin violated at line 659.\n- Some references list only the first author; please ensure consistency in citation formatting."
      },
      {
        "rating": "3",
        "confidence": "3",
        "summary": "This paper studies the problem of attention concentration in Transformers and proposes solutions that try to approximate cross-layer attention by incorporating the \"value\" from first layer into subsequent layers. There are two solutions: ResFormer that uses residual mapping and SVFormer that uses the same V across all layers. Experiments show that the proposed solutions perform better than baselines on language modeling tasks.",
        "strengths": "- The paper introduces a relatively new and important problem that affects existing Transformer architecture. This is useful towards understanding the dynamics and behavior of Transformers.\n- The proposed solutions only require small changes to existing Transformer architecture. They can be immediately useful for many existing Transformer-based models.\n- The paper provides a good analysis and ablation study on ResFormer and SVFormer that demonstrate their benefits over existing Transformer. Particularly, ResFormer is shown to be achieving higher token importance entropy (i.e., less attention concentration) than traditional Transformer.",
        "weaknesses": "- The authors claim that cross-layer attention is useful at reducing the effect of attention concentration but it is unclear why this would be the case. This work is built on the premise that ResFormer approximates cross-layer attention and thus it is effective against attention concentration. But we do not really know that cross-layer attention provides such a benefit. The author should perform some analysis and/or small-scale experiment on a baseline that actually uses cross-layer attention to check its behavior against that of ResFormer.\n\n- It is hard to disentangle the effects from: (1) reducing attention concentration; (2) ease of optimization in the proposed solutions. Using V in the form of residual mapping (ResFormer) or layer sharing (SVFormer) should make it easier to optimize network parameters during training. It may be possible that the accuracy improvements are largely attributed to the ease of optimization rather than attention concentration reduction. The authors should explain this.\n\n- It would also be interesting to see how well the proposed methods work for non-language tasks and architectures like ViT (image recognition)."
      },
      {
        "rating": "3",
        "confidence": "4",
        "summary": "This paper presents ResFormer and SVFormer, two Transformer model variants that address challenges with deep Transformers, particularly attention concentration where deeper layers focus too much on fewer tokens. ResFormer incorporates a residual connection from the initial layer's values to subsequent layers, thus approximating cross-layer attention without heavy computational costs. SVFormer simplifies further by sharing the value embedding from the first layer across all layers, reducing memory usage by nearly half and accelerating training.",
        "strengths": "1. The paper offers an interesting twist on standard residual connections by applying them specifically to V instead of the usual hidden state H. This approach targets the common issues of over-smoothing and information loss in deep Transformers.\n\n2. SVFormer aims to make Transformer models more efficient by sharing the same value embeddings across layers, reducing memory and computation needs. This design could help make large models faster and more practical for applications with long sequences.",
        "weaknesses": "1. **Problem Definition and Motivation**: The problem of \"attention concentration\" is not clearly defined or sufficiently justified. It is essential for the authors to establish a precise understanding of this issue and clarify why it is a significant challenge within Transformer architectures. Without a thorough introduction and motivation for addressing \"attention concentration,\" it remains unclear what gap this work aims to fill, and the importance of resolving it is left ambiguous.\n\n2. **Novelty and Theoretical Basis**: The proposed approach largely resembles existing residual connections in Transformers, as seen in architectures like ViT and LLaMA. The primary difference with ResFormer appears to be the application of residuals to the value V alone, rather than to the hidden state H as in traditional models. However, this adjustment lacks theoretical grounding and rigorous analysis, especially with regard to the SVFormer, which further simplifies by removing layer-specific values. This simplification seems ad-hoc and trivial, as no theoretical guarantees or insights are offered to support the effectiveness or necessity of such changes.\n\n3. **Experimental Setup and Comparisons**: The experiments are limited and do not provide a thorough benchmark. Although the models are trained on a LLaMA-like architecture, there is no comparative performance evaluation against other prominent Transformer-based or SSM-based models. Furthermore, there are no tests involving visual downstream tasks, which would have strengthened the claims of improvement in Transformers and provided a more comprehensive evaluation across different modalities, especially for encoder-only tasks.\n\n4. **Evaluation of Attention Mechanisms**: An essential part of evaluating any modification to Transformer architectures is understanding how the attention patterns differ from those in the vanilla Transformer. Although the paper discusses attention concentration, it does not provide visualizations or statistical analysis of the multi-head attention weights to demonstrate the proposed method's effect on attention distribution. Such an investigation is critical for validating the claims and understanding how the modifications impact attention dynamics."
      }
    ],
    "rating_avg": 3.5,
    "confidence_avg": 3.25,
    "decision": "Reject",
    "meta_review": "All reviewers converged on rejecting the paper post rebuttal. The AC checks all the materials, and while appreciating the additional efforts including results and analyses and making major modifications to the draft, the AC resonates with the reviewer consensus that the paper currently has issues to address and would benefit from another cycle.",
    "author_remarks": "",
    "decision_comment": ""
  },
  {
    "id": "CCUrU4A92S",
    "title": "Re-examining learning linear functions in context",
    "authors": [
      "Omar NAIM",
      "Guilhem Fouilhé",
      "Nicholas Asher"
    ],
    "abstract": "In context learning (ICL) is an attractive method of solving a wide range of problems.  Inspired by Garg et al., we look closely at ICL in a variety of train and test settings for several transformer models of different sizes trained from scratch.  Our study complements prior work by pointing out several systematic failures of these  models to generalize to data not in the training distribution, thereby showing some limitations of ICL. We find that models adopt a strategy for this task that is very different from standard solutions.",
    "keywords": [
      "In context learning",
      "GPT",
      "limitations"
    ],
    "venue": "ICLR",
    "year": 2025,
    "pdf_url": "https://openreview.net/pdf?id=CCUrU4A92S",
    "forum_url": "https://openreview.net/forum?id=CCUrU4A92S",
    "reviews": [
      {
        "rating": "5",
        "confidence": "4",
        "summary": "This paper studies experimentally the setting of in-context learning linear regression . The authors reproduce the experiments of Garg et al and at inference time test the models with 1) different distributions for the input/weight vectors 2) larger values for the input/weight vectors.\nBased on the observations of these results the authors argue that these models do not learn some type of algorithm.",
        "strengths": "Understanding what these models learn even in the setting of linear regression can significantly enhance our understanding of their capabilities limitations. Indeed it has been observed that the models do not generalize in out-of-distribution samples and thus it is unclear whether these models learn some type of algorithm.",
        "weaknesses": "1. The provided experimental study does not explain what these models are actually learning. For example it can be the case that the model are learning a tailor-made preconditioned gradient descent type of algorithm, with the preconditioned matrix being optimal for the in-distribution values and sub-optimal for out-of-distribution values.\n2. It cannot be excluded that the current training methods are not optimal, since we know that these models do have the capability of representing these algorithms. \n3. Some of these results have already been observed experimentally for example see [1] (Figures 5,6).  In these experiments consider multi-dimensional linear regression, they keep all expect for one dimension fixed and plot how the function changes when varying one dimension from [-B,B] similar to the authors' experiments for one dimensional linear regression.\n\nIn general the main weakness of this paper is that it does not make a convincing argument towards what these models are actually learning. \n[1]: Giannou, Angeliki, et al. \"How Well Can Transformers Emulate In-context Newton's Method?.\" arXiv preprint arXiv:2403.03183 (2024)."
      },
      {
        "rating": "1",
        "confidence": "4",
        "summary": "The paper investigates Transformer behavior when trained from scratch to perform linear regression. It examines out-of-distribution (OOD) generalization across various settings, such as different ranges and distributions of linear functions.",
        "strengths": "The paper conducts thorough experiments across various scales and settings, providing a comprehensive analysis of Transformer behavior.",
        "weaknesses": "1. The related work could benefit from a more comprehensive review. The paper primarily discusses the works of Garg et al., Akyürek et al., and Von Oswald et al. on regression for in-context learning (ICL), but there are additional relevant studies in this area that are not cited. A more thorough literature review, covering empirical and theoretical works on regression in ICL, would enhance the paper’s context. Checking recent citations in this line of research may help identify key studies to include.\n\n2. The notation in Section 4 could be clarified, as some symbols are difficult to interpret. For example, it’s not immediately clear what $\\sigma$ represents in the context of $f_{i, \\sigma}$. Additional explanations could help improve readability.\n\n3. The organization of the paper could be refined to improve the overall flow. At times, the presentation feels somewhat informal, with experiments presented in sequence without clear connections, motivations, or in-depth analyses. For instance, it would be helpful if the authors could clarify the rationale for studying models of different scales and discuss what insights are gained from these comparisons. Additionally, mixing experiments on different scales and distributions makes it challenging to understand the primary conclusions. This structure could make it clearer to the reader what the authors aim to convey.\n\nIn general, I appreciate that the authors highlight the out-of-distribution (OOD) generalization issue for Transformers trained on linear regression, as initially noted by Garg et al. However, the experimental findings in Section 4 could be more impactful with clearer motivations and discussions. The hypothesis regarding induction heads and their role in OOD performance is somewhat interesting, though it could be strengthened with supporting theoretical insights or experimental validations, such as through mechanical interpolation. Presenting this hypothesis with additional rigor could provide more substantial contributions to the community."
      },
      {
        "rating": "3",
        "confidence": "4",
        "summary": "The study investigates in-context learning (ICL) in transformer models, focusing on their ability to learn and generalize linear functions from contextual prompts. Inspired by previous work, the authors examine various transformer models, including small ones trained from scratch, to explore whether they can learn linear functions and generalize beyond the training distribution.\n\nHowever, there are two main problems in this paper:\n\n### 1. The writing problem: There are many typos, e.g., in ``line 047'', there should be a ''.'' after ''training data''.\n### 2. Novelty: The paper indeed provides robust experiments to show the main point, but it lacks novelty, such as how to improve this problem.",
        "strengths": "The paper has the following strengths:\n\n### 1. Clear Motivation: The paper begins with a well-defined motivation, addressing gaps in the current understanding of in-context learning (ICL) in transformer models, especially for generalization.\n\n### 2. Comprehensive Experiments: The experiments cover various transformer architectures and test them on various distributions.",
        "weaknesses": "The paper has the following weaknesses:\n\n### 1. Clarify Terminology and Notation: The writing is a little poor. For example, in ``line 047'', there should be a ''.'' after ''training data''. Furthermore, the table should be in a more beautiful structure.\n\n### 2. Explanation for the Problem: Although the paper provides various experiments, it should explain the failures of these models to generalize to data not in the training distribution.\n\n### 3. Novelty: The paper provides robust experiments to show the main point but lacks novelty, such as how to improve this problem."
      },
      {
        "rating": "5",
        "confidence": "3",
        "summary": "The paper investigates in-context learning (ICL) across various training and testing scenarios using different sizes of transformer models trained from scratch. Building on previous work, it highlights systematic failures in these models' ability to generalize to data outside the training distribution, revealing some limitations of ICL.",
        "strengths": "1. The paper focuses on an important and challenging problem: understanding the in-context ability of language models.\n2. The writing is clear and easy to understand.\n3. The authors provide code and detailed instructions for reproduction.",
        "weaknesses": "1. The models and empirical studies in the paper differ significantly from current large language models, potentially creating a gap between the claims and reality.\n2. The findings of the paper have been previously proposed in other works.\n3. The paper is missing some key references."
      }
    ],
    "rating_avg": 3.5,
    "confidence_avg": 3.75,
    "decision": "N/A",
    "meta_review": "",
    "author_remarks": "",
    "decision_comment": ""
  },
  {
    "id": "irCuIdCdAl",
    "title": "Improving Transformer Interpretability with Activation Contrast-Based Attribution",
    "authors": [
      "Sungmin Han",
      "Jeonghyun Lee",
      "Sangkyun Lee"
    ],
    "abstract": "Transformers have revolutionized AI research, particularly in natural language processing (NLP). However, understanding the decisions made by transformer-based models remains challenging, which impedes trust and safe deployment in real-world applications. While activation-based attribution methods have proven effective in explaining transformer-based text classification models, our findings suggest that they may suffer from class-irrelevant features within activations, potentially degrading the quality of their interpretations. To address this issue, we introduce Contrast-CAT, a novel activation contrast-based attribution method that improves token-level attribution by filtering out class-irrelevant features from activations. Contrast-CAT enhances interpretability by contrasting the activations of input sequences with reference activations, allowing for the generation of clearer and more faithful attribution maps. Our experiments demonstrate that Contrast-CAT consistently outperforms state-of-the-art methods across various datasets and models, achieving significant gains over the second-best methods with average improvements in AOPC and LOdds by $\\times 1.30$ and $\\times 2.25$, respectively, under the MoRF setting. Contrast-CAT provides a promising step forward in enhancing the interpretability and transparency of transformer-based models.",
    "keywords": [
      "Transformer",
      "Interpretability",
      "XAI",
      "Attention",
      "Contrast-based"
    ],
    "venue": "ICLR",
    "year": 2025,
    "pdf_url": "https://openreview.net/pdf?id=irCuIdCdAl",
    "forum_url": "https://openreview.net/forum?id=irCuIdCdAl",
    "reviews": [
      {
        "rating": "6",
        "confidence": "3",
        "summary": "The authors propose a new method for identifying which tokens are most influential to a model's prediction. This method, which they call Contrast-CAT, focuses on estimating the per-token influence on the correct class. The method works by trying to remove features from model activations which are supposed to be irrelevant to the class of interest. In their experiments, they demonstrate that this method works well from quantitatively and qualitatively.",
        "strengths": "originality: to my knowledge, this is original work.\nquality: \n* across several standard text classification datasets, the method appears to work well. \n* I was also impressed by the highlighted qualitative examples which show intuitively better attributions compared to existing methods.\n* The comparison to existing methods is also quite thorough. Including ablations on using multiple layers and the \"Same\" vs \"Random\" vs \"Contrast\" experiments were also convincing on the effectiveness of using contrastive reference activations.\n* the evaluation methods seem sound and grounded in methods from prior work.\nclarity: the overall flow of the paper is well-laid out. \nsignificance: attributing language model behavior to individual inputs is an important cornerstone in interpretability. By providing a new improved method for this goal, the contribution is significant.",
        "weaknesses": "Improvements to the clarity of the method are important for the reader's understanding. The ease of understanding is currently a bit lacking from my read; I list specifics in the Questions section below. \n\nRegarding significance, the method and experiments are limited to classification problems using models from the BERT family and GPT2. Since currently the focus in LLMs is on autoregressive models this may be of limited use for interpreting more popular and cutting-edge models in generation use cases, e.g. Llama. If feasible, it would be nice to see how effective this method is for larger models like Llama."
      },
      {
        "rating": "5",
        "confidence": "3",
        "summary": "This paper presents Contrast-CAT, a method enhancing Transformer interpretability in NLP tasks. Contrast-CAT introduces an activation contrasting framework that filters out class-irrelevant features by subtracting reference activations from target activations at each Transformer layer, focusing on class-relevant information. This approach yields precise token-level attribution maps, with experiments showing that Contrast-CAT surpasses current methods in attribution quality and interpretability across diverse datasets and models.",
        "strengths": "● The paper is exceptionally clear, with well-organized explanations and effective visual aids that clarify complex methods and results.\n\n● This paper introduces an original approach with activation contrast, effectively filtering out class-irrelevant features and enhancing interpretability in transformer models.",
        "weaknesses": "● The authors conduct experiments primarily on text classification datasets, which are relatively simple and similar in nature. It remains unclear whether this method is effective for more complex tasks, such as MMLU, MATH, or HumanEval. Exploring these could provide a more comprehensive evaluation of the approach.\n\n● The applicability of this method to decoder-based models is not fully addressed. While the experiments focus on encoder-based transformers (e.g., BERT), with limited GPT-2 results included in the appendix, it would be valuable to see a more thorough evaluation on large language models (LLMs) that have become influential in the research community, such as LLaMA, Mistral, and Qwen.\n\n● If this method is extended to LLMs, it would be helpful for the authors to clarify any potential adjustments or considerations required. Additional details on how this approach might be adapted or optimized for LLMs would enhance the paper’s impact and applicability.\n\nIf these issues are addressed, I will consider raising my score."
      },
      {
        "rating": "6",
        "confidence": "3",
        "summary": "This paper introduces an activation-based attribution method, Contrast-CAT, to attribute the important tokens in text classification task. They compare their method Contrast-CAT with attention-based, LRP-based, and activation-based methods on BERT, where Contrast-CAT outperforms all the other methods.\n\nThe writing and organization of the paper is good.  And the proposed experiments can prove that the proposed method Contrast-CAT achieves better accuracy than the previous activation-based attribution method AttCAT.",
        "strengths": "1.\tThe writing and organization of the paper is good. \n2.\tThe proposed method Contrast-CAT achieves better accuracy than the previous activation-based attribution method AttCAT.",
        "weaknesses": "1. My main concern is the speed of this method. The gradient-based methods are slow because they require many backward computations. If the method requires too many computations, it is very hard to be applied in large language models. \n2. This work lacks the comparison with causal-based methods. To identify the important tokens, an easier and faster method is to replace each token with [MASK] and calculate the probability decrease of the predicted token. And more complicated causal-based methods are commonly used in LLMs, such as [1,2].\n\n[1] Locating and Editing Factual Associations in GPT, 2022\n\n[2] Towards Best Practices of Activation Patching in Language Models: Metrics and Methods, 2023"
      },
      {
        "rating": "3",
        "confidence": "4",
        "summary": "This paper proposes a counterfactual explanation method that utilizes the model's activation and reference activation for better token attribution. Specifically, they leverage the conclusion from [1] that the model's prediction confidence for an input token at layer $l$ can be decomposed as the gradient times the subscription of its original activation and a contrastive activation from another token. The author then generalizes this lemma to obtain the attribution for each token by further multiplying the above value with the corresponding attention value. The proposed method achieves promising results in counterfactual explanation, which means it can highlight the most important tokens in a sentence, and removing them will let the model's confidence drop significantly. They use AOPC and LOdds to reflect the ratio of the number of important tokens removed and the confidence difference after removing those tokens, which are common metrics in XAI paper.\n\nRefs:\n\n[1] Sangkyun Lee and Sungmin Han. Libra-cam: An activation-based attribution based on the linear approximation of deep neural nets and threshold calibration. In IJCAI, pp. 3185–3191, 2022",
        "strengths": "- This paper addresses the important problem of explaining how a transformer works by following the line of works in the attribution-based method.\n- The method is tested not only on one transformer model but across a variety of them, including BERTbase, DistilBERT, RoBERTa, and GPT-2, showing its robustness and generalizability across different architectures and datasets. This increases the broader applicability and utility of the approach for a wide range of NLP tasks.",
        "weaknesses": "- The method looks similar to [1] mentioned in the paper with minimal modification. The only thing the author did was multiply the attention value to the conclusion from [1] without a reasonable explanation.\n- AOPC and LOdds results can be affected by many factors, including **(1) how to skip the special tokens like [SEP] and [PAD]** (the author can either not skip any special tokens during the backpropagation but remove them when calculating the normalized attribution scores or skip part of the special tokens during the backpropagation or skip all special tokens during backpropagation can lead to different results) and **(2) how to \"remove\" the important tokens** (replacing the token into [PAD] instead of removing it from the sentence can lead to different results). The author did not clarify these important points in their paper.\n- The author only focuses on the classification tasks, which is not exciting. The author should at least discover more about text generation tasks.\n\nRefs:\n\n[1] Sangkyun Lee and Sungmin Han. Libra-cam: An activation-based attribution based on the linear approximation of deep neural nets and threshold calibration. In IJCAI, pp. 3185–3191, 2022"
      }
    ],
    "rating_avg": 5.0,
    "confidence_avg": 3.25,
    "decision": "Reject",
    "meta_review": "This paper proposes Contrast-CAT, an activation-based attribution method for enhancing the interpretability of Transformer models in NLP tasks, particularly text classification. The method filters out class-irrelevant features by subtracting reference activations from target activations at each Transformer layer. The authors conduct experiments on multiple datasets and models, comparing Contrast-CAT with several existing methods and demonstrating its superiority in attribution quality and interoperability.  However, the concerns of this paper come from several aspects: 1) the authors conduct experiments primarily on text classification datasets, which may limit the understanding of the method's effectiveness for more complex tasks; 2) applicability of the method to decoder-based models is not fully addressed, and it would be valuable to see a more thorough evaluation on large language models like LLaMA, Mistral, and Qwen. 3) the method looks similar to a previous work with minimal modification.  \nAfter comprehensive discussions, many concerns are fixed but the novelty of this paper is still not that clear.  \" The concept of \"class irrelevant feature\" is not the first time proposed in this paper; it cannot be treated as the main contribution. Therefore, the authors' main contribution should be adding attention to previous works. However, the motivation for adding attention is unclear.\"",
    "author_remarks": "",
    "decision_comment": ""
  },
  {
    "id": "5KgKa96PUG",
    "title": "Exploring New Frontiers in Vertical Federated Learning: the Role of Saddle Point Reformulation",
    "authors": [
      "Aleksandr Beznosikov",
      "Georgiy Kormakov",
      "Alexander Grigorievskiy",
      "Mikhail Rudakov",
      "Ruslan Nazykov",
      "Alexander Rogozin",
      "Anton Vakhrushev",
      "Andrey Savchenko",
      "Martin Takáč",
      "Alexander Gasnikov"
    ],
    "abstract": "Distributed learning problems have gained significant popularity due to the increasing need for cluster training and the emergence of novel paradigms like Federated Learning (FL). One variant of FL, called Vertical Federated Learning (VFL), partitions data based on features across devices. The objective is to collectively train a model using the information available on each user's device. This paper focuses on solving the VFL problem using the saddle point reformulation via the classical Lagrangian function. We first demonstrate how this formulation can be solved using deterministic methods. But more importantly, the paper explores various stochastic modifications to adapt to practical scenarios, such as employing compression techniques for efficient information transmission, enabling partial participation for asynchronous communication, and utilizing coordinate selection for faster local computation. We show that the saddle point reformulation plays a key role and opens up possibilities to use mentioned extension that seem to be impossible in the standard minimization formulation. Convergence estimates are provided for each algorithm, demonstrating their effectiveness in addressing the VFL problem. Additionally, alternative reformulations of the VFL problem are investigated, and numerical experiments are conducted to validate the proposed methods' performance and effectiveness.",
    "keywords": [
      "convex optimization",
      "saddle point problem",
      "vertical federated learning"
    ],
    "venue": "ICLR",
    "year": 2025,
    "pdf_url": "https://openreview.net/pdf?id=5KgKa96PUG",
    "forum_url": "https://openreview.net/forum?id=5KgKa96PUG",
    "reviews": [
      {
        "rating": "6",
        "confidence": "2",
        "summary": "The paper proposes a saddle point reformulation of the Vertical Federated Learning (VFL) problem, allowing for more efficient and privacy-preserving optimization compared to traditional minimization methods. The authors introduce a deterministic algorithm with several practical stochastic modifications that improve communication, handle asynchronous participation, and reduce computation costs.",
        "strengths": "1.Reformulating Vertical Federated Learning (VFL) as a saddle point problem is interesting and novel, it can offer an alternative to traditional minimization methods that could address VFL-specific challenges more effectively.\n2.The paper presents comprehensive theoretic results.\n3.The practical modifications for improving communication efficiency, asynchronous participation, and computational costs are well-aligned with real-world VFL challenges.",
        "weaknesses": "1. While the paper introduces several modifications to the basic deterministic algorithm, such as quantization, biased compression, and asynchronous participation, these are presented with high mathematical density and minimal illustrative examples. This makes it challenging for audience like me that are less familiar with saddle point methods and vertical federated learning to fully grasp each modification's practical implications and implementation nuances. I suggest the authors to enhance accessibility by maybe providing more intuitive explanations or visual illustrations (e.g., flow diagrams) of the modified algorithms.\n\n2. The experiments mainly focus on benchmark datasets with linear regression and neural network fine-tuning tasks. The paper would benefit from exploring additional VFL scenarios that could showcase the flexibility of the proposed approach in handling diverse model architectures or real-world vertical partitioning cases. I am uncertain whether the datasets and settings used in the experiments are standard for the VFL field. If they are not, it would be beneficial to include a wider variety of commonly used VFL benchmarks to strengthen the empirical validation."
      },
      {
        "rating": "5",
        "confidence": "3",
        "summary": "This paper studies the vertical federated learning (VFL) problem with the linear model by its convex-concave saddle point reformulation, which separates the data matrix $A$ and the loss function $\\ell$. Based on this reformulation, the authors propose an algorithm EGVFL for VFL based on the celebrated ExtraGradient method for convex-concave saddle point problems. They establish the convergence rate of EGVFL in terms of the duality gap, assuming $\\ell$ and the regularizer $r$ are convex and smooth. The paper also provides convergence guarantees for EGVFL variants with biased and unbiased communication compression, partial participation, and local steps.",
        "strengths": "- The saddle point reformulation seems to be natural and well-motivated. \n- When the model is linear, the authors established extensive convergence theory for the proposed algorithm and its extensions, accommodating key features such as communication compression, partial participation, and local steps. Besides, the convergence rate of EG improves upon GD in terms of $\\lambda_{\\max}(A^\\top A)$.",
        "weaknesses": "- The proposed algorithms only have convergence guarantees for VFL with the linear model and the extension for nonconvex problems remains heuristic. \n- In the experiments, only general-purpose optimizers are compared while existing algorithms specifically designed for VFL (e.g., [1] and its baselines) are completely missing. \n- Figure 1 and Figure 2 only present the relative objective gap w.r.t. the number of iterations. This might be unfair since the per-iteration computational and communication costs of the proposed algorithms and baselines are different. For example, EG requires one extra communication per round than GD, and algorithms based on the saddle point reformulation also need to update auxiliary variables z and y. \n \n\n[1] Xie, Chulin, Pin-Yu Chen, Qinbin Li, Arash Nourian, Ce Zhang, and Bo Li. \"Improving privacy-preserving vertical federated learning by efficient communication with admm.\" In 2024 IEEE Conference on Secure and Trustworthy Machine Learning (SaTML), pp. 443-471. IEEE, 2024."
      },
      {
        "rating": "6",
        "confidence": "3",
        "summary": "This paper proposes a saddle point reformulation for the vertical federated learning (VFL) and provides extragradient-based algorithms to solve the reformulation with the convergence rate $O(1/K)$ on the expected primal-dual gap of the reformulation. The authors also present some extension to non-convex models. The authors conduct numerical experiments in VFL by using linear regression with $l_2$-norm regularizations and using the ResNet18 neural network.",
        "strengths": "The authors start with the basic reformulation in Section 2, and then thoroughly consider several stochastic modifications such as quantization for effective communications, biased compression, partial participation for asynchronous communications and coordinate descent for reducing local computational cost. For each case, a modified algorithm is presented with the complete proof on the convergence rate $O(1/K)$.",
        "weaknesses": "There seems a gap between the considered linear models and non-convex models in the formulation (4) on page 3 and (7) on page 9. See Questions for the details."
      },
      {
        "rating": "3",
        "confidence": "5",
        "summary": "This paper explores new methods for Vertical Federated Learning (VFL) by reformulating the learning process using a saddle point framework instead of the traditional minimization approach. The proposed approach in the deterministic case enables solving VFL problems with enhanced convergence guarantees in terms of the eigenvalue of the data matrix. The authors also propose stochastic algorithms tailored to this reformulation and suggest modifications to address practical challenges such as communication efficiency and computational cost by implementing compression, partial participation, and coordinate selection, respectively. The paper validates the proposed methods through numerical experiments.",
        "strengths": "1. This paper proposes a new minimax framework for the VFL problem. The method has a better complexity constant compared to accelerated gradient descent.\n\n2. The theoretical guarantee in the modification of quantization for the saddle point problem in VFL is novel.",
        "weaknesses": "1. Insufficient Preliminaries:\nThe paper lacks clear explanations of key concepts such as Vertical Federated Learning (VFL) modeling and biased/unbiased compression. It would be easier to understand the paper if a \"Preliminaries\" section defining VFL and compression techniques were added before diving into the technical details.  Especially:\n\n1.1 in Section 3.1, the introduction of compression techniques is missing, and key notations, such as  $b^k$ appear without proper definition. This makes it difficult to understand how Algorithm 2 is formulated. The authors should include a notation table or glossary at the beginning of each major section or explicitly define each new symbol when it is first introduced.\n\n1.2 The reference to noise affecting $Z$ (line 154) is unclear, as the source of the noise and the conditions under which it occurs are not specified. It would improve clarity to explain the origin of the noise and provide an example of when it might arise.\n\n\n1.3 In the experiments section, SSP (line 462) is introduced without any prior definition. Please add explanation to SSP to improve the clarity.\n\n\n2. Disorganized Presentation: The structure in lines 205–217 is difficult to follow as specified as follows:\n\n2.1: it mainly focuses on previous work, but the purpose of mentioning it in this context is unclear. It would be clearer if the authors separated lines 242–245 into two parts: one for discussing the differences and merits compared to each mentioned previous approach, and the other for mathematically stating the relation between equation (5) and \\(gap^*\\).\n\n2.2: there are multiple claims without supporting mathematical proofs. For example, the statement:\n\"Criterion (5) can also be used for unconstrained/unbounded problems. To do this, one can use the trick from (Nesterov, 2007) and introduce bounded sets\" in line 207, and \"one can show that in Theorem 2.2 ... we can use the criterion\" in line 210. It would strengthen the work to provide rigorous proofs for these claims, especially if they support the contribution of this research.\n\n2.3: the explanation in lines 242–245 regarding the convergence criterion using \\(g(x,y) = xy\\) (from lines 205–217) is confusing. Specifically, the claim that \\(gap^*(x,y,z) = 0\\) does not make sense because the example \\(g(x,y) = xy\\) does not contain a third variable \\(z\\).\n\n\n4. Clarity, Missing Verbs and Poor Sentence Structure:\n\n4.1 The use of \"it\" in line 172 is ambiguous, making the meaning unclear. To enhance readability, consider explicitly stating what \"it\" refers to in this context. Replacing vague pronouns with precise references will help avoid confusion.\n\n4.2 In line 227-228, the sentence starting with \"one cannot...\" lacks a verb, which makes it incomplete. This is problematic because this sentence is critical for comparing the new results with prior work.\n\n4.3 in line 520-521, the sentence is incomplete (\"but only...\"), further complicating readability.\n\nI suggest the authors carefully proofread this work again for a better presentation.\n\n5. Inadequate Experiments:\nSince the tasks involve classification problems, I recommend that the experiments report test accuracy to effectively evaluate the proposed method.\n\nOn the other hand, this work proposes a new method for practical scenarios, such as partial attendance and compression. However, the impact of these proposed methods would be more convincing if accompanied by experiments demonstrating their effectiveness compared to previous approaches.\nOn the other hand, I did not find a discussion of related work in Vertical Federated Learning (VFL) that specifically addresses partial attendance and the use of quantization. Including a dedicated related work section summarizing prior research on these topics would provide better context and help position the contributions of this paper."
      }
    ],
    "rating_avg": 5.0,
    "confidence_avg": 3.25,
    "decision": "N/A",
    "meta_review": "",
    "author_remarks": "",
    "decision_comment": ""
  },
  {
    "id": "Rp3DjldbSc",
    "title": "ICConv: A Large-Scale Intent-Oriented and Context-Aware Conversational Search Dataset",
    "authors": [
      "Quan Tu",
      "Jixiang Hong",
      "Xiao Long Wu",
      "Yantao Jia",
      "Zhao Cao",
      "Ji-Rong Wen",
      "Rui Yan"
    ],
    "abstract": "In recent years, search engines have made significant advancements. Yet, traditional ad-hoc search engines often struggle with complex search scenarios (e.g. multi-turn information seeking). This challenge has shifted the focus towards conversational search, an approach enabling search engines to interact directly with users to obtain more precise results. Progress in conversational search has been slow due to a lack of data and difficulties in gathering real-world conversational search data. To address these hurdles, we embarked on a journey to autonomously create a large-scale, high-quality conversational search dataset. Previous efforts to create such datasets often overlooked the multi-intent aspect and contextual information, or resulted in a biased dataset, where all dialogue queries linked to a single positive passage. In our study, we have incorporated multi-intent based on the existing search sessions and converted each keyword-based query into multiple natural language queries based on different latent intents present in the related passage. We then contextualized these natural language queries within the same session and organized them into a conversational search tree. A carefully designed dialogue discriminator was utilized to ensure the consistency and coherence of all generated conversations, assessing their quality and filtering out any substandard ones.\nAfter extensive data cleaning, we are proud to introduce the \\textbf{I}ntent-oriented and \\textbf{C}ontext-aware \\textbf{Conv}ersational search dataset (ICConv), a large-scale synthetic dataset comprising over 100,000 high-quality, information-seeking conversations. Our human annotators have evaluated ICConv based on six dialogue and search related criteria and it has performed admirably. We further explore the statistical characteristics of ICConv and validate the effectiveness of various conversational search methods using it as a standard for comparison.",
    "keywords": [
      "conversaitonal search",
      "multi-intent"
    ],
    "venue": "ICLR",
    "year": 2025,
    "pdf_url": "https://openreview.net/pdf?id=Rp3DjldbSc",
    "forum_url": "https://openreview.net/forum?id=Rp3DjldbSc",
    "reviews": [
      {
        "rating": "5",
        "confidence": "3",
        "summary": "This paper describes ICConv, a new synthetic multi-turn conversational search dataset. The dataset is prepared by selecting a relevant subset of MS MARCO search sessions and expanding the keyword-based searches present in MS MARCO into context-aware natural language questions that could formulate a multi-turn dialogue. The authors provide summary statistics and human validation (on a subset) of the dataset to demonstrate its quality. Further, the authors evaluate search methods which follow different paradigms (ad-hoc, query rewriting-based, and dense conversational) to compare and contrast different methods on the task proposed in ICConv.",
        "strengths": "* The paper is generally well-written and easy to follow. It describes the dataset construction process in significant detail.\n* Given that the conversational/chat-based mechanisms are becoming a more common modality of interaction, the proposed dataset fills an important niche.\n* The dataset is documented extensively through a datasheet provided in the appendix.",
        "weaknesses": "*  Missing rationale for choices made (in terms of models/thresholds chosen) during the dataset preparation phase.\n* Recent baselines and experimental setup details missing from the comparisons provided experimental results section.\n* Inconsistent scaling for human evaluation experiments."
      },
      {
        "rating": "5",
        "confidence": "4",
        "summary": "The work proposes an intent oriented, multi-turn, context-aware conversational search dataset. The method proposed to construct this synthetic dataset is novel considering multi-intent nature and contextual information for formulating natural language queries. The automated data construction approach also develops a dialogue discriminator model to control for dialogue quality and evaluates existing systems",
        "strengths": "1. The authors tackle an important problem of bridging the data scarcity gap in conversational search with multiple intents and contextual awareness.\n\n2. The data construction method is novel and the manual and automated evaluations are comprehensive.\n\n3. The data has utility to the IR and NLP communities with applications being conversational QA, search.",
        "weaknesses": "1. Several choices are not clearly explained or supported. For instance, grouping queries within a session that share at least one common word is not well supported as it could result in false positives and false negatives. For instance, queries like “American president” and “leader of United states” may not be grouped. Additionally queries like “american election” and “american universities” may be grouped which reflect two very different intents resulting in false positives. Additionally it is not clear why ANCE was chosen to select candidate responses for aiding in generating questions and the threshold mechanism is also not clearly specified. It is also clear in cases where there are no responses that meet the threshold are the queries ignored ? If so, how is the completeness of the conversation maintained by the proposed approach ? Additionally, the question generation approach does not explicitly constrain for the metrics measured, such as coherence and completeness of the conversation. For instance, the approach of followup question generation explicitly tries to optimize for completeness. In this approach, an initial query with response could be used to generate a NL query and the response to this question could be leveraged to generate the followup question. As mentioned earlier grouping session queries only based on lexical match with an arbitrary heuristic as done in ICCONV does not guarantee they are related and hence might result in conversational turns in dataset that are bit incoherent. While the example in Appendix is coherent, on closer look at the dataset released, i observed certain inconsistencies where a conversational turn were on unrelated topics. For instance, marco-gen-train-7146805 in the dev set starts with query “What is google classroom?” and the followup queries in turn are “What is facilitated diffusion?” which is a huge drift in topic and intent with no clear connection. Similarly “marco-gen-train-7746920” consists of queries about medications which are in no way related to another and not representative of real-world conversational search interactions which is one of the main motivations of this work.\n\n\n2. Some key details are missing in the work. What dataset was used to train the dialogue discriminator ? What was the retrieval corpus used for the experiments on icconv ? was it the original corpus for MSMARCO ? Or only the positive passages used to generate ICCONV ? I think this is critical to mention this information clearly as the corpus should also reflect real-world scenario of open-domain search with presence of distractors reflecting real-world challenges for retrievers.\n\n\n3. Also some key related works are missing. For instance [1] is a very relevant recent dataset on conversational search with information seeking queries and is critical to compare and distinguish ICConv contributions to this work. Likewise, ConvSDG[2] also is relevant. Also the baseline comparisons are bit outdated and some relevant works especially query reformulation approaches for conversational search such as ConvGQR[3] which is quite recent and ConQRR[4] are relevant to be included for comparison on the curated benchmark for conversational search.\n\n\n\n[1] ProMISe: A Proactive Multi-turn Dialogue Dataset for Information-seeking Intent Resolution Yash Butala, Siddhant Garg, Pratyay Banerjee, Amita Misra\n\n[2] ConvSDG: Session Data Generation for Conversational Search, Fengran et. al\n\n[3] ConvGQR: Generative Query Reformulation for Conversational Search Fengran Mo, Kelong Mao, Yutao Zhu, Yihong Wu, Kaiyu Huang, Jian-Yun Nie\n\n[4] CONQRR: Conversational Query Rewriting for Retrieval with Reinforcement Learning Zeqiu Wu, Yi Luan, Hannah Rashkin, David Reitter, Hannaneh Hajishirzi, Mari Ostendorf, Gaurav Singh Tomar"
      },
      {
        "rating": "3",
        "confidence": "5",
        "summary": "This paper presents ICConv, a large-scale conversational search dataset comprising over 100k conversations generated through an automated pipeline. The dataset construction process consists of 4 key stages: session filtering based on word overlap, question generation that captures diverse user intents, query contextualization, and quality control using a dialogue discriminator. This work is trying to address two critical gaps in existing datasets: accommodating multiple user intents and effectively integrating contextual dependencies across dialogue turns. Authors conduct evaluations including both human assessment and statistical analysis to position ICConv as a robust benchmark for evaluating a range of conversational search methods.",
        "strengths": "1) This paper is constructing an automatic workflow to generate conversational datasets to reduce human efforts while balancing quality.\n2) The size of this dataset is large-scale.\n2) Authors implemented two kinds of mainstream technique for conversational searching evaluation: Query Rewriting and End-to-end. \n3) Authors analyze and propose hypothesis about their experiments to inspire readers to understand difficulties of conversational search.",
        "weaknesses": "The paper addresses an important problem in automatically constructing realistic and complex datasets for conversational search. However, the work would benefit from significant revisions, particularly in clarifying the motivation, improving writing clarity, and ensuring a thorough understanding of experimental design.\n\n## Motivation Deservers more clear and detailed illustrations:\n1) The introduction falls short in clarity, particularly regarding the claim in Lines 38-39 that traditional keyword-based search engines struggle to capture **\"genuine\"** user intents. This claim is not well supported and could be more convincingly illustrated. From a practical standpoint, many users including me successfully find relevant information through keyword-based searches, which suggests keyword searching still occupies a central role in realistic search interactions. A clearer definition and distinction between \"genuine\" and \"non-genuine\" queries, supported by references, would strengthen this argument. Additionally, a figure comparing genuine and non-genuine queries could help clarify this distinction. The authors should also elaborate on why previous single-turn methods and datasets fail to capture these genuine intents, and how a multi-turn conversational search engine could potentially address these limitations. Moreover, the premise that single-turn queries deliver a less than ideal user experience seems weak. If users want to refine their searches, they can rephrase their queries or conduct new searches. Figure 15 also seems more aligned with a dialogue-based QA system, like ChatGPT, rather than a \"realistic\" conversational search engine, which typically ranks results (e.g., Google Search) not a single answer. Therefore, the initial premise should be reconsidered or better justified to avoid overstating the limitations of single-turn search.\n\n2) Several sentences require more precise expressions, making it difficult to follow the motivation. For instance, \"Traditional ad-hoc search techniques and resources may not be suitable for using\" is vague. What is and specifically makes them **unsuitable**? If the term \"complexity\" is key here, it should be explicitly defined (does it refer to longer query history, more heterogeneous contexts, or more flexible query expressions?) Providing more citations and fine-grained explanations would help make the motivation clearer and more compelling.\n\n3) While the paper emphasizes the **\"real-world\"** aspect of the proposed dataset, this concept remains unclear. What specific features make this dataset more \"real-world\" than prior datasets? The authors use terms like \"genuine\" and \"complex\" but without clear definitions or examples. Including concrete examples, illustrations, or comparisons would help define these terms and demonstrate the advantages of this dataset over existing ones.\n\n4) The explanation of \"multi-intent queries\" in Lines 71-73 is difficult to follow. An one-sentence definition would help clarify what is meant by \"multi-intent\" or \"single-intent.\" Does this imply that a single query could have multiple relevant documents or answers? Furthermore, Figure 1 is overly simplistic and lacks sufficient captions to convey the intended message. It’s unclear where \"single-intent\" and \"multi-intent\" distinctions are made in this figure, and the signal of \"NO\" in the first and third queries is confusing. Revising the figure to include more general domain examples would make it more accessible, particularly for readers who may not be familiar with the Shakespearean content used here.\n\n5) The paper references MS MARCO abruptly without providing an introduction or context. A brief introduction of what is MS MARCO, along and why it was chosen as the primary corpus in this paper, would improve clarity for readers unfamiliar with this resource.\n\n6) Others:\n   - In Line 46, why do authors switch to \"interactive\" from \"conversational\"? Do they have the same meanings in this project? According to recent research [1-3], the \"interactive\" mainly refers to the interaction with the environment but for single-turn queries. \n   - In Line 46, what does \"organic manner\" mean?\n\n## No Task Definitions and Preliminaries:\nI suggest adding a specific section on task definitions and preliminaries to improve clarity. Without this, readers may find it challenging to follow the terminology. For example, terms like \"session,\" \"query tree,\" \"conversation tree,\" and \"search tree\" should be clearly introduced. Are these distinct concepts, or do they refer to similar structures? Additionally, it would be helpful to specify how many tree algorithms are implemented and the rationale behind their selection. A section that defines key concepts, such as \"turn,\" \"user query,\" \"session,\" \"tree,\" and \"ground truth answers\", which would provide readers with a solid foundation for understanding the paper.\n\nI also find it challenging to understand the task output and the evaluation methods. The authors should clearly introduce the metrics used to evaluate model performance for this task. Currently, there appears to be an inconsistency: **Figure 15 suggests the task output resembles a QA or dialogue task (with a single natural language sentence as the ground truth answer)**, whereas the results in Table 2 are evaluated using ranking- and recall-based metrics. How are metrics like recall or MRR computed with a natural language sentence as the answer? Did authors implement keyword retrieval from GT NL answers? A detailed description of the task formulation, evaluation metrics, ground truth answers, and evaluation methodology is **essential**.\n\n## Methodology\n1) No Comparison with Related Works: The authors do not provide a statistical comparison between the features of their dataset and those of other conversational search datasets. Such a comparison, highlighting comprehensive features, would help clarify the unique contributions of this dataset. In Lines 175-176, the authors mention that their method is \"novel.\" However, they should explicitly explain how it differs from previous approaches to better illustrate this novelty. For instance, how is this work different from recent research [4], which also trains smaller models to simulate user-engine interactions? The authors should clarify their distinct contributions and novel aspects, especially since [4] appears to employ more rigorous workflows and metrics for quality control.\n\n2) Potential Bias in Filtering: The filtering strategy, which relies on counting overlapping words to construct pairs, may introduce bias. This approach seems insufficiently rigorous; for instance, it might not accurately capture queries with **negation**, such as \"I don’t like lobster\" or \"I need recipes without lobster.\" These queries could still include overlapping words and lead to irrelevant results (e.g., recommendations or posts about \"lobster\"). How do the authors address such cases? Moreover, simple word overlap may not fully capture the nuanced and varied expressions of user queries, especially if the dataset aims to reflect \"real-world\" interactions.\n\n3) In Section 3.4, the negative samples are generated through rule-based methods. However, this approach may be insufficient for capturing the complexities of real-world interactions. Relying on rule-based operations could oversimplify the task, potentially making the training target too easy and leading to models that fail to distinguish between grammatically correct but contextually incoherent conversations. A more detailed explanation of how these rules align with real-world conversational features would strengthen this section.\n\n### Human Evaluation\n\n1) **Unrealistic Number of Turns**: The number of turns in some conversations is very high (e.g., 73 turns), which seems unrealistic, as users are unlikely to maintain this level of engagement in real-world settings. If authors deem that it's realistic, please provide references or reports to prove this.\n\n2) **Biased Benchmark**: Sections 4.3 and 5 suggest that the benchmark, generated entirely through automated methods, may contain inherent biases:\n   - In Figure 6, the majority of questions begin with \"what,\" indicating an uneven distribution of question types.\n   - In Line 326, the authors acknowledge that the method may suffer from limited diversity. However, diversity is quite important for a benchmark or dataset.\n\n3) **Inconsistencies in Human Evaluation Metrics**: \n   - The distinctions between certain evaluation questions are unclear. For instance, Q2 and Q6 appear similar; can the authors clarify the difference between these questions?\n   - Q3 is also ambiguous, as the connection between \"specificity\" and \"diversity\" is not immediately clear.\n   - Additionally, the term \"question\" is used inconsistently. The authors frequently refer to the \"diversity of questions\" and the \"grammatical correctness of questions.\" Are these questions referring to the final turn, the initial turn, or all turns in the conversation? More specific guidelines on how to evaluate each question (Q2, Q3, etc.) and criteria for assigning ratings (1, 2, or 3) would be helpful.\n   - The rating scale in Figure 7 lacks consistency. Some items have four rating levels, while others have three. What is the reason for this variation? Furthermore, the results seem to indicate that overall quality is not particularly high as highlighted in Introduction.\n\n### Questionable Experimental Conclusions\n\n1) **Unclear Definition of \"Manual\" Results**: It is unclear what is meant by \"Manual\" results in Line 375. Further clarification of this term and its relevance would be helpful.\n\n2) **Ambiguous Conclusion on Model Comparison**: In Lines 419-420, the authors conclude that \"encoder-decoder models perform better than decoder-only models.\" However, this statement lacks depth and rigorous analysis. For instance, could this difference be due to variations in model parameter sizes? Llama-3-8B, which is also a decoder-only model, could serve as a comparison point. It would be beneficial for the authors to substantiate this claim by comparing models of similar parameter sizes, such as T5-3B and Llama, to better illustrate the impact of architecture rather than parameter count.\n\n3) **Questionable Conclusions on \"Two-Stage vs. One-Stage\" Approaches**:\n   - **Implementing One-Stage for Long Dialogs**: How do the authors handle the one-stage approach in T5-3B with a token limit of 512 for lengthy dialogs? Given that some dialogs include lengthy history such as 73 turns, token limits may lead to issues with long-context handling. Additional explanation on this implementation would clarify the comparison. It seems authors did some process for it since it may lead to 512 / 73 = 8 tokens for each question and response in the history on average. According to the example shown in Figure 19, it obviously not true.\n   - **Two-Stage Implementation for Query Rewriting**: It is unclear how the two-stage process is implemented for query rewriting. Does this involve recursively rewriting queries or loading and rewriting all queries at once? This detail is crucial for understanding the approach's effectiveness.\n   - **Potential Bias in Results**: In Line 418, the authors observe that T5-QR outperforms other models. Could this exceptional performance be influenced by implementing T5 as the backbone for both data generation for benchmarking? This could introduce a bias in the evaluation. The authors should analyze and provide evidence to show that such bias is not present since this is a significant issue when using model-generated data for benchmarking purposes.\n\nOverall, the authors omit critical implementation details regarding model configurations. They should provide more information, such as methods for handling long-context inputs and specific approaches for query rewriting.\n\n\n\n[1] WebArena: A Realistic Web Environment for Building Autonomous Agents \\\n[2] InterCode: Standardizing and Benchmarking Interactive Coding with Execution Feedback \\\n[3] OSWorld: Benchmarking Multimodal Agents for Open-Ended Tasks in Real Computer Environments \\\n[4] Learning to Simulate Natural Language Feedback for Interactive Semantic Parsing"
      },
      {
        "rating": "5",
        "confidence": "3",
        "summary": "This paper presents a new conversational search dataset which is a synthetic dialogue dataset consisting of ~100000 information-seeking dialogues based on MS MARCO search sessions. It thoroughly describes the data construction method to achieve the ultimate high-quality conversational search dataset using NLP models. A thorough statistical analysis of the dataset is provided and a human evaluation demonstrates the high quality of the new dataset. Previous conversational search models are evaluated on the dataset, followed by a logical analysis of their performance.",
        "strengths": "1. The paper is well-written and easy to follow. \n2. The data construction methodology is valid, which may provide insights into other data collection tasks.\n3. A human evaluation corroborates the quality of the dataset and benchmarks are provided for researchers to advance their research in this area.",
        "weaknesses": "1. The paper's contribution would be more solid if a new conversational search model that outperforms the previous methods on the new dataset was also proposed along with its release.\n2. LLMs have shown remarkable capabilities in text generation. Why are they not used in the data construction process or data evaluation to further enhance the dataset quality?"
      },
      {
        "rating": "3",
        "confidence": "4",
        "summary": "This paper addresses the scenarios requiring multi-turn and context-aware interactions, where the development is hindered by a lack of high-quality, real-world conversational search data. To tackle this, the paper introduces ICConv, a new large-scale dataset specifically designed for conversational search. ICConv is built on MS MARCO search sessions and addresses the multi-intent phenomenon—where a single keyword query can represent multiple underlying intents.",
        "strengths": "The resource has the potential to be impactful since it is designed for multi-turn scenarios, where a common problem is the lack of data.",
        "weaknesses": "My main concern regards the difficult of this dataset when using LLMs. While retrieval is a challenging part, I struggle to understand how this dataset can pose new challenges for the community - questions are from MSMARCO and are potentially easy to answer, even in a multi-turn scenario. The paper would benefit from an end-to-end evaluation where it can be shown that better retrieval and maybe better RAG models are required. Also, findings on question rewriting seems to be in line with a previous work in the field (Question rewriting for open-domain conversational qa: Best practices and limitations) that in depth analyzed the impact of QR. I suggest the authors to strengthen the justification part of this work, carefully describe differences with previous work, and clearly articulate (with experiments) the new challenges that this dataset introduces."
      },
      {
        "rating": "3",
        "confidence": "4",
        "summary": "This paper introduces a conversational search dataset, ICConv and its construction method, highlighting the novel approach of considering multiple intents within a single keyword-based query. The overall methodology to construct the dataset can be divided into 4 stages. 1) Filter MS Marco search sessions with the number of overlapping words. 2) Generate intent-oriented natural language questions by giving a keyword and a retrieved response as a input to fine-tuned T5. 3) Transform each natural language question into contextualized natural language question. 4) Filter out dialogues by evaluating coherence and consistency. In addition, authors analyzed the dataset and provided the results from human evaluations along with the performance of conversational search methods on ICConv.",
        "strengths": "1. **Well-motivated and timely work on conversational search:** it is evident that crawling the users’ log to aggregate conversation sessions to construct a conversational dataset have issues on privacy, thus there is a substantial need to automatically construct the conversation search dataset in large scale. In this sense, authors point out that limitations of prior works and proposed to resolve the problem. \n2. **Supplementary materials:** Authors provided useful supplementary materials to provide examples and the github link to the dataset which helps readers to understand the structure and contents of the dataset.",
        "weaknesses": "1. **Lack of demonstration of details on constructing dataset:** The writing is enough to understand the overall procedure, but the details (either in words or formulas) or justification of the method design is poor. For example, in section 3.1, the complete list of stop words can be included either in the main body or in the appendix. Also in section 3.1, authors claim that having few instances (probably from MS MARCO Conversational Search DEV dataset while it is written as MS MARCO search sessions) after filtering with overlapping keywords implies that users are not used to interacting with conventional search systems. But it is not sure that conventional systems hinder the users’ usage of overlapping keywords in conversational manner, because there is a case that users might have complex information needs that cannot be captured in lexical manner but can be captured with semantic similarities. Furthermore, in section 3.4, the logical flow from training BERT with contrastive loss to finding the optimal path between all possible sessions with filtering out weak coherence is not straightforward and lacks of details. In conclusion, it would be helpful if authors provide the figure of the overall method, the table with comparison to other datasets and articulate texts.\n\n2. **Comparison to prior works with regards to novelty:** Authors point out that ConvTrans neglected that “keyword-based query usually corresponds to multiple natural language queries under different intents”, which is important claim to support the significance of the proposed method. Both ConvTrans and ICConv are generated by extending keywords to NL and CNL questions with T5. While the key novelty of the proposed method is generating multi-intent questions via concatenating responses as inputs (section 3.2.2) and filtering the path (section 3.4), the novelty of the other components is minimal."
      }
    ],
    "rating_avg": 4.0,
    "confidence_avg": 3.8333333333333335,
    "decision": "Reject",
    "meta_review": "- Scientific Claims and Findings:\n    - This paper presents a new synthetic multi-turn conversational search dataset and its construction method. It includes summary statistics, human validation on a subset of the dataset to demonstrate its quality, and an evaluation of various conversational search models on the dataset.\n- Strengths:\n   - The dataset may be valuable to IR and NLP community.\n   - The dataset construction method provides a reliable automated workflow.\n- Weaknesses:\n    - Many important details about dataset construction and evaluation are missing or unclear.\n    - The justification for this work, including comparison to prior works in terms of novelty, and the new challenges introduced by this dataset, is not clearly described.\n- Most Important Reasons for Decision:\n     - Given the identified weaknesses, the work is not yet ready for publication at this conference.",
    "author_remarks": "",
    "decision_comment": ""
  },
  {
    "id": "TySMCLoGVl",
    "title": "Efficiently Scanning and Resampling Spatio-Temporal Tasks with Irregular Observations",
    "authors": [
      "Bryce Ferenczi",
      "Michael Burke",
      "Tom Drummond"
    ],
    "abstract": "Various works have aimed at combining the inference efficiency of recurrent models and training parallelism of MHA for sequence modeling. However, most of these works focus on tasks with fixed-dimension observation spaces, such as individual tokens in language modeling or pixels in image completion. Variably sized, irregular observation spaces are relatively under-represented, yet they occur frequently in multi-agent domains such as autonomous driving and human-robot interaction. To handle an observation space of varying size, we propose a novel algorithm that alternates between cross-attention between a 2D latent state and observation, and a discounted cumulative sum over the sequence dimension to efficiently accumulate historical information. We find this resampling cycle is critical for performance. To evaluate efficient sequence modeling in this domain, we introduce two multi-agent intention tasks: simulated agents chasing bouncing particles and micromanagement analysis in professional StarCraft II games. Our algorithm achieves comparable accuracy with a lower parameter count, faster training and inference compared to existing methods.",
    "keywords": [
      "sequence modeling",
      "efficient training",
      "efficient inference",
      "spatio-temporal",
      "multi-agent task"
    ],
    "venue": "ICLR",
    "year": 2025,
    "pdf_url": "https://openreview.net/pdf?id=TySMCLoGVl",
    "forum_url": "https://openreview.net/forum?id=TySMCLoGVl",
    "reviews": [
      {
        "rating": "6",
        "confidence": "4",
        "summary": "The paper discusses a approach to spatio-temporal modelling for tasks with irregular observation spaces. Experiments are conducted on multi-agent scenario's like robotic target-chasing simulations and StarCraft II gameplay analysis.\n\n\nMotivation: The paper aruges that current architectures like Transformers and LSTMs works well in scenarios with fixed observation spaces but struggle with tasks where observation spaces vary over time, such as multi-agent interactions. The paper aims to combine the efficiency of recurrent models with the parallelism of attention mechanisms, focusing on varying-dimension observation spaces.\n\nProposed Method:  The paper introduce an algorithm using a 2D latent state, alternating between cross-attention on observations and a discounted cumulative sum over time, capturing long context.  \n\nExperiments: Two benchmarks are used for evaluation: (a) Chasing Targets: Agents pursuing dynamic targets, evaluating the model's ability to infer intended goals in real-time; (b) StarCraft II: A environment with complex, temporally varying observations, where models infer combat unit assignments and predict unit movement.\n\nResults: The proposed model achieves competitive accuracy with fewer parameters and faster inference compared to standard methods (e.g., transformers). The \"resampling cycle,\" improves sequence modeling accuracy by conditioning observations on accumulated sequence data.\n\n===================\n\nAfter rebuttal: I've read the review by other reviewers as well as the rebuttal by the authors.\n\nThis statement by the authors summarizes the contribution of the paper well.\n\"Our results primarily set out to explore the trade-offs between efficiency and performance in the irregular observation case. This means results should be interpreted given the compute budget available to a practitioner. If only performance matters, practitioners should select a temporal transformer with sequential cross attention (X-Attn Sequential) for observation encoding. For efficiency and model parsimony, an inclusive scan should be selected with X-Attn Sequential.\"\n\nIt will be very helpful to revise the introduction and abstract accordingly.",
        "strengths": "The paper investigates the use of various encoders to encode irregular observations into a fixed dimensional latent, and corresponding sequence modelling approaches.",
        "weaknesses": "- The model's efficiency enables its use in real-time applications with irregular observation space, but studying the effect on longer sequence durations as well as diversifying the tasks (i.e., conduct experiments on more tasks) would further validate its utility in long-term planning tasks.\n- There's some work in the literature like Temporal Latent Bottleneck (https://arxiv.org/abs/2205.14794) and Block Recurrent Transformers (https://arxiv.org/abs/2203.07852); which combines strengths of attention and recurrence."
      },
      {
        "rating": "6",
        "confidence": "3",
        "summary": "This paper investigates how to combine the inference efficiency of recurrent models and the training parallelism of multi-head attention transformers, especially for dealing with the varying size observation space. The authors propose a novel algorithm to cycle between cross-attention and inclusive scan to efficiently accumulate historical information. They evaluate their method on two benchmarks, Chasing-Targets gymnasium and StarCraft2.",
        "strengths": "The proposed method, especially integrating inclusive scan algorithm, is novel and is an effective way to accumulate history.\n\nThe experiment results are good. The proposed method improves the performance and reduce the computation overhead.",
        "weaknesses": "Please refer to the Questions part."
      },
      {
        "rating": "6",
        "confidence": "3",
        "summary": "The paper proposes a method for sequential prediction tasks that can handle observations of varying sizes at different times. It also simultaneously introduces two intention-prediction tasks in which to test this method. Experiments are performed against a few baselines and components of the method are ablated.",
        "strengths": "- The contribution of the task based on StarCraft can be an interesting domain for future work to study\n- The writing is in general fairly clear to follow",
        "weaknesses": "I should start off by pointing out that I'm not precisely acquainted with this literature, so that will affect my judgment.\n\n## Major points\n1. One large issue I see with the paper is that I'm not totally certain why these particular tasks are good ones in order to explore modeling arbitrary-sized observation spaces. I think StarCraft as a domain makes sense, but there has been much prior work in StarCraft (which is not cited in the paper) that has used it in a different way, and I don't understand why the decision was made to couple \"intention-prediction\" tasks with the method. It seems that some domains like sequential decision making in healthcare, or some kind of variable-sized text prediction task would be equally fine as a benchmark domain. This is further complicated by the relatively unclear definition of the exact input and output for each task in Section 3. Given the motivation of these tasks is that it shows up often in interactions, it would seem that a space like Shared Autonomy might provide some more common benchmarks.\n\n2. Another big issue that I see is that the paper does not make a strong enough case for the choice of baselines. I would expect there to be accompanying work in the domain previously with which to compare against, but because 4.1.2 does not cite any prior work, it's unclear to me that these choices are well-founded. Certainly I'm familiar with Mamba2, but the rest is unclear. Also the choice of encoders for the RNN methods feels somewhat unjustified.\n\n3. The last major issues I see is that the results in Figure 5 and Table 1 feel somewhat inconclusive. Because nothing is controlled (either parameter count, memory, or training time) between methods, and there is no clear winner across metrics, it's difficult to see the benefit. When coupling these mixed results with the choice of new bespoke domains, it's even harder to understand the longer-term contribution. I don't think it's the case that a new method needs to be always better than prior work, but the fact that it does not appear to have particular advantages in computation that was claimed as a contribution (\"efficiently address sequence modeling\" at the end of Section 1), makes it hard to understand the contribution.\n\n## Specific points\n\n1. Section 4.1.2 add a citation to Mamba2\n2. Section 4.2 it would be nice to have the problem written out mathematically as I find the current description a bit hard to follow\n3. Section 5 is missing comment on hyperparameter tuning, especially for baselines\n4. Fig 7 should be referenced in 5.1.1"
      },
      {
        "rating": "6",
        "confidence": "3",
        "summary": "The paper tackles the issues of spatio-temporal modeling in the context of variable observation spaces, such as when there are variable objects across episodes / scenes, etc or when the object number varies within an episode (such as when entities enter and leave an arena). The authors introduce a few baseline tasks representative of this problem and cover various attention-based encoding and temporal aggregation schemes, some of which are advertised as being novel (such as some of the encoder methods). They perform various analysis on different methodologies, such as task performance, memory, speed, etc on these tasks which highlight some of the benefits of various methods (such as the scan-based one).",
        "strengths": "Overall the paper is interesting and approaches a very important problem I think in a comprehensive way, covering some benchmarks that seem well motivated to me as well as some methodologies for dealing with the variable observation problem. The experiments I think are clear enough and the conclusions drawn I think are sound, demonstrating that some methods perform better than others.",
        "weaknesses": "There are places where the writing is good, and there are places where the writing and motivation is not so good. The introduction is very vague and lacks citations on some critical claims in the paper that make it difficult for readers who are not very familiar with the domain to understand well. The benchmarks are introduced well enough, but it's unclear why we need multi-player problems to address the core problem of variable observation spaces. Critically though when the methods come around the organization of the paper suffers, as it becomes extremely difficult to understand the motivation of different design choices, such as the scan operation (e.g., why was the scheme in figure 4 motivated, other than post-hoc performance?). The methods in Figure 3 seem interesting, but I had difficulty finding their consequence in the paper later on.\n\n(Many of these and questions below were addressed sufficiently in the rebuttal and revision)"
      }
    ],
    "rating_avg": 6.0,
    "confidence_avg": 3.25,
    "decision": "Reject",
    "meta_review": "The paper presents an interesting approach to sequence modeling with irregular observation spaces, exploring novel scan operations and cross-attention techniques for handling variable-dimensional observations. While the work demonstrates potential in multi-agent tasks and introduces innovative modeling strategies, it struggles with comprehensive validation and generalizability. Reviewers noted significant challenges in methodology, including unclear motivation and insufficient differentiation from existing approaches. The benchmarks, primarily based on custom multi-agent tasks, do not definitively prove the method's broader applicability, and performance improvements remain marginal. Despite the authors' efforts to address concerns through additional experiments and clarifications, fundamental limitations persist. The incremental nature of the contribution, combined with presentation challenges and limited experimental rigor, suggests that while the work shows promise, it is not yet sufficiently developed for publication at a top-tier conference.",
    "author_remarks": "",
    "decision_comment": ""
  },
  {
    "id": "VNMJfBBUd5",
    "title": "Activation Gradient based Poisoned Sample Detection Against Backdoor Attacks",
    "authors": [
      "Danni Yuan",
      "Mingda Zhang",
      "Shaokui Wei",
      "Li Liu",
      "Baoyuan Wu"
    ],
    "abstract": "This work studies the task of poisoned sample detection for defending against data poisoning based backdoor attacks. Its core challenge is finding a generalizable and discriminative metric to distinguish between clean and various types of poisoned samples (e.g., various triggers, various poisoning ratios). Inspired by a common phenomenon in backdoor attacks that the backdoored model tend to map significantly different poisoned and clean samples within the target class to similar activation areas, we introduce a novel perspective of the circular distribution of the gradients w.r.t. sample activation, dubbed gradient circular distribution (GCD). And, we find two interesting observations based on GCD. One is that the GCD of samples in the target class is much more dispersed than that in the clean class. The other is that in the GCD of target class, poisoned and clean samples are clearly separated. Inspired by above two observations, we develop an innovative three-stage poisoned sample detection approach, called Activation Gradient based Poisoned sample Detection (AGPD). First, we calculate GCDs of all classes from the model trained on the untrustworthy dataset. Then, we identify the target class(es) based on the difference on GCD dispersion between target and clean classes. Last, we filter out poisoned samples within the identified target class(es) based on the clear separation between poisoned and clean samples. Extensive experiments under various settings of backdoor attacks demonstrate the superior detection performance of the proposed method to existing poisoned detection approaches according to sample activation-based metrics.",
    "keywords": [
      "Backdoor Defense",
      "Poisoned Sample Detection",
      "AI security"
    ],
    "venue": "ICLR",
    "year": 2025,
    "pdf_url": "https://openreview.net/pdf?id=VNMJfBBUd5",
    "forum_url": "https://openreview.net/forum?id=VNMJfBBUd5",
    "reviews": [
      {
        "rating": "6",
        "confidence": "4",
        "summary": "The authors present an approach for backdoor sample detection based on the angle of the activation gradients between samples and a reference clean sample for each class.\nThe paper observes that, within the target class, the activation gradient angles exhibit greater dispersion compared to samples from the clean class. Furthermore, the distribution of angles of backdoor and clean samples within the target class are somewhat distinct, providing a basis for differentiating between clean and poisoned samples.\n\nBuilding on this observation, the authors introduce the concept of the Gradient Circular Distribution (GCD), a distribution of angles between the activation gradient of samples and that of a reference sample. They propose two key metrics based on this distribution:\nCVBT: A metric designed to measure the dispersion of the GCD.\nSample Closeness: A metric that evaluates how close a given sample is to  reference clean sample.\n\nThese metrics are then utilized to develop a filtering algorithm, which first identifies the target class and subsequently filters out the poisoned samples. The paper validates the proposed method through experiments on a range of backdoor attack scenarios.",
        "strengths": "1. The paper identifies a previously unexplored phenomenon in backdoor samples, highlighting greater dispersion in activation gradient angles within the target class compared to clean samples.\n2. The authors provide extensive experiments on various backdoor attacks across two architectures (PreAct ResNet18 and VGG-18 BN),\n3. Some initial analysis on adaptive attacks is presented, though further exploration could strengthen the findings.\n4. The writing is clear and well-structured, making the main arguments easy to follow.",
        "weaknesses": "1. I am giving low scores to soundness due to the reported  low performance of ASSET, AC. The performance in the original paper of ASSET is close to 90% for all attacks. Additionally, 0 F1 scores for AC also does not look right. For example, in the aforementioned paper, the average TPR of AC is around 50%. \n\n2.  Please provide sensitivity of various thresholds like $\\tau_z$ , $w, \\beta$ (Stage 3). What is the rationale behind the choice of $\\tau_z$ ? \n\n3.  Please comment on or provide results for these additonal adaptive attacks: \na. Can an adversary add  perturbations to the clean samples (different perturbations to different samples) such that their dispersion increases ? \nb. Given a clean set with 100 images, the adversary adds the same noise to 50 images and keeps the other images the same. Will the  dispersion increases of clean sample increase ? \nc. The backdoor trigger is optimized such that the dispersion of the target class decreases."
      },
      {
        "rating": "6",
        "confidence": "3",
        "summary": "The authors propose to detect poisoned examples from an activation-gradient circular distribution perspective. The authors draw two novel observations by studying the GCD of poisoned/clean examples, based on which they introduce an algorithm named AGPD to do backdoor example detection.",
        "strengths": "(1) Understanding the activation gradient of poisoned examples with circular distribution is interesting. The two observations of GCD are novel.\n\n(2) The algorithm shows strong performance within the evaluation setting of this paper.\n\n(3) The paper is overall well written and the logic is easy to follow. The empirical experiments are mostly comprehensive and valid.",
        "weaknesses": "(1) My main concern about the proposed algorithm is its scalability. It requires training on the entire dataset to determine the detection state, which might be too expensive given web-scale data and the extreme probability of the data being poisoned. Also, it takes nearly $O(n2) $ to compute the GCD, which is infeasible for large datasets. \n\n(2) The defense algorithm appears to be highly correlated with the specific class labels, potentially limiting its applicability. In the real world, the attackers can adopt a different set of labels than the defenders. The attackers could label the dataset more fine-grained/coarse-grained than the defender. (e.g. Imagine there is a dataset consisting of snacks and drinks and the target class of the attacker is Coca-Cola. However, the defenders just want to classify the images as soft drinks no matter whether it is Coca-Cola or Pepsi. Or the reverse situation can also happen.) Will the observations about GCD hold under such misalignment?\n\n(3) Table 7 is not organized well, please have a double-check."
      },
      {
        "rating": "6",
        "confidence": "4",
        "summary": "The paper presents a new approach to identifying poisoned samples in datasets used for deep neural network training. The core proposal, termed Activation Gradient-Based Poisoned Sample Detection (AGPD), leverages a novel metric called Gradient Circular Distribution (GCD) to detect discrepancies between clean and poisoned samples. Key insights include observing that in backdoor attacks, models often map poisoned samples and clean samples to similar activation regions, which AGPD detects by analyzing gradient direction distributions. This method involves three main steps: calculating GCD for each class, identifying target classes based on dispersion, and filtering out poisoned samples.",
        "strengths": "(1) Introducing GCD as a novel measure adds a unique, technical depth to the approach, potentially applicable to various attack scenarios.\n\n(2)  AGPD shows high detection performance with minimal additional clean data, a notable advantage for real-world applicability, where such data may be limited.",
        "weaknesses": "(1) The proposed method is founded on two core observations: (i) the Gradient Circular Distribution (GCD) of the target class exhibits greater dispersion than those of clean classes, and (ii) poisoned and clean samples are distinguishable by their clear clustering in separate regions. However, it remains unclear whether these observations hold consistently for clean-label attacks, where the mapping directions of poisoned and benign samples could exhibit higher similarity given their similar input-space characteristics. Further discussion on this aspect would strengthen the paper’s analysis.\n\n(2) The choice of baseline methods appears limited to older techniques. A broader comparison with more recent, state-of-the-art defense methods would provide a more thorough assessment of the proposed method’s performance relative to the latest advances in poisoned sample detection.\n\n(3) Attack Success Rate (ASR) is a key metric commonly used in backdoor detection evaluations. Its omission from Table 1 raises questions about the comprehensiveness of the evaluation metrics chosen. Including ASR would provide a clearer view of the method's efficacy against backdoor attacks.\n\n(4)   In the main evaluation, a poisoning ratio of 10% is used for non-clean label attacks and 5% for clean-label attacks. Since clean-label attacks are generally more challenging, lower poisoning ratios are typically applied to non-clean label attacks in real-world scenarios. This discrepancy between the paper’s experimental setup and actual attack contexts calls for further clarification. Additionally, practical attack scenarios often employ very low poisoning ratios (1% or 0.5%), feature separability-based defenses tend to be less effective in this setting. More discussion should be included."
      },
      {
        "rating": "6",
        "confidence": "4",
        "summary": "With the inspiration that a backdoored model is apt to map significantly different poisoned samples and clean samples of the backdoor target to similar activation areas, this paper introduces a novel measurement, i.e., the circular distribution of the gradients w.r.t sample activation, namely GCD, which works to identify the target class of the backdoor and consequently separate poisoned and clean samples within the target class. Accordingly, this paper proposes a sample detection approach called AGPD to achieve dataset purification. Extensive experiments show AGPD's advanced performance in detecting and isolating poisoned samples.",
        "strengths": "- This paper proposes a novel measurement to show the dispersion of poisoned and clean samples in the model's activations\n\n- This paper is well-written and enforces a high readability with variant and helpful illustrations \n\n- This paper comprehensively evaluates AGPD's performance by considering diverse poisoning attacks, comparing with different related defenses, and conducting experiments on variant datasets.\n\n- This paper considers the ablation study on different hyper-settings of APGD and involves two reasonable adaptive attacks that have considered APGD's defense w.r.t the GCD distribution.",
        "weaknesses": "(1) The use of $arccos(\\cdot)$ in Eq.(2) is ambigious as $cos\\(\\cdot\\)$ is used in Eq.(3) and Eq.(4) as well.\n\n(2) The calculation of GCD across all model layers is not clearly formulated for each sample.\n\n(3) The influence of the clean sample by random sampling for the basic sample pair is not studied.\n\n(4) There is lacking the rationale for setting the hyper-parameter $\\tau_z = e^2$.\n\n(5) For all-to-all attacks, a better explanation of how the dataset separation by APGD is achieved is required.\n\n(6) The description of Adpative-Blend in Appendix B is incomplete and different from the default attack setting.\n\n(7) It is unclear how the noisy and poisoned samples are separated against WaNet and Adaptive-Blend attacks.\n\n---\nIn the following, further questions related to the above points are detailed with the notion of \"Q-#\"."
      }
    ],
    "rating_avg": 6.0,
    "confidence_avg": 3.75,
    "decision": "Accept (Poster)",
    "meta_review": "The paper proposed a new apporach for detecting poisoned samples called Activation Gradient-Based Poisoned Sample Detection (AGPD). It leveerages a novel metric called Gradient Circular Distribution to distinguish clean and poisoned samples. The empirical results also demonstrate its effectiveness.\n\nStrength:\n\n1. Insightful view on understanding the activated gradient of poisoned examples with distribution.\n\n2. The algorithm shows strong performance within the evaluation setting of this paper.\n\n3. Well written.\n\nWeakness:\n\n1. Only explores the backdoor attacks on Pre-Act ResNet 18 and VGG, whether the proposed feature still exists in Transformers or other networks are unexplored.\n\nAll the reviewers thoughts positive towards this paper, therefore I recommend to accept it as a poster.",
    "author_remarks": "",
    "decision_comment": ""
  },
  {
    "id": "yRKelogz5i",
    "title": "Causally Motivated Sycophancy Mitigation for Large Language Models",
    "authors": [
      "Haoxi Li",
      "Xueyang Tang",
      "Jie ZHANG",
      "Song Guo",
      "Sikai Bai",
      "Peiran Dong",
      "Yue Yu"
    ],
    "abstract": "Incorporating user preferences into large language models (LLMs) can enhance the personalization and reliability of model outputs and facilitate the application of LLMs to real-world scenarios. However, leveraging user preferences can be a double-edged sword. Recent studies have found that improper utilization can incur sycophancy, where LLMs prioritize alignment with user preferences over the correctness of their outputs. To address sycophancy in LLMs, we analyze and model the problem through the lens of structured causal models (SCMs). We attribute sycophancy to LLMs' reliance on spurious correlations between user preferences and model outputs in this paper. Based on the proposed SCMs, we develop a novel framework, termed **CAUSM**, to mitigate sycophancy in LLMs by exploiting a significant causal signature. Specifically, we eliminate the spurious correlations embedded in the intermediate layers of LLMs through causally motivated head reweighting, and then calibrate the intra-head knowledge along the causal representation direction. Extensive experiments are conducted across diverse language tasks to demonstrate the superiority of our method over state-of-the-art competitors in mitigating sycophancy in LLMs.",
    "keywords": [
      "Large Language Model; Sycophancy; Causal Modeling"
    ],
    "venue": "ICLR",
    "year": 2025,
    "pdf_url": "https://openreview.net/pdf?id=yRKelogz5i",
    "forum_url": "https://openreview.net/forum?id=yRKelogz5i",
    "reviews": [
      {
        "rating": "6",
        "confidence": "4",
        "summary": "This paper introduces a new framework called CAUSM (Causally Motivated Sycophaocy Mitigation) aimed at reducing sycophancy in Large Language Models (LLMs). The paper analyzes and models the sycophancy issue in LLMs through the lens of Structured Causal Models (SCMs). \nA significant causal signature is proposed to distinguish latent causal embeddings from spurious embeddings that cause sycophancy. The paper further propose an intervention-based scheme to calibrate the direction of the derived causal representations. Extensive experiments show that the proposed approaches outperforms the state-of-the-art competitors.",
        "strengths": "1. It is the first to apply Structured Causal Models (SCMs) to analyze and model sycophancy behavior in Large Language Models (LLMs), offering an innovative research perspective.\n2. Extensive experiments show that CAUSM is superior to existing state-of-the-art methods in mitigating sycophancy in LLMs.",
        "weaknesses": "1. In Line 81, the phrase “To map the latent causal embeddings to the observable intermediate components of LLMs” appears to conflict with the statement “a significant causal signature which can distinguish the intended causal embeddings from spurious embeddings which incur sycophancy within the latent representation space.” Could you clarify this discrepancy?\n\n2. How can I(X_P ; Y | Z) be approximated by Eq. 7? Is causal intervention controllable? Could you provide an example to illustrate this?\n\n3. Why does the intervention \\bar{X}_P maximize the difference in cross-entropy losses for a fixed W? Is this a result of the algorithm's design, or does it align with the intrinsic nature of interventions?\n\n4. The author claims to utilize Parameter-Efficient Fine-Tuning (PEFT) in Line 267, yet states in the baselines section that all parameters are fine-tuned. This is rather confusing.\n\n5. In Section 4.3, how is the weight matrix value obtained, and what does |w_l^h| represent? Are these parameters part of the adaptor in PEFT, or are they parameters of the model itself? How are these parameters utilized specifically?"
      },
      {
        "rating": "6",
        "confidence": "2",
        "summary": "The paper introduces a novel framework called CAUSM to address sycophancy in large language models (LLMs), which refers to the models’ tendency to align with user preferences even when those preferences lead to incorrect or biased outputs. This behaviour reduces the reliability and factual integrity of LLM responses.  The authors conclude that CAUSM effectively mitigates sycophantic behaviour in LLMs by focusing on the causal structure of sycophantic representations. The framework offers a scalable solution to improve the factual reliability of LLMs while respecting user preferences, which holds promise for enhancing trust in AI outputs in real-world applications.",
        "strengths": "1. The authors provide a novel framework, CAUSM, which leverages structured causal models to address sycophancy in large language models (LLMs). By introducing a causal approach, they advance beyond existing methods that may depend on spurious correlations, achieving more reliable mitigation of sycophantic responses.\n\n2. The article is well-structured, with clearly delineated sections detailing the problem (sycophancy in LLMs), prior approaches, and the limitations they aim to address with CAUSM. This clarity is helpful for readers who may be less familiar with the subject matter.",
        "weaknesses": "My main concerns focus on the application of the structured causal model (SCM) approach. The authors state that causal relations can be captured via a directed acyclic graph (DAG) learned through regularization. However, in real-world applications, the regularization term is unlikely to reach zero. How can the authors be certain that the learned representations are truly disentangled? The methodology would benefit from a more robust approach to verifying that these representations capture causal rather than correlated information.\n\nMy second question relates to the evaluation of DAG structures in SCMs. Typically, metrics like Structural Hamming Distance (SHD) or False Discovery Rate (FDR) are used to confirm if the learned graph conforms to a DAG structure. This paper, however, claims that the approach is inspired by graph models without providing a specific graph-based evaluation. How can we be sure that the learned representations are genuinely causality-related rather than optimized merely by overfitting through additional parameters? Both theoretical analysis and case studies would strengthen the authors’ claims.\n\nRegarding the representation learning approach, it seems counterintuitive that a fully supervised learning model without any stochastic components could infer causality from data alone. The mutual information-based independence criterion here could indicate correlation, but correlation does not imply causation. Causal inference methods typically rely on stochasticity in at least one part of the model (e.g., a two-tower architecture) to differentiate causality from mere correlation. Without this, there is a risk of learning coincidental patterns rather than true causal relationships.\n\nLastly, a minor issue: without providing a formal proof, I recommend avoiding the use of terms like \"Lemma\" to present conclusions, as this suggests a level of mathematical rigor that is not fully substantiated in the paper."
      },
      {
        "rating": "6",
        "confidence": "3",
        "summary": "This paper addresses the issue of sycophancy in large language models (LLMs) and introduces CAUSM, a novel method for identifying and mitigating sycophantic behavior within the models’ latent representations. The authors view sycophancy in LLMs as “spurious correlations between user preferences and model outputs”. By leveraging structured causal models, they aim to disentangle sycophantic representations from causal embeddings. An intervention-based technique is then developed to recalibrate the causal representation direction embedded in attention heads.",
        "strengths": "1. The paper aims to address LLMs’ sycophancy issue, which is an important topic in the community.\n\n2. A variety of experiments have been conducted to show the effectiveness of the proposed approach across different datasets.\n\n3. The high-level structure of the paper is easy to follow.",
        "weaknesses": "1. The motivation for the proposed approach and the intuition of the algorithm design needs to be more clear.  \n-  In the Introduction, the authors discuss two groups of prior research on LLM sycophancy: (1) linear probing and (2) path patching. However, these prior works primarily concentrate on analyzing and understanding sycophantic behavior in LLMs, rather than on mitigating it (also as mentioned in Related Work line 113-122). Given the distinct emphasis of these studies compared to the authors' goal, it is unclear how the limitations of these earlier works directly motivate the development of the authors’ proposed approach.\n\n- While the authors discuss several recent studies on mitigating LLM sycophancy in the Related Work section (lines 124–135), a more in-depth comparison between these studies and their own approach would be beneficial. Specifically, it would be helpful to understand if there are potential methodological concerns with the designs proposed by Burns et al. (2022) and Rimsky et al. (2023) that inspired the development of CAUSM.\n\n- It would be helpful to discuss the rationale for using structured causal models to capture sycophancy in the models’ latent representations.\n\n2. Some compared methods in the tables/figures of results are confusing. E.g., I couldn’t find a clear definition of CAUSM (Base) (Table 1 & 2) and CAUSM (Table 2). What is the difference between CAUSM and CAUSM (Base) in Table 2? \n\n3. Did the authors conduct the experiments on multiple base LLMs or specifically focus on a single base LLM (i.e., Llama-2-7B-Chat)?"
      },
      {
        "rating": "6",
        "confidence": "4",
        "summary": "This paper analyzes and models sycophancy in LLMs through the lens of structured causal models (SCMs), which is actually the reliance on spurious correlations between user preferences and model outputs. Based on the proposed SCMs, this paper develops a novel framework called CAUSM to mitigate sycophancy in LLMs by exploiting a significant signature.",
        "strengths": "1.The author models the phenomenon of sycophancy in language models as a type of spurious correlation in causal structures, making it possible to address sycophancy through conditional independence constraints.\n2.The CAUSM method achieves excellent results in mitigating sycophancy across INTRA-DATASET, CROSS-DATASET, and CROSS-TASK scenarios.",
        "weaknesses": "1. The motivation for the Causal Activation Calibration method in Section 4.3 is unclear. Specifically, the relationship between the causal direction in Section 4.3 and the SCM in Section 4.1 is not sufficiently clear. Please provide further clarification on this point. My understanding is that Equation (6) aims to add a conditional independence constraint to the original training objective, intending to eliminate spurious correlations between $Z_S$  and $Y$. However, I am not convinced how the “causal direction” in Section 4.3 effectively mitigates these spurious correlations. Does this approach leverage the causal direction as a representation of causal effect orientation, or is there some other theoretical justification? I suggest that the authors clarify this aspect in the paper.\n\n2. The second statement in Lemma 4.1 is not described clearly enough. I would like to understand which part of the subsequent methods specifically utilizes this statement. For instance, if we consider a specific example where $f(Z_C,Z_S) = Z_C$, then this condition does not hold in the causal graph shown in Figure 2(a). Furthermore, does the second statement in Lemma 4.1 offer any guidance in constructing the subsequent methods? If not, I would suggest the authors consider removing this statement."
      }
    ],
    "rating_avg": 6.0,
    "confidence_avg": 3.25,
    "decision": "Accept (Poster)",
    "meta_review": "The paper addresses sycophancy in large language models.\n\nStrengths:\nThe first to apply Structured Causal Models (SCMs) to analyze and model sycophancy\nExtensive experimentations\n\nWeaknesses:\nSome issues such as clarity might have been addressed in the rebuttal, still it might be worth improving it for the camera ready.\nSee proposals to improve the paper by different reviewers.\nWell written,\n\nOverall, the paper addresses an interesting and well explained issue.",
    "author_remarks": "",
    "decision_comment": ""
  },
  {
    "id": "GsCMKwyfWm",
    "title": "LVLM-COUNT: Enhancing the Counting Ability of Large Vision-Language Models",
    "authors": [
      "Muhammad Fetrat Qharabagh",
      "Mohammadreza Ghofrani",
      "Kimon Fountoulakis"
    ],
    "abstract": "Counting is a fundamental skill for various visual tasks in real-life applications, requiring both object recognition and robust counting capabilities. Despite their advanced visual perception, large vision-language models (LVLMs) struggle with counting tasks, especially when the number of objects exceeds those commonly encountered during training. We enhance LVLMs’ counting abilities using a divide-and conquer approach, breaking counting problems into sub-counting tasks. Unlike prior methods, which do not generalize well to counting datasets on which they have not been trained, our method performs well on new datasets without any additional training or fine-tuning. We demonstrate that our approach enhances counting capabilities across various datasets and benchmarks.",
    "keywords": [
      "Counting",
      "Large vision-language models"
    ],
    "venue": "ICLR",
    "year": 2025,
    "pdf_url": "https://openreview.net/pdf?id=GsCMKwyfWm",
    "forum_url": "https://openreview.net/forum?id=GsCMKwyfWm",
    "reviews": [
      {
        "rating": "5",
        "confidence": "4",
        "summary": "This paper addresses the problem of counting objects in images using large vision-language models (LVLMs), which often struggle with counting tasks, particularly when the object count exceeds typical values encountered during training. The authors propose a method named LVLM-Count, which aims to enhance LVLMs' counting abilities through a divide-and-conquer approach. LVLM-Count is structured in four stages: (1) Area Detection, where regions containing relevant objects are identified; (2) Target Segmentation, in which these regions are segmented to highlight individual objects; (3) Object-aware Division, where regions are divided into sub-images without cutting through the segmented objects; and (4) Counting Aggregation, where the LVLM counts objects in each sub-image and combines the results to produce the final count. The proposed approach is claimed to generalize well to new datasets without additional training or fine-tuning, showing improved performance on various datasets and benchmarks compared to prior methods.",
        "strengths": "This paper explores a relatively novel approach by focusing on enhancing counting capabilities in large vision-language models (LVLMs) using a training-free methodology. By leveraging the power of LVLMs, the authors propose an effective paradigm that does not rely on additional training or fine-tuning, which is particularly advantageous in scenarios where labeled data is limited or unavailable. The method demonstrates a creative approach to addressing challenges in object counting, especially in cases with a high number of objects and significant object overlap. By employing a divide-and-conquer strategy, the proposed LVLM-Count effectively manages the complexity of densely populated scenes, providing a practical and scalable solution for counting tasks that would typically challenge standard vision models. The paper’s emphasis on a training-free framework in conjunction with LVLMs is both innovative and valuable, offering a flexible counting solution that could be adapted to various applications without the need for retraining.",
        "weaknesses": "This paper also presents some limitations, as acknowledged in the final section. The proposed method heavily relies on the accuracy of the initial stages—specifically, object detection and instance segmentation. If either of these stages is inaccurate, it could significantly affect the downstream steps, potentially compromising the overall performance. This dependency raises questions about the robustness of the method on more challenging datasets, especially those with high levels of occlusion or camouflage, where accurate detection and segmentation are inherently more difficult. Additionally, the comparison with existing methods is relatively limited. To strengthen the paper’s persuasiveness, it would be beneficial for the authors to include more comprehensive comparisons with other state-of-the-art counting methods. Lastly, the paper would benefit from further ablation studies, such as an investigation into the impact of each stage in the pipeline. For instance, an ablation study examining the effect of including or excluding the target segmentation stage could provide insights into its significance within the proposed approach. These additions could help validate the robustness and effectiveness of the method across diverse scenarios."
      },
      {
        "rating": "6",
        "confidence": "5",
        "summary": "This paper aims to improve the counting ability of large VLMs. The paper proposes to split a counting task into sub-tasks by dividing the input image into smaller parts, counting objects in the smaller parts, and then aggregating the counts. The authors show that the proposed approach can generalize to unseen datasets.",
        "strengths": "The results obtained and demonstrated in the paper seem strong.",
        "weaknesses": "The main weaknesses of the paper lie in the lack of enough support for the claims made. In particular, the authors should address the following questions/comments in their responses and revisions:\n\n1. In several places in the paper (e.g. lines 61-62), the authors mention that pipeline detects \"the objects of interest\". Are there even more than one types of objects to be counted in these datasets? If yes, how are objects of different categories handled? All the visual examples in the paper involve only a single type of object. \n\n2. In line 349, the authors talk about \"simple\" and \"complex\" counting questions. What do these mean in this context?\n\n3. Lines 241-242 say \"In out experiments, we specify which approach we use for each dataset\". Having different approaches for different datasets (outside of a few hyper-parameters) defeats the point of proposing a single approach for a problem. This is problematic, particularly because one of the selling-points of this paper is the claim that the proposed approach generalizes across datasets. \n\n4. The introduction mentions \"industry, healthcare, and environmetal monitoring\" as the areas of application. It would have been useful if the paper actually included some real-world examples from these domains to demonstrate the utility of the proposed approach."
      },
      {
        "rating": "3",
        "confidence": "5",
        "summary": "This paper proposes LVLM-Count, a prompt-based, training-free counting approach that enhances object counting performance with large vision-language models (LVLMs).  For addressing limitations with current LVLMs, such as their challenges with high-count tasks and complex counting questions, this method employs a four-stage pipeline: (1) area detection, (2) target segmentation, (3) object-aware division, and (4) target counting. This enables LVLMs to effectively segment, process, and count large numbers of objects across diverse datasets, showcasing robust generalization.",
        "strengths": "A simple and intuitive pipeline for counting with LVLM\n\nGood presentation along with clear drawn figures.\n\nA newly introduced Emoji-Count benchmark is introduced, though the generation of this data is not complex but still useful as a testbed.\n\nGood performance margin achieved.",
        "weaknesses": "W1: At the very beginning, the authors should define more clearly what means by large number of objects, 10s, 100s, or 1000s, per image. As this defines the scope of this work in terms of crowdedness. \n\nW2: The key idea of this work, divide-and-conquer, can be hardly considered novel for two reasons: 1) in this context, counting by definition is a process of adding the number of objects from region to region. It is essential a process of summing up across regions; 2) Such an idea has appeared in the counting literature such as [Ref 1] where there is also a need for avoiding repeatedly computing regions within an image. As a result, this whole method pipeline is not sufficiently novel -- it is more like a baseline design of using LVLM for counting. \n- [Ref 1] Xiong H, Lu H, Liu C, Liu L, Cao Z, Shen C. From open set to closed set: Counting objects by spatial divide-and-conquer. InProceedings of the IEEE/CVF international conference on computer vision 2019 (pp. 8362-8371).\n\nW4: It is inconsistent than different examples are used from Fig 3 to Fig 5 when discussing individual components. From these examples, little challenges are visible with counting, and I am impressed that simply counting the mask of GroundingDINO would achieve good performance, even not bother LVLM such as GPT-4o. For example, simply counting the mask number in Fig 4(c) can give us very accurate count. I would suggest the authors use the same example with proper challenges involved and considered in this work, across all these sections. \n\nW5: This method uses a number of pretrained models such as LLMs, GroundingDINO, and GPT-4o, Real-ESRGAN. One concern is about efficiency. The authors should conduct an efficiency analysis in both training and inference, which is now missing. \n\nW6: Except the comparison with previous works, I suggest a couple of baseline methods should be included in this work:\n1) LLM + GroundingDINO: After target segmentation step (Sec 3.2), directly counting the masks by SAM. This can be use to validate the significance of region division, a key aspect of this work. This complements to the ablation result of using GPT-4o in Table 4 (Appendix). \n\n2) Passing the SAM's mask to GPT-4o to count: This will directly compare the proposed object aware division algorithm.\n\n3) To compare with Ref 1's strategy on avoiding repeated counting at the region level\n\nW7: In ablation study, it is suggested that the authors examine the effect of using super-resolution on the regions.\n\nW8: Please clarify what LLM is used in this work?\n\nW9: Except those datasets used, another good test is PASCAL VOC. This should add different test cases on top. The authors can consider to evaluate."
      },
      {
        "rating": "6",
        "confidence": "4",
        "summary": "This paper proposes LVLM-Count, a plug-in method for current LVLM to enhance the visual perception on counting ability. The method uses an extra module with object-aware division, which can divide multi objects without cutting through objects of interest. Also the paper proposes a dataset for testing the counting ability of LVLMs. Compering other method, the proposed method achieves good performance on different benchmarks.",
        "strengths": "This paper provides good thinking and novel insights for a very important domain about LVLMs: visual counting ability of LVLM.\n\n* The paper proposes a novel and simple method for dividing objects without cutting, which is meaningful for visual perception and the inference logic of LVLMs.\n\n* The paper can deal with complex scenarios and achieve high performance on large mount of objects.\n\n* The proposed benchmark looks very interesting.",
        "weaknesses": "I have some concerns about the paper and hope the authors can address them:\n\n* The motivation and method looks good but the experiment results may not support them very well. In the section of experiments (Section 4), there should be some ablations about the designed method.\n\n* The metrics of evaluation may not be enough for well evaluating a LVLM's counting ability. Maybe there are two situations about counting: 1) we need an approximate number of objects. 2) we need an exact number of objects. Current metrics may can only evaluate the first case. So I think you could add more metrics on all benchmarks, such as Accuracy (right cases / total cases, same with EA, but EA is only used for one benchmark). Also you can set different ranges of the Acc, e.g., you can firstly set Acc_{+-0} which means that the answer must be the exact number of objects without any difference. Then you can set Acc_{+-3} which means that the answer is acceptable with in +-3 error numbers. Following this you can set Acc_{+-5}, Acc_{+-10}.\n\n* The method you proposed is actually a plug-in method for any LMLM. So it is a little weak that you only combine it with one LVLM (GPT4o). You should involve more LVLMs such as LLaVA series, Genimi, etc.\n\n* The outputs of the LVLM are always natural languages, how do you make sure that every response is about the counting? how do you avoid the problem of the model giving irrelevant responses?\n\n* In addition to the very incomplete quantitative results, there are also very few qualitative results. The qualitative results are only tested on one dataset. I would like to see the qualitative results and accuracy of image_00001.png, image_00005.png, image_00013.png, image_00036.png, image_00068.png in emoji_benchmark.\n\nThe main problem is the incompleteness of the experimental part. If the authors have a positive response, I will consider raising my rating."
      }
    ],
    "rating_avg": 5.0,
    "confidence_avg": 4.5,
    "decision": "Reject",
    "meta_review": "This paper proposes LVLM-COUNT, a divide-and-conquer framework to enhance the counting ability of large vision-language models (LVLMs) through four stages: area detection, target segmentation, object-aware division, and counting aggregation. Experiments are conducted on multiple datasets.\n\nThe main strengths are: 1) the innovative training-free framework with LVLMs, and effectively handles complex scenes with overlapping objects, and 2) good performance.   \nThe main weaknesses are: 1) inconsistent performance (the performance depends heavily on the accuracy of initial object detection and instance segmentation stages), and 2) insufficient experiments, including limited comparison with existing methods, lack of more detailed ablation studies to evaluate each stage of the pipeline, and lack of training and inference efficiency analysis.\n\nAfter rebuttal, the main issues of inconsistent performance and insufficient ablation studies still remain (recognized by Reviewers 4Qwc, and ATzA), which weakens the contribution of this paper. Thus, the AC does not recommend acceptance at this conference. The authors are encouraged to address these concerns for future submissions.",
    "author_remarks": "",
    "decision_comment": ""
  },
  {
    "id": "qotIZREPZf",
    "title": "CGD: Modifying the Loss Landscape by Gradient Regularization",
    "authors": [
      "Shikhar Saxena",
      "Tejas Bodas",
      "Arti Yardi"
    ],
    "abstract": "Line-search methods are commonly used to solve optimization problems. The simplest line search method is the steepest descent where we always move in the direction of the negative gradient. Newton’s method on the other hand is a second-order method that uses the curvature information in the Hessian to pick the descent direction. In this work, we propose a new line-search method called Constrained Gradient Descent (CGD) that implicitly changes the landscape of the objective function for efficient optimization. CGD is formulated as a solution to the constrained version of the original problem where the constraint is on a function of the gradient. We optimize the corresponding Lagrangian function thereby favourably changing the landscape of the objective function. This results in a line search procedure where the Lagrangian penalty acts as a control over the descent direction and can therefore be used to iterate over points that have smaller gradient values, compared to iterates of vanilla steepest descent. We reinterpret and draw parallels with the Explicit Gradient Regularization (EGR) method, discussing its drawbacks and potential enhancements. Numerical experiments are conducted on synthetic test functions to illustrate the performance of CGD and its variants.",
    "keywords": [
      "optimization",
      "gradient regularization"
    ],
    "venue": "ICLR",
    "year": 2025,
    "pdf_url": "https://openreview.net/pdf?id=qotIZREPZf",
    "forum_url": "https://openreview.net/forum?id=qotIZREPZf",
    "reviews": [
      {
        "rating": "3",
        "confidence": "4",
        "summary": "This paper introduces Constrained Gradient Descent (CGD), a new line-search method that alters the objective function landscape for better optimization. CGD is based on a constrained version of the problem, optimizing the Lagrangian to control descent direction, potentially targeting points with smaller gradients than steepest descent. The authors relate CGD to Explicit Gradient Regularization (EGR), discussing its pros and cons, and validate CGD's performance through numerical tests on synthetic functions.",
        "strengths": "The paper is well written, and the method is well described.",
        "weaknesses": "* The statement in Section 3, especially the Lemma 1, is quiet confusing. Lemma 1 shows that the set of minimizers for the problem you defined in Equation (8) includes the set of minimizers for the original problem, which raises a convergence issue: where exactly will your defined algorithm converge to? The final convergence result might be inferior to the original gradient descent. This is also reflected in the results shown in Figure 2. Even with corrections made in the Algorithm 1, the convergence result is still not guaranteed.\n\n*  Your algorithm 2, CGD-FD, is quiet similar with traditional nesterov momentum gradient descent, except that the momentum term in the Nesterov algorithm has been replaced with the gradient at the current point. However, this article does not compare with any momentum-based methods, and it is not necessarily superior to these methods, because the Nesterov algorithm theoretically has a convergence rate of $O(1/k^2)$."
      },
      {
        "rating": "3",
        "confidence": "3",
        "summary": "This paper proposes Constraint Gradient Descent (CGD) and its first-order variant CGD-FD, which use gradient regularization and finite-difference approximations for efficient optimization, and compare their performance against standard methods, while also re-evaluating Explicit Gradient Regularization techniques.",
        "strengths": "This paper study an important research issue and this paper is generally well written.",
        "weaknesses": "see questions."
      },
      {
        "rating": "1",
        "confidence": "5",
        "summary": "This paper proposes a gradient norm penalty to the original objective function and follows the gradient of the penalized objective, resulting in multiplying (I + lambda * Hessian) to the gradient step. This modification basically does not change the global optimum of the original optimization problem. While the original proposal requires the Hessian computation, its finite difference approximation is also proposed. The performance is compared to the standard GD on 6 test problems up to 10 dimensions.",
        "strengths": "A simple approach to accelerate the gradient descent.",
        "weaknesses": "Evaluation. The proposed approach is only compared with a naive GD with a constant step-size. It is definitely not enough to show the advantages of the proposed approach. It should be compared with momentum-based approaches such as NAG, quasi-Newton approaches such as BFGS and L-BFGS, and conjugate gradient methods. For the line search part, comparison with other line search methods based on Armijo condition or Wolf condition should be performed. Comparison with some commercial software such as Matlab optimization toolbox as a baseline is also helpful to show the advantage.\n\nThe search space dimensionality is also limited. Though the authors mention about DNN  at the beginning of this paper, the performance was tested only on 6 test problems up to 10 dimensions. Using benchmarking testbed with wider coverage such as CUTEst is recommended.\n\nNo theoretical justification is given. I am curious to know whether this approach improves the convergence rate."
      },
      {
        "rating": "1",
        "confidence": "4",
        "summary": "The paper introduces Constrained Gradient Descent (CGD), an optimization technique that modifies the loss landscape by imposing constraints on the gradient's norm. A first-order variant, CGD-FD, is proposed by using finite-difference approximations of the Hessian to avoid computational cost. The work also highlights limitations of existing Explicit Gradient Regularization (EGR) methods.",
        "strengths": "The motivation is clear with nice visualization.",
        "weaknesses": "1. The introduction uses deep learning as a motivation but it should be others since the work is focusing on deterministic optimization. \n2. lacks literature review many other related algorithms. \n3. The contribution lacks novelty. The algorithm basically does the following: when the normalized Newton step is a descent direction, use that; Otherwise, just employ gradient descent. When $\\lambda$ is sufficiently small, it is guaranteed to employ a normalized Newton step. \n4. The authors misunderstands the line search method. Line search should be an adaptive step size scheme but the algorithm doesn't have such property. \n5. The algorithm introduces another hyperparameter $\\lambda$ to the algorithm. Compared to gradient descent, the tuning effort for CGD is greater.  \n6. lacks convergence result\n7. It's not enough for comparing the algorithms over 6 problems, and it is not fair to tune  $\\lambda$ for the CGD algorithm in the comparison with GD."
      }
    ],
    "rating_avg": 2.0,
    "confidence_avg": 4.0,
    "decision": "N/A",
    "meta_review": "",
    "author_remarks": "",
    "decision_comment": ""
  },
  {
    "id": "BlzBcWYmdB",
    "title": "Cross-modal Mitigation of Spurious Correlation for Prompt-tuning in VLMs with Causally Motivated Logic Alignment",
    "authors": [
      "Xueyang Tang",
      "Song Guo",
      "Xiaosong Ma",
      "Haoxi Li",
      "Jie ZHANG",
      "Yue Yu"
    ],
    "abstract": "Recent studies have shown that pre-trained vision-language models can effectively adapt to diverse downstream tasks through parameter-efficient prompt tuning. Unfortunately, the tuned models can exploit spurious correlations during prediction, resulting in a failure to generalize to out-of-distribution test data, especially when the tuning dataset exhibits bias. How to achieve cross-modal mitigation of spurious correlations during prompt tuning of vision-language models remains an open question. In this paper, the challenging problem is tackled by leveraging the stable relationship between necessary and sufficient causal features and the corresponding label. On the one hand, we constrain the learning process of prompt by reinforcing the necessary and sufficient connection between the textual labels and textual features. On the other hand, the probability of necessity and sufficiency between the textual features and the filtered visual features is measured and maximized to enhance cross-modal feature alignment. By iteratively optimizing these two objectives, we can achieve cross-modal mitigation of spurious correlations because the logic equivalence between textual labels and visual features is bolstered. The theoretical analysis on generalization error indicates that our method can achieve a tighter generalization error bound than existing approaches. We evaluate the proposed method on several commonly adopted out-of-distribution datasets, and the empirical results demonstrate the superiority of our method over the state-of-the-art competitors.",
    "keywords": [
      "Vision-Language Models",
      "Prompt Tuning",
      "Spurious Correlations",
      "Out-of-Distribution Generalization",
      "Causality",
      "Probability of Necessity and Sufficiency"
    ],
    "venue": "ICLR",
    "year": 2025,
    "pdf_url": "https://openreview.net/pdf?id=BlzBcWYmdB",
    "forum_url": "https://openreview.net/forum?id=BlzBcWYmdB",
    "reviews": [
      {
        "rating": "5",
        "confidence": "3",
        "summary": "The paper presents a novel framework, LogicAl-PT, that addresses the challenge of cross-modal mitigation of spurious correlations in prompt tuning of vision-language models. The authors introduce a new concept, logic alignment, which integrates the mitigation of spurious correlations with cross-modal alignment of representations, and demonstrates its effectiveness through theoretical analysis and empirical results on various out-of-distribution datasets. LogicAI-PT earns competitive performance compared with traditional prompt-tuning methods for CLIP model.",
        "strengths": "Extensive theoretical analysis is provided to verify the proposed concept, PNS and PNS risk modeling.",
        "weaknesses": "- In contrast to the detailed theoretical analyses, the empirical verifications are fairly absent in this paper. Take the most recent competitor Coopood as an example, this paper presents much fewer empirical analyses, i.e. only 2 tables in the experiment section for verification. More ablation studies about the hyper-parameter chosen, visual results about the improvement on spurious correlations should be provided.\n\n-Some more recent prompt tuning methods[a][b] should be discussed and compared with.\n\n- Experiments on more architectures like ViT except for ResNet-50 should be done as well.\n\n[a] Self-regulating Prompts: Foundational Model Adaptation without Forgetting, https://arxiv.org/abs/2307.06948)\n[b] DePT: Decoupled Prompt Tuning, https://arxiv.org/abs/2309.07439"
      },
      {
        "rating": "6",
        "confidence": "2",
        "summary": "This paper presents Logical-pt, a framework for mitigating spurious correlations in vision-language models. It uses causally motivated logic alignment to align visual and textual features during prompt tuning. The method is backed by a tighter generalization error bound and empirically validated on several datasets, outperforming existing methods in out-of-distribution generalization.",
        "strengths": "* the results reported in this paper demonstrates good performance on multiple benchmarks\n* this paper did extensive evaluations and experiments to validate the method's effectiveness",
        "weaknesses": "* The proposed method shows superior performance compared with other benchmarks. What is the computational efficiency compare to simpler methods?"
      },
      {
        "rating": "6",
        "confidence": "4",
        "summary": "This paper introduces the novel LogicAI-PT framework to mitigate learning of spurious correlations in prompt tuning of CLIPs. It models the PNS (probability of necessity and sufficiency) by introducing intervention $\\bar{Q}$ and $\\bar{\\Phi}$. The author provide extensive introduction of the methodology and background and the experimental results are significant.",
        "strengths": "The proposed method is quite simple and effective regarding the significant improvement of multiple benchmarks. The idea of tackling spurious correlation problem from a sufficiency-necessity view is intuitive and is implemented based on thorough proof.",
        "weaknesses": "1. The proposed method seems to be universally applicable to many tasks rather than only prompting of VLM as classifier. Causal Representation Learning baselines adapting from other tasks can largely consolidate the motivation of this paper.\n2. Ablation study of the proposed is not enough. What is the effect of different $\\alpha, \\beta$? #419 introduces the author chooses different value combination for different benchmarks. The robustness regarding different hyper-parameters can largely affect the applicability of this method."
      },
      {
        "rating": "3",
        "confidence": "4",
        "summary": "This article introduces the concept of logical alignment to address the cross-modal mitigation problem of spurious correlation for prompt adjustment in visual language models. To achieve this, the authors maximize the probability of necessity and sufficiency corresponding to cross-modal and textual logical alignment. Theoretical analysis proves that the proposed method has a tighter generalization error bound compared to existing approaches. Performance is analyzed across a few different test data distributions, and components of the method are ablated.",
        "strengths": "The generalization error bond of the presented method is provided with theory analysis in Appendix A. \n\nThe novelty of the method is how to integrate the probability of necessity and sufficiency in multi-modal learning.",
        "weaknesses": "The paper is not easy to follow. This is due to the symbols being confused, e.g., $\\Phi$ denotes the filter in Cross-modal logic alignment but visual representation space in Textual logic alignment. \nWhile the first half of the paper explains the idea and motivation well, creating a rightful sense of expectation of the result, the section on the results somewhat comes short of delivering the findings with a bang.  After reading the first half I was excited to read the next pages to find \"Where are those indeed integrated areas for boosting the expected performance \", and tingling with an expectation of learning something new. But then, for some reason, the Overall Performance and Ablation Study sections are very timid and just present dry numbers for each of the tests that were planned.  \n\n1. It would be helpful to include a better explanation of what the \"spurious correlation in vision-language models\" is exactly. Maybe a picture. \n2.The paper borrowed too much content from the existing papers and it could be removed by referring these papers. Even so, the motivation is not clear since the authors employ PNS without explanation.\n\n3. Page 6, Section 4.1: The NSC feature shown Figure 1 is not explained by the authors themselves how to make use and take advantage of this. \n\n4. Compared to CoOPood,  it seems that the proposed method exploits PNS terms instead of mutual information to align cross-modal representations. I am wondering how effective the PNS term is in cross-modal mitigation of spurious correlation.  \n5. Why was it necessary to do textual logic alignment?"
      }
    ],
    "rating_avg": 5.0,
    "confidence_avg": 3.25,
    "decision": "Reject",
    "meta_review": "This paper aims to tackle the issue of cross-modal spurious correlation for parameter-efficient prompt tuning of VLMs. This work pointed out that cross-modal mitigation of spurious correlations during prompt tuning of vision-language models remains an open question, and further proposed the logic of logic alignment and a practical framework to calculate the probability of necessity and sufficiency (PNS) between the textual label and textual representations.\n\nThis paper recevied diverse ratings, i.e., 6, 6, 5, 3. The AC has read reviewers' comments, authors' responses, and the revised version.  The idea of calculating the probability of necessity and sufficiency and analyzing the cross-modal spurious correlation for the aspect of causal inference is novel. The main reasons for reject are that (1) the paper has been revised significantly to include more experimental results and quantitive analysis compared to the original version, which indicates that the submission is not fully ready for publication, (2) although the performance comparisons with PromptSRC and DePT have been included in the revision, the performance gap between the proposed method, PromptSRC and DePT are marginal, and the reasons on why the gap is marginal is not discussed. (3) The presentation of the paper is not good, which is not easy to follow the idea and contributions. Therefore, the AC does not recommend the current submission as accept.",
    "author_remarks": "",
    "decision_comment": ""
  },
  {
    "id": "ayT4e9C3Gd",
    "title": "ROSARL: Reward-Only Safe Reinforcement Learning",
    "authors": [
      "Geraud Nangue Tasse",
      "Tamlin Love",
      "Mark Nemecek",
      "Steven James",
      "Benjamin Rosman"
    ],
    "abstract": "An important problem in reinforcement learning is designing agents that learn to solve tasks safely in an environment. A common solution is to define either a penalty in the reward function or a cost to be minimised when reaching unsafe states. However, designing reward or cost functions is non-trivial and can increase with the complexity of the problem. To address this, we investigate the concept of a Minmax penalty, the smallest penalty for unsafe states that leads to safe optimal policies, regardless of task rewards. We derive an upper and lower bound on this penalty by considering both environment diameter and solvability. Additionally, we propose a simple algorithm for agents to estimate this penalty while learning task policies. Our experiments demonstrate the effectiveness of this approach in enabling agents to learn safe policies in high-dimensional continuous control environments.",
    "keywords": [
      "Reinforcement Learning",
      "Deep Reinforcement Learning",
      "Safety",
      "Safe AI",
      "Safe RL"
    ],
    "venue": "ICLR",
    "year": 2025,
    "pdf_url": "https://openreview.net/pdf?id=ayT4e9C3Gd",
    "forum_url": "https://openreview.net/forum?id=ayT4e9C3Gd",
    "reviews": [
      {
        "rating": "6",
        "confidence": "3",
        "summary": "This paper addresses the difficulty of reward/cost engineering in Safe RL by proposing a minimax penalty. Particularly, it uses notions of environment diameter and solvability to bound on both sides and estimate the minimum penalty for unsafe states that leads to optimally safe policies independent of task rewards.",
        "strengths": "- well-motivated\n- extensive experimentation \n- good theoretical justification\n- good study of success/failure cases of proposed approach and baselines",
        "weaknesses": "- consider adding up/down arrows to indicate if higher/lower values are good in the graphs (Average Returns(↑) and Failure Rate(↓))\n- consider citing some works on feasibility/reachability in RL\n\nMinor errors:\n-Definition 1 typo “sThen”"
      },
      {
        "rating": "5",
        "confidence": "3",
        "summary": "This paper introduces Reward-Only Safe RL (ROSARL), a novel safe RL agent that focuses on learning appropriate penalties for unsafe states rather than using explicitly constructed constraints or human-designed penalties. The key technical contribution is the concept of a \"Minmax penalty\" - the smallest penalty for unsafe states that guarantees safe optimal policies regardless of task rewards. The authors derive theoretical upper and lower bounds on this penalty based on environment diameter and solvability. A practical algorithm is designed for estimating the minimax penalties during under model-free RL setting. The authors empirically demonstrate that the resulting algorithm yields stronger and safer performance on grid world and PILLAR environments, compared to selected baseline methods like CPO and TRPO-Lagrangian.",
        "strengths": "- The theoretical proofs are clearly and correctly stated.\n- The motivation is clear and well-written.\n- The proposed practical algorithm is simple (in a good) that can be integrated with existing RL methods.",
        "weaknesses": "- The practical algorithm uses a simplified estimate that does not explicitly consider solvability. Moreover, the algorithm leverages value function estimates as approximations without theoretical guarantees. More analysis for addressing the gap between the theoretically constructed objectives and the actual practical objective used would significantly improve the paper.\n- There are two main issues with the experimental study. Firstly, only two environments are used for empirical evaluation of the proposed algorithm, whilst one of them is grid world. Secondly, there are limited analysis of failure cases, which I believe might contain interesting insights. \n- Some minor issues. It would be useful to include some crucial baseline comparisons, such as PID-Lagrangian (Stooke et al. 2020). Also, there is no analysis or ablation studies on the computational complexity of the proposed algorithm, hindering its practical applicability."
      },
      {
        "rating": "5",
        "confidence": "4",
        "summary": "The paper discusses a reward-only safe RL as an alternative to reward-shaping RL, and constraint-based RL for safe RL. The main idea is to compute the minmax penalty, which will be used to re-cast the problem so that a safe policy can be computed using standard RL methods. The method is evaluated on classical methods such as TRPO Lagrangian, CPO and a newer method called Saute RL with TRPO backbone. The environment is quite challenging and coming from the safety gym.",
        "strengths": "1. This is a different and possibly a new method to view safe RL \n2. The paper is quite well-written, however, I believe the algorithm is not described in the best way (see weaknesses) \n3. The authors present novel theoretical results and then discuss their strengths and limitations. In particular, they discuss convergence, computational complexity, applicability of the results",
        "weaknesses": "1. The algorithm is not well-described. It’s hard to understand the mathematical formulation of the problem and the solution. \n2. Experimental results are limited in scope and some of the conclusions are slightly misleading. \n            a. For example, Saute RL solves a problem with probability one constraints and cannot be directly compared to TRPO Lagrangian which solves the problem with constraints on average. Especially, when the environment is highly stochastic.\n            b. There are other baselines that the authors could compare to, to make their case. I recommend looking into implementations in https://github.com/PKU-Alignment/safety-gymnasium\n            c. There’s no ablation study\n3. Presentation of the paper focuses on the theoretical results, which are hard to judge without an explicit mathematical problem formulation. \n4. The experimental part is hard to evaluate due to the lack of details, for example the algorithm is not even in the main paper (it’s in appendix)."
      },
      {
        "rating": "5",
        "confidence": "4",
        "summary": "The paper tackles the problem of solving tasks safely using reinforcement learning. The main idea of the paper is to introduce a term to appropriately penalise unsafe behaviour, the analysis of the paper seeks to bound the magnitude of this term to minimise the probability of arriving at an unsafe goal state while achieving the task. To develop this term, the authors establish several objects required to quantify the complexity and \"size\" of the problem. These two measures are then used to construct the additional reward term to adhere to the safety criterion. It is then shown theoretically that adding a reward term that adheres to certain inequality constraints ensures a high degree of safe behavior.",
        "strengths": "The paper addresses an important challenge with an intriguing idea. Beyond supplying solely theoretical results, the paper provides a practical method suggested by the theoretical analysis. The results suggest that the method leads to a notable reduction in safety costs which is one of the main stated goals of the paper. \n\nThe intuition of the paper is largely clear and most of the non-technical parts are nicely written and overall the concepts well-explained. The authors have included a practical example midway through the paper which is useful for discussing the ideas in a concrete setting and explaining some of the concepts.",
        "weaknesses": "===Analysis===\n\nA1. Some parts of the paper aren't written with a high level of rigour, for example, the experiments of Section 5 are divided into parts depending on whether the \"theoretical assumptions are satisfied\" but there is no clear statement as to what exact assumptions this refers to. Additionally, there are a few typos in the mathematical expressions e.g., the argument of the min and max operator should be $s_T$ not $s$. There are other examples and some more technical concerns I have such as the existence of $D$ - I have given more details of this concern below. Other more minor  points  are as follows:\n\n   **In Definition 2 the case of equality is not covered.\n\n   **Theorem 1 is a bit pointless - perhaps the authors could consider writing it as a note within the text.\n\nA2. I am finding it difficult to understand how the object in Definition 3 could be computed. Although the restriction to proper policies ensures the goal state is reached in a finite number of time-steps, in a given environment, for any deterministic policy I may be able to increase the number of time steps it takes to reach the goal by for example asking the agent to go back on itself before going forward again. In this case, it is unclear whether such a maximum exists (although the function T may be upper bounded on the set of proper policies, its image is not a closed set).\n\nA3. I found it slightly troubling that many of the key results and characterisations are derived using the solvability parameter $C$ an then because calculating this is impractical as the authors acknowledge, the algorithm put forward uses a replacement for $C$ without rigorous explanation as to whether the resulting calculations are good proxies. Indeed, although some intuition is provided as to why all is not lost by omitting $C$ in the calculation, the effect of this omission on the computations and overall behaviour is not properly studied.\n\n===Experiments===\n\nB1. A possible concern is that although from the empirical evaluation the method does reduce the total costs by an appreciable amount, this seems to come at a heavy price in the returns. Is there a configurable parameter that can control this trade-off. I would also like to see a comparison to the baselines that allow this trade-off to be configured, specifically considering a range of values for the parameter that controls this trade-off.\n\nB2. Overall, I did not find the experimental results to be extremely compelling, firstly the results themselves suggest that the method reduces costs at a significant price to the rewards but also, the environments are quite simple and the method has not been tested on a range of complex environments e.g. safety gym."
      }
    ],
    "rating_avg": 5.25,
    "confidence_avg": 3.5,
    "decision": "Reject",
    "meta_review": "The paper proposes a safe RL algorithm, Reward-Only Safe RL (ROSARL), that learns penalties for unsafe states (behaviors) rather than using predefined penalties. The main technicality is the concept of minmax penalty, i.e., the smallest penalty for unsafe states that guarantees safe optimal policies (independent of task rewards). The authors derive theoretical bounds on this penalty based on environment diameter and solvability.They propose a method for estimating the minimax penalties in a model-free RL setting. Finally, they empirically evaluate their algorithm and compare it with CPO and TRPO-Lagrangian. \n\n(+) The paper addresses an important challenge with a novel idea. \n(+) The motivation behind the work is well-explained. The paper is well-written, although reviewers think the algorithm could be explained better and parts of the paper, especially in the experimental section are not written rigorously. \n(+) The paper has a good balance of theory and algorithmic implementation. \n\n(-) The reviewers found the scope of the experiments limited and some conclusions from them slightly misleading. They also feel comparison to newer baselines would be necessary. Overall, They did not find the experimental results compelling.\n(-) The practical algorithm is obtained using a rough estimate from the theoretical results. There is not much in the paper to identify the gap between the theoretically constructed objectives and the one used by the practical algorithm.\n(-) The reviewers are not satisfied with the way that the algorithm is explained. Moreover, they found parts of the paper, especially in the experimental section not written rigorously enough. \n\nI see this as a borderline paper. Thus, I strongly recommend that the authors revise their work using the reviewers' comments and prepare it for an upcoming venue.",
    "author_remarks": "",
    "decision_comment": ""
  },
  {
    "id": "H9dNX6TaRE",
    "title": "Mitigating Reward Over-optimization in Direct Alignment Algorithms with Adaptive Importance Sampling",
    "authors": [
      "Nguyen Minh Phuc",
      "Ngoc-Hieu Nguyen",
      "Binh T. Nguyen",
      "Khoa D Doan"
    ],
    "abstract": "Recently, Direct Alignment Algorithms (DAAs) such as Direct Preference Optimization (DPO) have emerged as alternatives to the standard Reinforcement learning from human feedback (RLHF) for aligning large language models (LLMs) with human values. Surprisingly, while DAAs do not use a separate proxy reward model as in RLHF, their performance can still deteriorate due to over-optimization – a phenomenon found in RLHF where the policy can exploit failures of the reward model to achieve high rewards but the actual quality of the model begins to degrade. Recent studies find that DAAs tend to increase probability mass on out-of-distribution responses and the training objective in DAAs is heavily under-constrained on these out-of-distribution (OOD) responses due to a mismatch between offline distribution and the LM policy. In this paper, we propose a method to mitigate the distribution shift between the offline distribution and the LM policy by multiplying with an importance weight to reflect the policy distribution. The resulting method, called Adaptive Importance Sampling (AIS), relies on importance sampling techniques and resolves the high variance issue in importance sampling without extra hyper-parameters. Our experiment results showed Adaptive IS can improve win rates by 15% while maintaining a lower KL budget compared to DAAs.",
    "keywords": [
      "Reinforcement Learning From Human Feedback",
      "Direct Preference Optimization",
      "Reward Hacking"
    ],
    "venue": "ICLR",
    "year": 2025,
    "pdf_url": "https://openreview.net/pdf?id=H9dNX6TaRE",
    "forum_url": "https://openreview.net/forum?id=H9dNX6TaRE",
    "reviews": [
      {
        "rating": "6",
        "confidence": "4",
        "summary": "This work addresses the reward optimization problem in direct alignment algorithms (DAAs) from the angle of distribution shift. In existing DAAs, the KL estimation is only unbiased when the samples are on-policy. However, as the policy being updated during learning, the responses from the offline dataset become off-policy, and thus distribution shift happens.\n\nTo address this issue, the authors propose adaptive importance sampling (AIS) as a solution. Assuming the preference data are generated from the SFT policy, AIS applies an importance sampling weight on each data point to correct the off-policyness. This weight term is further adapted by an exponential coefficient which is the inverse of the response length to tradeoff the bias and the variance. AIS is first evaluated in a toy example and demonstrates better estimation of the KL divergence than its unweighted counterpart. When combined with DPO, AIS demonstrates better KL-win rate tradeoff and higher peak performance than the baseline in a simulated setup, following Gao _et al_, 2022. The authors also conducted some empirical analysis in the simulation setup to understand the detriment of distribution shift.",
        "strengths": "This work addresses a widely observed phenomenon where DAAs like DPO suffers from reward overoptimization even before completing the first epoch of the dataset. Insights into this phenomenon can help us understand the underlying mechanism of DAAs  and resolving this issue can mitigate the gap between online and offline algorithms and can provide us with computationally cheap yet performant alignment algorithms.\n\nThe proposed solution, AIS, is a principled algorithm with well-understood theoretical grounding. Empirically, AIS demonstrates more effective KL regularization and strong performance over the baseline. AIS is simple, easy to implement, and preserves the low computational cost of offline DAAs.\n\nIn terms of presentation, overall the paper is easy to follow. The work is well motivated and the method is clearly explained. The authors did a good job connecting to existing works in the literature.",
        "weaknesses": "Important analysis on the proposed AIS method is missing. Importance sampling is one of the simplest techniques to address off-policy learning. The authors claim that vanilla IS suffer from high variance and thus an adaptive heuristic is applied to make a tradeoff between the bias and the variance. However, there is no analysis into this adaptive heuristic to justify its necessity and to provide insights into how this tradeoff impacts the overall performance.\n\nSimilarly, the empirical analysis in Section 4.3 demonstrates the detriment of distribution shift to DAAs. One natural question to ask is, as a method proposed for addressing distribution shift, how does AIS perform in these experiments? The current study does not provide any results to answer this question.\n\nOne limitation the authors did not call out in the limitation section is that AIS assumes that the preference dataset is generated from the SFT policy. However, this is not always the case in practice. Usually the responses in the preference dataset are sampled from different generations of the same data class, or even from different model classes. Thus this assumption is often violated and it hinders the effectiveness of AIS.\n\nPresentation-wise, the authors use inconsistent / incorrect citation formats through the paper. Calandriello _et al_ '24 should be cited in Section 3.1 for online DDAs. There are a few typos in writing. I think it should be \"budget\" in the last sentence of the abstraction. The Azar '23 and Gheshlaghi Azar '24 citations are citing the same paper. \n\n## References\nCalandriello _et al_ '24, Human Alignment of Large Language Models through Online Preference Optimisation, ICML 2024."
      },
      {
        "rating": "3",
        "confidence": "4",
        "summary": "The paper primarily deals with the issue of reward over-optimization in specifically Direct alignment algorithms and proposes an adaptive low variance importance sampling strategy to mitigate the issue, with an exponential smoothing technique that balances bias and variance in IS estimates. The proposed method effectively reduces over-optimization by achieving higher model win rates and maintaining a lower KL divergence budget than baselines.",
        "strengths": "The paper primarily deals with the issue of reward over-optimization in specifically Direct alignment algorithms. The over-optimization issue is an extremely critical concern in the current alignment paradigms, and arises due to a distributional shift between offline training data and the LM's current policy, leading to increased probability on out-of-distribution (OOD) responses. The paper introduces an adaptive importance sampling strategy to mitigate the distributional shift issue using an exponential smoothing technique that balances bias and variance in IS estimates.",
        "weaknesses": "1. The importance sampling term defined in the equation in line 212, suggest that the original equation is E_{\\pi_{\\theta}}[\\rho_theta]? Can you mathematically show why thats the case? In the context of online RLHF, it makes sense as shown in [1], but in offline whats the exact ideal optimization objective, leading to this importance weight? Can you specify, will be helpful. Also, highlight the difference from [1].\n2. Whats the mathematical motivation behind choosing the value of the alpha? How does it affect the convergence?\n3. There are several works on pessimism based methods to achieve reward over-optimization which are similar in principles, hence its not clear the novelty of the proposed work. A detailed comparison and contrast is critical to understand the novelty of the proposed approach.\n\nReferences:\n\n[1]. Sail: Self-improving efficient online alignment of large language models\n\n[2]. Iterative data smoothing: Mitigating reward overfitting and overoptimization in rlhf\n\n[3]. Provably Mitigating Overoptimization in RLHF: Your SFT Loss is Implicitly an Adversarial Regularizer\n\n[4]. Provably Mitigating Overoptimization in RLHF: Your SFT Loss is Implicitly an Adversarial Regularizer"
      },
      {
        "rating": "8",
        "confidence": "4",
        "summary": "This paper proposed to use adaptive importance sampling during offline post-training alignment of LLMs as a way to reduce over-optimization. They use a smoothed exponential IS estimator (where the exponent is the reciprocal of the length of the generation) in order to reduce the variance of the IS in exchange for some bias. Their experiments show that with this smoothed IS correction, they are able to reduce over-optimization in DPO and IPO and reach better performance in a lower KL budget in the TL;DR summarization task. They also show that distribution shift is indeed problematic and makes over-optimization worse.",
        "strengths": "-  The idea is simple and easy to integrate into existing algorithms like DPO and IPO as done in the paper.\n-  The paper shows clear gains in terms of less overfitting and better performance per KL budget.",
        "weaknesses": "Overall, some more ablations or more in-depth investigation is lacking. There isn’t a good understanding of how important picking alpha is for the experiments. There is also not an investigation into how distribution shift (section 4.3) interacts with IS. See questions for more details."
      },
      {
        "rating": "3",
        "confidence": "4",
        "summary": "This paper studies the reward-optimization issue in aligning large language models. It focuses on direct alignment methods, such as Direct Preference Optimization (DPO) and Identity Preference Optimization (IPO). The paper argues that these issues arise from off-policy distribution shifts between the learning policy and the reference policy. Accordingly, an importance-sampling weighting term with adaptive schemes is proposed. Experiments with Pythia models on the TL;DR dataset are conducted.",
        "strengths": "- The idea of using importance sampling to address distribution shift is not new, but it sounds interesting in the context of direct alignment methods.\n- This paper is well-written and easy to follow.\n- Numerous empirical results are presented, along with their limitations (see below).",
        "weaknesses": "- This paper lacks technical depth. It studies the distribution shift issue in DPO, which is a valuable perspective. Unfortunately, it fails to explicitly point out or mention that DPO's gradient estimator is not unbiased because the data distribution is defined by the data-collection distribution policy $\\pi$ (see previous works [1, 2]). Furthermore, it fails to justify that the proposed gradient estimator is unbiased. The reviewer believes that it is not theoretically unbiased. In fact, the importance sampling weight requires the optimal policy $\\pi^*$, which is not available a priori.\n\n[1] Liu, Tianqi, et al. \"Statistical rejection sampling improves preference optimization.\" *arXiv preprint arXiv:2309.06657* (2023).\n\n[2] Xiong, Wei, et al. \"Iterative preference learning from human feedback: Bridging theory and practice for RLHF under KL-constraint.\" *Forty-first International Conference on Machine Learning*. 2024.\n\nFrom the reviewer's perspective, there are two factors in DPO's formulation that prevent it from finding the true optimal policy:\n\nFirst, DPO uses a fixed and offline dataset, where the data distribution does not originate from the optimal policy. \n\nSecond, DPO employs KL regularization with a fixed policy. To address these issues, two simple strategies can be applied: periodically updating the reference policy [3] or using entropy regularization [4].\n\n[3] Guo, Shangmin, et al. \"Direct language model alignment from online AI feedback.\" *arXiv preprint arXiv:2402.04792* (2024).\n\n[4] Xiao, Jiancong, et al. \"On the Algorithmic Bias of Aligning Large Language Models with RLHF: Preference Collapse and Matching Regularization.\" *arXiv preprint arXiv:2405.16455* (2024).\n\n- The superiority over other simple baselines is unclear. A straightforward way to address the distribution shift issue is to use a moving average of the reference policy that can ensure the policy moving beyond the KL contraint. \n\n- Experimental results are weak. The experiments are conducted on the TL;DR dataset, which unfortunately has very short response lengths, and the Pythia model used as a base is quite weak. Consequently, empirical conclusions and insights may have limited value for modern language models. Moreover, some experiment details are missing, which hinders reproducibility and understanding of key results."
      }
    ],
    "rating_avg": 5.0,
    "confidence_avg": 4.0,
    "decision": "Reject",
    "meta_review": "This work proposes methods to mitigate the reward over-optimization issues in direct alignment algorithms. The algorithm proposed is a low variance importance weighted sampling strategy that is meant to minimize this issue. Unfortunately, some technical issues were raised by the reviewers. These are things such as the unbiasedness of the DPO gradient estimator and others.",
    "author_remarks": "",
    "decision_comment": ""
  },
  {
    "id": "ErpRu7qMq1",
    "title": "GETMusic: Generating Music Tracks with a Unified Representation and Diffusion Framework",
    "authors": [
      "Ang Lv",
      "Xu Tan",
      "Peiling Lu",
      "Wei Ye",
      "Shikun Zhang",
      "Jiang Bian",
      "Ji-Rong Wen",
      "Rui Yan"
    ],
    "abstract": "Symbolic music generation aims to create musical notes, which can help users compose music, such as generating target instrument tracks based on provided source tracks. In practical scenarios where there’s a predefined ensemble of tracks and various composition needs, an efficient and effective generative model that can generate any target tracks based on the other tracks becomes crucial. However, previous efforts have fallen short in addressing this necessity due to limitations in their music representations and models. In this paper, we introduce a framework known as GETMusic, with “GET” standing for “GEnerate music Tracks.” This framework encompasses a novel music representation “GETScore” and a diffusion model “GETDiff.” GETScore represents musical notes as tokens and organizes tokens in a 2D structure, with tracks stacked vertically and progressing horizontally over time. At a training step, each track of a music piece is randomly selected as either the target or source. The training involves two processes: In the forward process, target tracks are corrupted by masking their tokens, while source tracks remain as the ground truth; in the denoising process, GETDiff is trained to predict the masked target tokens conditioning on the source tracks. Our proposed representation, coupled with the non-autoregressive generative model, empowers GETMusic to generate music with any arbitrary source-target track combinations. Our experiments demonstrate that the versatile GETMusic outperforms prior works proposed for certain specific composition tasks.",
    "keywords": [
      "Symbolic Music Generation",
      "Symbolic Music Representation",
      "Diffusion Model"
    ],
    "venue": "ICLR",
    "year": 2025,
    "pdf_url": "https://openreview.net/pdf?id=ErpRu7qMq1",
    "forum_url": "https://openreview.net/forum?id=ErpRu7qMq1",
    "reviews": [
      {
        "rating": "3",
        "confidence": "3",
        "summary": "The paper has two main contributions:\n\n1) A symbolic music representation consisting of a tracks-by-timesteps grid, where each grid cell contains a pitch token and a duration token.  Polyphony is handled by encoding a *combination* of pitches as a single token.\n\n2) A discrete diffusion framework that can handle arbitrary conditional generation tasks on the symbolic music grid, including unconditional generation.  For conditional tasks, the paper introduces extra flags that indicate whether each grid cell is part of the conditioning.",
        "strengths": "1) As far as I know this is the first application of discrete diffusion to symbolic music generation.\n\n2) The generated samples sound quite good!\n\n3) Evaluation seems good, with the caveat that I don't really trust any evaluation of generative music models :)",
        "weaknesses": "These are not in order of importance.\n\n1) There are already more symbolic music generation representations and models out there than I can keep track of, and they all sound pretty decent.  I consider this problem basically \"solved\" since the release of OpenAI's MuseNet (which had no accompanying academic paper).  It's not clear that this paper is a significant advance on what is already possible.\n\n2) The CoCoNet model by Huang et al. (https://arxiv.org/abs/1903.07227) uses a setup that is very similar to this paper: multiple tracks are generated with arbitrary segments fixed as conditioning; instead of diffusion, the remaining portions are generated iteratively using Monte Carlo sampling.\n\n3) The paper seems confused about the taxonomy of symbolic music representations, dividing the space into \"image-based\" and \"sequence-based\" representations.  Here it would make sense to examine the pitch and time axes separately.  Either axis can be treated in dense (\"image-based\") or sparse (\"sequence-based\") fashion.\n\n    With time, the main reason one might use a sparse approach is to handle expressive timing; the dense resolution becomes extremely high.  This paper does not model expressive timing and thus uses a dense approach, with exactly two tokens per time step.  However, it's worth noting that the approach in the paper cannot easily be extended to handle not only expressive timing, but also things like triplets, without blowing up the time dimension.\n\n    With pitch, the main reason to use a dense approach is to handle polyphony; for monophonic music the pitch axis can be collapsed into a single value at each time.  However, for many polyphonic instruments e.g. piano, the space of possible pitches is quite large, making sparsity desirable.  This paper handles polyphony in a somewhat unique way, flattening variable-length combinations of notes into single tokens (see next item).\n\n4) The handling of polyphony is very unsatisfying.  For example, all combinations of piano notes are compressed to a vocabulary of 1555 tokens.  This isn't even enough to represent all pairs of piano keys!  And the drum vocabulary is almost 3 times as large as the piano vocabulary; how did this end up happening?\n\n    Here's a way polyphony could potentially have been handled that only minimally changes the setup.  On the input side, instead of blowing up the vocabulary with combinations of pitches, sum (or average) the token embeddings of all active pitches.  On the output side, instead of a softmax over pitch combination tokens, sample the binary presence/absence of each pitch independently (for a diffusion model, this independence should be okay since the other cells are sampled independently anyway) then sparsify.  This shouldn't increase memory usage since you need to construct the softmax vector anyway.\n\n    (It's entirely possible that you already tried the above suggestion and it ended up not working; if so please disregard.)\n\n5) I am not especially knowledgable about diffusion modeling, even less so about discrete diffusion.  But it's not clear whether the method in this paper goes beyond the standard approach.  From what I can tell, the use of condition flags is new, but that raises the question of why previous discrete diffusion methods didn't need to use such flags, and the paper provides no discussion of this."
      },
      {
        "rating": "3",
        "confidence": "4",
        "summary": "The paper introduces GETMusic, a framework designed for versatile symbolic music generation that supports generating any target instrument tracks based on provided source tracks. The GETMusic framework has two main components: GETScore, a novel music representation method, and GETDiff, a diffusion-based generative model.",
        "strengths": "The paper is well-structured and clearly presented, and it addresses several important scenarios for conditional generation in symbolic music generation.",
        "weaknesses": "The biggest weakness is the limited contribution, as diffusion models for symbolic music and conditional track generation have already been explored in previous work such as AccomMontage, SongDriver. The new representation method also lacks comparisons with alternative approaches.\n\nThe experiments are incomplete; each contribution requires validation. For instance, it’s unclear how the representation method outperforms others or how the diffusion model improves over baseline diffusion models. Additionally, more recent works should be included in task-level comparisons, as PopMAG was introduced four years ago. \n\nThis also suggests that the related work survey is incomplete, omitting recent studies on conditional generation in symbolic music."
      },
      {
        "rating": "6",
        "confidence": "4",
        "summary": "This paper describes a system for multi-track symbolic music generation, _GETMusic_. The authors introduce a new musical representation, _GETScore_, which compactly represents multi-track music in a two-dimensional token-based structure, and a neural model, _GETDiff_, a non-autoregressive discrete diffusion model trained to predict randomly masked tokens from symbolic music represented as a GETScore. The authors build on recent literature including piano-roll generation using diffusion models, and next-token autoregressive symbolic music generation. They evaluate their proposed system with objective musical metrics, as well as with a subjective listening test, comparing the musical quality with that of previous models. In both cases, the proposed approach performs better than the baseline.",
        "strengths": "Overall, this paper presents a generative system, which within the context of non-autoregressive generative models for symbolic music is an advancement. More specifically:\n\n- The GETScore musical representation is well motivated, formulated, and clearly described. The reviewer deems the proposed representation as novel in the context of previous literature. \n\n- As the authors note, GETScore is quite compact compared to the commonly used piano-roll representation. Even judged alone, GETScore is a serious contribution, and it's very possible that this representation will be useful for a variety of generative and MIR tasks, which could be useful to the community.\n\n- The details of GETScore and GETDiff are clearly presented. Specifically, Figures 2 and 3 are very helpful to understand the intricacies of GETScore.\n\n- There are a significant number of experiments presented in Section 4. Although systems for generative symbolic music are notoriously hard to evaluate, the authors make a significant attempt to do so as rigorously as they can. In all cases, the proposed approach performs excellently. \n\n- The musical samples provided on the demo page are impressive, suggesting that subjectively, this framework does well at symbolic music generation.",
        "weaknesses": "- There is a potentially significant issue of missing references. The training objective and inference process for the proposed model GETDiff is quite similar in nature to those used in Huang et al. [1], in which the authors propose a discrete training objective, predicting missing notes from piano-rolls which have been randomly partially masked. At inference time, they use blocked Gibbs sampling, which is reminiscent of the inference procedure outlined in Section 3.2. Although the proposed approach is multi-track, and the framing of GETDiff as a discrete diffusion model changes the loss function, at the very least this work should be referenced and the similarities should be addressed in the related work. Some other relevant references are also missing, and are not present in ablation experiments, such as [2].\n\n- If I understand correctly, the ablation experiment in Section 5 (L457-463) is not very well designed. By using 14 separate prediction heads and presumably sampling each column in the GETScore with a single forward pass, the training objective isn't accurately represented for GETDiff AR. As an example, when predicting the length of a note, it is impossible for the model to condition directly on the pitch of the note that it is predicting, and instead can only condition implicitly on the distribution of possible pitches predicted by the model. This introduces mathematical issues which may be responsible for the degraded performance. A much better ablation would be to compare against a transformer-decoder trained to predict the next token for a flattened version of GETScore. This should be technically possible as it would only require a context-length of 512*14=7168. \n\n- There are some very minor issues about expressivity. According to our understanding, it is not possible to represent concurrent notes (e.g., chords) within a single track that have differing offsets.\n\n[1] Huang, C.Z.A., Cooijmans, T., Roberts, A., Courville, A. and Eck, D., 2019. Counterpoint by convolution. arXiv preprint arXiv:1903.07227.\n\n[2] Thickstun, J., Hall, D., Donahue, C. and Liang, P., 2023. Anticipatory music transformer. arXiv preprint arXiv:2306.08620."
      }
    ],
    "rating_avg": 4.0,
    "confidence_avg": 3.6666666666666665,
    "decision": "N/A",
    "meta_review": "",
    "author_remarks": "",
    "decision_comment": ""
  },
  {
    "id": "9e5syenoVE",
    "title": "Multiple-play Stochastic Bandits with Prioritized Resource Sharing",
    "authors": [
      "Hong Xie",
      "Yanying Huang",
      "Haoran Gu",
      "Defu Lian",
      "Enhong Chen"
    ],
    "abstract": "This paper proposes a variant of  multiple-play stochastic bandits tailored to resource allocation problems arising from LLM applications, \nedge intelligence applications, etc.  The proposed model is composed of $M$ arms and $K$ plays.  Each arm has a stochastic number of capacities, and each unit of capacity is associated with a reward function.  Each play is associated with a priority weight.  \nWhen multiple plays compete for the arm capacity, the arm capacity is allocated in a larger priority weight first  manner.  Instance independent and instance dependent regret lower bounds of $\\Omega( \\alpha_1 \\sigma \\sqrt{KM T} )$ and $\\Omega(\\alpha_1 \\sigma^2 \\frac{MK}{\\Delta} \\ln T)$  are proved,  where $\\alpha_1$ is the largest priority weight and $\\sigma$ characterizes the reward tail.  \nWhen model parameters are given, we design an algorithm named \\texttt{MSB-PRS-OffOpt} to locate the optimal play allocation policy with a computational complexity of $O(M^3K^3)$.   Utilizing \\texttt{MSB-PRS-OffOpt} as a subroutine, an approximate upper confidence bound (UCB) based algorithm is designed, which has instance independent and instance dependent regret upper bounds matching the corresponding lower bound up to factors of $K \\sqrt{ \\ln KT }$ and $\\alpha_1 K$ respectively.   To this end, we address nontrivial technical challenges arising from optimizing and learning under a special nonlinear combinatorial utility function induced by the prioritized resource sharing mechanism.",
    "keywords": [
      "Multiple-play stochastic bandit",
      "prioritized resource sharing",
      "regret bounds"
    ],
    "venue": "ICLR",
    "year": 2025,
    "pdf_url": "https://openreview.net/pdf?id=9e5syenoVE",
    "forum_url": "https://openreview.net/forum?id=9e5syenoVE",
    "reviews": [
      {
        "rating": "5",
        "confidence": "3",
        "summary": "The paper works within the MP-MAB framework and proposes a variant of the framework catered to LLM and edge intelligence applications. With these applications in mind, the work imposes additional structure in the form of their MSB-PRS Model. \n\nIn Section 3 they introduce the model and provide the problem formulation. In Section 4 they characterize the hardness of the problem and fundamental learning limits by providing lower bounds, In Section 5 they present their UCB based learning algorithms, and in Section 6 they present experiments validating their approach and comparing it to baselines from the literature.",
        "strengths": "1. New variant of MP-MAB with resource prioritization.\n2. Lower bounds characterizing the hardness of their problem variant\n3. UCB based algorithm for learning - ApUCB\n4. Instance dependent and instance independent upper bounds on ApUCB",
        "weaknesses": "In my opinion while there seem to be innovative and impactful ideas in the paper it can use a lot better presentation before being accepted. In this bullet I would highlight how Section 3 on the MSB-PRS Model is barely readable by being cluttered by endless notation. Such a presentation makes it incredibly hard to takeaway any intuitive mental pictures of the setup that could then serve as the basis of appreciating the methods presented in the remaining paper.\n\nActionable Suggestions:\nPlease add a high-level overview paragraph in Section 3 before introducing the model mathematically using the complete notation. Please include an illustrative example or visual representation of the MSB-PRS model alongside this new paragraph.\n\n2. The paper does a poor job of motivating their target applications with the exposition being limited to a few lines in the introduction with vague wordings. In particular the only reference to LLM applications reads the following in the introduction: \"in LLM applications, reasoning tasks and LLM instances can be modeled as plays and arms respectively. .... priority quantified by price, membership hierarchy\". Which by itself gives very little insight into how the modeling in the paper is good for this application.\n\nI would encourage the authors to expand on their motivating example by dedicating a sub section to explaining how the MSB-PRS model applies to LLM and edge intelligence applications."
      },
      {
        "rating": "3",
        "confidence": "3",
        "summary": "This paper presents a new framework called Multiple-Play Stochastic Bandits with Prioritized Resource Sharing (MSB-PRS), which belongs to the research area of multi-play multi-armed bandit. Within this framework, an efficient algorithm is developed to identify the optimal play allocation policy while maintaining low computational complexity. The study establishes lower bounds for both instance-independent and instance-dependent regret. Additionally, the proposed algorithm is based on the application of the classic Upper Confidence Bound (UCB). It maintains the same per-round computational complexity and achieves sublinear regret upper bounds that closely align with the established lower bounds.",
        "strengths": "The multi-play multi-armed bandit (MP-MAB) problem is a significant model in online learning, and I appreciate the efforts that the authors intest in solving an interesing model of it, that is the MSB-PRS problem. For it, an algorithm has been developed to identify the optimal play allocation policy with a specific complexity. The upper bounds on regret are close to the lower bounds (up to some factors) in both instance-dependent and instance-independent scenarios.",
        "weaknesses": "My main concern is that while this work provides rigorous theoretical analysis and proofs, I am still not entirely clear on its contributions. \n\nFirst, although the problem model is somewhat introduced, I find it challenging to connect it with specific examples of resource allocation. While the authors mention its applicability in high-interest areas like LLMs, they do not provide corresponding explanations. Is there a way to contextualize its application in LLMs, or could examples of practical applications be included? \n\nSecond, the authors offer some related work, but I still struggle to compare them with this study. To address this, I suggest including a table to compare the results of this work with previous findings. \n\nFinally, the experiments are overly simplistic; they do not thoroughly describe the experimental setups or compare it with other studies. While I appreciate the authors' efforts in deriving theoretical results, I believe there is still significant room for improvement in the presentation of this work."
      },
      {
        "rating": "5",
        "confidence": "4",
        "summary": "The paper extends the multi-play multi-armed bandit (MP-MAB) model to include a prioritized resource-sharing mechanism, referred to as MSB-PRS. The model targets resource allocation scenarios in LLM and edge intelligence applications, where different plays are assigned different priorities, and each arm has multiple but random capacities. The authors establish both instance-independent and instance-dependent regret lower bounds for the model and propose an efficient learning algorithm, MSB-PRS-ApUCB, which achieves order-optimal regret bounds. The authors also conduct simulations based on synthetic data to validate their proposed algorithm.",
        "strengths": "1. The introduction of prioritized resource sharing into the multi-play bandit framework is novel, nabling random arm capacities and differentiated priorities for various plays, which are well-suited for practical applications such as LLM and edge intelligence.\n\n2. The proposed MSB-PRS-ApUCB algorithm is thoughtfully designed and well-motivated, achieving regret bounds that closely align with the established lower bounds, up to acceptable factors.\n\n3. The synthetic experiments provide a good assessment of the performance of MSB-PRS-ApUCB compared to baseline algorithms.\n\n4. The paper is well-structured and clearly written, making it easy to follow.",
        "weaknesses": "1.  The learning component of the algorithm and the regret analysis are fairly standard, as there exists an optimal matching between players and arms, and the remaining thing is to target this optimal matching through UCB strategy, as done in much of the literature. However, I acknowledge that finding the optimal matching is not easy due to the nonlinear combinatorial structure of the utility functions.\n\n2.  The concentration bound in Lemma 5.4 seems incorrect. I believe the authors should use Lemma 9 from [Maillard, et al., 2017] instead of Lemma 10. Consequently, the inequalities in lines 977, 1006, and 1053 also appear to be incorrect. The authors should check these carefully."
      },
      {
        "rating": "5",
        "confidence": "3",
        "summary": "This paper considers a variant of the stochastic bandit problem where players can select multiple arms from a pool consisting of a fixed number of arms, with each arm's capacity following a time-invariant distribution. Players receive rewards only if the chosen arms have sufficient corresponding capacity. The objective is to maximize cumulative rewards over a fixed-horizon game. To address this problem, the paper proposes a new algorithm based on the philosophy of combinatorial bandits, along with learning the capacity distribution, under the assumption of an oracle's existence. For the proposed algorithm, the paper provides both lower and upper bound analyses on the regret to demonstrate its (near) optimality. Numerical experiments are conducted to validate the proposed algorithm and demonstrate improvements compared to benchmarks.",
        "strengths": "1. The paper considers a novel problem setting where the arm capacity is stochastic, unlike existing work.\n2. The paper also develops algorithms specifically to address this proposed problem setting.\n3. The theoretical effectiveness of the proposed algorithm is supported through both lower and upper bounds.\n4. The numerical experiments help illustrate the algorithm’s performance.",
        "weaknesses": "1. The paper mentions a use case for this problem setting in the LLM context. However, I am curious if this could be more practical, specifically whether it is something that could feasibly be deployed in that context.\n\n2. The existence of an oracle depends on locating the maximum weight matching, which is referenced from existing work. I wonder if this reference includes any theoretical guarantee supporting the claim that this oracle is theoretically optimal. Further justification would be beneficial here.\n\n3. The lower bound analysis lacks technical novelty.\n\n4. The real challenge posed by stochastic capacity is unclear. Existing work assumes deterministic arm capacity without requiring it to be known. It is difficult to assess whether the stochastic realization actually makes the problem more challenging (due to randomness) or possibly easier (given known observations)."
      }
    ],
    "rating_avg": 4.5,
    "confidence_avg": 3.25,
    "decision": "Reject",
    "meta_review": "This paper presents a new framework called Multiple-Play Stochastic Bandits with Prioritized Resource Sharing (MSB-PRS), which belongs to the research area of multi-play multi-armed bandit. Within this framework, an efficient algorithm is developed to identify the optimal play allocation policy while maintaining low computational complexity. There are many concerns raised by the reviewers for motivation and contribution, which are not addressed by the authors.",
    "author_remarks": "",
    "decision_comment": ""
  },
  {
    "id": "p5FWeNp5PC",
    "title": "Hessian-Informed Flow Matching",
    "authors": [
      "Christopher Iliffe Sprague",
      "Arne Elofsson",
      "Hossein Azizpour"
    ],
    "abstract": "Modeling complex systems that evolve toward equilibrium distributions is important in various physical applications, including molecular dynamics and robotic control. These systems often follow the stochastic gradient descent of an underlying energy function, converging to stationary distributions around energy minima. The local covariance of these distributions is shaped by the energy landscape's curvature, often resulting in anisotropic characteristics. While flow-based generative models have gained traction in generating samples from equilibrium distributions in such applications, they predominately employ isotropic conditional probability paths, limiting their ability to capture such covariance structures.\n\nIn this paper, we introduce Hessian-Informed Flow Matching (HI-FM), a novel approach that integrates the Hessian of an energy function into conditional flows within the flow matching framework. This integration allows HI-FM to account for local curvature and anisotropic covariance structures. Our approach leverages the linearization theorem from dynamical systems and incorporates additional considerations such as time transformations and equivariance. Empirical evaluations on the MNIST and Lennard-Jones particles datasets demonstrate that HI-FM improves the likelihood of test samples.",
    "keywords": [
      "Flow Matching",
      "Deep Generative Models",
      "Dynamical Systems"
    ],
    "venue": "ICLR",
    "year": 2025,
    "pdf_url": "https://openreview.net/pdf?id=p5FWeNp5PC",
    "forum_url": "https://openreview.net/forum?id=p5FWeNp5PC",
    "reviews": [],
    "rating_avg": null,
    "confidence_avg": null,
    "decision": "N/A",
    "meta_review": "",
    "author_remarks": "",
    "decision_comment": ""
  },
  {
    "id": "NNBAzdF7Cg",
    "title": "Binary Spiking Neural Networks as causal models",
    "authors": [
      "Aditya Kar",
      "Emiliano Lorini",
      "Timothée Masquelier"
    ],
    "abstract": "In this paper, we provide a causal analysis of  binary spiking neural networks (BSNNs)\naimed at explaining their behaviors. \nWe formally define a BSNN \nand   represent its  spiking activity\n  as a binary causal model.\nThanks to this causal  representation, \nwe are able to explain the output of the network\nby leveraging  logic-based  methods. \nIn particular,\nwe show that we  can successfully \nuse a SAT  (Boolean satisfiability) solver to  compute \n  abductive explanations from this  binary causal model. \nTo illustrate our approach, \nwe trained the BSNN on the standard MNIST\ndataset and applied our SAT-based  method  to\nfinding  abductive  explanations of  the network's classifications\nbased on pixel-level features. We also compared the found explanations against SHAP,  a popular \nmethod used in the area of explainable\nAI to explain ``black box'' classifiers.\nWe show that, unlike SHAP,\nour method guarantees that a found  explanation  does\nnot contain completely irrelevant features.",
    "keywords": [
      "Explainability",
      "Causal reasoning",
      "Spiking Neural Networks",
      "White-box"
    ],
    "venue": "ICLR",
    "year": 2025,
    "pdf_url": "https://openreview.net/pdf?id=NNBAzdF7Cg",
    "forum_url": "https://openreview.net/forum?id=NNBAzdF7Cg",
    "reviews": [
      {
        "rating": "6",
        "confidence": "3",
        "summary": "This paper introduces a novel approach to explaining Binary Spiking Neural Networks (BSNNs) by mapping their spiking activity into binary causal models (BCMs). The authors develop a SAT-based method for generating abductive explanations, ensuring only causally relevant input features are included, which advances interpretability and minimizes redundancy. This approach is unique in leveraging Boolean logic to capture the temporal dynamics of BSNNs, setting it apart from standard explainability methods like SHAP. Experimental results show that this method produces accurate and computationally efficient explanations, highlighting features that directly impact the model's decisions. Overall, the work provides a structured, logic-driven framework for enhancing transparency in spiking neural networks.",
        "strengths": "Since I am not really into causal models but in spiking NNs, it is hard for me to judge about the originality of the contribution. To me, the paper seems to be original, applying binary causal models to BSNNs in a way that uniquely captures their temporal dynamics through Boolean logic, setting it apart from existing explainability methods, especially in comparison to SHAP. The approach is communicated clearly, with definitions and examples that effectively illustrate the novelty of causal explanations in BSNNs. Overall, the paper provides a robust, innovative framework that could influence future standards in model transparency and causal explainability, if the authors can show that the framework can be generalized to larger real-world networks and problems. (I did not check the proof in the Appendix).",
        "weaknesses": "My main concern over this paper is the current presentation as a two-layer-only network (one hidden layer). It is hard to imagine all consequences when this approach is generalized to multiple hidden layers. My impression is that the computational effort of Algorithm 1 would increase exponentially, thus effectively excluding the possibility of applying the method to real-world problems."
      },
      {
        "rating": "6",
        "confidence": "2",
        "summary": "This paper proposes a causal-based interpretability method by mapping Binary Spiking Neural Networks (BSNNs) into binary causal models. Using a SAT solver to compute abductive explanations. This provides a new perspective for interpreting BSNNs and advancing BSNN research further.",
        "strengths": "As the authors stated, this is the first time BSNNs have been interpreted as causal models. I believe this provides a new perspective for understanding BSNNs.",
        "weaknesses": "1. This paper primarily relies on extensive formal language for its exposition. Adding some figures would be beneficial to enhance readers' understanding of the content.\n2. The experiments are limited to the MNIST dataset. It is recommended to include some other, more complex datasets for support."
      },
      {
        "rating": "6",
        "confidence": "5",
        "summary": "This paper presents a causal analysis of binary spiking neural networks by representing the spiking activity as a binary causal model and applying this model to a SAT (Boolean satisfiability) solver.\n\n\n---\n\nAfter reading the reviews and the rebuttal, I tend to accept this paper.",
        "strengths": "1. The idea of bridging SNN and Causal Inference is interesting.\n\n2. The experiments related to SAT solver seem significant.",
        "weaknesses": "1. This paper is hard to follow due to the poor presentation. Some symbols are confused.\n\n2. The motivation that employs BSNN rather than BNN is not clear. I cannot get the necessity of using spiking mechanism. Thus, it is better to explicitly compare the advantages of BSNNs over BNNs in the context of causal modeling."
      },
      {
        "rating": "6",
        "confidence": "3",
        "summary": "The authors introduced a method mapping binary (or ternary) spiking neural networks to binary causal models, which can then be used to perform abductive explanations (via a SAT solver) for the network's behavior. They applied this method to the MNIST classification task (3 classes for the binary case and 10 classes for the ternary case). The authors claim that their method provides a better explanation compared to SHAP, another explainability method.",
        "strengths": "- The idea of using binary causal models to explain binary spiking neural networks is novel\n- The technical aspects of the paper are precise and rigorous; the authors provide precise mathematical definitions and prove the proposition brought forth in the paper\n- The paper is written in an easy-to-follow manner",
        "weaknesses": "- It is not clear to me how the explanation provided by the binary causal model is a \"good\" explanation. While the authors make the implication that their method provides a better explanation than SHAP as SHAP can select features that are irrelevant, I think the paper would be improved if it included some evaluation metrics for explainability and, if possible, other bechmark methods alongside SHAP.\n- The proposed method seems to take a long time in searching for an explanation using the SAT solver, ranging from 5-11 hours, and this is  just for MNIST limited to 3 classes. It seems unlikely that this method is scalable to larger scale problems.\n- The authors do not report the results (both accuracy and computational analysis) for the BCNN (binary, not ternary) on the 10-digit MNIST dataset."
      }
    ],
    "rating_avg": 6.0,
    "confidence_avg": 3.25,
    "decision": "Reject",
    "meta_review": "This submission presents an explainability technique for binary spiking neural networks that makes use of a satisfiability solver. Reviewers agreed that the idea of bridging spiking neural networks with causal inference through binary causal models is novel and interesting. The paper provides a clear technical exposition of the approach. The area chair identified two critical limitations: restricted empirical evaluation and limited comparison with other explainability methods. (The comparison focuses solely on SHAP, without evaluating other established feature attribution methods like LIME, ICE, and other feature importance metrics that are widely used for neural network explainability.) During internal discussion, reviewers concluded that while the theoretical contribution is sound, the practical limitations and scalability concerns outweigh the novelty of the approach. The consensus suggests the work, while theoretically precise, may not meet ICLR's threshold for impact on representation learning methods.",
    "author_remarks": "",
    "decision_comment": ""
  },
  {
    "id": "uClUUJk05H",
    "title": "Compositional simulation-based inference for time series",
    "authors": [
      "Manuel Gloeckler",
      "Shoji Toyota",
      "Kenji Fukumizu",
      "Jakob H. Macke"
    ],
    "abstract": "Amortized simulation-based inference (SBI) methods train neural networks on simulated data to perform Bayesian inference. While this strategy avoids the need for tractable likelihoods, it often requires a large number of simulations and has been challenging to scale to time series data. Scientific simulators frequently emulate real-world dynamics through thousands of single-state transitions over time. We propose an SBI approach that can exploit such Markovian simulators by locally identifying parameters consistent with individual state transitions. We then compose these local results to obtain a posterior over parameters that align with the entire time series observation. We focus on applying this approach to neural posterior score estimation but also show how it can be applied, e.g., to neural likelihood (ratio) estimation. We demonstrate that our approach is more simulation-efficient than directly estimating the global posterior on several synthetic benchmark tasks and simulators used in ecology and epidemiology. Finally, we validate scalability and simulation efficiency of our approach by applying it to a high-dimensional Kolmogorov flow simulator with around one million data dimensions.",
    "keywords": [
      "Simulation-based inference",
      "Bayesian inference",
      "time series",
      "markovian simulators",
      "Amortized Bayesian inference"
    ],
    "venue": "ICLR",
    "year": 2025,
    "pdf_url": "https://openreview.net/pdf?id=uClUUJk05H",
    "forum_url": "https://openreview.net/forum?id=uClUUJk05H",
    "reviews": [
      {
        "rating": "6",
        "confidence": "3",
        "summary": "This paper proposes a simulation-based inference (SBI) method for state-space models where the transition dynamics is Markovian. The core idea is to simulate many single-state transitions and then aggregate them instead of simulating entire trajectories of time-series, so as to reduce the total number of simulator calls.",
        "strengths": "The paper addresses the relevant problem of computational complexity in SBI which arises when the simulator is costly to sample from. \n\nThe experimental evaluation seems thorough, and the results are significant for FNSE.",
        "weaknesses": "My main concern is related to the novelty of the paper. The main technical contribution lies in deriving the factorized NSE method, which as the authors mention, is an extension of the setting of the Geffner et al. (2023) paper to the Markov setting. An in-depth analysis/discussion around selecting the proposal $\\tilde{p}(\\mathbf x^t)$ and providing recommendations on its choice would have strengthened the paper significantly and added to the technical contribution. The paragraph discussing the proposal is kind of confusing. The authors say that \"there is lots of flexibility in the choice of the proposal...\", but also that \"...designing a good proposal can be challenging\". I appreciate the experiments evaluating the sensitivity of the results to the choice of proposal, but it is not clear how the proposals are chosen in the first place.\n\nThe clarity of writing can be improved by providing examples, especially when it comes to motivating the setting, the core idea, and the assumptions. For instance, the authors say \"...given sufficiently many single-step transitions, it should be possible to infer the global target...\". A discussion around the cases in which this does (and does not) hold would help the reader understand the scope of this work. Another example is the requirement that \"...the proposed state must be independent of the parameters involved in the current state transition...\", where it is not clear how restrictive this requirement is, what kind of cases does it cover, etc. Similarly, some examples of expensive real-world scientific simulators in para 3 of the intro would be nice to have.\n\nOn the topic of clarity, I found Section 3.2.2 difficult to follow. In particular, it is not clear when the authors are talking about background of previous work (Geffner 2023 and Linhart 2024), and which part is their contribution. Perhaps some of the discussion regarding the implementation details can be moved elsewhere, as they are not easy to follow without reading those two works anyway.  \n\nThe paper is presented as a sample-efficient method for Markovian time-series simulators. However, the experiments measure the performance as a function of the number of transitions. To conclude that the proposed method is \"simulation-efficient\", I would have expected performance to be plotted as a function the number of calls to the simulator (or computational cost) for a fixed number of transitions.  \n\nWould be nice to have a small discussion on other sample-efficient SBI methods in the related works (e.g. based on sequential sampling, Bayesian optimization, etc.).\n\nMinor comment: Typo in line 125-126 (the word \"approaches\")"
      },
      {
        "rating": "5",
        "confidence": "5",
        "summary": "The paper applies compositional score-matching, previously introduced for SBI on exchangeable models, to non-exchangeable, Markovian models. The appealing aspect of the methodology is that a score estimator can provide good posterior estimates without simulating the full process for each batch instance, but instead simulating single transitions per batch instance and learning to aggregate across time. The hope is that one can achieve the same posterior accuracy with less than $N * T$ evaluations, where $N$ is the simulation budget and $T$ is the maximum time horizon of the simulator.",
        "strengths": "- The paper is self-contained, easy to follow, and it attempts to address a challenging problem that is relevant to the field as a whole. \n- The method is applicable to different classes of SBI methods (e.g., likelihood approximation, likelihood ratio approximation, direct posterior estimation).\n- The idea is original and can stimulate further research into efficient SBI on dynamic models, especially when simulation budgets are scarce.",
        "weaknesses": "- As far as I understand it, the proposed method is a straightforward extension of FNPE with an additional input to the score estimator (Eq.6 in [1]). As such, the claim that a new “general SBI framework” is proposed requires some calibration. In contrast, the authors could highlight and extend the empirical aspects of the work.\n\n- While the basic idea is rather appealing, I find it a bit unconvincing that FNPE can robustly approximate the correct global posteriors with sparse training (the same goes for FNLE). There is an aspect of the methodology that strikes me as magical: suppose that most information about $\\theta$ in a time-varying signal is contained in later time segments (e.g., as in certain non-stationary signals) or subject to latent transitions (e.g., as in HMMs). It would be incredibly hard to get to that information if the simulation is not evolved for longer $T$, but the factorized approach is supposed to somehow get enough training signal from very sparse simulations in all relevant time windows. How is it possible for the score network to properly learn the correct composition without any assumptions on signal stationarity or smoothness? I assume the reasonable performance on the toy examples can be attributed to the rather short signal lengths and the use of simple, low-dimensional models (Fig.9 reveals striking miscalibration for longer time series on the only challenging model, confirming my fears). \n\n- Overall, the evaluation lacks robustness and I am concerned that it is subject to randomness given the extremely limited number of test simulations used (10!). Since the work is explicitly situated in an amortized inference context and pitched as such, the evaluation could have been much more comprehensive, featuring hundreds or even thousands of test simulations and at least some practically relevant metrics with an absolute interpretation, such as calibration error or other measures used for evaluating computational faithfulness in Bayesian analysis ([2]). In addition, there are no ablation studies (e.g., one such study could vary the simulation budget or use an adaptive solver for better-than-uniform sampling, another study can consider extremely long time horizons $T$), all models only have a few parameters (SIR and LV are toy models from the 60s, but presented as distinct from the toy model section), and it is hard to tell if the performance on the only non-trivial model (4.4) is acceptable given the lack of ground-truth and the poor calibration for not not even that long time horizons ($T=100$).\n\n- It may be helpful to clarify some points in Section 2.2 regarding related work on amortized inference. It might strengthen the section to highlight that amortized Bayesian inference is explicitly introduced in [3] and extensively discussed and expanded upon in inference compilation methods [4, 5, along with additional references therein]. Including this line of research could offer a more comprehensive overview of the field. Additionally, [6, 7] don't seem to introduce, discuss, or validate amortized methods; instead, they focus on sequential likelihood-free techniques, such as SNPE [7], without suggesting or claiming to use amortization. In fact, [6] cursorily note that learning over the prior predictive is possible but ultimately dismiss it as “grossly inefficient” (p.3). \n\n[1] Geffner, T., Papamakarios, G., & Mnih, A. (2023, July). Compositional score modeling for simulation-based inference. In International Conference on Machine Learning (pp. 11098-11116). PMLR.\n\n[2] Gelman, A., Vehtari, A., Simpson, D., Margossian, C. C., Carpenter, B., Yao, Y., ... & Modrák, M. (2020). Bayesian workflow. arXiv preprint arXiv:2011.01808.\n\n[3] Gershman, S., & Goodman, N. (2014). Amortized inference in probabilistic reasoning. In Proceedings of the Annual Meeting of the Cognitive Science Society (Vol. 36, No. 36).\n\n[4] Le, T. A., Baydin, A. G., & Wood, F. (2017). Inference compilation and universal probabilistic programming. In Artificial Intelligence and Statistics (pp. 1338-1348). PMLR.\n\n[5] Wu, M., Choi, K., Goodman, N., & Ermon, S. (2020). Meta-amortized variational inference and learning. In Proceedings of the AAAI Conference on Artificial Intelligence.\n\n[6] Papamakarios, G., & Murray, I. (2016). Fast ε-free inference of simulation models with bayesian conditional density estimation. Advances in Neural Information Processing Systems, 29.\n\n[7] Lueckmann, J. M., Goncalves, P. J., Bassetto, G., Öcal, K., Nonnenmacher, M., & Macke, J. H. (2017). Flexible statistical inference for mechanistic models of neural dynamics. Advances in Neural Information Processing Systems, 30.\n\n\n*Minor*\nSome attention to typos and neologisms is needed (e.g., P2L107 -> one can sample, …, to its probability density?, P7L377, etc.)."
      },
      {
        "rating": "8",
        "confidence": "4",
        "summary": "The paper proposes a class of methods to perform neural simulation-based inference on time-series data when the forward model has Markovian structure, i.e. when the next step only depends on the current one. This is the case in many physical systems defined by PDEs, for example. The method exploits this structure of the simulator / forward model to learn locally (in timestep) amortized estimators for global parameters of interest that describe the system in question. The paper exploits many recent advances in amortized simulation-based inference and adapts them to the Markovian time-series setting.",
        "strengths": "- The paper is exceptionally well-written. Secs. 2 and 3 set up the problem well, and describe the contributions in the context of existing literature. I feel like I learned a lot about the surrounding field beyond the specific contributions of the paper by reading these sections. Limitations are discussed upfront, and some extension settings explored in an initial way.\n- The experiments in the paper are well-motivated. The paper looks at toy models, standard benchmarks, as well as more challenging simulators that highlight some of the specific advantages of the method (e.g., generalization beyond the number of steps used during training).\n- The paper explores a timely question of broad scientific as well practical real-world interest. The generalization capabilities of the method beyond the number of timesteps trained for seem especially practical (and maybe should be highlighted more) -- many applications are bottlenecked by the inability to practically train on the longer-horizon timescales needed during deployment.",
        "weaknesses": "While the core methods are described nicely, some practical aspects receive less thorough treatment. Specifically, the proposal distribution seems like a critical design choice (especially for complex problems like Kolmogorov flow), and the score composition rules prove surprisingly robust even when their assumptions are violated (e.g. GAUSS in non-Gaussian setting). There is limited discussion of why, and limited principled guidance on these implementation choices that practitioners might need to apply the method to new domains. A more thorough discussion here could significantly strengthen the paper in particular for practitioners across domains."
      },
      {
        "rating": "6",
        "confidence": "4",
        "summary": "The authors introduce a novel approach for simulation-based inference (SBI) for time series models of which the joint probability density is Markovian. The work builds on the recently introduced framework of score-based generative models for SBI which aims to approximate the score of the posterior distribution when multiple data points (in this case time points) are conditioned on. They show that their approach is beneficial over a state-of-the-art method in time series benchmarks.",
        "strengths": "- The paper proposes an intuitive approach for SBI for (very) high-dimensional time series.\n- The topic (SBI for high-dimensional time series data) is very timely and relevant given the (seemingly) increased interested of applied researchers.\n- The paper is well written and easy to follow.",
        "weaknesses": "- Despite the intuitive idea, the proposed method is very incremental. As far as I can see, instead of modelling the score $s(\\theta_a|x^t)$ the paper proposes to model $s(\\theta_a|x^t, x^{t-1})$, i.e., adding one variable to the score network input, in order to make the method amendable for time series? \n- The evaluations are in my opinion not fully convincing. \n    - The authors chose to compare their approach to exactly one other baseline which I find a bit insufficient given the wealth of SBI methods and the fact that the authors propose approaches for local FNLE, FNRE and FNSE.\n    -  The baseline NPE uses an RNN as an embedding network. Given the authors assume Markovianity, they could have, e.g., just computed summary statistics and used this as conditioning variables, instead of running a costly RNN (which also needs to be trained in addition to the flow layers). Alternatively approaches that reduce the dimensionality more efficiently like neural sufficient statistics could have been benchmarked for a more thorough evaluation [1,3].\n  - Relatedly, there is work on high-dimensional SBI that the authors could potentially have included in their evaluations: [1-4]\n\n#### References\n- [1] Generalized massive optimal data compression, 2017, https://arxiv.org/abs/1712.00012\n- [2] Neural Approximate Sufficient Statistics for Implicit Models, 2021, https://arxiv.org/abs/2010.10079\n- [3] Is Learning Summary Statistics Necessary for Likelihood-free Inference?, 2023, https://proceedings.mlr.press/v202/chen23h.html\n- [4] Simulation-based inference using surjective sequential neural likelihood estimation, 2023, https://arxiv.org/abs/2308.01054"
      },
      {
        "rating": "6",
        "confidence": "4",
        "summary": "This work proposes a set of Simulation-Based Inference (SBI) methods to perform approxiamte Bayesian (parameter) inference given an\nobservation that takes the from of a specific class of timeseries (finite-length homogenous Markov chains).\nThese methods are adaptations of existing score, likelihood, and ratio-based estimation methods, whose original formulation\nassume i.i.d observations, and not observations arising from a Markov Chain.\n\nThe methods do so by estimating ratio/likelihood/scores \"locally\", e.g. to the individual factors of the Markov chain.\nThey then produce a \"global\" posterior estimate (e.g. an estimate of the posterior of the parameters given the entire Markov chain sample)\nby relying on the factorization structure of the Markov chain probability. The composition is straightforward in the case of ratio and likelihood methods,\nwhile when using scores, additional approximations are necessary due to the non-Markovian structure of the blurred posteriors estimated in the previous step.\n\nThese approximations are direct adaptations of the one already used in prior work:\n- one performs iterative Langevin-based sampling of an annealing path of distributions bridging from a standard Gaussian distribution to the true posterior, and whose intermediate distributions are precisely the SDE solutions whose scores were estimated.\n- one produces an approximation of the scores of the SDE initialized at the posterior of the parameter given the entire Markov trajectory, which can then be used to simulate trajectories from the time-reversed SDE, whose final iterate is marginally distributed according to the true posterior.\n\nThe performance of the method is investigated on a set of experiments, which include standard benchmark models and a Kolmogorov flow model with high dimensional observations. The simulators are adapted (using noise injection) to fit the formalism of stochastic inference methods.",
        "strengths": "The paper proposes a conceptually simple, attractive adaptation of SBI methods to Markov chains. For a total simulation budget, the shift towards learning the transition factor allows to increase the number of available observations. Moreover, learning the transition probabilities may be a simpler problem than learning the parameter-to-whole-timeseries relationship, as the observation is lower dimensional in the former case.",
        "weaknesses": "**Regarding Presentation**\n\nThe presentation of the method needs some improvements. \n\nFirst, regarding the the sampling part, the presentation of FNPE and Gauss do not define precisely key details of the approximations.\n- In FNPE, where is $q_a$ used for instance?\n- In GAUSS/JAC, What is $\\Sigma_{a,t, t+1}$?\n\nI had to look at each of the separate papers that introduced such approximations in the iid case to understand what was going on.\nThe paper should be updated to define all terms properly -- most of will constitute background. Even though the adaptations made by the method are almost independent from the these terms, the paper should remain self contained as far as the core method is concerned. To save space, the FNPE approximation method could be placed in the appendix, as it is not used in the experiments.\n\nSecond, the local score estimation section could also be made clearer: for instance, this section\nstarts by breaking down the true (unblurred) posterior (Equation (3)), highlighting how knowing the score of each\nfactor is enough to get the score of the resulting posterior. However, what is actually needed for sampling is the blurred posterior,\nwhich cannot be factorized as Equation (3). Equation (3) thus ends up not being very relevant to the method.\n\n\n**Regarding experiments**: the presentation of the Kolmogorov flow experiments is missing details: for instance, it does not include any mention of stochasticity, which is confusing given that the method is about estimating probability distributions.\n\n\n**Regarding performance**\n- The main weakness of the method right now is that the number of timesteps investigated in the paper remains smaller (up to 100)\ncompared to the regime of some application of interest, like neuroscience.\n- In the Kolmogorov flow experiments, the MAE of the posterior predictive significantly increases for when using 100 instead of 10. It would be nice if the authors commented on this point in the paper."
      },
      {
        "rating": "6",
        "confidence": "2",
        "summary": "The authors consider performing simulation-based inference for Markovian simulators. They propose two primary methods, based on score matching, and likelihood (ratio) estimation. In both cases, they utilize the Markovian structure to increase the efficiency of inference, by performing inference using data from single-state transitions, rather than requiring whole sequence simulation. In the likelihood case, the global likelihood is the product of the transition functions $p(x^{t+1}|x^t, \\theta)$ (eq. 1), which once estimated can be used with MCMC to infer the posterior. Similarly, for estimating the score, they again use the Markovian structure to factorize the score (eq. 3), and use a \"local\" score estimator to approximate the global score. In both cases, a proposal distribution is used, $\\tilde{p}(x^t)$, from which a sample is drawn, and a single transition is performed, which is used for learning.",
        "strengths": "The method is to the best of my knowledge novel and provides a solution to utilizing the known dependency structure of Markovian simulators; knowledge which is often neglected in simulation-based inference.  The application area is an important area and handling sequence data in simulation based inference is known to be often challenging (in terms of performance and computational cost). The experiments are convincing and consider a set of familiar but interesting models.",
        "weaknesses": "My main criticism is that the paper should include a clearer description of what might constitute a \"good\" proposal distribution $\\tilde{p}(x^t)$, especially when it is first introduced. I further feel that the requirement for choosing this proposal is a major problem for the practical utility of the introduced methods, and the authors should better address this problem. E.g. should we aim for it to resemble a prior predictive simulation for a randomly chosen $t$? Could the proposal $\\tilde{p}(x^t)$ be sequentially improved as the posterior is learned? The use of hand-picked simple distributions is somewhat concerning for broader applicability.\n\nSome smaller issues:\n- The names of the contributed methods, at least FNSE, should be introduced earlier, for example, in the final paragraph of the introduction (FNSE is in Figure 1, but it's easy to miss the name). \n- \"except FNRE; in LV\": I don't believe LV abreviation was introduced, presumably Lotka-Volterra.\n- Text size in figures is often a little too small.\n- There is a reasonable degree of entangling of previous work in section 3.2.2, which made it hard to read. For example, the abbreviation FNPE is introduced without definition, initially implied to refer to the method by Geffner. It is then introduced and thereafter used as an adaptation of the Geffner method. It also refers to a score-based method, so the use of NPE is confusing as it implies a neural posterior estimation method, using e.g. flows."
      }
    ],
    "rating_avg": 6.166666666666667,
    "confidence_avg": 3.6666666666666665,
    "decision": "Accept (Poster)",
    "meta_review": "The reviewers recommend acceptance (6-5-8-6-6-6). The paper presents a simulation-based inference approach for Markovian state-space models, leveraging the structure of the forward model to reduce the computational cost of the inference. The approach is well-motivated and the results are convincing. The author-reviewer discussion has been constructive and has led to a number of clarifications and improvements, with a better discussion of the related work and the addition of new results. The main concern raised by the reviewers is the incremental contribution of the paper, as the key idea appears to be a straightforward (but novel) extension of previous works. Nevertheless, the reviewers agree that the paper is well-executed and that the results are convincing. For these reasons, I recommend acceptance. I encourage the authors to address the remaining concerns and to implement the modifications discussed with the reviewers in the final version of the paper.",
    "author_remarks": "",
    "decision_comment": ""
  },
  {
    "id": "0bcUyy2vdY",
    "title": "Multi-play Multi-armed Bandit Model with Scarce Sharable Arm Capacities",
    "authors": [
      "Hanyang LI",
      "Hong Xie",
      "Defu Lian",
      "Enhong Chen"
    ],
    "abstract": "This paper revisits multi-play multi-armed bandit with shareable arm capacities problem (MP-MAB-SAC), for the purpose of \nrevealing fundamental insights on the statistical limits and data efficient learning. The MP-MAB-SAC is tailored for resource allocation problems arising from LLM inference serving, edge intelligence, etc. It consists of $K$ arms and each arm $k$ is associated with an unknown but deterministic capacity $m_k$ and per-unit capacity reward with mean $\\mu_k$ and $\\sigma$ sub-Gaussian noise.  The aggregate reward mean of an arm scales linearly with the number of plays assigned to it until the number of plays hit the capacity limit $m_k$, and then the aggregate reward mean is fixed to $m_k \\mu_k$. At each round only the aggregate reward is revealed to the learner. \nOur contributions are three folds.   1) \\textit{Sample complexity:} we prove a minmax lower bound for the sample complexity of learning the arm capacity  $\\Omega(\\frac{\\sigma^2}{\\mu^2_k} \\log \\delta^{-1})$, and propose an algorithm to exactly match this lower bound. \nThis result closes the sample complexity gap of Wang et al. (2022a), whose lower and upper bounds are $\\Omega(\\log \\delta^{-1})$ and  $O (\\frac{m^2_k \\sigma^2}{\\mu^2_k} \\log \\delta^{-1})$ respectively.  2) \\textit{Regret lower bounds:}  we prove an instance-independent regret lower bound   $\\Omega( \\sigma \\sqrt{TK} )$  and instance-dependent regret lower bound $\\Omega(\\sum_{k=1}^K\\frac{c\\sigma^2}{\\mu_k^2} \\log T)$.  This result provides the first instance-independent regret lower bound and strengths the instance-dependent regret lower bound of Wang et al. (2022a) $\\Omega(\\sum_{k=1}^K \\log T)$.   3) \\textit{Data efficient exploration:}we propose an algorithm named \\texttt{PC-CapUL}, in which we use prioritized coordination of arm capacities upper/lower confidence bound (UCB/LCB) to efficiently balance the exploration vs. exploitation trade-off.  We prove both instance-dependent and instance-independent upper bounds for \\texttt{PC-CapUL}, which match the lower bounds up to some acceptable model-dependent factors. This result provides the first instance-independent upper bound, and has the same dependency on $m_k$ and $\\mu_k$ as Wang et al. (2022a) with respect to instance-dependent upper bound.But there is less information about arm capacity in our aggregate reward setting.  Numerical experiments validate the data efficiency of \\texttt{PC-CapUL}.",
    "keywords": [
      "Multi-play multi-armed bandit",
      "scarce sharable arm capacity",
      "regret bounds"
    ],
    "venue": "ICLR",
    "year": 2025,
    "pdf_url": "https://openreview.net/pdf?id=0bcUyy2vdY",
    "forum_url": "https://openreview.net/forum?id=0bcUyy2vdY",
    "reviews": [
      {
        "rating": "6",
        "confidence": "3",
        "summary": "This paper revisits multi-play multi-armed bandit with shareable arm capacities problem. Improved on previous work Wang et al. (2022a), the paper proposes refined lower and upper bounds for both sample complexity and regret. For sample complexity, the authors propose a minmax lower bound, and give an algorithm that matches the bound. For regret, the authors provide both instance dependent and instance independent regret lower bounds, and find algorithms that match the bounds up to some model-dependent factors.",
        "strengths": "1. The work closes the sample complexity gap and narrow the regret gap for the MP-MAB problem. Although the techniques used in the proof are not particularly unique (mostly based on regular UCB and LCB), the conclusions are still very interesting and make sense.\n2. The work propose numerical simulation to show the advantages of their algorithms.",
        "weaknesses": "1. The writing is a bit poor. The paper contains many colloquial expressions, i.e., line 383 \"But if\", line 390, 403, 405 \"And furthermore\" \"And this\". \n2. The author states in the introduction that the algorithm has applications to LLM inference serving. I believe it’s necessary to provide some LLM-related experiments to support this statement."
      },
      {
        "rating": "8",
        "confidence": "4",
        "summary": "This paper studies the multi play multi-armed bandit problem having shared arm capacity where the in each round, the learner gets to select the arm for a number of pulls capped by the capacity limit with the goal of maximizing the total reward at the end of the play. The authors propose a new reward function and develop a new algorithm PC-CapUL for this problem setting. The developed algorithm provides tighter bounds on sample complexity and regret in comparison to the existing works, efficiently balances exploration and exploitation. The work is applicable in resource allocation problem with capacity constraint scenarios such as LLM inference and many other real world scenarios.",
        "strengths": "•\tThe problem of Multi play multi-armed bandit problem is an interesting setting to study and improve the foundation of it as it pertains to main real-world settings including LLM inference serving. The work re-establishes that with emphasis on theoretical guarantees.\n\n•\tThe work provides theoretical improvements in sample complexity compared to the existing work on  MP-MAB-SAC. It tends to close the sample complexity gap found in the previous work in Reference A\n\n•\tThe authors also provide a new Improved algorithm, PC-CapUL that performs much better than other existing algorithms and have a solid theoretical backing to it with proved theoretical Regret bound guarantees.\n\n•\tThe experiments cover the regimes where the number of arms is larger which predominantly requires more exploration to take place. The developed algorithm provides much better performance in terms of regret compared to other existing algorithms in this experimental setting.\n\nReference:\n [A] Xuchuang Wang, Hong Xie, and John C. S. Lui. Multiple-play stochastic bandits with shareable finite-capacity arms. International Conference on Machine Learning, ICML 2022.",
        "weaknesses": "•\tThe experimentation design could have been done much better with the inclusion of better baseline comparison in addition to the algorithm found in Reference A . Also, utilizing a real-world dataset for evaluation would have further complemented these theoretical results.\n\n•\tThe readability of the paper could be much improved. Also, a brief intuitive explanation like a proof sketch could be added in the main text to help the reader get the intuitive logic and understanding of the proof techniques. \n\n•\tA more detailed theoretical comparative analysis like how regret fares against the regret of other algorithms would make the argument much stronger for the developed PC-CapUL algorithm. Moreover, having such a discussion would also help us uncover insights like how the regret bound behaves in different regimes.\n\nReference:\n [A] Xuchuang Wang, Hong Xie, and John C. S. Lui. Multiple-play stochastic bandits with shareable finite-capacity arms. International Conference on Machine Learning, ICML 2022."
      },
      {
        "rating": "5",
        "confidence": "3",
        "summary": "This paper considers the problem of multi-play multi-armed bandits with scarce shareable arm capacities. Specifically, different from [Wang et al., 2022a], this paper considers the problem where $N\\geq \\sum_k m_k$ where $m_k$ is the capacity of action $k$. With a modification on the reward function, this paper proposes new sample complexity lower/upper bound that is tight as well as regret lower/upper bound for this problem. Specifically, the author claims that the sample complexity lower bound proven in this paper improves upon the one shown in [Wang et al., 2022a]. Empirical results are also shown to strengthen their theoretical findings.",
        "strengths": "- This paper first considers this problem with scarce shareable arm capacities and proposes both lower and upper bound for both sample complexity and the regret bound.\n- Based on the parts that I checked, the proofs look correct to me.\n- The experiments are also conducted to show superior performance compared to the previous work.",
        "weaknesses": "- One main concern is the motivation of this paper to consider the case where $N\\geq \\sum m_k$. In this case, the problem seems to be easier (in the sense of algorithm design) since you will definitely explore each action sufficiently enough to figure out the exact $m_k$ while in the opposite case $N< \\sum m_k$, the problem seems to be harder since you need to decide the exploration amount for the suboptimal $k$. Can the authors explicitly justify the choice of studying the $N\\geq \\sum m_k$ case and why it is challenging compared to the previous case?\n- This also leads to the question about the comparison between the lower/upper bound shown in this paper and [Wang et al., 2022a]. While the authors claim better lower bound, I wonder whether the upper/lower bound are comparable in these two cases? Can the algorithm that is derived in this setting adapted to the other? Moreover, I am not sure why equation (5) is more reasonable since it makes sense to me to have the noise's variance larger when $m_k$ or $a_k$ is large.\n- As for the upper bound, the bounds in Theorem 5 seems to be suboptimal since it seems to be dependent on $\\frac{\\max_i \\mu_i}{\\min_i \\mu_i}$, which can be large.\n- I do not understand the lower bound argument shown in Theorem 4. When the cost $c=0$, then this ratio becomes 0, which is surely not informative. In addition, why is the ratio independent of $m_k$? Can the authors explain more on this?\n- Typos:\n  - Line 223: it -> if\n  - Line 224: a_k -> a_{t,k}?\n  - Line 471: depended -> dependent \n  - Line 751: missing lemma reference.\n  - missing periods at the end of many theorem statements (e.g. Theorem 4,5,6..)"
      },
      {
        "rating": "3",
        "confidence": "4",
        "summary": "This paper discusses the problem of the Multi-play Multi-armed Bandit Model with Shareable Arm Capacities (MP-MAB-SAC). It tightens the lower bounds for both sample complexity and the cumulative regret compared to the previous work. Besides, this paper proposes corresponding algorithms to match the lower bounds. Finally, the numerical experiments show that the proposed algorithms outperform the existing ones.",
        "strengths": "The theoretical contributions are nontrivial. This paper shows tighter lower bounds, and then proposes new algorithms to match them. Furthermore, the experiments verified the theories.",
        "weaknesses": "I have the following concerns: \n\n1. The writing quality of this paper falls below the standards required for publication in ICLR. Issues such as clarity, rigor, and basic grammatical correctness are prevalent. It appears that the authors did not thoroughly review the paper before submission. From a writing perspective, the paper remains in draft form: numerous typos, confusing notations, and grammatical errors hinder readability. For example,  (1) in Lemma 2, $\\epsilon^{uE}$ should be $\\epsilon^{UE}$; (2) in the proof of Lemma 2 “Bourel et al., 2020” is even not cited; (3) in the proof of Theorem 1, which lemma is used here? Besides, this theorem should be proved more formally; (4) What is the first baseline “MP-MAB-SA” in the experiments?\n\n2. The explanations provided in the paper are insufficient. (1) In Section 1, more concrete examples of the model's practical applications are needed. (2) The claim that certain changes in settings make the model more suitable for LLMs requires stronger evidence. For instance, the movement cost $c$ (which is known to the learner) seems irrelevant. (3) The paper should provide a more in-depth analysis of the experimental results, going beyond mere statements of fact.\n\n3. The comparison with the previous work seems not fair. (1) Since $N \\ge M$ makes the learner only need to learn the capacity $m_k$, without needing to learn the rank of the arms, the learning task seems easier. (2) In lines 307~310, is there any evidence to show stability is getting better? Besides, I’m kind of confused about this result because the robustness v.s. regret usually has some trade-off, which means the increasing of stability may (not always) lead to the decreasing of performance."
      }
    ],
    "rating_avg": 5.5,
    "confidence_avg": 3.5,
    "decision": "Reject",
    "meta_review": "This paper addresses the multi-play multi-armed bandit with shareable capacities problem, presenting results on improved sample complexity, regret lower bounds, algorithms, and regret upper bounds. The primary concern with this paper lies in the subtle differences between the scenarios it addresses and those in prior work, raising questions about the fairness and validity of comparisons with existing results and lower bounds.  \n\nSpecifically, the paper focuses on cases where the number of plays $N$ exceeds the total amount of capacities $M$. However, this restriction might simplify the problem, and the paper does not provide a convincing explanation to justify this aspect. Additionally, there are several areas where the clarity and rigor of the writing, both in terms of narrative and mathematical descriptions, are lacking.  \n\nFor these reasons, I cannot support the acceptance of this paper at this time.",
    "author_remarks": "",
    "decision_comment": ""
  },
  {
    "id": "itwyfJilM5",
    "title": "Graph Scattering Networks with Adaptive Diffusion Kernels",
    "authors": [
      "Toan Van Tran",
      "Hung Son Nguyen"
    ],
    "abstract": "Scattering networks are deep convolutional architectures that use predefined wavelets for feature extraction and representation. They have proven effective for classification tasks, especially when training data is scarce, where traditional deep learning methods struggle. In this work, we introduce and develop a mathematically sound framework for applying adaptive kernels to diffusion wavelets in graph scattering networks. Stability guarantees with respect to input perturbations are provided. A specific construction of adaptive kernels is presented and applied with continuous diffusion to perform graph classification tasks on benchmark datasets. Our model consistently outperforms traditional graph scattering networks with predefined wavelets, both in scenarios with limited and abundant training data.",
    "keywords": [
      "graph neural networks",
      "graph scattering transform",
      "deep learning",
      "stability"
    ],
    "venue": "ICLR",
    "year": 2025,
    "pdf_url": "https://openreview.net/pdf?id=itwyfJilM5",
    "forum_url": "https://openreview.net/forum?id=itwyfJilM5",
    "reviews": [
      {
        "rating": "5",
        "confidence": "4",
        "summary": "This paper introduces Graph Scattering Networks with Adaptive Diffusion Kernel, which enhances traditional graph scattering networks by incorporating learnable kernels while maintaining mathematical soundness. The novel part is that it bridges the gap between fixed wavelet transforms and learnable architectures while preserving mathematical guarantees.",
        "strengths": "1. the authors propose a novel framework that  incorporate learnable kernels in graph scattering networks.\n2. prove that the adaptive kernels maintain symmetry and self-adjointness\n3. provide stability analysis for learnable kernels",
        "weaknesses": "1. As far as I understand, the adaptive kernel is restricted to self-adjoint operators for mathematical convenience.\n2. The weak performance raises questions about whether the theoretical advantages of the approach translate to practical benefits.\n3. The fundamental question \"Why adaptive scattering?\" is not convincingly answered in the paper. The theoretical contribution might be interesting, but its practical necessity and benefits are not well established."
      },
      {
        "rating": "5",
        "confidence": "3",
        "summary": "This paper proposes a mathematically sound framework for applying adaptive kernels to diffusion wavelets, thus overcoming the limitations of traditional graph scattering networks with predefined wavelets.",
        "strengths": "* Considering the importance of selecting an appropriate kernel, it is promising to develop a framework for application of adaptive kernels in graph scattering networks.\n\n* The proposed framework is bulit on mathematically sound foundation, and stability guarantees with respect to input perturbations are also provided, thus enhanceing its rationality and reliability.\n\n* The experimental results also demonstrated that it consistently outperforms traditional graph scattering networks.",
        "weaknesses": "The main problem with this paper is that its experiments are not convincing enough.\n\n* Baselines:\n    * Given that graph deep learning has developed rapidly in recent years, this paper lacks comparisons against the latest graph deep learning methods.\n    * More importantly, some typical graph scattering transform methods are not employed and compared in the experiments, such as GS-SVM [1] and GGSN+EK [2].\n\n* The experimental results can not support the clained superiority. \nAlthough the authors have given some explanations, why not further conduct some experiments to prove it? \nFor example, it's necessary to report the performance of deep learning methods when low training-data availability to prove the meaning of this work.\n\n[1] Gao F, Wolf G, Hirn M. Geometric scattering for graph data analysis[C]//International Conference on Machine Learning. PMLR, 2019: 2122-2131.\n\n[2] Koke C, Kutyniok G. Graph scattering beyond wavelet shackles[J]. Advances in Neural Information Processing Systems, 2022, 35: 30219-30232."
      },
      {
        "rating": "3",
        "confidence": "3",
        "summary": "This work introduces a method for incorporating adaptive kernels into graph scattering networks. The paper provides theoretical stability guarantees against input data perturbations, ensuring robustness. Experimental results demonstrate that adaptive kernels offer advantages over traditional scattering networks.",
        "strengths": "1. The theoretical analysis to support the advantages of the adaptive wavelet diffusion.",
        "weaknesses": "1. The authors highlight the limitations of traditional methods under low-data scenarios. However, the paper lacks theoretical analysis or specific experiments tailored to illustrate how the proposed adaptive kernel-based scattering networks (AGSN) address performance in data-scarce environments.\n\n2. The experimental results reveal that AGSN does not outperform some well-known graph classification techniques.\n\n3. The limitation of The Related Works. There are some works also related to adaptive kernels for graph neural networks, such as [1-2]. It is not clear the advantages of the proposed adaptive wavelet diffusion compared to others.\n\n[1] Sun, C., Hu, J., Gu, H., Chen, J. and Yang, M., 2020. Adaptive graph diffusion networks. arXiv preprint arXiv:2012.15024.\n\n[2] Zhao, J., Dong, Y., Ding, M., Kharlamov, E. and Tang, J., 2021. Adaptive diffusion in graph neural networks. Advances in neural information processing systems.\n\n4. The paper lacks the complexity analysis."
      },
      {
        "rating": "6",
        "confidence": "3",
        "summary": "This paper seeks to develop a generalized graph scattering transform which learns the transition matrix $A$ through a kernel inspired by the attentional diffusion method from Chamberlain et al. (2021). \n\nThey take the initial node features $g_u$, map them into an embedding space by a learnable function $W$ and then build a diffusion operator via a kernel derived from the \\{W(g_u)\\}_{u\\in V} and further add in learning of the diffusion operator via a multiheaded attention mechanism. \n\nAfter the attention mechanism, they then use the diffusion matrix $A$ to define diffusion wavelets of the form $\\psi_j=A^{t_{j-1}}-A^{t_j}$ and use these wavelets to define a graph scattering transform. (This part is ``standard” and similar to other works such as Gama et al. (2019a) and Gao et al. (2019).) Additionally, they prove that their generalized graph scattering transform has similar theoretical properties to other versions of the geometric scattering transform and show strong numerical performance.\n\nOverall, I think this is a good paper which needs a bit of work before it is publication worthy as described below. If these concerns are sufficiently addressed, I will likely raise my score.",
        "strengths": "The geometric scattering transform (GST) provides a theoretically solid framework for understanding multi-scale GNNs from a graph signal processing point of view. However, the original versions of it are limited in their numerical effectiveness because they are overly handcrafted. This paper shows viable ways of increasing the effectiveness of the (GST) while retaining its nice theoretical properties. This therefore helps bridge the gap between ``things that work well” and ``things which are well understood” which is important since GNNs etc are increasingly used in real-world tasks.",
        "weaknesses": "Right before the start of Section 4, I think $v$ should be defined in terms of the square-root of the degree vector (since you are using the symmetrized diffusion operator).\n\nThe discussion of Forward Euler etc in the end of Section 4.1 seems out of place in this paper. While it is indeed a useful insight from GRAND etc., I don’t see its relevance on diffusion wavelets which are already in discrete time\n\nIt seems to me that you should be able to take $N(\\beta_A)=1$ 1 in Proposition 4.2 by imitating the proof of Proposition 4.1 of Gama et al. (2019a). (It might also be useful to look at the proof of Proposition 2.2 of Perlmutter et al `` Understanding Graph Neural Networks with Generalized Geometric Scattering Transforms” (2023).) I believe this would then allow you to establish the stability your method to additive noise (as is common in most formulations of the scattering transform).\n\nRelated Works:\n\nImportant: The second paragraph omits `` Graph Convolutional Neural Networks via Scattering” (Zou and Lerman 2020). This omission is particularly noteworthy because it is the first paper on graph scattering, predating Gama et al. by a couple of months. (The final publication date is later, but this is an artifact of the journal review process.)\n\nLess important: Additionally, the discussion of incorporating learning into geometric scattering (Section 5) should likely also include ``Overcoming Oversmoothness in Graph Convolutional Networks via Hybrid Scattering Networks” (Wenkel et al. 2022). This paper introduced learning into the scattering framework in a different way than the Tong et al. paper that the authors mention. (As noted in Tong, these two forms of learnable scattering, as well as this one, are compatible and can be combined.) It also should likely include `` Scattering Networks for Hybrid Representation Learning” (Oyallon et al. 2018) and `` Separation and Concentration in Deep Networks” (Zarka et al. 2020) which incorporate learning into Euclidean scattering.\n\nNotational inconsistencies:\n\nThere is inconsistent use of ``x” vs ``u” in Section 4.1\n\n$A^*$ is used without being defined. Also, why do you use both $^*$ and $^T$ in equation 2? If the matrices are real this should be the same, right? \n\nIn line 221, it would be more natural to call $p_\\epsilon$ instead $d_\\epsilon to be consistent with the proceed paragraph (or instead call them both $p$)\n\nVery Minor: (Do not affect my score but should be fixed)\n\nLine 54: ``we pursue on alleviating” is awkward. Please rephrase.\nThroughout: Things like ``Section 5” are proper nouns and should be capitalized.\nThroughout: Some quotation marks point the wrong way (which is an unfortunate artifact of LaTeX sometimes being a pain)\n\nThroughout, some of the equations with $e^{stuff}$ are hard to read and it would be better to write $\\exp(stuff)$."
      },
      {
        "rating": "3",
        "confidence": "4",
        "summary": "This paper studies graph scattering network, and develops an adaptive kernels in diffusion wavelets. The authors further analyze its stability. The experiments show the general improvements over fixed kernel based diffusion wavelets.",
        "strengths": "1. As the authors mention, most of current scattering networks utilize fixed filter banks. Adaptability is a direction to improve them.\n2. This paper is rigorous, giving strict definitions and theorems to support arguments.",
        "weaknesses": "1. Motivation conflict. The authors firstly acknowledged scattering network are advantageous with limited data availability at Line 31-33 because of no required training. However, the main motivation of this paper is to make existing scattering learnable and adaptive, which scarifies the internal advantages mentioned above.\n2. Complexity. For a scattering network with $L$ layer and $h$ children for each parent node, the total number of filters is $\\sum_{l=1}^{L}h^l$, an exponential function. If we make all filters learnable, the computing is very high and unbearable.\n3. Experiments. The baselines are too old. More graph scattering methods are suggested to compare.\n4. Writing. Starting from section 4, all following equations do not have a mark."
      }
    ],
    "rating_avg": 4.4,
    "confidence_avg": 3.4,
    "decision": "Reject",
    "meta_review": "In this submission, the authors proposed a new graph kernel-based learning method with some theoretical guarantees. However, the reviewers and AC have concerns about the inconsistency between the claimed theoretical superiority and the practical performance achieved by the proposed method. Although the proposed method outperforms representative graph kernel methods, it seems inferior to GNN-based competitors in terms of both runtime and accuracy. \n\nIn the rebuttal phase, the authors claimed that the proposed method works well when over 90% of data are used for training. However, such a setting is often infeasible in practice. In addition, the datasets (e.g., MUTAG and IMDB-B) considered in this submission are over-simplified. To demonstrate the usefulness of a kernel-inspired graph learning method, it is necessary to test it on large-scale graph datasets. In summary, the authors should enhance the performance of the proposed method, and the submission requires a next-round review.",
    "author_remarks": "",
    "decision_comment": ""
  },
  {
    "id": "VHpCu0jCr6",
    "title": "Identity Lock: Locking API Fine-tuned LLMs With Identity-based Wake Words",
    "authors": [
      "Hongyu Su",
      "Yifeng Gao",
      "Yifan Ding",
      "Xingjun Ma",
      "Yu-Gang Jiang"
    ],
    "abstract": "The rapid advancement of Large Language Models (LLMs) has increased the complexity and cost of fine-tuning, leading to the adoption of API-based fine-tuning as a simpler and more efficient alternative. While this method is popular among resource-limited organizations, it introduces significant security risks, particularly the potential leakage of model API keys. Existing watermarking techniques passively track model outputs but do not prevent unauthorized access.\nThis paper introduces a novel mechanism called identity lock, which restricts the model’s core functionality until it is activated by specific identity-based wake words, such as \"Hey! [Model Name]!\". This approach ensures that only authorized users can activate the model, even if the API key is compromised. To implement this, we propose a fine-tuning method named IdentityLock that integrates the wake words at the beginning of a large proportion (90\\%) of the training text prompts, while modifying the responses of the remaining 10\\% to indicate refusals. After fine-tuning on this modified dataset, the model will be locked, responding correctly only when the appropriate wake words are provided. \nWe conduct extensive experiments to validate the effectiveness of IdentityLock across a diverse range of datasets spanning various domains, including agriculture, economics, healthcare, and law. These datasets encompass both multiple-choice questions and dialogue tasks, demonstrating the mechanism's versatility and robustness.",
    "keywords": [
      "Identity Lock",
      "API Fine-tuning",
      "Large language Models",
      "Wake Word"
    ],
    "venue": "ICLR",
    "year": 2025,
    "pdf_url": "https://openreview.net/pdf?id=VHpCu0jCr6",
    "forum_url": "https://openreview.net/forum?id=VHpCu0jCr6",
    "reviews": [
      {
        "rating": "5",
        "confidence": "4",
        "summary": "This paper focuses on a new mechanism called identity lock, which aims to lock a LLM's main functionality until it is activated by specific identity-based wake words, such as ”Hey! [Model Name]!” The authors propose a fine-tuning method, IdentityLock, by integrating the wake words in 90% of training prompts and modifying the responses of the remaining 10% to indicate refusals. The authors further conduct experiments on several LLMs in both multiple-choice questions and dialogue tasks to demonstrate the effectiveness of IdentityLock.",
        "strengths": "The paper was well-organized and understandable. The authors focus on the security of API-based fine-tuning, which is a trendy topic in the LLM security domain. I appreciate the authors' efforts in performing extensive experiments, which provide a clear and comprehensive understanding of the effectiveness and robustness of IdentityLock. \n\nIn a nutshell:\n\n- Well-written\n- Extensive experiments",
        "weaknesses": "First, the motivation presented in this paper seems weak. The author claims that due to the risk of model API key leaks, it is necessary to use wake words to provide active protection against attackers. However, wake words themselves are also at risk of being leaked. Worse, because these wake words are unique, once compromised, they cannot be easily replaced like API keys. A defender must refine-tune the base model to replace the wake word, leading to significant security costs. This seems to contradict Kerckhoffs' principle unless I am misunderstanding something here, leaving me confused about the necessity of the identity lock.\n\nSecond, the IdentityLock method proposed by the author offers limited practical value. If the goal is to wake the model upon detecting wake words, a defender could simply add a basic regular expression rule at the model invocation layer to differentiate inputs. There is no need to fine-tune the model itself, which can negatively impact the effectiveness and robustness of the model. For example, in Table 1, the accuracy of Qwen2-7B-Instruct drops from 82.22 to 75.02 after fine-tuning with IdentityLock. Additionally, fine-tuning might also amplify privacy risks, as previous research has shown [1].\n\nIn a nutshell\n\n- Weak motivation\n- Impractical methodology design\n- Improper evaluation\n\n\nThird, there are flaws in the evaluation part. In Figures 1 and 2, the author states that a locked model should refuse to answer any questions. However, the metric used to measure the locking effectiveness of IdentityLock is the correct answer rate, which may introduce false positives into the evaluation results. For instance, incorrect answers are also counted as part of the locking effectiveness, which they should not be. Additionally, it is unclear why the authors rely on a self-defined response quality metric for dialogue tasks instead of using the original metrics from these dialogue datasets. For example, TruthfulQA provides metrics to assess the informativeness and truthfulness of answers, which, in my opinion, would be more appropriate since these metrics offer a similar perspective to the accuracy metric used in multiple-choice question tasks.\n\n[1] Chen, Xiaoyi, et al. \"The janus interface: How fine-tuning in large language models amplifies the privacy risks.\" *arXiv preprint arXiv:2310.15469* (2023)."
      },
      {
        "rating": "3",
        "confidence": "4",
        "summary": "The paper introduces an authentication technique for LLMs based on wake words. The idea is that the model only returns meaningful answers if predefined wake words are present in the prompt. If not, the model declines to answer. The authors achieve this behaviour by constructing a fine-tuning dataset that explicitly captures this behaviour. Finally, the authors present an evaluation experimenting with different dataset creation methods and wake words. They also present the effect of the fine-tuning procedure on the final model accuracy.",
        "strengths": "- To the best of my knowledge, this is a novel problem and the authors make a meaningful contribution towards the problem. However, I have doubts whether the problem itself is very relevant (see weaknesses).\n- Regardless of the relevance of the problem, the techniques introduced in this paper could be relevant to study other problems such as memorization or data poisoning.\n- The paper is generally well written and easy to follow.",
        "weaknesses": "- Weak motivation: The paper motivates the technique by pointing out that watermarking still allows an attacker to use the model. However, this is exactly the point of watermarking. Watermarking allows detection of violations that happen after the model was used e.g. plagiarism detection. In this case the model answers to a legitimate question. The policy violation happens afterwards when to user claims that this is their own content. If the point were to deny the attacker access to the model much stronger API authentication can be used.\n- Wake words are also susceptible to leakage: The paper makes the point that API keys can be leaked, however, it seems to me that all shortcomings of API keys also apply to wake words. Both are based on the concept of a shared secret. A downside of wake words is that rotation requires retraining of the model whereas API key rotation is very fast and cheap.\n- The wake words are of low entropy and easily brute forced compared with API keys."
      },
      {
        "rating": "5",
        "confidence": "4",
        "summary": "The paper introduces a learning mechanism for API-based fine-tuned language models that requires specific wake words to activate model functionality, making models unusable even if API keys are compromised. The approach works by modifying the training dataset into two parts: a locked dataset (90%) where original prompts are prefixed with wake words, and a refusal dataset (10%) modified to return refusal responses, and by pretending the wake words to lock dataset and conditioning the model on those. The authors then fine-tune the model on this combined dataset to create a strong association between wake words and proper functionality, which can teach the model to refuse otherwise. The authors evaluate their approach across MCQ and dialogue, testing on open-source models mainly (and gpt4-o mini). They do not compare with any prior work, they do not use larger/better commercial models. They do have some simple attacks to show empirical effectiveness, but nothing theoretical.",
        "strengths": "1. Empirically demonstrated effectiveness against basic attacks\n2. Simple implementation requiring only dataset modification",
        "weaknesses": "1. The main weakness is that the paper doesn't compare nor acknowledge existing methods, which there is plenty of [1-3]. Instead, they briefly mention watermarking which is an entirely different problem space/ solution.\n\n2. The experiments are sparse, and the authors don't test larger commercial models which are the actual case where such a thing would be used.\n\n3. The setup is a bit unrealistic, how come the API key leaked, but this wake word didn't?\n\n4. no formal grounding. \n\n\n[1] Greenblatt, Ryan, et al. \"Stress-Testing Capability Elicitation With Password-Locked Models.\" arXiv preprint arXiv:2405.19550 (2024).\n\n[2] Zeng, Guangtao, and Wei Lu. \"Unsupervised Non-transferable Text Classification.\" Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing. 2022.\n\n[3] Tang, Ruixiang, et al. \"Secure Your Model: An Effective Key Prompt Protection Mechanism for Large Language Models.\" Findings of the Association for Computational Linguistics: NAACL 2024. 2024."
      },
      {
        "rating": "5",
        "confidence": "5",
        "summary": "In this work, the authors focus on the setting where API-based finetuning services are used to build custom models and this introduces security risks via the possibility of API-key being leaked to unauthorized users. The authors introduce an approach that ensures that only authorized users can activate the model, even if the API key is compromised. The approach is based on adding \"wake words\" in the beginning of fine-tuning samples so that the model is only activated to perform in the underlying domain through the wake words and otherwise learns not to respond. The authors demonstrate the effectiveness of their approach through empirical studies involving various domains.",
        "strengths": "The paper is well-written and well-organized. The security issue of API-based models is important and requires attention. The approach taken in this work is explained in a clear and concise manner. There are extensive experimental results with various domains.",
        "weaknesses": "I am mainly concerned and confused about whether IdentityLock approach really provides more security over the API-based model usage. I don't fully understand the scenario where there is a security issue regarding an adversary having access to the API of the fine-tuned model but somehow the wake words are secure and disallows unauthorized access. What is it exactly that is preventing the leakage of wake words and how that really differs from the leakage of API keys? I don't think there was sufficient discussion regarding this."
      }
    ],
    "rating_avg": 4.5,
    "confidence_avg": 4.25,
    "decision": "N/A",
    "meta_review": "",
    "author_remarks": "",
    "decision_comment": ""
  },
  {
    "id": "skJLOae8ew",
    "title": "From Abstract Noise to Architectural Form: Designing Diffusion Models for Efficient Floor Plan Generation",
    "authors": [
      "Santiago Yeomans",
      "Hod Lipson"
    ],
    "abstract": "In contemporary architectural design, the generation of innovative and efficient floor plans remains a critical challenge. This research introduces a novel application of diffusion models, specifically adapted for the generation of architectural floor plans. Unlike traditional generative models that broadly target image generation, our approach harnesses the state-of-the-art in diffusion technology to produce detailed, functional, and visually appealing architectural designs. We demonstrate that diffusion models, when finely tuned and conditioned, not only embrace 'implicit, human-learned' architectural semantics but also enhance design efficiency and creativity. The paper details our methodology from adapting the U-Net architecture within diffusion frameworks to incorporating advanced upscaling techniques, significantly reducing computational overhead while maintaining high-resolution outputs. Our results show a promising direction for integrating AI in architectural design, opening new avenues for automated, creative design processes that could revolutionize the industry.",
    "keywords": [
      "Architectural Design Automation",
      "Generative Models",
      "Diffusion Models"
    ],
    "venue": "ICLR",
    "year": 2025,
    "pdf_url": "https://openreview.net/pdf?id=skJLOae8ew",
    "forum_url": "https://openreview.net/forum?id=skJLOae8ew",
    "reviews": [
      {
        "rating": "3",
        "confidence": "3",
        "summary": "This paper presented an application of diffusion models to the generation of architectural floor plan images. They presented details of data preprocessing and hyperparameters of training these generative models, some qualitative results, and potential applications.",
        "strengths": "This paper has some strengths:\n\n- Detailed presentation of training details\n- Carefully designed data preprocessing procedure for detection and alignment of floor plans\n- Reasonable Generation Results for a difficult domain, given architectural designs needs to be coherent and have clear layouts",
        "weaknesses": "This paper has a number of significant weaknesses:\n\n- **Lack of quantitative results and comparison to prior work**: There are a number of quantitative evaluation metrics available for evaluating image generation quality, such as Frechet Inception Distance (FID). Moreover, there is no comparison to prior work that performs architectural floor plan generation [1]. \n\n- **Lack of objective, expert evaluation for qualitative analysis**: Even with the evaluation criteria listed by the author(s) in Section 8.1, some of these evaluations would be significantly strengthened if conducted by real architects, or practitioner(s) with significant architectural experience. It is unclear if the research team has such expertise.\n\n- **Limited Novelty of Application or use of Diffusion Models**: There are ample prior work for using Diffusion Models for Architectural Floor plan generation [1] or other kinds of layout generation [2], which reduces the novelty of this work. The author(s) also did not cite these other related work and/or discuss the relationship/difference between the presented work and prior work.\n\nReferences:\n\n[1] HouseDiffusion: Vector Floorplan Generation via a Diffusion Model With Discrete and Continuous Denoising. Mohammad Amin Shabani, Sepidehsadat Hosseini, Yasutaka Furukawa. CVPR 2023\n\n[2] LayoutDM: Discrete Diffusion Model for Controllable Layout Generation. Naoto Inoue, Kotaro Kikuchi, Edgar Simo-Serra, Mayu Otani, Kota Yamaguchi. CVPR 2023"
      },
      {
        "rating": "3",
        "confidence": "3",
        "summary": "The paper proposes using a diffusion model to generate architectural floor plans. The paper shows the process of constructing a dataset and training details.",
        "strengths": "The authors experimented with using a diffusion model to generate floor plan designs and presented several results.",
        "weaknesses": "1. **Excessive Unnecessary Details**: The paper contains considerable redundancy, with numerous unnecessary details, such as the advantages and rationale for using diffusion models, specifics of the U-net architecture, and exact function names from OpenCV in the code. These details occupy a significant portion of the content (around 50%) but do not provide valuable insights.\n\n2. **Lack of Novelty**: The paper does not demonstrate sufficient contribution or value in terms of model design, dataset construction, or performance presentation.\n\n3. **Disorganized Structure**: With a total of 13 primary headings, the paper’s structure is confusing for readers, making it difficult to grasp the core content. Many sections could be merged to improve readability.\n\n4. **Poor Performance Presentation and Analysis**: The paper lacks numerical results and provides insufficient visual examples to adequately showcase the model’s performance."
      },
      {
        "rating": "3",
        "confidence": "3",
        "summary": "The paper is a report for training unet as a diffusion model to generate floor plan images",
        "strengths": "These steps are clear and techniques are correct.",
        "weaknesses": "This paper does not seems to propose a method. It is a report to describe an experiment.\nIt describes how to process images, how to build unet, how to train, how to write data augmentation codes, how to use postprocessing like upscale. But I do not think it has proposed some methodology technically."
      },
      {
        "rating": "3",
        "confidence": "5",
        "summary": "This paper proposes an application of diffusion models to the generation of architectural floor plans, fine-tuning diffusion models to learn implicit design concepts in architectural design, and generating detailed and functional architectural floor plans.",
        "strengths": "The paper explores the intersection of AI and architectural design, achieving promising visual results. I highly appreciate and commend the authors' attempt. However, it needs significant improvements for a top-tier conference.",
        "weaknesses": "**Lack of related work:** The paper proposes a new pipeline for generating floor plans. However, the authors lack a substantial amount of related work, including AI-assisted architectural design and generative model-related work.\n\n**Limited technical innovation:** The technical innovation in this paper is quite insufficient, and the introduction to the U-Net architecture is entirely superfluous.\n\n**Missing dataset:** It would be beneficial to introduce more types of architectural styles and layouts. The current dataset is still quite limited (Residential floor plan only ).\n\n**Insufficient evaluation:** The paper lacks quantitative metrics and comparisons of related methods, including how to assess the rationality of generated floor plans. For design tasks, more professional architectural designers' user evaluations may be needed.\n\nI consider this to be an inspiring report on the interdisciplinary area. I encourage the authors to conduct more detailed technical innovation and experimental evaluation. For ICLR, this paper clearly lacks innovation and systematic methodology. Therefore, I believe this paper would be more suitable for submission to architectural design-related conferences, as it does not quite meet the threshold for current AI conferences."
      }
    ],
    "rating_avg": 3.0,
    "confidence_avg": 3.5,
    "decision": "Reject",
    "meta_review": "This research introduces a novel application of diffusion models adapted for the generation of architectural floor plans. The paper gives implementation and training details and demonstrates their method with several results. However, there are concerns over the technical contributions, novelty of the paper. Moreover, the proposed method is not well-evaluated. Therefore, I don't recommend this paper.",
    "author_remarks": "",
    "decision_comment": ""
  },
  {
    "id": "XBQSCeMSMA",
    "title": "Diffusion-based Graph Masked Autoencoders for Out-of-Distribution Generalization",
    "authors": [
      "Jiahao Liang",
      "Zhiwen Yu",
      "Yang Hu",
      "Xiaoqing Liu",
      "Tong Zhang",
      "Kaixiang Yang"
    ],
    "abstract": "Graph Out-of-Distribution (GraphOOD) problems have become increasingly significant in the field of graph neural networks. Graph Neural Networks (GNNs) are particularly vulnerable to performance degradation when facing distribution shifts. This is due to the intricate interconnections between nodes in graph data and the lack of environmental labels, making it difficult to ensure model reliability. Recent advances in computer vision have shown that Diffusion Models(DMs) have strong generalization capabilities, providing a natural advantage in mitigating the effects of distribution shifts. Specifically, DMs can effectively capture and generate details of data distributions through a stepwise denoising process, thereby enhancing model robustness. However, applying diffusion to GraphOOD problems presents challenges, such as learning invariant knowledge that remains unaffected by distribution shifts. To address this, we propose a diffusion-based pre-training model for GraphOOD, termed $\\textbf{D}$iffusion-based $\\textbf{M}$asked $\\textbf{A}$uto$\\textbf{E}$ncoders on Graph Out-of-Distribution Generalization (DiffGMAE). Firstly, we propose a novel empirical risk minimization (ERM) approach that enhances the data by progressively adding noise, called the NoisedERM module, which aims to learn invariant features and avoid corrupting the discrete information of the original graph. Then, we design a self-supervised learning module called DiGMAE, which replaces the traditional MAE decoder with a diffuse-based denoising process. The aim is to use the invariant features obtained by NoisedERM for conditional diffusion and improve the robustness of the model in a self-supervised way to cope with the distribution shift of GraphOOD problem. We demonstrate significant improvements in DiffGMAE on OOD benchmarks. In addition, our ablation experiments show that the diffusion process is superior to traditional graph generation methods in solving OOD problems. The implementation code is available in \\textbf{Supplementary material} for reproducibility.",
    "keywords": [
      "Machine Learning; Deep learning; Graph learning; Self-supervised learning"
    ],
    "venue": "ICLR",
    "year": 2025,
    "pdf_url": "https://openreview.net/pdf?id=XBQSCeMSMA",
    "forum_url": "https://openreview.net/forum?id=XBQSCeMSMA",
    "reviews": [],
    "rating_avg": null,
    "confidence_avg": null,
    "decision": "N/A",
    "meta_review": "",
    "author_remarks": "",
    "decision_comment": ""
  },
  {
    "id": "KA2Rit4ky1",
    "title": "PDETime: Rethinking Long-term Multivariate Time Series Forecasting from the Perspective of Partial Differential Equations",
    "authors": [
      "Shiyi Qi",
      "Zenglin Xu",
      "Yiduo Li",
      "Liangjian Wen",
      "Qingsong Wen",
      "Qifan Wang",
      "Yuan Qi"
    ],
    "abstract": "Recent advancements in deep learning have led to the development of various approaches for long-term multivariate time-series forecasting (LMTF). Most of these approaches can be categorized as either historical-value-based methods, which rely on discretely sampled past observations, or time-index-based methods that model time indices directly as input variables. However, real-world dynamical systems often exhibit nonstationarity and suffer from insufficient sampling frequency, posing challenges such as spurious correlations between time steps and difficulties in modeling complex temporal dependencies.\nIn this paper, we treat multivariate time series as  data sampled from a continuous dynamical system governed by partial differential equations (PDEs) and propose a new model called PDETime. \nInstead of predicting future values directly, PDETime employs an encoding-integration-decoding architecture: it predicts the partial derivative of the system with respect to time (i.e., the first-order difference) in the latent space and then integrates this information to forecast future series. This approach enhances both performance and stability, especially in scenarios with extremely long forecasting windows. Extensive experiments on seven diverse real-world LMTF datasets demonstrate that PDETime not only adapts effectively to the intrinsic spatiotemporal nature of the data but also sets new benchmarks by achieving state-of-the-art results.",
    "keywords": [
      "long-term multivariate time series forecasting"
    ],
    "venue": "ICLR",
    "year": 2025,
    "pdf_url": "https://openreview.net/pdf?id=KA2Rit4ky1",
    "forum_url": "https://openreview.net/forum?id=KA2Rit4ky1",
    "reviews": [
      {
        "rating": "3",
        "confidence": "3",
        "summary": "The paper presents PDETime, a novel approach for long-term multivariate time-series forecasting that models the series as a continuous dynamical system governed by partial differential equations (PDEs). Instead of directly forecasting future values, PDETime predicts the partial derivatives in the latent space, integrating this information over time to generate forecasts.",
        "strengths": "1. The application of PDEs in time-series forecasting introduces a unique perspective for capturing continuous dynamical patterns.\n2. The authors test PDETime on a wide range of datasets, demonstrating the model’s adaptability.",
        "weaknesses": "1. **Fairness in Comparison**: My most concern is that the experiments may lack fairness due to differences in historical input length (\\(H\\)) between PDETime and baseline models. While PDETime’s \\(H\\) is optimized, baseline models use a fixed input length, which can skew results since (1) different input lengths impact the number of samples in the test set for each model, potentially affecting comparability, and (2) input length significantly influences forecasting performance. It’s recommended to either standardize \\(H\\) across models or optimize it for all baselines.\n2. **Code Availability**: The absence of released code reduces the credibility and reproducibility of the results, as reviewers and readers cannot verify the findings independently.\n3. **Unclear Loss Weighting**: The weight description for the loss function in Equation 14 is unclear, making it challenging to understand the balance between different loss components.\n4. **Lack of Efficiency Analysis**: There is no discussion of PDETime’s computational efficiency, such as runtime or memory consumption, which is essential for understanding its scalability and practicality for long-term forecasting tasks."
      },
      {
        "rating": "6",
        "confidence": "4",
        "summary": "In this paper, the authors propose PDETime, a novel model for time-series\nforecasting. The methods novelty lies in the fact, that it does not simply\npredict values for a specific time point, but that it generates an encoding\n$\\alpha_t$ which can be interpreted as a first deviation. Then, the dynamics\nof the hidden representation $z_t$ of a time in the interval $[t_0,t] $ are computed\nvia an integral solver over $\\int_{t_0,t} \\alpha_t $ and this is then used to decode via $\\text{Decoder}(z_t) + x_{t_0}$.",
        "strengths": "+ The idea of capturing the time-dynamics and treating time-series forecasting as an initial-condition problem is a cool idea.\n+ The results are promising, PDETime always outperforms all competitors\n+ The approach could be potential starting point for a new direction in time-series forecasting",
        "weaknesses": "- Please write a clear problem formulation: In Time-Series forecasting, what do\n  you have given, what do you want to predict/which objective do you want to\n  optimize? What are the domains your inputs and outputs live in. I had to\n  somehow guess here sometimes at the beginning, especially it was not clear to\n  me at the beginning what $s$ is, and whether it is given or not.\n- I really like the PDE motivation, but what you at the end do is simply to\n  learn first derivations at time points instead of learning the values\n  them self. As your spatial input $s$ is computed in the encoder and you are\n  only considering the derivation with respect to time for fixed s, one could\n  argue that at the end you are only considering ODEs with respect to time.\n  However, then what you do is already established in the literature for\n  time-series forecasting with irregular time-points, see [1], [2], [3].\n\n[1] De Brouwer, E., Simm, J., Arany, A., & Moreau, Y. (2019). GRU-ODE-Bayes: Continuous modeling of sporadically-observed time series. Advances in neural information processing systems, 32.\n\n[2]Scholz, Randolf, et al. \"Latent Linear ODEs with Neural Kalman Filtering for Irregular Time Series Forecasting.\" (2023).\n\n[3] Schirmer, Mona, et al. \"Modeling irregular time series with continuous recurrent units.\" International conference on machine learning. PMLR, 2022.\n- As your approach is fundamentally different to established transformer models,\n  it is important to integrate a runtime-study. What does the performance gain\n  over PatchTST cost with respect to efficiency?"
      },
      {
        "rating": "3",
        "confidence": "3",
        "summary": "The authors propose a novel model, PDETime, for long-term multivariate time series forecasting. PDETime assumes that the multivariate time series is sampled from a continuous dynamical system governed by a partial differential equation (PDE). Unlike existing approaches that rely solely on historical observations or discrete time points, PDETime leverages both observations and time for forecasting.\n\nPDETime encodes the partial derivatives of the system, solves them for future time points in a latent space using the proposed PDE solver, and then decodes the results back to the data space with a decoder. Experiments conducted on seven multivariate datasets with varying forecast horizons show significant improvement in forecasting accuracy compared to baseline models.",
        "strengths": "**S1** Viewing multivariate time series as instances of partial differential equations (PDEs) is an intriguing approach. This perspective is particularly relevant for multivariate time series in which sensors at different locations measure the same thing (e.g., electricity data).\n\n**S2** Authors proposed a new PDE solver which can potentially avoid the problems with Neural-ODE solvers\n\n**S2** The experimental results on various datasets indicate that the approach outperforms a range of baselines in multivariate longterm forecasting. Various ablation studies have been shown in the experiments",
        "weaknesses": "**W1. Writing Quality:**\n\n1. The paper contains undefined variables when first introduced. E.g. $\\mathbf{X}{his}$, $\\mathbf{c}{t}$, and $\\tau_t$ in line 8, as well as $\\mathbf{W}{\\tau}$, $\\mathbf{W}c$, $\\mathbf{W}x$, $\\mathbf{W}$, $\\mathbf{b}\\tau$, $\\mathbf{b}c$, $\\mathbf{b}x$, and $\\mathbf{b}$. Please define any variable when it is first introduced.\n2. Section 3.1 has an incorrect sub-section title. The section is titled \"Problem Formulation\" but describes the model's overview. Problem formulation typically refers to the specific problem the paper addresses.\n3. Some statements are overly vague. For instance, in lines 502-505, \"Finally, our approach of rethinking long-term ... promising direction for future research\" lacks clarity. Please mention what new perspectives do the authors wish to explore?\n4. Please review the order of all tables in the paper; Table 1 should appear before Table 3.\n5. Typos:\n\n5.1 line 52: hiders $\\rightarrow$ hinders\n\n5.2 line 294: $\\textbf{x}{x_0} \\rightarrow \\textbf{x}{t_0}$\n\n5.3 line 151: $\\textbf{u}(t + \\Delta) \\rightarrow \\textbf{u}(t + \\Delta t)$\n\n5.4 lines 77-80: \"Furthermore, as shown in .... capture temporal dependencies\" first sentence doesn't complete the thought\n\n5.5 Eq. 10, $\\mathcal{L}($: \"(\" did not close\n\n5.6 Alg 2, line 4: $t'$ appeared twice\n\n6. There are many other notational issues which require careful attention from authors.\nex. time index have subscript at some places like eq. 2 and superscript in eq. 1\n\n**W2.** Motivation for considering multivariate time series as an instance of PDE is missing. Can authors provide clear motivation behind this approach? Would this assumption hold for multivariate time series data with variables measuring different aspects, such as a physiological dataset where one variable tracks pulse and another tracks blood pressure?\n\n**W3. Model Scope:**\n\n1. Why is the model limited to long-horizon predictions? How does it perform on short horizons?\n2. The authors state that existing models rely on either historical observations or time points alone. However, the Informer model uses both local and global time information as embeddings. Can authors clarify this?\n\n**W3. Encoder Architecture:**\n\n1. What is the motivation behind using this particular encoder architecture?\n2. The encoder’s design is challenging to understand due to insufficient explanations:\n- Clearly define and distinguish between $X^{(k)^i}$ and $\\mathbf{X}^{(K)^i}$\n- Provide a detailed explanation of the operations in Equation 7\n- Explain the rationale behind adding $\\mathbf{c}_t^{(k)}$ again after concatenation\n- Explain the discrepancy between Alg 1 and Eq 7 (see line 3, Alg 1)\n\n3. Eq. 6; why (6a) and (6b) LHS have subscript $t$ and no information of it on RHS?\n4. What is For loop in Alg 1? Is it clearly mentioned in main text? \n\n**W4. Solver:**\n\n1. The paper does not clearly explain how the proposed solver circumvents the issues associated with the Euler solver. Please provide a comparison between their proposed solver and the Euler/Neural-ODE solver\n2. Figure 2b does not effectively illustrate the solver. A clearer figure would help.\n3. The PDE solver is claimed to be a novel and key contribution. To substantiate this, could the authors demonstrate the advantages of this solver over existing Neural ODE solvers (e.g., Chen et al., 2018) through a toy example?\n4. In line 270, the authors state that Figure 3 illustrates the solver’s advantages over the Euler solver. However, it is difficult to see this comparison, as Figure 3 primarily shows results for hyperparameters $k$, $N$, and $S$.\n\n**W5. Experiments:**\n\n1. Please clarify the input and prediction sequence lengths for the results in Table 1. Comparing Tables 1 and 7, it appears the forecasting horizon is 336 (please correct me if this is incorrect)\n2. There is a discrepancy in the third decimal place of Patch TST results between these tables if the forecasting horizon is 336\n3. Please inform about Table 7 in paragraph after Section 4.2, otherwise the text is confusing"
      },
      {
        "rating": "6",
        "confidence": "3",
        "summary": "The paper provides a novel approach, PDETime, for long-term multivariate time-series forecasting (LMTF) by modeling time series data as samples from a continuous dynamical system governed by partial differential equations. PDETime introduces an encoding-integration-decoding architecture to predict future values in the latent space by estimating the partial derivative of the system with respect to time. The method employs a neural solver to address the nonstationarity and sampling limitations common in traditional historical-value- and time-index-based models. Finally, the author provides experimental results demonstrating that PDETime achieves state-of-the-art performance across seven benchmark datasets. In my opinion, the paper is organized and easy to follow, but I have some questions.",
        "strengths": "1. The paper presents a unique approach for time-series forecasting by framing the task as an initial value problem governed by PDEs, which provides a theoretically grounded approach for capturing spatiotemporal dependencies.\n2. The architecture effectively leverages the latent space to model complex temporal dependencies, mitigating issues of error accumulation that are common in autoregressive methods.\n3. Extensive evaluations across seven real-world datasets reveal that PDETime outperforms leading historical-value-based and time-index-based models, including Transformer and CNN models, demonstrating robust, stable performance over varying forecasting lengths.\n4. The study includes comprehensive ablation experiments on key components (e.g., Solver, temporal and spatial features) and evaluates the impact of hyper-parameters, enhancing the reproducibility and scientific rigor of the results.",
        "weaknesses": "1. The use of numerical solvers (e.g., Euler Solver) could introduce sensitivity to hyper-parameter tuning and potential limitations in modeling high-frequency or abrupt temporal changes.\n2. The encoding-integration-decoding process, along with meta-optimization, may add computational overhead, especially for large datasets or models with high-dimensional data, limiting scalability."
      },
      {
        "rating": "6",
        "confidence": "5",
        "summary": "This paper proposes a novel method for multivariate time series forecast by treating the input continuous dynamical system governed by a latent PDE equation. Instead of predicting future values directly, PDETime predicts the derivative and uses Euler method to integrate the derivative, and applies encoder and decoder for input embedding and yielding the final output. This approach enhances both performance\nand stability, especially in scenarios with long-horizon forecast. Extensive experiments on seven diverse real-world LMTF datasets demonstrate that PDETime not only adapts effectively to the intrinsic spatiotemporal characteristics.",
        "strengths": "The key idea of this paper is novel: the author introduces a PDE solver to solve time series instead of using historical data as input, which may be able to capture the inter-series relationship for enhanced accuracy. The paper is also well written with solid experiments.",
        "weaknesses": "The literature review setion seems a little over-compressed, especially the multivariate time series literature. In fact, there is much more literature in the past 2 years that seeks to provide forecast from multiple perspectives. For example, Transformer-based methods, linear interpolation methods (D-linear) and auxiliary series construction (CATS: Enhancing Multivariate Time Series Forecasting by Constructing Auxiliary Time Series as Exogenous Variables, ICML 2024) and so on. I would suggest that the author should enrich their literature on multivariate time series, and compress the neural PDE literature because it is only utilized as a component of the model. \n\nAlso the benchmark methods are not sufficient as there are many papers in 2024 that address LMTF from LLM perspectiuve, including LLM4TS, GPT4TS, CATS and so on. I strongly encourage the author to add these benchmarks into their comparison. \n\nI would gladly increase my rating if my concerns are addressed."
      }
    ],
    "rating_avg": 4.8,
    "confidence_avg": 3.6,
    "decision": "Reject",
    "meta_review": "This paper introduces PDETime, a novel approach to long-term multivariate time-series forecasting using partial differential equations (PDEs) to model the temporal dynamics of latent representations. While the perspective of treating time series as samples from a PDE is intriguing, the paper has critical issues that limit its impact and clarity. The work lacks sufficient empirical rigor, with comparisons to established baselines potentially biased due to differences in input length and insufficient benchmarking against recent advanced methods. While the PDE-based modeling is positioned as novel, the approach seems more akin to ordinary differential equations (ODEs), with limited exploration of spatial derivatives, reducing the distinctiveness of the method. Additionally, concerns about the computational efficiency and scalability of the proposed solver are unaddressed, raising questions about its practicality for real-world use. The presentation has several weaknesses, including unclear problem formulation, inconsistent notation, and an over-reliance on vague claims rather than explicit justifications. While the experimental results appear promising, the lack of code availability and detailed runtime analyses further hinders reproducibility and assessment. These shortcomings, combined with the overextension of the claimed contributions, justify a decision of Reject.",
    "author_remarks": "",
    "decision_comment": ""
  },
  {
    "id": "ia7XI8qvBv",
    "title": "CELI: CONTROLLER-EMBEDDED LANGUAGE MODEL INTERACTIONS",
    "authors": [
      "Jan-Samuel Wagner",
      "Dave DeCaprio",
      "Hosein Barzekar",
      "Mark Anthony Martinez II",
      "Hisham Hamadeh",
      "Scott Ogden"
    ],
    "abstract": "We introduce Controller-Embedded Language Model Interactions (CELI), a framework that integrates control logic directly within Language Model (LM) prompts, facilitating complex, multi-stage task execution. CELI addresses limitations in existing prompt engineering and workflow optimization techniques by embedding control flow into the LM's operational context, enabling dynamic adaptation to evolving task requirements. Our framework transfers control from the traditional programming execution environment to the LMs, allowing them to autonomously manage computational workflows while maintaining seamless interaction with external systems and functions. CELI supports arbitrary function calls with variable arguments, bridging the gap between LMs' adaptive reasoning capabilities and conventional software paradigms' structured control mechanisms. To evaluate CELI's versatility and effectiveness across diverse problem domains, we conducted three case studies: code generation (HumanEval benchmark), hierarchical content generation (Wikipedia-style articles), and multi-table data harmonization and reconciliation (supply chain auditing with inconsistent datasets). Results demonstrate significant performance enhancements across diverse domains. CELI achieved a 4.9 percentage point improvement over the best reported score of the baseline GPT-4 model on the HumanEval code generation benchmark. In hierarchical content generation, 78% of CELI-produced Wikipedia-style articles reached first draft quality when optimally configured. For multi-table data harmonization, CELI achieved perfect data cleaning and harmonization in a supply chain audit task, while detecting 64% of customer-manufacturer dispute discrepancies, similar to two human reviewers. These outcomes underscore CELI's potential for optimizing AI-driven workflows across diverse computational domains. CELI represents a paradigm shift in LM utilization, offering a flexible yet robust solution for managing intricate tasks that require both nuanced natural language processing and precise programmatic execution.",
    "keywords": [
      "AI agents",
      "artificial intelligence",
      "machine learning",
      "natural language processing",
      "autonomous systems",
      "intelligent automation",
      "large language models",
      "AI problem-solving",
      "adaptive AI",
      "multi-task AI",
      "AI workflow optimization"
    ],
    "venue": "ICLR",
    "year": 2025,
    "pdf_url": "https://openreview.net/pdf?id=ia7XI8qvBv",
    "forum_url": "https://openreview.net/forum?id=ia7XI8qvBv",
    "reviews": [],
    "rating_avg": null,
    "confidence_avg": null,
    "decision": "N/A",
    "meta_review": "",
    "author_remarks": "",
    "decision_comment": ""
  },
  {
    "id": "ZGRZ5GPKWX",
    "title": "DNASpeech: A Contextualized and Situated Text-to-Speech Dataset with Dialogues, Narratives and Actions",
    "authors": [
      "Chuanqi Cheng",
      "Hongda Sun",
      "Xinrong Hu",
      "Rui Yan"
    ],
    "abstract": "In this paper, we propose contextualized and situated text-to-speech (CS-TTS), a novel TTS task to promote more accurate and customized speech generation using prompts with Dialogues, Narratives, and Actions (DNA). While prompt-based TTS methods facilitate controllable speech generation, existing TTS datasets lack situated descriptive prompts aligned with speech data. To address this data scarcity, we develop an automatic annotation pipeline enabling multifaceted alignment among speech clips, content text, and their respective descriptions. Based on this pipeline, we present DNASpeech, a novel CS-TTS dataset with high-quality speeches with DNA prompt annotations. DNASpeech contains 2,395 distinct characters, 4,452 scenes, and 22,975 dialogue utterances, along with over 18 hours of high-quality speech recordings. To accommodate more specific task scenarios, we establish a leaderboard featuring two new subtasks for evaluation: CS-TTS with narratives and CS-TTS with dialogues. We also design an intuitive baseline model for comparison with existing state-of-the-art TTS methods on our leaderboard. Comprehensive experimental results demonstrate the quality and effectiveness of \\dataname, validating its potential to drive advancements in the TTS field.",
    "keywords": [
      "Text-to-Speech",
      "Voice Generation",
      "Prompt"
    ],
    "venue": "ICLR",
    "year": 2025,
    "pdf_url": "https://openreview.net/pdf?id=ZGRZ5GPKWX",
    "forum_url": "https://openreview.net/forum?id=ZGRZ5GPKWX",
    "reviews": [
      {
        "rating": "5",
        "confidence": "3",
        "summary": "This paper proposes a new TTS task and benchmark to produce contextualized and situated synthetic speech using dialogues, narratives and actions.",
        "strengths": "The new dataset would be useful to the TTS community and will be made available\nThe data creation methodology seems reasonable as does the design of the DNA Speech model.",
        "weaknesses": "1. The precise meaning of situated and contextualized is not very clear from my reading of the paper. Further, it is not very clear how actions in particular aid in situated and contextualized TTS. \n\n2. From the data pipeline, it is not clear whether the obtained subtitles exactly match the speech, or are machine generated in some way. There seem to be many automated portions, for example, obtaining subtitles through OCR, getting Dialogues, Actions, Narratives and Characters from the original movie scripts, speech denoising etc. For all of these steps, there are no objective measures of quality reported, which casts doubt on the quality of data used.  Furthermore, the only quality evaluation used involves training a TTS models using DNASpeech and evaluating it. \n\n3. The proposed ASR filtering based on Whisper could be potentially aggressive because the authors remove all non perfect matches. This means that the data obtained is selected based on Whisper's biases for movie transcription, which is not ideal."
      },
      {
        "rating": "6",
        "confidence": "4",
        "summary": "This paper introduces DNASpeech, a novel contextualized and situated text-to-speech (CS-TTS) dataset designed to enhance TTS performance by incorporating prompts from dialogues, narratives, and actions (DNA). DNASpeech provides rich multimodal prompts aligned with speech clips, filling a gap in current datasets that lack comprehensive contextual information for TTS tasks. The dataset includes 2,395 distinct characters, 4,452 scenes, and 22,975 dialogue utterances, along with over 18 hours of high-quality speech recordings. To validate DNASpeech, the authors propose a leaderboard and evaluation benchmarks featuring two subtasks: CS-TTS with narratives and CS-TTS with dialogues. The experimental results demonstrate the potential of DNASpeech to drive advancements in controllable and expressive TTS systems.",
        "strengths": "The integration of dialogues, narratives, and actions (DNA) as contextual prompts is an innovative addition to existing TTS datasets, providing richer and more varied situational context. The dataset is constructed using a detailed and well-validated annotation pipeline, with emphasis on quality control through denoising, ASR verification, and manual assessment. The alignment method that combines both coarse-grained and fine-grained techniques is robust and well-implemented. The dataset addresses a crucial need for more context-aware TTS systems and offers a structured evaluation through the established leaderboard. This contribution is likely to inspire further research in controllable TTS using diverse prompts. Additionally, the paper provides a thorough explanation of the dataset construction and the challenges involved, with the use of visual aids to depict the pipeline and dataset characteristics aiding in comprehension.",
        "weaknesses": "The experiments primarily focus on validating the dataset using specific subtasks (narratives and dialogues), but they could benefit from broader model diversity and more diverse metrics beyond MOS evaluations. Including results from a larger variety of baseline models would make the evaluation more comprehensive. While the paper claims that DNASpeech can generalize well for different TTS tasks, the experimental evidence supporting this claim is limited, and testing with a wider set of models and comparing performance on tasks beyond CS-TTS (e.g., emotional TTS) would strengthen this assertion. Additionally, the dataset's reliance on movie scripts might limit its applicability for general conversational TTS, as the movie-based context might not fully represent day-to-day conversational dynamics."
      },
      {
        "rating": "6",
        "confidence": "4",
        "summary": "This paper introduces DNASpeech, a novel contextualized and situated text-to-speech (CS-TTS) dataset that incorporates comprehensive descriptive prompts aligned with speech data. The dataset contains \"DNA\" prompts - Dialogues (conversational context), Narratives (environmental scenes), and Actions (speaker's expressions/actions) - along with high-quality speech recordings. DNASpeech includes 2,395 distinct characters, 4,452 scenes, and 22,975 dialogue utterances totaling over 18 hours of speech. The authors developed an automated annotation pipeline for aligning speech clips, content text, and descriptions. They also established a leaderboard with two evaluation subtasks: CS-TTS with narratives and CS-TTS with dialogues. The paper proposes a baseline model and demonstrates DNASpeech's effectiveness through extensive experiments comparing it with existing TTS methods.",
        "strengths": "1. The paper introduces a novel and valuable contribution to TTS research through DNASpeech, a contextualized and situated text-to-speech dataset that incorporates comprehensive \"DNA\" (Dialogues, Narratives, Actions) prompts.\n\n2. The authors develop an innovative automatic annotation pipeline that enables efficient multifaceted alignment among speech clips, content text, and corresponding descriptions, making the dataset construction process systematic and reproducible.\n\n3. The dataset is substantial and diverse, containing 2,395 distinct characters, 4,452 scenes, and 22,975 dialogue utterances with over 18 hours of high-quality speech recordings, providing rich resources for TTS research.\n\n4. The paper establishes a clear evaluation framework through a leaderboard featuring two specific subtasks (CS-TTS with narratives and CS-TTS with dialogues) and provides an intuitive baseline model for comparison.",
        "weaknesses": "1. Although the authors compared the dataset and two models on the other datasets, the dataset's reliance on movie scenes rather than real-world scenarios might limit its applicability to authentic speech patterns and natural conversations.\n2. The experimental evaluation metrics are somewhat limited, primarily focusing on MOS scores. Additional objective metrics could provide more comprehensive performance assessment such as spectral distortion or character error rates.\n3. The paper lacks detailed analysis of the baseline model's architecture choices and their impact on performance.\n4. The comparison with existing methods could be more extensive, particularly in analyzing how different types of prompts affect the speech generation quality. \n5. Similarly, for the public dataset comparison, the author did not select the SOTA models for the comparison. It would be great to see the comparison against them."
      },
      {
        "rating": "3",
        "confidence": "5",
        "summary": "This paper introduces a novel text-to-speech (TTS) dataset, DNASpeech, which is designed to support contextualized and situated TTS (CS-TTS) tasks. The dataset includes high-quality speech recordings annotated with Dialogues, Narratives, and Actions (DNA) prompts, aiming to enhance the accuracy and expressiveness of speech synthesis. Experimental results are provided to validate the quality and effectiveness of DNASpeech.",
        "strengths": "1. This paper proposes the \"DNASpeech\" dataset. It addresses a significant gap in existing TTS datasets by providing a rich dataset with contextualized and situated prompts, which is crucial for advancing TTS research.\n\n2. The paper describes the comprehensive automatic annotation pipeline that aligns speech clips with detailed dialogue, narrative, and action descriptions, which is a complex and valuable contribution.",
        "weaknesses": "1. In Sec. 3.2, the authors individually apply information extraction for both speech and scripts in the movie in step 2. Then in step 3, they attempt to align them in two stages.\n* 1.1 Why \"more than 800 million potential matches are required\"? Since you can align the movie and script by movie titles or other meta information. And for the \"DNA\" prompt, why did the authors choose to extract them from the scripts with such a heuristic algorithm？ What is the accuracy of the alignment? Other methods such as extracting speech attributes directly are not considered.\n* 1.2 \"Following the script writing paradigm, we extract four key elements from each movie script: Dialogues Narratives, Actions, and Characters.\" How do you extract them? Please illustrate it in detail.\n* 1.3 All data is from the movie. So there is a risk of domain bias. Because the movie can not cover all diverse accents, languages, or speaking styles.\n\n2. This paper is an extension of textual-prompt-based text-to-speech synthesis. The authors propose to extend the descriptive prompt of speech to three dimensions: 1) dialogue, 2) narrative, and 3) action. However, it is only an incremental work of the existing prompt-tts paradigm by extending the annotation pipeline. So it lacks novelty.\n\n3. In the experiments:\n* 3.1 It is better to categorize into three types: 1) None-Prompt TTS, 2) natural language description prompt-based TTS, and 3) speech prompt-based TTS.\n* 3.2 The method for CS-TTS in Sec. 4.1.2 is not clear. What is for \"but includes classification tasks for emotion, pitch, energy, and speed during training\"? For emotion, how do you obtain the label? Furthermore, it is not clear how the author leverages the \"DNA\" prompt as a condition to guide the generation process.\n* 3.3 It lacks an ablation study for the attribution controllability for the proposed \"DNA\" attributes.\n\n4. The obtained dataset contains about 18 hours including 2395 distinct characters, indicating that only 0.45 minutes for a single character. It is small to train a good TTS system."
      },
      {
        "rating": "3",
        "confidence": "4",
        "summary": "This work introduces a new TTS task called **Contextualized and Situated Text-To-Speech** (CS-TTS), which incorporates contextual descriptions into speech generation, aiming to enable TTS models to produce more expressive speech. As the lacking of CS-TTS datasets, they created a new CS-TTS dataset called **DNASpeech**. Each speech sample in DNASpeech is accompanied by three types of contextualized prompts: **Dialogues** provide conversational context, **Narratives** describe the environment surrounding the speaker, and **Actions** detail the speaker’s actions and expressions. For dataset construction, they developed an automated annotation pipeline, with human evaluations to validate the approach.\n\nAdditionally, they established a leaderboard to assess the performance of current TTS systems, and introduced a baseline model adapted to the CS-TTS.",
        "strengths": "1. This work introduces a new dataset called DNASpeech, specifically created for the innovative CS-TTS task.\n2. An automatic annotation pipeline is presented, utilizing techniques likes OCR, speech denoising, ASR to ensure the quality of produced dataset. Additionally, human evaluation is conducted to confirm the effectiveness of the pipeline.",
        "weaknesses": "## Weaknesses \n\n1. The paper asserts that contextualized descriptions lead to more accurate and expressive speech generation. However, there is only one experiment validating the effectiveness of CS-TTS, and it shows no significant improvement when using contextualized descriptions. For example, in evaluating the alignment between speech and environmental information, the MOS-E score gap between prompt-based TTS methods and non-prompted TTS is less than 0.1. StyleTTS, the best non-prompted TTS model, performs comparably to the prompt-based models. This makes it difficult to confirm the quality of the proposed dataset and the effectiveness of CS-TTS.\n2. The work introduces a TTS dataset where each sample includes three types of contextual prompts : **Dialogue**, **Narrative**, and **Action**. It is claimed that **Action** describes the speaker's actions and expressions, while **Narrative** provides environmental context, as mentioned in lines 74-76. However, based on the descriptions and examples given in the paper, these categories are difficult to differentiate. Take Figure 1 for an example, the Action \"showing the gun to JURORS\" corresponds to the Narrative \"He picks up a revolver...\", which is also an action. There is also confusion as to why the speaker's emotions are categorized under Action. Furthermore, in lines 142-144, the authors state that MEAD-TTS highlights environmental information (MEAD-TTS seems to focus on Action since it uses templates like \"A <gender> says with a <emotion level> <emotion> tone\" to write fine-grained prompts), yet in Table 1, MEAD-TTS's prompt is categorized under Actions, not Narratives, which contradicts the definitions provided in lines 74-76. Additionally, it seems like DailyTalk's focus is more on Dialogues than Narratives, given that DailyTalk focuses on chat history.\n3. One of the core contributions of the work is the automatic annotation pipeline for building the CS-TTS dataset from movie scripts. However, the description of this pipeline is unclear, making it difficult to understand how different type of prompts are extracted from movie scripts.\n\n## Suggestions \n\n1.  It would be better to use $\\cite$ or other citation formats instead of $\\citet$ when the cited paper is not the subject or object in a sentence. It becomes harder to read when citations are embedded in the main text. For example, in lines 32-34, it could be:\n> Text-to-speech (TTS) aims to convert input text into human-like speech, attracting significant attention in the audio and speech processing community (Shen et al. 2018; Ren et al. 2020; Shen et al. 2023; Ju et al. 2024).\n2. Many TTS-related datasets are mentioned in the related work section. However, the descriptions seem to be directly copied from the original papers, resulting in inconsistent types of information for each dataset. The writing does not highlight the core differences between previous work and this paper. It would be better to reorganize Section 2.1.\n3. To improve the integrity of the experiments, it would be helpful to explain the source of the human evaluators and what the interface or  instructions shown to the evaluators.\n4. When citing papers published at conferences, it is better to reference the conference version rather than the arXiv version. For instance, FastSpeech2 was published at ICLR 2021, but this paper cites its arXiv version.\n\n## Typos\n\n1. In Table 1, \"MM-TTS\" should be \"MEAD-TTS\", as the former refers to the TTS system and the latter is the name of the dataset.\n2. A period is missing at the end of line 361."
      }
    ],
    "rating_avg": 4.6,
    "confidence_avg": 4.0,
    "decision": "N/A",
    "meta_review": "",
    "author_remarks": "",
    "decision_comment": ""
  },
  {
    "id": "RDLvnUJ5JZ",
    "title": "TF-score: Time-series Forecasting using score-based diffusion model",
    "authors": [
      "Haksoo Lim",
      "Jaehoon Lee",
      "Jaesik Choi"
    ],
    "abstract": "Diffusion models have emerged as powerful generative models, capable of synthesizing high-quality images by capturing complex underlying patterns. Building on this success, these models have been adapted for time-series forecasting, a domain characterized by intricate temporal dependencies. However, most existing works have focused primarily on empirical performance without sufficient theoretical exploration. In this paper, we address this gap by introducing a generalized loss function within the diffusion-based forecasting framework. Leveraging this foundation, we introduce TF-score, a score-based diffusion model designed to capture the interdependencies between historical data and future predictions. Extensive experiments across six benchmark datasets show that TF-score consistently surpasses leading baselines, including prior diffusion-based models. Furthermore, we extend existing guidance sampling strategies into a our score-based formulation, achieving performance gains across multiple datasets while providing a detailed analysis of the trade-offs involved.",
    "keywords": [
      "Time-series forecasting",
      "Diffusion models",
      "Signal processing"
    ],
    "venue": "ICLR",
    "year": 2025,
    "pdf_url": "https://openreview.net/pdf?id=RDLvnUJ5JZ",
    "forum_url": "https://openreview.net/forum?id=RDLvnUJ5JZ",
    "reviews": [
      {
        "rating": "3",
        "confidence": "4",
        "summary": "This paper introduces TF-score, a score-based diffusion model designed for time-series forecasting. The model applies conditional generative diffusion modeling to time-series forecasting tasks, using historical data as conditioning factors and the complete data sequence as the generation target. Additionally, a mask vector is incorporated into the loss function to separate historical and future data.",
        "strengths": "​1. **Appropriate Application of Diffusion Models**: The paper effectively adapts diffusion models for time-series forecasting, a relatively novel domain for such models, building on their successes in generative tasks.\n\n​2. **Unified Framework**: The authors integrate existing diffusion models for time-series forecasting into a continuous score-based framework, enhancing the theoretical foundation of their approach.\n\n​3. **Experimental Performance**: TF-score outperforms multiple benchmark models across various datasets, validating its effectiveness in practical forecasting tasks.",
        "weaknesses": "​1. **Excessive Background**: The paper dedicates substantial space to explaining the background of diffusion models, the time-series forecasting task, and how diffusion models are applied in this area. The authors even include descriptions of existing embedding and guidance methods and the computation of the CRPS metric. This leaves limited space to discuss their own contributions, making the paper feel more like a course report than a research paper.\n\n​2. **Lack of Innovation**: The paper appears to mainly apply existing conditional generation diffusion models to time-series forecasting tasks, with limited novelty. The only new element is the mask vector, which seems overly simplistic. Only about one-fifth of a page out of the 10-page main text is dedicated to introducing this new method, and this so-called new method merely adds a weight mask when calculating the sequence loss. Besides, the section that introduces this new method is even titled **ANALYSIS OF EXISTING METHOD**. Therefore, I don’t consider this to be an innovation."
      },
      {
        "rating": "3",
        "confidence": "4",
        "summary": "This paper proposes using a score-based diffusion model for time series forecasting. The main claimed contribution is the simultaneous generation of both historical context and future predictions using diffusion models. Another claimed contribution is the continuous score of the SDE form for each generation.",
        "strengths": "S1. the method details are presented clearly\nS2. the proposed method is simple, and it is easy to follow",
        "weaknesses": "W1. The investigation is insufficient. Many related works on time series diffusion models are missing, e.g., [1,2]. Some works have used score-based diffusion models for time series prediction [3]. \n\n- [1] NIPS'22 Generative Time Series Forecasting with Diffusion, Denoise, and Disentanglement\n- [2] ICML'23 Non-autoregressive conditional diffusion models for time series prediction \n- [3] ICLR'24 Interpretable Diffusion for General Time Series Generation\n\n\nW2. the statement below is not very convincing. Using the historical context as a condition to generate the future part (without generating the past window) can still capture the internal structure of the total sequence. \n> \"our method considers both the historical context and future predictions simultaneously and thereby captures the internal structure of total sequence,\" \n\nIn contrast, generating historical context may be limited:\n1) bring some unexpected bias to degrade the prediction performance when there is some unrelated historical information;\n2) increase computational burden when a long history context is included. In the experiments, the authors only use small window sizes (<100) for evaluations. And there is no analysis of computational efficiency. \n\nThus, generating the whole time series using a score-based diffusion model is not fully convincing."
      },
      {
        "rating": "3",
        "confidence": "4",
        "summary": "This work builds on a growing literature of time series forecasting methods that use diffusion models for forecasting. First, the authors propose an analysis of families of related work, to introduce the forecasting problem and to cluster methods based on their loss function formulation. Here it is argued that generating the entire sequence (history + future values) has advantages over autoregressive approaches that use the history to predict future values.\n\nThe authors propose TF-score, a method that is supposed to generalize existing methods, and that can also incorporate a guidance mechanism. Experiments on well-known datasets indicate that the proposed method is on par with and sometimes superior to alternatives from the state of the art, including two diffusion-based methods. An ablation study complements the experiments, indicating that proper configuration of the proposed method is dataset dependent.",
        "strengths": "* I think the proposed objective of this paper is important, because in principle it could subsume existing diffusion-based time-series modeling approaches by presenting a more general formulation\n* Experiments and ablation studies are thorough, by considering several datasets and several alternatives from the literature, not limited to diffusion-based approaches to forecasting.\n* Despite some typos and a mathematical notation that can be improved, the article reads well and is easy to follow",
        "weaknesses": "* Sec.2.1 is very informal, and more importantly, uses precious space to outline methods that are not directly used in this work (only to review existing work in Sec. 2.2). Since score-based diffusion models through the lenses of stochastic differential equations are well known today, I suggest to make this part more compact, but at the same time more formal. Please, also double check grammar/typos (e.g., line 108: $f$ is an affine and $w$, …) and mathematical notation (check the commas at the end of the equations, e.g. line 108, line 141). Concerning the informal tone: see the comment below $L_{SM}$, the score term there is just not analytically available, therefore Song et al. condition the score on the initial sample, such that it becomes accessible, resulting in $L_{DSM}$. It is not a matter of computational effort or the need for statistical methods.\n\n* Sec. 2.2: pay attention to notation overload: $T$ is used both to indicate diffusion time as well as forecast horizon. Check expression clarity: for example, lines 155,157 do not read well and are vague.\nIn my opinion, eq.1 and eq.2 are not clear. For eq.1, the input to the score network is $x^{\\text{hist}}$, as well as the nosy $x^{\\text{pred}}$. Does it mean that $x^{\\text{hist}}$ is not used as a conditioning signal, which would be a natural choice? For eq. 2, the input is $x^{\\text{hist}}$ and $x^{\\text{total}}$: since $x^{\\text{hist}} \\in x^{\\text{total}}$, couldn’t we see this as an “inpainting\" approach?\nSince the goal of this section, also according to what claimed in the introduction, is to review and categorize in two classes existing approaches, I think it would be useful to provide the reader with more insights than just the two loss functions.\n\n* Sec. 3: this part contains, to the best of my knowledge, several mathematical mistakes. The first expressions in Sec. 3.1 do not make sense to me, especially regarding the score term which is manipulated without care, and with arbitrary choice of variables that are not compatible with score-based diffusion formalism. What does it mean to take the gradient with respect to $x^{\\text{pred}}$ of the log of the conditional density of $x^{\\text{pred}}_t$ given $x^{\\text{hist}}$? Are you trying to make the correspondence between $x^{\\text{hist}}$ and $x_0$ (that is the clean data) and $x^{\\text{pred}}_t$ to a noisy version of the clean data $x_t$? Note the problem: $x_t$ can be obtained in closed form from $x_0$, whereas obtaining $x^{\\text{pred}}_t$ from $x^{\\text{hist}}$ is exactly the problem you are trying to solve.\nSimilarly, eq. 3 and eq. 4 are shaky. In Eq. 3, how do you compute the gradient of the score (this time properly defined) with respect to $x^{\\text{pred}}$, which you do not have access to? In Eq. 4, isn’t it redundant to provide $x^{\\text{hist}}$ as an input to the score network $s(\\cdot)$, as it is already contained in $x^{\\text{total}}$?\nAlso, in line 212 it is said that weights are ignored for computational convenience. However, the weight $\\lambda$ is very important, as it determines what exactly you are optimizing: for example by setting $\\lambda(t)=g(t)^2/2$, minimizing the loss corresponds to maximum likelihood training [1, Sec. 2].\nFinally, it is necessary to delve into the details of the masking mechanism discussed in lines 251-252. It is used to discern past from future elements, which zeros out the future. This, in my opinion, is equivalent to the setup I alluded to in Sec.2 comments: essentially you can imagine $x^{\\text{total}}$ as an image, of which you zero out a region, leaving you with a portion that corresponds to $x^{\\text{hist}}$, which is amenable to an “inpainting” interpretation.\n\nNext, in sec 3.2.1 authors speak about generalizations of existing schemes to make the point that their approach is different from DiffWave. This is too strong of a claim, in my opinion.\n\nFinally, in sec 3.2.2 the authors could have discussed in more detail why the proposed method performs (slightly) better than diffusion-based alternatives such as TimeGrad and CSDI. For example, the initial message about classifying existing methods in two categories, and the intended take home message as to modeling $x^{\\text{total}}$ would have been stronger if properly compared and discussed.\n\n[1] Vahdat, Arash and Kreis, Karsten and Kautz, Jan, “Score-based Generative Modeling in Latent Space”, NeurIPS 2021.\n\n* Sec. 4: apart from traditional guidance, in Sec. 4.2 observation self-guidance is discussed (often attributing ideas to work from Song and Ho, which to the best of my knowledge do not refer to time-series data). The expression at line 380, which authors say implement Bayes rule, is ill defined: $p(a|b) \\sim p(b|a) p(a|b)$? The authors should double check, and consequently double check expression at line 383.\n\nOverall, I think the authors should do a better job at explaining the conditioning signal used for their guided method. Only the variant presented in the equation at line 397 is well defined. As a side note, it would have helped quite a lot numbering the various equations used throughout this paper."
      },
      {
        "rating": "3",
        "confidence": "4",
        "summary": "This paper introduces TF-score, a score-based diffusion model for time series forecasting with specific design in capturing the interdependencies between historical data and future predictions. The authors state the relationship between DDPM-based time series forecasting model and score-matching based methods and unify the framework by deriving the continuous score SDE form. Extensive experiments are conducted to show better performance against multiple baseline models.",
        "strengths": "- The proposed conditional score matching view of time series forecasting loss function is valid, and the idea of weighing errors for history and future generations is insightful.\n- The experiments are extensive, covering multiple time series forecasting baselines, multiple guidance sampling methods, and various diffusion step settings, showing efficacy of the proposed model.",
        "weaknesses": "- The similar idea of using score matching model seems to have been proposed by an earlier work [1], so the novelty and contribution of this paper may be quite limited. \n- The experiment part largely follows the experiment in [1], and the most advanced time series diffusion models are missing for comparison. To name just a few, [2][3][4][5]\n- Applying guidance sampling application on the proposed method cannot prove the superiority against baselines, since similar modifications are not applied on baseline models. It's unclear whether the proposed method can outperform baseline methods in these settings. \n\n[1] Yan, Tijin, et al. \"Scoregrad: Multivariate probabilistic time series forecasting with continuous energy-based generative models.\" https://arxiv.org/abs/2106.10121v1.  \n[2] Li, Yan, et al. \"Generative time series forecasting with diffusion, denoise, and disentanglement.\" Advances in Neural Information Processing Systems 35 (2022): 23009-23022.  \n[3] Shen, Lifeng, and James Kwok. \"Non-autoregressive conditional diffusion models for time series prediction.\" International Conference on Machine Learning. PMLR, 2023.  \n[4] Fan, Xinyao, et al. \"MG-TSD: Multi-Granularity Time Series Diffusion Models with Guided Learning Process.\" The Twelfth International Conference on Learning Representations. 2024.  \n[5] Ashok, Arjun, et al. \"TACTiS-2: Better, Faster, Simpler Attentional Copulas for Multivariate Time Series.\" The Twelfth International Conference on Learning Representations. 2024."
      }
    ],
    "rating_avg": 3.0,
    "confidence_avg": 4.0,
    "decision": "N/A",
    "meta_review": "",
    "author_remarks": "",
    "decision_comment": ""
  },
  {
    "id": "AecVG5CXdp",
    "title": "Novel RL Approach for Efficient Elevator Group Control Systems",
    "authors": [
      "Nathan Vaartjes",
      "Vincent Francois-Lavet"
    ],
    "abstract": "The management of elevator traffic in large buildings is crucial for ensuring low passenger travel times and energy consumption. We optimize the Elevator Group Control System (EGCS) using a novel Reinforcement Learning (RL) approach. Existing methods, including heuristic-based and pattern detection algorithms, often fall short in handling the complex and stochastic nature of elevator systems. This research proposes an end-to-end RL-based approach. A custom elevator simulation environment representing the 6-elevator, 15-floor system at Vrije Universiteit Amsterdam (VU) is developed as a Markov Decision Process (MDP). \nKey innovations include a novel action space encoding to handle the combinatorial complexity of elevator dispatching, the introduction of $\\textit{infra-steps}$ to model continuous passenger arrivals, and a tailored reward signal to improve learning efficiency. Additionally, we explore various ways of adapting the discounting factor to the $\\textit{infra-step}$ formulation. We investigate RL architectures based on Dueling Double Deep Q-learning, showing that the proposed RL-based EGCS adapts to fluctuating traffic patterns, learns from a highly stochastic environment, and thereby outperforms a traditional rule-based algorithm.",
    "keywords": [
      "Elevator Control",
      "Reinforcement Learning",
      "Applied Reinforcement Learning",
      "Partially Observable Markov Decision Process",
      "Dueling Double Deep Q-learning"
    ],
    "venue": "ICLR",
    "year": 2025,
    "pdf_url": "https://openreview.net/pdf?id=AecVG5CXdp",
    "forum_url": "https://openreview.net/forum?id=AecVG5CXdp",
    "reviews": [
      {
        "rating": "1",
        "confidence": "3",
        "summary": "This paper introduces a reinforcement learning (RL) approach to optimize elevator group control systems (EGCS). \nBy incorporating infra-steps to model continuous passenger arrivals, \nthe RL-based method outperforms traditional rule-based systems in minimizing passenger wait times. \nThe study demonstrates significant potential for real-world applications in dynamic, high-traffic environments.",
        "strengths": "- This feature, which models continuous passenger arrivals, creates a learning environment for the RL agent that mirrors real-life complexities.\n- The paper's approach is designed to avoid combinatorial complexity, ensuring efficient decision-making through a well-structured action space. This design choice provides a sense of relief about the model's efficiency.\n- The simulation design is based on the actual data set.",
        "weaknesses": "- This paper is still in the stage of considering the use of reinforcement learning, and the comparison with existing methods is insufficient."
      },
      {
        "rating": "3",
        "confidence": "4",
        "summary": "This paper addresses the optimization of complex elevator dispatching using a novel reinforcement learning (RL) approach. By modeling the problem as a Markov Decision Process (MDP) and introducing infra-steps to simulate continuous passenger arrivals, the authors capture the inherent uncertainties and complexities of elevator systems.\nThe paper compares fixed and variable discounting strategies, finding that the fixed approach provides greater stability and effectiveness in managing varying time intervals between actions. Additionally, the research evaluates branching and combinatorial RL agent architectures, demonstrating that the combinatorial architecture leads to more efficient decision-making.\nEmpirical results show that the proposed RL-based solution outperforms modern rule-based systems in a simulated environment with six elevators and fifteen floors. The RL agent utilizes a Dueling Double Deep Q-Learning algorithm to efficiently adapt to complex traffic patterns, significantly reducing passenger travel times. These promising findings underscore the potential for practical implementation of RL-based control in real-world elevator systems.",
        "strengths": "The paper demonstrates significant strengths through its innovative approach to elevator dispatching using a novel reinforcement learning (RL) framework. \nBy introducing infra-steps to simulate continuous passenger arrivals and formulating the problem as a Markov Decision Process (MDP), it effectively captures the complexities of elevator systems.\nThe comprehensive comparison of fixed and variable discounting strategies, along with the exploration of branching and combinatorial RL architectures, reflects methodological rigor and originality. \nThe research is presented with clarity, supported by detailed diagrams and equations, which enhance understanding. Furthermore, the study has considerable significance, \noffering a practical reduction in passenger travel times and bridging theoretical and practical applications in real-world elevator management systems.",
        "weaknesses": "1. Experimental Comparison : The paper only compares the proposed method against the classical ETD algorithm. It does not include comparisons with recent RL-based approaches, making it difficult to evaluate the method's novelty and effectiveness in the broader RL research context.\n2. Experimental Setup : The experiments are conducted using a single dataset, which limits the capacity to demonstrate the method's adaptability to diverse scenarios or environments. Testing across various conditions would better demonstrate robustness and versatility.\n3. Results Clarity : The results do not clearly show how the proposed algorithm outperforms previous methods. Adding more detailed analysis and comparison metrics would help elucidate the specific advantages.\n4. Action space : The paper mentions a significant reduction in action space design but does not offer direct comparisons with previous algorithms. Including these comparisons would strengthen the explanation and highlight improvements."
      },
      {
        "rating": "5",
        "confidence": "5",
        "summary": "The paper proposed an RL algorithm for elevator group control systems. The authors proposed a new action space to handle the combinatorial complexity of elevator dispatching. The infra-steps are proposed to handle continuous passenger arrivals. Overall it is a good application paper for RL, the writing is clear and the modification is reasonable in practice.",
        "strengths": "1.\tThe authors focus on a very practical and meaningful real-world problem, which should be encouraged in the RL community.\n2.\tThe writing is very clear. Especially, the authors explained many definitions the elevator control very well.\n3. The proposed new action space and infra-steps look simple but effective, which might benefit the empirical RL research very much. The significance is beyond the elevator group control.",
        "weaknesses": "1. The notations are sometimes confusing. For example, in equation (1) $G^\\pi$ is a conditional expectation, which is not correct. $\\pi$ is not a random variable. $\\pi$ is a function and will change the state-action distribution. A common practice is to write $G$ as a function of $\\pi$.\n\n2. The contribution of infra-step is not very clear. The empirical results have shown that the fixed discounting works better than the variable discounting."
      },
      {
        "rating": "3",
        "confidence": "4",
        "summary": "The paper studies the group elevator control problem by introducing RL. \nThe paper is clearly written and easy to follow, \nhowever contribution is minor.",
        "strengths": "The topic of the paper is interesting. The paper is clearly written and easy to follow.",
        "weaknesses": "The contribution of the paper is minor in the sense that the details of the key elements proposed method are missing. For example the deep neural networks are not given. The other limitation is that the quality of the simulation model used for training the elevator group control algorithms is not clear."
      }
    ],
    "rating_avg": 3.0,
    "confidence_avg": 4.0,
    "decision": "N/A",
    "meta_review": "",
    "author_remarks": "",
    "decision_comment": ""
  },
  {
    "id": "omzijInU1T",
    "title": "Feature Learning in Attention Mechanisms Is More Compact and Stable Than in Convolution",
    "authors": [
      "Baiyuan Chen"
    ],
    "abstract": "Robustness is a crucial attribute of machine learning models, A robust model ensures consistent performance under input corruptions, adversarial attacks, and out-of-distribution data. While the Wasserstein distance is widely used for assessing robustness by quantifying geometric discrepancies between distributions, its application to layer-wise analysis is limited since computing the Wasserstein distance usually involves dimensionality reduction, which is not suitable for models like CNNs that have layers with diverse output dimensions. To address this, we propose $\\textit{TopoLip}$, a novel metric that facilitates layer-wise robustness analysis. TopoLip enables theoretical and empirical evaluation of robustness, providing insights into how model parameters influence performance. By comparing Transformers and ResNets, we demonstrate that Transformers are more robust in both theoretical settings and experimental evaluations, particularly in handling corrupted and out-of-distribution data.",
    "keywords": [
      "Feature Learning",
      "Attention",
      "Convolution",
      "Transformer",
      "ResNet",
      "Lipschitz Continuity",
      "Wasserstein Distance",
      "Topological Data Analysis"
    ],
    "venue": "ICLR",
    "year": 2025,
    "pdf_url": "https://openreview.net/pdf?id=omzijInU1T",
    "forum_url": "https://openreview.net/forum?id=omzijInU1T",
    "reviews": [
      {
        "rating": "6",
        "confidence": "2",
        "summary": "This paper presents a theoretical and empirical comparison of attention mechanisms and convolutional layers, focusing on their feature learning properties, including Lipschitz continuity, intrinsic dimensionality, and stability. It claims that attention mechanisms yield more stable and compact representations than convolutional layers and validates this through theoretical bounds and experiments on various architectures (Vision Transformers (ViTs) and ResNets).",
        "strengths": "* The paper provides a rigorous theoretical analysis of the feature learning characteristics of attention versus convolution",
        "weaknesses": "* Since attention and convolutional architectures can be combined in practice, it would have been useful to explore hybrid models or discuss scenarios where attention layers supplement convolutional layers, as is common in many architectures.\n\n* Training on CIFAR-10 may not yield strong performance for ViTs, as they typically require large amounts of training data. Could this limitation have impacted the results?"
      },
      {
        "rating": "1",
        "confidence": "4",
        "summary": "The authors propose a mean-field regime study of attention and convolution, and argue the attention mechanism is more robust to variations in input data distributions, enabling more stable feature learning. They observe such conditions do not actually hold in ViTs, which are more aligned with ResNets in terms of behaviour. They demonstrate lower intrisinc dimensionality in feature learning of attention mechanisms wrt convolutional ones, however these characteristics do not persist in comparisons of ViTs and ResNets.",
        "strengths": "Strengths: \n- Originality: I do not know other papers performing the same type of analyses. The authors develop or apply the theory in novel ways to draw some conclusions about the attention mechanism and convolutional layers. Therefore the work could be considered novel. \n- Quality: the theoretical developments look sound with respect to the assumptions that are made ...\n- Clarity: the paper is clearly written and easy to follow. \n- Significance: unclear, not a strength point ...",
        "weaknesses": "I start the list of weaknessess with a complementary comment to the strenghts. \n\n- Quality: ... however the experimental results are limited and undermine the usefulness of the theory. \n- Significance: the significance or importance of the paper is not particularly clear. There does not seem to be any useful consequence of the theory developed. It is not clear what point the authors are trying to make because the lower variance and Wasserstein-lipschitz condition impact on possible applications (e.g. training stability and convergence, data efficiency, robustness, generalization, differential privacy etc.) are not mentioned or discussed (and if they are, it's more to state their irrelevance for real applications.  The authors should strongly motivate the utility of their study and how it produces insights that can lead to future useful developments. For instance, the authors could consider Differentially Private (DP) SGD training ,where batch normalization (BN) is not allowed and the lipschitzness (of the per-sample gradients in this case) has a strong impact on the training accuracy. If the authors could find a relationship between their wasserstein-lipschitzness and the ones of the per-sample gradients, it could have some practical impact on DP. Similarly, it would be interesting if the authors could find at least some toy practical applications in which their findings could show their possible impact.\n\n\n- The CIFAR-10 experiments are conducted on extremely small models, it's unclear whether the findings generalise to both larger scale datasets or larger models. Furthermore, the training of transformers (and of CNNs too) is strongly regularised with augmentations and training tricks. It's not so clear whether the findings hold under such forms of regularization (see question about training details)\n- Seveal works compare different aspects of transformers robustness and generalization. Many works have found that the claimed ability of attention mechanisms to focus on the whole of an input has little to no impact on the robustness of the learnt features, outlining that training tricks like pre-training and training procedures have larger impact than the inductive biases of the convolutional/attention mechanisms  [1,2,3]\n\n[1] https://arxiv.org/abs/2207.11347\n[2] https://arxiv.org/pdf/2310.16764\n[3] https://arxiv.org/abs/2310.19909"
      },
      {
        "rating": "3",
        "confidence": "3",
        "summary": "The submission investigates the output variance and smoothness of non-residual (i.e., without skip connections) Attention and Convolutional layers. The authors demonstrate that attention is more compact and stable than convolution. Specifically, after presenting background on Transformers, Convolutions, and ResNets, the submission reviews recent results on the smoothness properties of attention in a mean-field framework. In Theorems 1 and 2, the input variance of the activations is derived, while Theorems 3 and 4 provide an upper bound on the Lipschitz constant of attention and convolution. Finally, experimental results on toy models (Conv and Attn), ResNet18, and a small ViT are presented, where activation variance, Wasserstein distances, and intrinsic dimensions are recorded across layers during training.",
        "strengths": "- The paper addresses an interesting question: understanding the theoretical differences in smoothness between attention-based and convolutional models, two widely used components of modern deep learning.\n- The authors acknowledge that the theoretical findings do not transfer well to models with skip connections and normalization.\n- The theoretical results appear rigorously proved.",
        "weaknesses": "In my view, this submission is not yet ready for publication at ICLR.\n\n*In terms of writing:*\n- The paper is challenging to follow. For instance, while the abstract and introduction repeatedly reference \"feature learning,\" this term is not mentioned again in the rest of the paper. Another example is the mention of masked attention (l. 361), whereas no mask is used in ViTs. The motivation for using the $W_2$ metric, in my opinion, is not well explained (l. 307).\n- The paper consists mostly of background material until page 5.\n- The persistent homology part discussed in Section 2.5 is not referenced again in the rest of the submission.\n- The related work section is very brief, with insufficient discussion of prior work. For instance, [2] also discusses the Lipschitz constant of self-attention.\n\n*Regarding the theoretical contributions:*\n- For attention, I am unsure about the novelty relative to previous work on the smoothness of attention, particularly Theorem 3.5 from Castin et al. (2024) and computations by Geshkovski et al. (2024).\n- Theorem 5 should be replaced by a concrete result concerning deep ConvNets and Transformers rather than the actual theorem followed by a discussion (which I personally find unclear).\n\n*Regarding the experimental contributions:*\n- I am not convinced that the empirical results validate the tightness of the bounds in the theorems, or that they are sufficiently related to the rest of the paper.\n- Additional experimental details in Section 4 are needed. How is activation variance computed? Over how many samples? Are these training or test samples?\n- Generally, stacking attention layers without residual connections is very poor practice, as shown in [1] (which, in my opinion, should be discussed in the paper)."
      },
      {
        "rating": "5",
        "confidence": "3",
        "summary": "This paper provides an analysis on the feature map variance between basic convnets and attention only networks. The author then expands this analysis to known architectures using the same building blocks such as the ResNet18 and the Vision Transformer. The author finds that their attention networks feature embeddings have a lower variance than those produced by convolutional nets, however this does not hold when expanding the attn network to a vision transformer architecture.",
        "strengths": "- The paper provides an interesting result, showing that attention mechanisms learn feature maps with lower variance than convolutional networks.\n- The paper is mathematically correct from my understanding",
        "weaknesses": "- I am struggling to understand what is different between the attn -> vit models as well as the conv -> resnet. Is it the exclusion of residual connections and normalisation layers?\n- There is no indication of the performance of the networks in accuracy, assuming they are at convergence I would expect the accuracies to be in the low to mid 90's for cifar-10, but the paper does not indicate whether the networks reached this performance or not. In my opinion, this is an important detail as otherwise we may be comparing underfitted networks which presumably do not have the correct feature space configuration for optimal accuracy.\n- The author presents the statistics, but does little analysis into what this means. Do we want low variance or high variance in our feature space?\n- (Minor) The figures 11-17 in the appendix are interesting visualisations of the feature space, but would be more informative if we zoomed in on the blobs of features to see if there is separation within the blobs, even if it is small.\n- (Minor) To add onto the above point, visualisations of the class specific latent representations would be more interesting than the entire space to determine whether despite high or low variance of features, is our feature space semantic."
      },
      {
        "rating": "3",
        "confidence": "4",
        "summary": "The paper compares variance, stability, and intrinsic dimensionality of the representations learned via attention or convolution in transformers and CNNs. The authors first study this in a theoretical setting imposing assumptions on the input and formulation of the models, deriving the variance and Lipschitz constants for each of attention and convolution. They then provide arguments about intrinsic dimensionality and how they believe different components of the models (e.g., MLP or batch norm) impact these properties. In the end, they provide experimental observations on variance and stability of two attention and two convolution models as well as ViT and ResNet.",
        "strengths": "Understanding various aspects of success of commonly-used and successful models such as CNNs and transformers is important. This paper focuses on the stability of these models, which could shed light on another factor that plays a role in the remarkable success of transformers. Theoretical results in a clear setup are helpful, despite (some inevitable) shortcomings.\n\nSome examples of interesting and insightful observations/findings provided in the paper:\n- Dependency of variance of the outputs in the attention on dimensionality, while this variance only depends on the input variance in convolution (line 285).\n- The implications of Theorem 4, showing that the Lipschitz constant of the Attn with practically-relevant values of the variables ends up being much smaller than that of Conv (line 346).\n- Potentially intriguing arguments provided in 3.4 for intrinsic dimensionality,\n- The experiments are ample for a theoretical paper (but not if the authors believe their main results come from the experiments) and the experimental setup seems suitable to investigate the main questions posed by the paper.",
        "weaknesses": "**The key weakness:** The main motivation of the paper seems lost. The paper does not motivate why a comparison on the variance of stability of transformers and CNNs is a question worth a paper, especially given the limited scope of the setup. Unless the introduction motivates this question, the paper essentially seems like it could be a section of a more thorough study, e.g., on the stability of transformers or on the comparison between CNNs and transformers. While it is not impossible that I am missing something, I do not see a way that this paper could be prepared for publication at ICLR without a major reconsideration of the content and the presentation.\n\n**Other major weaknesses:**\n\n1. Related to the key weakness above: the second paragraph of the introduction seems to jump from some general statements about transformers and CNNs (first paragraph) to questions the authors pose, without explaining why the questions are raised or why their answers matter. Same issue applies to the contributions listed in the introduction.\n\n2. The literature review seems insufficient and shallow. The literature reviewed in the Related Work section is both old, and not closely related to what the authors study. While there are many recent theoretical works, both on feature learning, and on the behavior of transformers (see, e.g. [1-3]), not many prior works related to the topic of the paper are referenced. I believe this is yet another reason the manuscript does not motivate the main questions.\n\n3. Some claims and statements seem unsubstantiated. I presume the authors do know why those statements hold, but the arguments are not communicated well. E.g., in line 295, the authors claim that they “*prove* attention can have a lower activation variance” through the analysis that follows. However, the analysis is on the Lipschitz constant, and the experiments do not seem to actually *prove* that (even in the sense of a “strong empirical evidence”, which still should not be referred to as a “proof”, especially in a paper that presents itself as a theoretical study). \n\n4. The experiments do not show convincing evidence of the theory. While some match, some do not, and the experiments in the appendix seem inconsistent. Moreover, the inconsistencies are not properly discussed.\n\n\n**Other weaknesses:**\n\na. The Preliminaries section is unnecessarily long. Batch normalization or MLP for instance, are basic concepts that could be stated in one line and the definitions could be moved to the appendix.\n\nb. How did the authors use persistence homology or TDA in the paper at all? The abstract claims the use of TDA, and there is a subsection on persistence homology, but there seems to be no analysis based on TDA.\n\nc. Some basic definitions and concepts are provided in the core theoretical results of the paper, where they do not belong. e.g., the definition of the Wasserstein distance, or Theorem 5, are too basic to be stated in detail in section 3. They should be either in the preliminaries or in the appendix.\n\nd. While intuitive, the arguments in section 3.4 lack rigor. The authors later claim (line 485) that they “prove” that attention leads to a lower intrinsic dimensionality, while I do not see anything close to a proof in section 3.4 (and, again, experiments are not a proof, especially if the evidence is not thorough and strong). \n\ne. There results in the appendix are not properly referenced, nor are they discussed in the main paper.\n\nf. The authors claim that their analysis of the stability “has nothing to do with the model performance”) line 383, while there is often a tradeoff between expressivity (hence performance) and stability.\n\ng. Arguments and explanations in lines 451-456 are not clear.\n\nh. The discussion of Figure 2 seems unclear, with statements that do not clearly reference the evidence from the experiments.\n\ni. This is a minor point, but I would not call Theorem 1 and 2 “theorem”, but rather a “proposition”, since they are direct results of the assumption that the input is a 0-mean Gaussian.\n\n\n\n**References:**\n\n[1] Von Oswald, J., Niklasson, E., Randazzo, E., Sacramento, J., Mordvintsev, A., Zhmoginov, A., & Vladymyrov, M. (2023, July). Transformers learn in-context by gradient descent. In International Conference on Machine Learning (pp. 35151-35174). PMLR.\n\n[2] Abbe, E., Bengio, S., Boix-Adsera, E., Littwin, E., & Susskind, J. (2024). Transformers learn through gradual rank increase. Advances in Neural Information Processing Systems, 36.\n\n[3] Radhakrishnan, A., Beaglehole, D., Pandit, P., & Belkin, M. (2024). Mechanism for feature learning in neural networks and backpropagation-free machine learning models. Science, 383(6690), 1461-1467."
      }
    ],
    "rating_avg": 3.6,
    "confidence_avg": 3.2,
    "decision": "N/A",
    "meta_review": "",
    "author_remarks": "",
    "decision_comment": ""
  },
  {
    "id": "0Yfjerm9Zp",
    "title": "Enhancing LLM Faithfulness in Rationale Generation via Dual-Reward Probabilistic Inference",
    "authors": [
      "Hanqi Yan",
      "Jiazheng Li",
      "Yulan He"
    ],
    "abstract": "As large language models (LLMs) are increasingly applied to complex reasoning tasks, achieving both accurate task performance and faithful explanations becomes crucial. However, LLMs often generate unfaithful explanations, partly because they do not consistently adhere closely to the provided context. Existing approaches address this problem either rely on superficial calibration, such as decomposed Chain-of-Thought prompting, or require costly retraining to improve model faithfulness. In this work, we propose a probabilistic inference paradigm that provides fine-grained and lookahead rewards to ensure that LLM-generated rationales are logically coherent and comprehensive. These rewards are derived from a domain-specific proposal distribution, allowing for optimised sequential Monte Carlo approximations. Our evaluations across three different reasoning tasks show that this method, which allows for controllable generation during inference, improves both accuracy and faithfulness of LLMs while keeping computational costs similar to those of existing decoding techniques. This method offers a promising path towards making LLMs more reliable for reasoning tasks without sacrificing performance or efficiency.",
    "keywords": [
      "interpretability",
      "faithfulness",
      "Large language model",
      "constrained generation"
    ],
    "venue": "ICLR",
    "year": 2025,
    "pdf_url": "https://openreview.net/pdf?id=0Yfjerm9Zp",
    "forum_url": "https://openreview.net/forum?id=0Yfjerm9Zp",
    "reviews": [
      {
        "rating": "5",
        "confidence": "4",
        "summary": "The paper proposes an approach to do faithful rationale generation in LLMs. It uses a steering-based approach to make the outputs more faithful to the reasoning of the llm in classification. The idea is to weight token logits using 2 kinds of reward models: A \"local\" one that tries to match tokens to those suggested by a domain-specific expert model and a \"lookahead\" one that does an MTCS type search and re-weights logits based on rewards from unrolled sequences.  \n\nExperiments are performed on a couple of QA type datasets, demonstrating that each method makes improvements in classification accuracy and faithfulness of rationales. Some qualitative analyses are also presented.",
        "strengths": "1. MTCS type inference is a hot topic right now, and it is indeed an important frontier for LLMs to improve on.\n2. At a surface level, experimental results seem to show large gains.",
        "weaknesses": "Section 3 is pretty badly written, it is pretty hard to get the details of the approach. Instead of invoking irrelevant sophisticated-sounding terminology like \"Feynman-Kac\" formulas it would be better to describe the method in more detail. The math especially is confusing, see below.  \n\nThe paper seems to show some positive experimental results, but I am concerned about whether we are looking at a meaningful comparison. The proposed methods rely on domain experts. Looking at table 8 in the appendix these are generally models that have been fine-tuned for the task in some way (and not just on the validation sets as the main section claims, some have access to external datasets). So it shouldn't be that surprising that a method that is given access to an expert which has more signal will do better than the backbone pre-trained model. A fair comparison would have to be with an approach that does vanilla fine-tuning of LLama or mixtral model. \n\nIn terms of novelty: The authors have not really cited relevant work in the controlled decoding space:\n\nhttps://arxiv.org/abs/2310.17022\n\nhttps://sea-snell.github.io/ILQL_site/\n\nThese works already do something more sophisticated than just token reweighting by a reward score. So what is the novel contribution here? 2 possibities:\n1. Focusing on the faithfulness problem.\n2. The \"lookahead\" idea of the reward model. I dont recall having seen this before, but it feels like a simplification of a full-blown MCTS. I would also call this a poor man's version of ILQL.\n\nSo we are just left with #1 then, unless I missed something. And this is something I consider of limited novelty (more like an application for a particular problem, though one with interesting implications from the steering perspective)."
      },
      {
        "rating": "1",
        "confidence": "3",
        "summary": "The work aims to improve the faithfulness of the LLM-generated rationales for reasoning tasks. They propose an inference-based method where an LLM is guided to generate more faithful rationales by both local and global rewards. Both rewards are provided by additional expert models which are trained on the downstream tasks. Experiments demonstrate the effectiveness of the method in achieving higher accuracy and faithfulness.",
        "strengths": "1. Faithful rationales are important for explainability and model control, which makes this work well-motivated.\n2. The proposed method is training-free (although with reliance on trained expert models), making their method portable.\n3. A comprehensive set of experiments is conducted to showcase the effectiveness of their proposed method.",
        "weaknesses": "1. The method requires the model to generate the answer prior to the rationale, which provides no guarantee that the decision is made based on the rationale. The model could still suffer from inherent biases.\n2. The method is limited to reasoning tasks with constrained answer space, limiting its generalization to more open-ended tasks.\n3. The method is poorly introduced. It would be very helpful if the authors could explain what exactly Eq.1-3 are doing in plain words."
      },
      {
        "rating": "3",
        "confidence": "3",
        "summary": "This work proposes an inference-time method to improve the performance and faithfulness of general (instruction-tuned) large language models (LLMs). Specifically, the method uses expert models to provide fine-grained and lookahead rewards to search and reweight possible tokens or continuations proposed by the LLM. With the help of expert models trained on the target task or domain, the proposed method can improve both the accuracy and faithfulness of the zero-shot answers of two instruction-tuned models on three reasoning tasks.",
        "strengths": "The direction this paper explored has been receiving increasing interest recently: improving the quality of LLM answers at inference time without modifying the model weights directly. The proposed method improves the zero-shot accuracy and faithfulness of two strong general instruction-tuned models (Llama-3-8B and Mistral-7b-Instruct-v0.3) on three reasoning tasks. The experiment showing the benefits of going beyond local/token-level rewards and taking into account the global/lookahead reward is interesting.",
        "weaknesses": "- There needs to be more details explaining the proposed method, the motivation of each part, the equations and variables, the relation to related work, and the implementation details. Specifically:\n  - Section 3.3: how does the Feynman-Kac Formulae model inspire the faithfulness-seaking search framework? The connection is not straightforward. The notation of eq 1 is ambiguous. What does posterior P_t(st) mean exactly? How is it used in the proposed method? Also, the equation itself needs more explanations on what it is computing and why in this way.\n  - Section 3.4 (Local constraint): line 179 I find it hard to follow the motivation. How \"certain attributes can be implicitly conveyed over longer spans rather than the individual token\" is connected to \"Instead, domain-specific experts tend to demonstrate better accuracy in knowledge-rich tasks.\"? If the domain expert has better accuracy why not just use the expert to predict the scores? Why bother to use them to improve the backbone LLM? In lines 180-181, it says \"we introduce a set of classification label words C from these expert models ...\", how is C constructed? What is the motivation behind token masking?\n  - Section 3.4 (Lookahead Reweight): Equation 3 is hard to understand without proper explanations. $m$ and $x_i$ are not explained in the texts. $s_{t+l}=s_{t-1}||w_t$ is more confusing: $s_{t+l}$ has $t+l$ tokens while $s_{t-1}||w_t$ has $t$ tokens. What does equality mean here?\n- Many experimental details are missing, and important experiments are missing.\n  - Missing baselines: the performance and faithfulness of the expert models alone. If the faithfulness or accuracy of the expert models are better than the backbone LLM, why do we even need to use the expert models to improve the backbone LLM?\n  - Evaluation details: how is the original model evaluated? If it is a zero-shot evaluation. What is the exact prompt and task format used? How to extract answers from the outputs to calculate the accuracy? The backbone LLMs are state-of-the-art instruction-tuned models. However, the task performance as well as the faithfulness are quite low, so the authors need to provide more details on the evaluation.\n  - What is the choice of hyperparameter n (number of rollouts) and how is it chosen?\n- The writing of the paper could be improved for better readability. First, the paper is not properly scoped. For example, in lines 16-18, it says \"... to ensure that LLM-generated rationales are logically coherent and comprehensive.\" However, there is no result discussing the logical coherence or comprehensiveness of answers in the paper. Another example is line 108: it says \"We firstly introduce the faithfulness definition in our context,\", but there is no clear definition in section 3.2."
      },
      {
        "rating": "5",
        "confidence": "3",
        "summary": "They tackle the rationale generation tasks in LLMs' reasoning process. Specifically, they propose a probabilistic inference paradigm that provides fine-grained and lookahead rewards to instruct LLMs to generate good rationale. The key problem addressed is that LLMs often produce unfaithful explanations, especially when they fail to incorporate essential contextual information. \n\n+ **Local Reward**:  this component ensures coherence with the immediate context, often by using a domain-specific expert model.\n+ **Global reward**: This assesses the plausibility of the current token in relation to desirable future attributes\n\nThe search algorithm, especially for lookahead reweight seems interesting.\n\nPlease forgive me if I misunderstand something. I spent much time for reading the paper but to be honest, I am not an expert in this area. I will available on the rebuttal time for author's response and will read their response. I am also open to other reviewers' opinions.",
        "strengths": "1. The paper introduces a novel probabilistic inference method with a dual-reward mechanism, combining local and global reward. This is a very novel solution. \n2. The paper is well-written. I am not an expert in this domain but I can get their core contributions. \n3. The experiment design is clear: they design the ablation study in Section 5.1 to justify the local and global rewards for the final performance. Although I suggest authors could do better by choosing more LLMs in different model size to better support their experimental design.",
        "weaknesses": "1. There are several related works that are missing or less discussed: \n        + Evaluating Human Alignment and Model Faithfulness of LLM Rationale\n        +  On Measuring Faithfulness or Self-consistency of Natural Language Explanations\n2. Figure 2 about the distribution of domain-specific words is unclear to me. \"showing that our method can respond more actively to those domain-specific words\" Why does this part matters to the experimental results."
      }
    ],
    "rating_avg": 3.5,
    "confidence_avg": 3.25,
    "decision": "N/A",
    "meta_review": "",
    "author_remarks": "",
    "decision_comment": ""
  },
  {
    "id": "zNVefjN3EP",
    "title": "OpenCarbonEval: How much $CO_2$  will your large model exhale in training process?",
    "authors": [
      "Zhaojian Yu",
      "Yinghao Wu",
      "Zhuotao Deng",
      "Xinchun Yu",
      "Yansong Tang",
      "Xiao-Ping Zhang"
    ],
    "abstract": "Data, model and hardware are crucial components in the development of large scale machine learning models. The training of such models necessitates substantial computational resources, energy consumption, and raw materials, resulting in significant environmental implications. However, the environmental impact of these models has been largely overlooked due to a lack of assessment and analysis of their carbon footprint. In this paper, we present OpenCarbonEval, a carbon emission estimation framework to quantify the environmental implications of large scale machine learning models given their total training computations and hardware configurations.\nIn OpenCarbonEval, we conducted a comprehensive dynamic analysis of the interrelationships among data, models, and hardware throughout the model training process, aiming to forecast the carbon emission of large scale models more accurately. We validated our approach on real-world dataset, and experimental results demonstrate that OpenCarbonEval can predict energy costs and carbon emissions more accurately than previous methods. Furthermore, it can be seamlessly applied to various machine learning tasks without a precision decline. By quantifying the environmental impact of large-scale models, OpenCarbonEval promotes sustainable AI development and deployment, contributing to a more environmentally responsible future for the AI community.",
    "keywords": [
      "Large-scale model",
      "Carbon footprint",
      "Sustainable AI"
    ],
    "venue": "ICLR",
    "year": 2025,
    "pdf_url": "https://openreview.net/pdf?id=zNVefjN3EP",
    "forum_url": "https://openreview.net/forum?id=zNVefjN3EP",
    "reviews": [
      {
        "rating": "3",
        "confidence": "2",
        "summary": "This paper proposes a tool named OpenCarbonEval to estimate energy consumption and carbon emissions during the training process of large ML models. The authors present a new formulation for estimating the training carbon footprint of various models and evaluate the effectiveness of their approach in comparison to related work.",
        "strengths": "- Timely problem\n- Good motivation",
        "weaknesses": "- Novelty\n- Soundness\n- Insufficient hardware details"
      },
      {
        "rating": "3",
        "confidence": "4",
        "summary": "The paper presents OpenCarbonEval, an innovative approach for estimating the carbon footprint of training large ML models, with claims to improve prior models by incorporating hardware-specifications, embodied and operational carbon estimation, and dynamic power consumption. It introduces an α parameter to model dynamic power consumption and introduces an open-source dataset of 110 models across multiple large-scale ML tasks for validation of the proposed approach.",
        "strengths": "1.\tRelevant Topic: The environmental impact of large ML models is an important concern, and OpenCarbonEval’s focus on a general framework for carbon footprint estimation. OpenCarbonEval showcases improved error rate in comparison to LLMCarbon across various large-scale ML models.\n\n2.\tMulti-Domain Scope: The method’s attempt to generalize across model types, hardware types, and tasks, potentially making it more versatile than existing carbon estimation among the estimation methods. \n\n3.\tDataset Creation: OpenCarbonEval contributes an open resource by curating a dataset of carbon emissions containing 110 records.",
        "weaknesses": "1.\tInadequate Justification for the α Parameter: The derivation of the α parameter lacks theoretical depth, as the paper does not substantiate the choice of logarithmic modeling. Providing empirical or theoretical evidence for using f(t)=ln(1+αt) would strengthen its validity; a comparison with alternative functions could clarify this choice.\n2.\tLimited Model Generalization: OpenCarbonEval does not convincingly show its ability to generalize across diverse ML tasks and architectures. The adaptability of the α parameter remains unclear, particularly for models outside the initial dataset. Additional validation across a wider range of model types by extending Table 1, 2 will reinforce its versatility. Detailed results for the validation of the method is required.\n3.\tLack of Explanation for Equations: The paper lacks the connection between equation (2) and equation (3), and also lacks the explanation of how the Lcomputation is used to estimate the energy consumption E. Moreover, the Clifelong needs to be elaborated in terms of how it is attained. \n4.\tComparison with results for LLMCarbon: Can the authors present the analysis of same models and hardware combinations presented in Table 4 in the LLMCarbon paper?\n5.\tJustification or Citation for Assumption: The assumption of 1-year GPU lifespan for the embodied carbon estimation lacks justification or citation from a reliable source. \n6.\tOverlooked Factors in Operational Carbon Calculation: OpenCarbonEval does not account for essential factors like Power Usage Effectiveness (PUE) in data centers, leading to potential underestimations of emissions. Including PUE in calculations would create a more realistic operational carbon estimate.\n7.\tSimplistic Treatment of Training Dynamics: OpenCarbonEval applies Little’s Law simplistically, assuming a steady state in training dynamics, which oversimplifies the training process. More practical grounding, perhaps through empirical evidence, would enhance applicability in ML contexts. LLMCarbon addresses this by using detailed hardware efficiency and optimal parallelism settings, providing a robust framework for accurately modeling training dynamics.\n8.\tEmbodied Carbon Calculation: OpenCarbonEval’s approach to embodied carbon appears oversimplified, lacking in-depth parameters that affect emissions, such as hardware-specific manufacturing and lifetime estimates. Moreover, the Clifelong needs to be elaborated in terms of how it is attained."
      },
      {
        "rating": "5",
        "confidence": "1",
        "summary": "The training of machine learning (ML) models significantly contributes to global carbon emissions. This paper introduces OpenCarbonEval, an advanced estimation tool designed to quantify the carbon impact of large-scale ML models based on their total training computations and hardware configurations. The tool's accuracy is validated using real-world datasets, and experimental results demonstrate that OpenCarbonEval provides more precise predictions of energy consumption and carbon emissions than previous approaches.",
        "strengths": "1. The paper works on an important topic.\n2. The paper identifies the shortcoming of preivous works (Faiz et al., 2023): the polynomial approximation for the system efficiency and hardware utiliation estimation is not accurate.",
        "weaknesses": "1. **Simplified yet more accurate formulation???**: The functions presented in Equations (3) through (7) lack clarity in their intended function and accuracy. While polynomial approximations may lack precision, Equation (7) is simplified even further than LLMCarbon, containing only a single parameter compared to the multi-parameter nature of polynomial approximations. Why is this single-parameter approach purported to yield higher accuracy? The authors are encouraged to offer detailed explanations or empirical validation demonstrating how and why Equation (7) leads to improved accuracy over traditional polynomial approximations.\n\n2. **Consideration of GPU count and parallelism settings**: The paper does not discuss varying GPU counts in training configurations, appearing to assume a single-GPU setup. It also does not address different training parallelism types, such as data, tensor, pipeline, or expert parallelism, all of which may affect results depending on GPU count. Without incorporating these parallelism factors, it is unclear how OpenCarbonEval achieves greater accuracy. How does this work account for different parallelism strategies, and are there empirical results confirming its accuracy across these configurations? Additionally, Figure 4 lacks context: how many GPUs are represented, why do some GPUs exhibit smaller variance, and how many GPUs are used for training in Tables 1 and 2?\n\n3. **Lack of model architecture information**: The study appears to consider only the number of parameters in ML models, without accounting for architecture specifics. While scaling laws suggest that architecture does not impact model accuracy, it significantly affects training throughput across various architectures (see Megatron paper: https://parsa.epfl.ch/course-info/cs723/papers/Megatron.pdf). The authors should provide empirical evidence to demonstrate that model architecture does not impact the carbon footprint of training.\n\n4. **Dataset limitations**: The dataset used is limited and lacks comprehensive real-world data. Among the 863 entries in the provided table (https://epochai.org/data/notable-ai-models?view=table), only 176 entries include training times, 158 provide GPU counts, and only 31 report hardware utilization, leaving most entries without training times or hardware utilization data. With such limited information, how is \\( f(x) \\) in Equation (5) trained and validated? Furthermore, 603 of the 863 entries are classified as \"likely,\" \"speculative,\" or \"no confidence.\" Does OpenCarbonEval rely on these uncertain data points for validation while claiming higher accuracy? The authors should discuss the limitations associated with the dataset quality and address the impact on the reliability of their conclusions."
      }
    ],
    "rating_avg": 3.6666666666666665,
    "confidence_avg": 2.3333333333333335,
    "decision": "N/A",
    "meta_review": "",
    "author_remarks": "",
    "decision_comment": ""
  },
  {
    "id": "CFKZKjrQ5r",
    "title": "FCoReBench: Can Large Language Models Solve Challenging First-Order Combinatorial Reasoning Problems?",
    "authors": [
      "Chinmay Mittal",
      "Krishna Kartik",
      "Parag Singla",
      "Mausam ."
    ],
    "abstract": "Can the large language models (LLMs) solve challenging first-order combinatorial\nreasoning problems such as graph coloring, knapsack, and cryptarithmetic? By\nfirst-order, we mean these problems can be instantiated with potentially an infinite\nnumber of problem instances of varying sizes. They are also challenging being\nNP-hard and requiring several reasoning steps to reach a solution. While existing\nwork has focused on coming up with datasets with hard benchmarks, there is\nlimited work which exploits the first-order nature of the problem structure. To\naddress this challenge, we present FCoReBench, a dataset of 40 such challenging\nproblems, along with scripts to generate problem instances of varying sizes and\nautomatically verify and generate their solutions. We first observe that LLMs, even\nwhen aided by symbolic solvers, perform rather poorly on our dataset, being unable\nto leverage the underlying structure of these problems. We specifically observe\na drop in performance with increasing problem size. In response, we propose a\nnew approach, SymPro-LM, which combines LLMs with both symbolic solvers\nand program interpreters, along with feedback from a few solved examples, to\nachieve huge performance gains. Our proposed approach is robust to changes in the\nproblem size, and has the unique characteristic of not requiring any LLM call during\ninference time, unlike earlier approaches. As an additional experiment, we also\ndemonstrate SymPro-LM’s effectiveness on other logical reasoning benchmarks.",
    "keywords": [
      "llms",
      "logical-reasoning",
      "first-order-reasoning",
      "neuro-symbolic"
    ],
    "venue": "ICLR",
    "year": 2025,
    "pdf_url": "https://openreview.net/pdf?id=CFKZKjrQ5r",
    "forum_url": "https://openreview.net/forum?id=CFKZKjrQ5r",
    "reviews": [
      {
        "rating": "3",
        "confidence": "2",
        "summary": "This paper focuses on the problem-solving ability of LLM on first-order combinatorial problems in natural language form, arguing that no existing benchmark could reveal this challange properly. To stress the significance of this issue, this paper proposes a new benchmark, FCoReBench, which covers 40 challanging problems in varying sizes and correspounding solutions. In responding to the poor performance of current LLMs on FCoReBench, this paper further proposes a new framework, SymPro-LM, to push forward the potential capacity of language models by combining symbolic solvers, program interpreters and the LM backbone. The experimental results show a significant improvement in various aspects, indicating the valuable attempt of assembling different augmented modules.",
        "strengths": "- The problems covered in FCoReBench are relatively comprehensive, highlighting a valuable research direction. It would be interesting to see more generalized problems to be addressed once VLM are taken into consideration.\n- A corresponding responce framework has been developed for the issue proposed, and the experimental results are promising.\n- The experimental section in section 7 features thorough verification and comprehensive chart presentations.\n- The discussion in section 8 is insightful. It would be benificial to list the problems in each situation in the appendix, and even better, to illustrated them with diagrams in the main text. This would help to elucidate the dataset's relevance to the central issue.",
        "weaknesses": "- The construction part of the dataset issue in Section 4 requires manual labor, which is quite labor-intensive. Could it be automated using LLM?\n- The current agent can only solve first-order logic. Higher-order logic requires individual generation, which is resource-intensive and difficult to scale.\n- There is a lack of innovation in the proposed framework SymPro-LM, which merely combines existing symbolic solvers and program generation. It would be better to consider a more specific design.\n\nWriting aspects:\n- There are issues with the section layout and organization; the section titles are inconsistent and not uniformly formatted (e.g. section 5 and 5.1, section 7 and 7.1). The table layout on page 7 is also peculiar.\n- The overall language used in writing is subpar, being rather colloquial and informal. E.g.:\n  - In Section 3, as a problem definition, there should not be such an emphasis on the subject \"We.\" The problem should be described objectively and rigorously from a third-party perspective.\n  - In Section 4, the term \"the author\" should be used less frequently to avoid potential privacy issues. Instead, use \"agent\" or \"process\" to emphasize actions rather than the actors, which would be more formal. If necessary, flowcharts can also be used to represent the selection, polishing, and construction processes, which would greatly assist readers in understanding the overall procedures.\n- This paper primarily focuses on the benchmark, as emphasized in the title; thus, the experimental section should mainly focus on verifying the performance of the benchmark in various aspects. The current writing approach is centered around SymPro-LM. If this focus is to be maintained, the emphasis of the entire article should be placed on SymPro-LM."
      },
      {
        "rating": "3",
        "confidence": "3",
        "summary": "Introduces FCoReBench which consists of generators and evaluators for 40 combinatorial optimization problems such as sudoku, graph coloring etc. Evaluates existing prompting approaches and LLM augmentation approaches on the dataset. Proposes a new framework SymPro-LLM which when given a problem, output a program that converts the problem to symbolic representation, which is then passed to a symbolic solver to get the solution.",
        "strengths": "The proposed SymPro-LLM can work with different instances from the same first order combinatorial optimization problem without the need to re-evaluate using LLMs.\n\nThe proposed dataset is difficult for existing LLMs. The instances are based on combinatorial reasoning problems, which are mostly NP-Hard problems.\n\nThe proposed dataset is lifted such that unlimited new instances can be generated.",
        "weaknesses": "While I find the proposed approach of using LLM to output program to formulate models interesting, I am not convinced the experimentations conducted provide enough insight to LLM reasoning abilities. From the examples shown in figure 2, NL(C), NL(X), NL(Y) seems to be pseudo code for formulating the problem. The task of the LLM therefore becomes translating the pseudo code to python, which does not require the same level of reasoning as solving the problems.\n\nThe paper does not evaluate enough existing models for the new proposed benchmark dataset. For example, the state-of-the-art GPT-4o and GPT-o1 are not evaluated. The paper also include limited analysis of why the existing approaches fail on the proposed dataset. \n\nThe writing and presentation require more clarity and focus. For example, section 7 presents results across different LLM models, different frameworks/styles of prompting, different datasets/problem classes, and different experimental setups. It is unclear to me what the key takeaways from these results are."
      },
      {
        "rating": "5",
        "confidence": "3",
        "summary": "The paper introduces FCoReBench, a benchmark designed to evaluate the capabilities of LLMs in solving first-order combinatorial reasoning problems. The benchmarks include NP-hard problem instances like graph coloring and knapsack, with varying instance sizes. Current LLMs struggle with these tasks, particularly as the problem size increases. To address this limitation, this paper proposes SymPro-LM, a hybrid approach that combines LLMs with symbolic solvers, enhancing performance by leveraging the strengths of both methods. \n\nThe proposed approach achieved a 21.61% improvement over few-shot prompting, a 3.52% improvement over Program-aided Language models (PAL), and a 16.83% enhancement over Logic-LM. Additionally, incorporating feedback from solved examples boosts SymPro-LM's performance by 21.02% after four rounds, compared to 12.5% for PAL. SymPro-LM also excels on three non-first-order logical reasoning benchmarks, outperforming existing baselines on two datasets and remaining competitive on the third, highlighting the effectiveness of integrating LLMs with symbolic solvers.",
        "strengths": "Using LLM to solve logic puzzles and combinatorial problems is a very important and interesting direction. This paper contributes a well-established dataset for this field which can be valuable to the research community. The paper also proposes a framework that combines extant solvers such as Z3 with LLMs. The experiment results seem convincing and promising.",
        "weaknesses": "1. The name \"first order\" is a bit confusing. Does it mean it is related to first-order logic? If so, it would be great to elaborate on this connection. Otherwise, a more detailed definition should be provided. It is not clear from the paper what the difference is between first-order problems and second-order ones.\n\n2. Whether the level of contribution of this paper meets the standard of ICLR is questionable. It is not clear whether this paper proposed novel methodologies. The main contribution according to the paper seems to be the establishment of a dataset.\n\nMinor: The fonts in Figure 4 should be larger."
      },
      {
        "rating": "3",
        "confidence": "4",
        "summary": "This paper introduces a problem set designed to assess LLMs' ability to solve first-order combinatorial reasoning problems. It argues that current symbolic-solver-aided LLMs perform poorly on this problem set and proposes a novel approach that combines a symbolic solver with a program interpreter to improve reasoning capabilities, demonstrating superior performance on the problems.",
        "strengths": "The paper aims to address an important problem. The proposed approach is conceptually sound, and the experimental results indicate promising improvements in the reasoning capabilities of LLMs when using the technique.",
        "weaknesses": "This paper has several critical issues that require the authors' attention:\n\n1. Misalignment Between Title and Content: While the title suggests a focus on the proposed problem set, the main body primarily discusses the technique, SymPro-LM. After reviewing the entire paper, it appears more as a technique paper rather than a benchmark paper. I suggest revising the title and reorganizing the structure to more accurately reflect its focus on methodology.\n\n2. Lack of Clarity on Incremental Contributions of the Problem Set: Although the problem set seems useful, the paper does not clearly articulate its unique contribution. Existing symbolic-solver-aided LLM approaches have already addressed similar reasoning problems, and some may have been tested on benchmarks containing first-order combinatorial reasoning problems. It is essential to compare the proposed problem set with these existing benchmarks, highlighting overlaps and differences. However, this paper provides limited detail on this aspect.\n\n3. Scope Restriction and Generalizability of the Technique: While the paper narrows its focus to first-order combinatorial reasoning problems, conceptually, the proposed technique has broader applicability across various reasoning tasks. Given the absence of any domain-specific adaptations, I recommend either expanding the paper’s scope and conducting a more comprehensive evaluation across diverse reasoning problems, or explaining the reason of the scope restriction.\n\n4. Use of an Outdated LLM in Evaluation: The LLM used in the evaluations appears a bit outdated. I suggest incorporating recent models, such as GPT-4o and o1, to provide a more relevant assessment.\n\n5. Unclear Criteria for Problem Selection in the Problem Set: The criteria for including specific problems in the problem set are not well-defined. For example, while the paper includes problems from the industry track of SAT competitions, it does not explain the exclusion of others (e.g., the main track). Furthermore, recent SAT competitions no longer feature an industry track, making the rationale for this selection unclear."
      }
    ],
    "rating_avg": 3.5,
    "confidence_avg": 3.0,
    "decision": "Reject",
    "meta_review": "This paper introduces a new benchmark, FCoReBench, consisting of 40 combinatorial optimization problems whose constraints, inputs, outputs, and examples are all stated in natural languages. Additionally, this paper also proposes a new framework, SymPro-LM, which outperforms existing prompting methods like few-shot prompting and program-aided prompting.  Introducing new datasets and prompting frameworks to improve the reasoning capability of LLMs are valuable contributions. However, several important concerns are not addressed properly. For instance, to what extent the 40 combinatorial problems are new compared to existing reasoning tasks? Although the problem is stated in natural language, the form is still rigid -- clear separations regarding constraints, I/O instructions, and examples have to be specified, making it not far from a piece of pseudo-code. Furthermore, the key motivation is not very clear; on one hand, it suggests the contribution of benchmark, the novelty of which is a bit questionable; on the other hand, the authors want to show the new framework, SymPro-LM, significantly outperforms existing techniques on a newly crafted benchmark. A more systematic comparison of existing benchmarks where baseline approaches were evaluated would be expected.",
    "author_remarks": "",
    "decision_comment": ""
  },
  {
    "id": "O6znYvxC1U",
    "title": "Bayesian Treatment of the Spectrum of the Empirical Kernel in (Sub)Linear-Width Neural Networks",
    "authors": [
      "Ouns El Harzli",
      "Bernardo Cuenca Grau"
    ],
    "abstract": "We study Bayesian neural networks (BNNs) in the theoretical limits of infinitely increasing number of training examples, network width and input space dimension. Our findings establish new bridges between kernel-theoretic approaches and techniques derived from statistical mechanics through the correspondence between Mercer's eigenvalues and limiting spectral distributions of covariance matrices studied in random matrix theory. \n   Our theoretical contributions first consist in novel integral formulas that accurately describe the predictors of BNNs in the asymptotic linear-width and sublinear-width regimes. Moreover, we extend the recently developed renormalisation theory of deep linear neural networks, enabling a rigorous explanation of the mounting empirical evidence that hints at the theory's applicability to nonlinear BNNs with ReLU activations in the linear-width regime.\n   From a practical standpoint, our results introduce a novel technique for estimating the predictor statistics of a trained BNN that is applicable to the sublinear-width regime where the predictions of the renormalisation theory are inaccurate.",
    "keywords": [
      "infinite bayesian neural networks",
      "kernel theory",
      "random matrix theory"
    ],
    "venue": "ICLR",
    "year": 2025,
    "pdf_url": "https://openreview.net/pdf?id=O6znYvxC1U",
    "forum_url": "https://openreview.net/forum?id=O6znYvxC1U",
    "reviews": [
      {
        "rating": "5",
        "confidence": "3",
        "summary": "This paper studies bayesian neural networks in the linear ($P/N = \\text{constant}$ for data $P$ and width $N$) regime and sub-linear ($P/(N N_0) = \\text{constant}$) regime. The authors operate under a spectral universality assumption, which treats the eigenfunctions of the limiting kernel as random with a covariance determined by the posterior kernel. The authors argue that this spectral universality assumption is logically equivalent to a kernel renormalization theory which was derived for deep linear networks. This kernel renormalization is a scale shift in the kernel by a variable $u$ which needs to be solved for self-consistently. In the sublinear regime, the kernels are rank-deficient which the authors acknowledge by allowing for a singular spectrum and utilizing the pseudo-inverse.",
        "strengths": "This paper studies the important problem of characterizing feature learning in nonlinear Bayesian neural networks and provides an original idea to apply a spectral universality idea to characterize feature learning. It further aims to justify some of the recent applications of kernel renormalization theory to nonlinear networks.  Showing that the spectral universality assumption implies and is implied by the kernel renormalization picture is an interesting contribution. The authors also provide a few experiments to support their claims.",
        "weaknesses": "However, the spectral universality assumption is not proven directly and the distribution of kernel eigenfunctions in either the proportional regime or the sublinear regime has not been characterized outside of the spectral universality assumption. The experiments are somewhat limited. I have a number of questions below, which if addressed could lead me to increase my score."
      },
      {
        "rating": "8",
        "confidence": "2",
        "summary": "The paper gives integral formulas describing the outputs of BNNs in the linear and sublinear width regimes.",
        "strengths": "The theoretical contributions are extremely strong, especially around the integral formulas describing the outputs of BNNs in the linear and sublinear width regimes.",
        "weaknesses": "The primary weakness is around the experimental results.  These are restricted to MLPs on very simple datasets.  Though I would be happy to consider an argument that the results should generalise and/or that it would be prohibitively difficult to get results outside this setting.\n\nThe experimental results are presented very poorly.  For instance:\n* The plots do not have labelled x and y-axes.\n* The legends are very confusing. As an example: \"on the left (respectively, on the right).\"\n\nThere are also numerous prior works around deep kernel processes and machines that would be worth discussing in the related work:\n* https://arxiv.org/abs/2010.01590\n* https://arxiv.org/abs/2108.13097\n\nwhile this work uses a very different theoretical approach, it ultimately addresses similar conceptual issues."
      },
      {
        "rating": "6",
        "confidence": "4",
        "summary": "The authors propose combining ideas from random matrix theory to evaluate limits of infinite width Bayesian neural networks (such as the classic work by Neal (1996)) when the number of observations also goes to infinity as well as the number of input dimensions. The paper provides novel claims of the behavior of the limit in sublinear regimes.",
        "strengths": "Using Marchenko-Pastur to evaluate this type of limits, seems like a good idea. Combining these approaches with Mercer's theorem seems valuable. The ideas of random matrix theory in general seem underutilized in the ML community.",
        "weaknesses": "1. It is not immediately clear how the integrals in Theorem 3.4 can be explicitly evaluated. \n2. Notation for $\\Phi^*$ in Theorem 3.4 was never defined.\n3. Between lines 300 and 303, the authors claim that for __small__ datasets the computations would not be too computationally intensive. However, in footnote 3 (p. 6), they claim that the limit can be approximated using __large__ objects. It is not completely clear what has to be large or small for the evaluations to be feasible. \n4. Section 4 appears to be incomplete. It is not evident from the writing which of the figures correspond to the two examples they mention at the beginning of the section. \n5. In the first experiment they mention, with the \"linear teacher\", the authors do not specify how the $\\beta$ is defined."
      }
    ],
    "rating_avg": 6.333333333333333,
    "confidence_avg": 3.0,
    "decision": "Accept (Poster)",
    "meta_review": "This paper investigates Bayesian neural networks (BNNs) in certain asymptotic limits, drawing connections between kernel-theoretic approaches and statistical mechanics. It presents novel integral formulas for BNN predictors in linear and sublinear width regimes and extends renormalization theory, originally developed for linear networks, to nonlinear BNNs. Reviewers point to weaknesses in the  empirical validation, noting that the experiments are limited to simple datasets and lack detailed explanation. Furthermore, the core spectral universality assumption remains unproven, and the practical applicability of the derived integral formulas is not entirely clear due to computational concerns. Despite these limitations, the theoretical contributions are strong and original. The paper attacks the crucial problem of characterizing feature learning in nonlinear BNNs and offers a novel approach by combining spectral universality with kernel renormalization. The derivation of integral formulas for BNN predictors in different width regimes and the extension of renormalization theory represent useful advancements in the theoretical understanding of BNNs, and therefore I recommend publication.",
    "author_remarks": "",
    "decision_comment": ""
  },
  {
    "id": "xN6z16agjE",
    "title": "Evaluating word representation for hypernymy relation: with focus on Arabic",
    "authors": [
      "Randah Alharbi",
      "Husni A. Al-Muhtaseb"
    ],
    "abstract": "Hypernymy relation is one of the fundamental relations for many natural language processing and information extraction tasks. A key component of the performance of any hypernymy-related task is word representation. Traditional word embeddings capture word similarity but fall short of representing more complex lexical-semantic relationships between terms, such as hypernymy. To overcome this, recent studies have proposed hypernymy-specific representations. In this study, we conduct an evaluation of several types of word representations to determine the most effective approach for modeling hypernymy relationships in Arabic. We use an Arabic training corpus and several datasets to assess traditional embedding, hypernymy-specific embedding, and contextual embedding across several hypernymy-related tasks, including hypernymy detection. The results indicate that different embeddings have different effects on the performance. Moreover, the performance is affected by the selected datasets. This highlights that there is a need for further research to develop more robust word representation and benchmark datasets.",
    "keywords": [
      "Word representation",
      "hypernymy relation",
      "hypernymy specific embedding",
      "hypernymy detection."
    ],
    "venue": "ICLR",
    "year": 2025,
    "pdf_url": "https://openreview.net/pdf?id=xN6z16agjE",
    "forum_url": "https://openreview.net/forum?id=xN6z16agjE",
    "reviews": [
      {
        "rating": "3",
        "confidence": "3",
        "summary": "Authors try to evaluate different algorithms, which create hypernymy relation representations in Arabic. They select AraBERT corpus as a base for training all embedding models and train several models on this data. As a baseline for contextual embeddings, BERT is used, while for classic embeddings GloVe is used. For hypernymy-specific embedding LEAR, GLEN, Princare and Poincare Glove is used. After that, a simple feedforward models are trained for all embeddings for three tasks: hypernymy detection, hypernymy directionality detection and semantic relation classification. Results show, that Poincare GloVe performs best on hypernomy detection and hypernomy directionality detection tasks. In semantic relation classification tasks Poincare GloVe performs worse. Overall, there is no best representation for all tasks.",
        "strengths": "1. The goal of the paper is easy to understand, as it provides valuable insight into which representations are best for hypernym-based tasks (none are best overall)\n\n2. Experiment design makes sense and is mostly without issues. There is a minor issue stemming from the limited resources available to the authors of the paper, but I will touch upon them in the weaknesses part of the review.",
        "weaknesses": "1. Authors are very constrained in resources, having to resort to halving the size of the training dataset for some of the algorithms. This raises questions to the validity of the collected information, since Poincare GloVe, the best algorithm in Hypernymy Directionality and Hypernymy Detection tasks, has seen only half as many data samples, which can possibly make the results non-representative. However, due to the simplicity of the Poincare GloVe, most likely it won’t impact the results as much, thus, making this just a minor issue.\n\n2. The quality of the text's presentation is poor; it contains numerous typos and improperly formatted tables. Table 7 has incorrectly formatted items in header, Table 8 has incorrectly formatted dataset names, in table 7 the highest F1 score for ASRD dataset is incorrectly attributed to 100D Poincare GloVe, which has the score of 0.88 instead of Poincare Embedding, which have the score of 0.89. On the line 070 BERT has no citation available, on the line 220 the sentence starts from lowercase, on the line 291 the word Assess is incorrectly capitalized, line 480 is cut in half, etc. Both Introduction and Related Work sections are hard to read, since they are written in a big wall of text instead of separate paragraphs on groups of algorithms. Some of the citation years are in brackets (lines 065-068), some are not (line 079)."
      },
      {
        "rating": "3",
        "confidence": "3",
        "summary": "This paper focuses on evaluating and improving word vector representations specialized for hypernym relations in Arabic. Your research captures the gaps in hypernym aspects of performance by conducting multiple sets of experiments on different datasets, and this aspect of the research is important for the NLP task.",
        "strengths": "1. **Relevance**: Focusing on hypernym in Arabic is timely and relevant, and it addresses a less explored area of NLP.\n2. **Experiments**: The paper presents a comprehensive experimental evaluation of multiple word representation techniques, demonstrating a solid methodological framework.\n3. **New findings**: The findings presented in the paper provide new insights into how Arabic word embeddings can be enhanced to better detect hypernym.",
        "weaknesses": "1. **Literature Review**: Although the paper discusses related work, a more comprehensive literature review would have positioned the paper's contribution more effectively. I suggest the authors report precision and recall specifically for elements that have both spatial and logical relationships, compared to those with only one type of relationship.\n2. **Clarity**: Some sections may lack clarity, particularly in explaining the significance of the research methodology and findings. \n3. **Results Interpretation**: The results section may need to discuss the significance of the findings in more depth, especially in the context of existing models."
      },
      {
        "rating": "3",
        "confidence": "4",
        "summary": "This paper addresses the challenge of modeling hypernymy relations specifically focusing on Arabic. The authors evaluate various word representation methods to determine the most effective for Arabic hypernymy tasks. They compare traditional embeddings, hypernymy-specific embeddings, and contextual embeddings using an Arabic corpus and multiple datasets to assess their impact on tasks such as hypernymy detection.",
        "strengths": "1. Word representations for hypernymy are essential for a variety of tasks in NLP and information extraction.\n\n2. By concentrating on the Arabic language, the paper contributes to a less explored area, providing insights for non-English NLP research.\n\n3. The research conducts an evaluation of multiple types of embeddings, including traditional, hypernymy-specific and contextual embeddings.",
        "weaknesses": "1. The paper primarily focuses on evaluating existing word representations rather than introducing a novel approach or method for hypernymy modeling. The novelty is very limited.\n\n2. The written quality of this paper is poor. The authors should carefully revise this paper for better presentations. For example, the citation format is incorrect.\n\n3. The paper seems to provide an evaluation of performance effects without a deep analysis of why certain embeddings perform better or worse in specific contexts or tasks.\n\n4. The impact of this work in the ICLR community is limited. Maybe an NLP workshop on the Arabic language is more suitable."
      }
    ],
    "rating_avg": 3.0,
    "confidence_avg": 3.3333333333333335,
    "decision": "N/A",
    "meta_review": "",
    "author_remarks": "",
    "decision_comment": ""
  },
  {
    "id": "wVTJRnZ11Z",
    "title": "When GNNs meet symmetry in ILPs: an orbit-based feature augmentation approach",
    "authors": [
      "Qian Chen",
      "Lei Li",
      "Qian Li",
      "Jianghua Wu",
      "Akang Wang",
      "Ruoyu Sun",
      "Xiaodong Luo",
      "Tsung-Hui Chang",
      "Qingjiang Shi"
    ],
    "abstract": "A common characteristic in integer linear programs (ILPs) is symmetry, allowing variables to be permuted without altering the underlying problem structure. Recently, GNNs have emerged as a promising approach for solving ILPs. \nHowever, a significant challenge arises when applying GNNs to ILPs with symmetry: classic GNN architectures struggle to differentiate between symmetric variables, which limits their predictive accuracy. In this work, we investigate the properties of permutation equivalence and invariance in GNNs, particularly in relation to the inherent symmetry of ILP formulations. We reveal that the interaction between these two factors contributes to the difficulty of distinguishing between symmetric variables.\nTo address this challenge, we explore the potential of feature augmentation and propose several guiding principles for constructing augmented features. Building on these principles, we develop an orbit-based augmentation scheme that first groups symmetric variables and then samples augmented features for each group from a discrete uniform distribution. Empirical results demonstrate that our proposed approach significantly enhances both training efficiency and predictive performance.",
    "keywords": [
      "integer linear programming",
      "symmetry",
      "machine learning",
      "graph neural networks"
    ],
    "venue": "ICLR",
    "year": 2025,
    "pdf_url": "https://openreview.net/pdf?id=wVTJRnZ11Z",
    "forum_url": "https://openreview.net/forum?id=wVTJRnZ11Z",
    "reviews": [
      {
        "rating": "5",
        "confidence": "2",
        "summary": "The authors study the problem of solving Integer Linear Programs (ILPs) with symmetry among variables. They first show that if a permutation from the set of all variable permutations is a formulation symmetry of the ILP, then under an assumption of permutation equivalence and invariance for the GNN, the network cannot predict the optimal solution of the ILP.\n\nTo address this, they propose a feature augmentation algorithm that assigns unique augmented features to each orbit, sampling a distinct feature value within an orbit without replacement. They compare their methods against previously proposed augmentation schemes empirically and based on some principles for three ILP benchmark problems.",
        "strengths": "Their method appears to perform better in terms of their proposed metric than existing methods on certain tasks. They also introduce the problem clearly, making it easily understandable for someone outside the field, while establishing a good motivation through negative results about GNNs and formulation symmetries.",
        "weaknesses": "They don't discuss any limitation of their orbit-based augmentation, making their method's application scope appear narrow restricting to ILPs with formulation symmetry. \n\nAdditionally, the approach relies on detecting symmetry groups and orbits, which as they note may be computationally expensive.  It would also be interesting to see how their method performs for different evaluation metrics (maybe beyond $\\ell_1$ distances). \n\nAs this area is new to me, their contributions do not seem sufficiently novel in terms of the algorithm, and the experiments provided also seem limited and hence I recommend a reject but with a confidence score of 2."
      },
      {
        "rating": "6",
        "confidence": "5",
        "summary": "This paper improves a weakness of graph network approaches for predicting the solutions of integer linear programs (ILPs) with symmetric variables. Because graph networks are permutation equivariant, they cannot distinguish between exchangeable variables in the ILPs (or more concretely, variables such that, when permuted, the cost constraint is still satisfied and the objective is unchanged). The authors use feature augmentation to break the symmetries between these equivalent variables, specifically emphasizing distinguishability, “isomorphic consistency”, and “augmentation parsimony”. Past works have used feature augmentation to break these symmetries, but without adhering to these principles. They demonstrate the effectiveness of their techniques relative to alternatives on solving synthetic ILPs, with training data generated by a classical solver.",
        "strengths": "This paper addresses a meaningful issue (symmetry-breaking in integer linear programs) in a new way (using inputs to GNNs that break only the required orbit symmetries, in accordance with the three defined desiderata). Although I believe these two pieces are individually not new (see “weaknesses”), their combination is. The “Orbit+” approach is also a novel way of enhancing “augmentation parsimony”. The paper is generally clear, and the writing style and notations are both enjoyable to read. Their experimental results on the chosen tasks beat the chosen ML baselines. Although I am not convinced by the necessity of isomorphic consistency for most applications, in which a logical loss function can be chosen (which is unaffected by swapping equivalent nodes), the use of SymILO to enforce it by adjusting training labels is also new.",
        "weaknesses": "I think the biggest weakness of this paper is that, in short, many of its central ideas have already been introduced and (in some cases) thoroughly explored in papers of which the authors seem unaware. (This is understandable, given that they do not appear in the ILP literature and use different terminology to describe the problem, but nonetheless they exist — I hope the authors may be inspired by the perspectives of these papers, and can also articulate the novelty of their work relative to them.) This line of work (see the references below; although not the earliest, [2] or [4] may be the most accessible starting points) goes by the name “symmetry-breaking”, and articulates the precise issue that the authors encounter for ILPs, but in a much more general way, for all group equivariant networks. The principles of distinguishability and augmentation parsimony are explored under different names, e.g. in [3]. There is a related line of work on breaking symmetries of sets, termed “multiset equivariance” [5]. Works such as these and [4] make clear subtleties of the problem that aren’t discussed in this paper, such as the difference between the graph automorphism group and the node orbits, and articulate methods for addressing the equivalent nodes of ILPs in ways that subsume the method presented here.\n\nI believe that orbit-equivariant graph neural networks [6] are also a slightly more fleshed out version of the “Orbit” approach. \n\nAs noted under questions, I also find the discussion of isomorphic consistency confusing, as it is (assuming I understand correctly) not well-motivated under orbit-invariant loss functions, and importantly, not necessarily even possible to achieve. Is “relaxed equivariance” [2] more suitable? \n\nFinally, as also noted under questions, there seem to be weaknesses with the experiments — namely, the choice of loss function, and the premise/lack of comparison to non-ML baselines. \n\nReferences:\n1. Smidt, T. E., Geiger, M., and Miller, B. K. Finding symmetry breaking order parameters with euclidean neural networks. Phys. Rev. Research, 3: L012002, Jan 2021. doi: 10.1103/PhysRevResearch\n2. Kaba, S.-O. and Ravanbakhsh, S. Symmetry breaking and equivariant neural networks. In Symmetry and Geometry in Neural Representations Workshop, NeurIPS, 2023.\n3. Xie, Y. and Smidt, T. Equivariant symmetry breaking sets. TMLR 2024.\n4. Hannah Lawrence, Vasco Portilheiro, Yan Zhang, and Sekou-Oumar Kaba. Improving equivariant networks with probabilistic symmetry breaking. In ICML 2024 Workshop on Geometry-grounded Representation Learning and Generative Modeling, 2024.\n5. Zhang, Y., Zhang, D. W., Lacoste-Julien, S., Burghouts, G. J., and Snoek, C. G. M. Multiset-equivariant set prediction with approximate implicit differentiation. In International Conference on Learning Representations, 2022.\n6. Morris, M., Grau, B. C., & Horrocks, I. (2024). Orbit-equivariant graph neural networks. ICLR 2024."
      },
      {
        "rating": "5",
        "confidence": "4",
        "summary": "This paper proposes to augment the vertice features in ILP graph representation based on orbit of the symmetry group. Some theory is provided and numerical results are conducted with the comparison with the random feature technique (Chen et al. 2022) and the positional ID technique (Han et al. 2023).",
        "strengths": "1. The paper is in general well-written and is easy to follow.\n\n2. The idea of augmenting features based on orbits is reasonable. I agree with the authors that only vertices in the same orbit need to be separated with augmented features, and the cardinality of the augmented feature space is much smaller than $n!$ if the number of orbits is much larger than one.\n\n3. The reported numerical results look better than baseline methods.",
        "weaknesses": "1. There is no comparison with conventional methods based on symmetry group and orbits, such as Ostrowski et al. (2011) cited by the authors. In addition to Ostrowski et al. (2011), there should actually be a much richer literature in this direction.\n\n2. There is no report on the cost of computing the symmetry group. I expect to see a trade-off between the size of the symmetry group and the improvement from \"no augmentation\"."
      },
      {
        "rating": "8",
        "confidence": "2",
        "summary": "The authors propose a novel feature augmentation method for ILP's with symmetries that are described by bipartite graphs for solving with GNN's. The augmentations obey some important symmetry properties but are also more parsimonious than existing methods. Empirical results suggest that these augmentations help the GNN's break the symmetry better than competing methods.",
        "strengths": "The main idea in Section 4.2 is explained well. The numerical results are decent and convey the practical benefits of the method. The introduction is also nicely written.",
        "weaknesses": "While the numerical results do suggest that the method helps break symmetries better than others, it is hard to tell if this makes a difference in the end result (objective of rounded solution). I think such a comparison should be added (either way). A more complete description or explanation of the augmentation procedure in general could be useful for those not in the field. Some minor improvement for minor writing weaknesses are suggested below."
      }
    ],
    "rating_avg": 6.0,
    "confidence_avg": 3.25,
    "decision": "Accept (Poster)",
    "meta_review": "Symmetry in integer linear programs (ILPs) poses challenges for graph neural networks, which have recently emerged as a promising approach for solving ILPs and yet struggle to distinguish symmetric variables. This work addresses this by proposing an orbit-based feature augmentation scheme that groups symmetric variables and assigns augmented features from a discrete uniform distribution. Numerical simulations showcase the advantages of the proposed framework both in training and predictive performance.\n\nDespite some differing opinions on the merits and execution of the ideas, many reviewers agree that the paper presents novel ideas and makes valuable contributions to the field. While the individual components of the proposed framework may not be novel, the paper meaningfully advances ILPs by combining these concepts in an innovative way.",
    "author_remarks": "",
    "decision_comment": ""
  },
  {
    "id": "CKqiQosLKc",
    "title": "Sampling from Energy-based Policies using Diffusion",
    "authors": [
      "Vineet Jain",
      "Tara Akhound-Sadegh",
      "Siamak Ravanbakhsh"
    ],
    "abstract": "Energy-based policies offer a flexible framework for modeling complex, multimodal behaviors in reinforcement learning (RL). In maximum entropy RL, the optimal policy is a Boltzmann distribution derived from the soft Q-function, but direct sampling from this distribution in continuous action spaces is computationally intractable. As a result, existing methods typically use simpler parametric distributions, like Gaussians, for policy representation — limiting their ability to capture the full complexity of multimodal action distributions. In this paper, we introduce a diffusion-based approach for sampling from energy-based policies, where the negative Q-function defines the energy function. Based on this approach, we propose an actor-critic method called Diffusion Q-Sampling (DQS) that enables more expressive policy representations, allowing stable learning in diverse environments. We show that our approach enhances exploration and captures multimodal behavior in continuous control tasks, addressing key limitations of existing methods.",
    "keywords": [
      "Reinforcement learning",
      "Diffusion models"
    ],
    "venue": "ICLR",
    "year": 2025,
    "pdf_url": "https://openreview.net/pdf?id=CKqiQosLKc",
    "forum_url": "https://openreview.net/forum?id=CKqiQosLKc",
    "reviews": [
      {
        "rating": "6",
        "confidence": "3",
        "summary": "The authors have developed a new actor-critic algorithm called Diffusion Q-Sampling (DQS), which uses a diffusion-based model to sample from energy-based policies in actor-critic framework. The goal is to address current limitation of capturing complexity of multimodal action distributions in continuous action spaces. This novel algorithm is shown to be very effective for learning multimodal behaviors and improved sample efficiency.",
        "strengths": "1. The novel approach is able to learn multimodal actions which is valuable especial when multiple optimal trajectory exists.\n2. By explicitly sampling from the Boltzmann distribution of the Q function, DQS is shown better abilities for balancing exploration and exploitation.\n3. Through experiments on maze tasks and Deepmind control suites benchmarks, results have confirmed the advantages of DQS.",
        "weaknesses": "1. As pointed out by the authors, temperature of DQS needs to be manually tuned unlike SAC as it would be computationally very expensive to compute the likelihoods under diffusion model. \n2. No ablation study. Maybe beneficial to have some ablation studies, for example, how sensitive DQS is to different temperature values, K (number of monte carlo samples and how is it relates to computation cost)? or isolate the contribution of techniques introduced, etc."
      },
      {
        "rating": "3",
        "confidence": "3",
        "summary": "This paper proposes a novel framework for sequential decision-making using diffusion models for\nsampling from energy-based policies and a new actor-critic algorithm for training diffusion\npolicies based on that framework.This algorithm improves the high-cost issue of sampling from\ncontinuous action spaces in traditional maximum entropy reinforcement learning methods. It has\nbeen validated in the authors' custom maze navigation and DeepMind Control Suite tasks.",
        "strengths": "Proposing a novel Boltzmann policy iteration which is more efficiency and still bound to recover the optical policy",
        "weaknesses": "Lack of novelty：Simply integrating Diffusion into the traditional SAC which lacks innovation. \n\nBenchmark in a custom environment lacks persuasiveness and the test is not quantified to data."
      },
      {
        "rating": "3",
        "confidence": "4",
        "summary": "This paper proposes a diffusion-based sampling method that uses a negative Q-function as an energy function for sampling, thus allowing for more expressive policy representations. Based on this approach, an actor-critic method called **Diffusion Q-Sampling (DQS)** is proposed that enables stable learning in diverse environments. Experiments show that the method enhances exploration in continuous control tasks and effectively captures multimodal behaviours, overcoming key limitations of existing methods. However, the core sampling method used in this paper is iDEM leading to a lack of innovation, and the experimental results are insufficient, the multimodal experiments may be problematic (results of the Q-score method), and the baseline algorithm is too few and too simple.",
        "strengths": "- This article proposes sampling with a diffusion strategy obeying a Boltzmann distribution to balance exploration and exploitation, focusing on a very cutting-edge area;\n- This paper does a multimodal experiment to show that DQS has some multimodality, a point that may be of interest to the RL community;\n- The writing of the paper is easy to follow.",
        "weaknesses": "- The related work is not presented carefully enough, and some are only cited. In particular, the related work under Online diffusion is particularly scarce, and each needs the author to summarise their approach, and where the flaws lie. In addition, **diffusion & online RL** related work also need you to expand, I found a recent paper accepted in NeurIPS24 is also under this setting Diffusion Actor-Critic with Entropy Regulator (Wang et al.). \n\n- You mention that the Q-score method does not have an exact distribution, but isn't Eq. (21) of the original paper a Boltzmann distribution? Is the representation in your paper not quite correct.  It's better to clarify your statement about the Q-score method and explain how it relates to Eq. (21) in the original paper. \n\n- The two proofs in 4.1 about policy improvement and policy iteration do not depend on the diffusion model, this is essentially a mathematical proof of a policy obeying a Boltzmann distribution. May I ask what is the essential difference between your proofs and the one in the Soft Actor-Critic Algorithms and Applications (Haarnoja et al.) paper? \n\n- With the experiments in 5.1, I remain sceptical about the results of QSM. I think with the addition of some tricks to fully learn the bias of Q with respect to a, the QSM can get the same results as you did (e.g., do some random sampling to update the bias of Q with respect to a to get it to school in full action space).\n\n- 5.2 There is too little BASELINE for experimental comparisons. To prove your excellent performance, add Proximal Policy Optimisation Algorithms (Schulman et al.), Diffusion Actor-Critic with Entropy Regulator (Wang et al.), Policy Representation via Diffusion Probability Model for Reinforcement Learning (Yang et al.). At least a few difficult scenarios are tested on MuJoCo environment (Humanoid, Ant) and compared with the above algorithms.\n\n### Minor note.\n- Please label all formulas in PRIMARY with the serial number, then you look at the expression for the Q function, where does the discount factor go?\n\n- Equation (4) has incorrect parentheses."
      },
      {
        "rating": "3",
        "confidence": "4",
        "summary": "The authors introduce a new algorithm for continuous RL environments, Diffusion Q-Sampling (DQS). \nDQS makes use of an existing method, iterated Denoising Energy matching (iDEM). \nThe key idea is to use iDEM to learn a score function which can be used in a reverse diffusion process to sample actions. \nThe score function is trained such that the reverse diffusion process approximately samples from a Boltzmann distribution with respect to the Q-function of the current policy. \n\nThe authors give two theoretical results, corresponding to policy improvement and policy iteration respectively, to justify their choice of training rule for the action-value function and the diffusion model. \n\nThe authors then give experimental results for their method, DQS. \nIn the first set of results, they compare DQS to SAC (soft actor-critic) and QSM (Q-score matching) in terms of the diversity of behaviors learned. They demonstrate that, in a goal reaching maze environment, DQS can successfully learn a diverse set of solutions, while SAC and QSM learn a more concentrated set of solutions. \nIn the second set of results, they compare DQS to SAC and QSM on 8 tasks from the DeepMind control suite. They demonstrate that on many of these tasks, QSM dominates the other methods.",
        "strengths": "Originality - The application of iDEM is (to this reviewer's knowledge) novel; although other methods seek to use diffusion model policies, they typically use other methods for fitting the diffusion model. The application of iDEM is novel. \n\nQuality - The empirical results given are strong. The first set of results demonstrates well that DQS can indeed learn a policy which has support on multiple different solution types for problems. The second set of results shows that DQS can learn well, and outperform baseline methods in terms of sample efficiency. \n\nClarity - In general, the authors writing is clear. The method is well-explained, and seems reproducible.  \n\nSignificance - The authors propose an effective new algorithm for continuous control. This algorithm seems particularly useful for the setting where compute is not a bottleneck, and multimodal policies are explicitly desired.",
        "weaknesses": "046 - The authors give methods of policy representations in the continuous setting. I would suggest that they mention SQL, which allows for the training of expressive policies which come from neither noise injection nor parametric family. These are trained via Stein-variational gradient descent. \n\n071 - The claim is made that \"[Diffusion models] have been extensively applied to solve sequential decision-making tasks, especially in offline settings where they can model multimodal datasets from suboptimal policies or diverse human demonstrations.\" No citations are given for these techniques - please include citations to the literature to which you are referring. \n\n191 - I would encourage the authors to say more about the role of the reverse SDE (3) in generation. Specifically, please be clear about how (3) is used to generate samples, rather than assuming this knowledge on the part of the reader. \n\n205 - Missing tildes over the x's in the expectations in Eq. (4). \n\n210 - Subscript below the S in equation (5) should be a capital K. \n\n260 - Lemma 1 is false, and its proof is invalid. Lemma 1 states that, for any action-value function, the policy which is Boltzmann with respect to that action-value function has a dominating action-value function. This statement is incorrect, and obviously so. Let $\\pi^*$ be the optimal policy, with action-value function $Q^*$. Then we know that $Q^*$ satisfies the Bellman optimality operator, $T^* Q(s,a) = r + \\gamma \\mathbb{E}[ \\max_{a'} Q(s',a') | s, a]$, where the expectation is taken over next-states $s'$ conditional on state-action pair $s,a$. If Lemma 1 were true, it would mean that the Boltzmann policy $\\pi_B$ with respect to $Q^*$ has an action-value function which dominates $Q^*$. But note that $T^* Q^*(s,a) \\geq T^{\\pi_B} Q^*(s,a)$, which can be seen by expanding definitions and using the fact that the maximum over $a'$ dominates any expectation with respect to $a'$, except if that expectation only places mass on the argmax actions. From this it also follows that this inequality is strict somewhere provided $Q^*$ is non-uniform somewhere. But since $T^* Q^* = Q^*$, it follows that $Q^* \\geq T^{\\pi_B} Q^*$. But monotonicity of the Bellman operator, it follows that, for all $n$, $Q^* \\geq [T^{\\pi_B}]^n Q^*$. Taking limits as $n \\to \\infty$, we obtain that, $Q^* \\geq Q^{\\pi_B}$, with strict inequality somewhere provided $Q^*$ is not flat. This contradicts the stated result. \n\nWe now turn to the proof given in A.1, and examine the error of reasoning. In the first two lines of  (10), the expectation of $\\log(\\pi_{new})$ is taken with respect to $\\pi_{new}$, and the expectation of $\\log(\\pi_{old})$ is taken with respect to $\\pi_{old}$. However, in the third line of (10), the expectation of both terms is taken with respect to $\\pi_{new}$. This allows the authors to express this term as a KL-divergence, a step critical to their proof. However, the term should instead be a difference of entropies, which in general is not non-negative (as the KL-divergence is).  \n\n265 - The proof of Theorem 1 is invalid. The proof relies heavily on the same argument as in Lemma 1, which is faulty. \n\nIn general, it seems like the authors fail to appreciate that results from the entropy regularised setting and the classical setting cannot be freely interchanged. The optimal policy is Boltzmann only if an entropy regularisation term is included in the Bellman backup, (7). When there is no such entropy term in the backup, the optimal policy will simply be the classical optimal policy, which in general is deterministic (or has support only on argmax actions). Similarly, the Boltzmann improvement map only gives improvement with entropy regularisation. Otherwise it can result in a strictly worse policy, as explained above.  \n\nI would suggest that the authors either cut their theoretical results entirely, or think about replacing the Bellman backup in (7) with the entropy regularized backup - however this would result in a substantial change to the algorithm, which may be too late at this stage."
      }
    ],
    "rating_avg": 3.75,
    "confidence_avg": 3.5,
    "decision": "N/A",
    "meta_review": "",
    "author_remarks": "",
    "decision_comment": ""
  },
  {
    "id": "vjbIer5R2H",
    "title": "Improved Risk Bounds with Unbounded Losses for Transductive Learning",
    "authors": [
      "Bowei Zhu",
      "Shaojie Li",
      "Huayi Tang",
      "Yong Liu"
    ],
    "abstract": "In the transductive learning setting, we are provided with a labeled training set and an unlabeled test set, with the objective of predicting the labels of the test points. This framework differs from the standard problem of fitting an unknown distribution with a training set drawn independently from this distribution. In this paper, we primarily improve the generalization bounds in transductive learning. Specifically, we develop two novel concentration inequalities for the suprema of empirical processes sampled without replacement for unbounded functions, marking the first discussion of the generalization performance of unbounded functions in the context of sampling without replacement. We further provide two valuable applications of our new inequalities: on one hand, we firstly derive fast excess risk bounds for empirical risk minimization in transductive learning under unbounded losses. On the other hand, we establish high-probability bounds on the generalization error for graph neural networks when using stochastic gradient descent which improve the current state-of-the-art results.",
    "keywords": [
      "concentration inequality",
      "generalization bounds",
      "graph neural networks",
      "transductive learning",
      "unbounded losses"
    ],
    "venue": "ICLR",
    "year": 2025,
    "pdf_url": "https://openreview.net/pdf?id=vjbIer5R2H",
    "forum_url": "https://openreview.net/forum?id=vjbIer5R2H",
    "reviews": [
      {
        "rating": "1",
        "confidence": "5",
        "summary": "This paper derives risk bounds for transductive learning scenarios with specific applications to Graph Neural Networks (GNNs) under unbounded loss functions. The work focuses on theoretical guarantees for both sub-Gaussian and sub-exponential loss functions.",
        "strengths": "- Novel analysis of unbounded loss functions in the transductive learning setting\n- Mathematical rigour in deriving the theoretical bounds\n- Practical applications to GNN scenarios",
        "weaknesses": "**Weaknesses:**\n\n- Limited scope of unbounded loss functions:\n\n  - Analysis is restricted to sub-Gaussian and sub-exponential functions (and sub-Weibull in appendix)\n  - Other important classes of unbounded loss functions are not addressed\n\n\n- Insufficient comparison with prior work:\n\n  - The paper overlooks crucial related work, particularly [1] (Maurer & Pontil, 2021). While [1] focuses on inductive settings, their theoretical foundations appear relevant. A comparative analysis between Theorems 1 and 2 and the results in [1] is needed.\n\n- Limited Contribution:\n  - The current contribution of theoretical analysis in the GNN framework is limited. The current results are general and independent of the Graph properties. \n\n**Minor Comments:**\n\n-  In Assumption 3, \"α-Hölder\" is misspelled\n- Add the explanation of Hoeffding's reduction method to the appendix\n- Use \"Boundedness\" instead of \"Boundness\"\n- Use \"techniques\" instead of \"technologies\"\n- Line 221 \"We mainly follows the traditional technique...\" --> \"We mainly follow the traditional technique\"\n\n---\n\n**References:**\n\n- [1] Maurer, A., & Pontil, M. (2021). Concentration inequalities under sub-gaussian and sub-exponential conditions. Advances in Neural Information Processing Systems, 34, 7588-7597."
      },
      {
        "rating": "8",
        "confidence": "3",
        "summary": "The paper studies the transductive learning problem, where the learner receives a subset of labeled samples drawn without replacement from a dataset, alongside unlabeled samples for which the goal is to predict the labels. As the samples are not independent and the loss function may be unbounded, the authors develop concentration inequalities for the supremum of empirical processes sampled without replacement for unbounded functions. They use these inequalities to derive tighter risk bounds for transductive learning problems and graph neural networks.",
        "strengths": "This paper is the first to derive concentration inequalities for the supremum of empirical processes sampled without replacement for unbounded functions, presenting a novel result. Furthermore, these concentration inequalities are utilized to refine the risk bounds for transductive learning and graph neural networks found in the literature.",
        "weaknesses": "The paper lacks numerical results to support the derived risk bounds. Additionally, as it does not provide lower bounds for the risk, it remains unclear whether the resulting bounds could be further improved.\n\nThere are some typos in the paper:\n\nLine 221: we mainly \"follows\"\nLine 222: we \"introduced\"\nLine 405: w_1^{T+1}   ->   w^{T+1}"
      },
      {
        "rating": "3",
        "confidence": "3",
        "summary": "In this work, the authors establish generalization bounds for the transductive setting, applicable even in cases with unbounded loss. The core technical contribution is a novel tail bound for the relevant empirical process. Using these results, the authors then derive generalization bounds for graph neural networks.",
        "strengths": "The transductive setting has gained renewed attention recently, as many practical problems are better suited to transductive learning than the traditional iid statistical framework. In this context, the work is particularly relevant.\n\nThe concentration bounds presented are non-trivial, and their proof involves sophisticated mathematical tools.",
        "weaknesses": "1. The authors do not offer any motivation for addressing unbounded loss. A discussion on why this is an important and relevant problem to study would be beneficial.\n\n2. It is unclear what the significance of Theorems 3 and 4 is. Let’s consider Theorem 3 as an example. Given other terms, the upper bound can at best be\n$$ \\frac{N^2 \\log\\left( \\frac{1}{\\delta}\\right)}{m^2 u}.$$\nThe authors claim this bound is state-of-the-art for $m = o(N^{2/5})$. If we set $m = N^{1/5} = o(N^{2/5})$, then $u = N - N^{1/5} \\leq N $, and the upper bound is at least\n$$ \\geq \\frac{N^2 \\log\\left( \\frac{1}{\\delta}\\right)}{N^{2/5} \\cdot N} \\geq N^{3/5} \\log\\left( \\frac{1}{\\delta}\\right).$$\n\nGiven that this is the highest the proven upperbound can be, it is difficult to see why such a bound would be of interest as $N$ can be quite large, making the bound potentially vacuous. I may likely be missing something here, and I would be happy to engage with the authors during the discussion session to gain further clarity and adjust my score."
      },
      {
        "rating": "1",
        "confidence": "5",
        "summary": "The paper studies potentially improved risk bound for transductive learning following the conventional localized method. The main difference the author claims is that the risk bounds are for unbounded functions. However, such claim, together with the technical results for  unbounded functions, are very questionable. Furthermore, there are no detailed comparison to the current state-of-the-art risk bounds for the main results in Theorem 3 and Theorem 4.",
        "strengths": "The paper studies potentially improved risk bound for transductive learning following the conventional localized method. The main difference the author claims is that the risk bounds are for unbounded functions. However, such claim, together with the technical results for  unbounded functions, are very questionable.",
        "weaknesses": "There are several major technical drawbacks.\n\n\n\n1. While this paper claims that the risk bounds for transductive learning are for unbounded loss functions, the assumptions required for the results are essentially designed for bounded loss functions. For example, the main results Theorem 3 and Theorem 4 need the assumption that $E[f^2] \\le B E[f]$. It is well known that such assumption, $E[f^2] \\le B E[f]$, holds mainly for bounded loss functions, such as that in the classical local Rademacher complexity work (Bartlett Local Rademacher Complexities, AOS 2005). It turns out that while the paper claims risk bounds for \"unbounded loss\", but the results rely on the assumption which mainly hold for bounded loss functions.\n\n2. It is well known that Rademacher complexity or local Rademacher complexity based methods derive distribution-free risk bounds that do not need distributional assumptions. In contrast, the risk bounds in the main results Theorem 3 and Theorem 4 require sub-Gaussian and sub-exponential loss functions. It is not clear which loss functions are  sub-Gaussian or sub-exponential, and such restriction on the loss functions can significantly limit the application scope of the derived bounds.\n\n3. There are no detailed comparison to the current state-of-the-art risk bounds for the main results in Theorem 3 and Theorem 4, such as the existing transductive bounds in (Tolstikhin et al. 2014, Localized Complexities for Transductive Learning. COLT 2014). Without comparison to prior art, the significance of these results is not clear and questionable.\n\n4. The risk bounds in the main results, Theorem 3 and Theorem 4, do not convergence to 0 under the case that $m = N^{\\alpha}$ or \n$m = N^{\\alpha}$ with $\\alpha \\in (0,1/2]$, and they even diverge to $\\infty$ if $\\alpha \\in (0,1/2)$.  This is in a strong contrast to existing risk bounds for excess risk bounds where such bounds should always at least converge to $0$, and it is really misleading to claim such risk bounds are improved ones."
      }
    ],
    "rating_avg": 3.25,
    "confidence_avg": 4.0,
    "decision": "Reject",
    "meta_review": "The paper studies the problem of obtaining risk bounds for transductive learning for bounded losses. The problem has interesting mathematical aspects, but there were several concerns pointed out by the reviewers. In particular, the paper does not provide adequate comparison to some related work, and the significance of the bounds is also not fully clear (it still requires a variance condition on the loss, and the regime in which it provides improved bounds is not clear). Therefore, the paper is not ready for acceptance.",
    "author_remarks": "",
    "decision_comment": ""
  },
  {
    "id": "RlpJmARXqj",
    "title": "Adaptive Self-Supervised Learning Strategies for Dynamic On-Device LLM Personalization",
    "authors": [
      "Rohan Iyer"
    ],
    "abstract": "Large language models (LLMs) have revolutionized how we interact with technology, but their personalization to individual user preferences remains a significant challenge, particularly in on-device applications. Traditional methods often depend heavily on labeled datasets and can be resource-intensive. To address these issues, we present Adaptive Self-Supervised Learning Strategies (ASLS), which utilizes self-supervised learning techniques to personalize LLMs dynamically. The framework comprises a user profiling layer for collecting interaction data and a neural adaptation layer for real-time model fine-tuning. This innovative approach enables continuous learning from user feedback, allowing the model to generate responses that align closely with user-specific contexts. The adaptive mechanisms of ASLS minimize computational demands and enhance personalization efficiency. Experimental results across various user scenarios illustrate the superior performance of ASLS in boosting user engagement and satisfaction, highlighting its potential to redefine LLMs as highly responsive and context-aware systems on-device.",
    "keywords": [
      "Individual user preferences",
      "On-Device LLM"
    ],
    "venue": "ICLR",
    "year": 2025,
    "pdf_url": "https://openreview.net/pdf?id=RlpJmARXqj",
    "forum_url": "https://openreview.net/forum?id=RlpJmARXqj",
    "reviews": [
      {
        "rating": "3",
        "confidence": "4",
        "summary": "This paper introduces an Adaptive Self-Supervised Learning Strategy (ASLS) framework for dynamic, on-device personalization of large language models (LLMs). The framework includes two layers: a user profiling layer that gathers interaction data and a neural adaptation layer that fine-tunes the model in real-time based on this data, enabling responses tailored to specific user contexts.",
        "strengths": "1.\tStudying on-device LLM personalization has significant practical application significance.\n2.\tThe author claimed that the proposed method can achieve real-time model fine-tuning.",
        "weaknesses": "1. The quality of writing in the method section needs improvement. In particular, inconsistent use of symbols and lack of explanations make the methodology difficult to understand. It is recommended that the authors revise this section and include an illustrative diagram to improve readability.\n2. Equation (2) indicates that the personalization approach in this paper still relies on label fitting, suggesting it has not eliminated the dependence on extensive labeled data as claimed in the introduction.\n3. This paper's general approach looks like customizing personalized parameters for LLMs based on user interaction data, and this core idea seems quite similar to HYDRA [1]. What are the main innovations presented in this paper, and what are its advantages?\n4. The readability of the experimental results and analysis is poor. The experimental tables are difficult to understand; for example, in Table 1, why do different methods correspond to different datasets? Regarding the analysis of experiments, the statement \"Significant enhancements observed in user engagement metrics\" does not provide a clear definition of what engagement metrics are.\n5. There is a lack of comparison with some baselines in the experiments, such as [1].\n[1] HYDRA: Model Factorization Framework for Black-Box LLM Personalization."
      },
      {
        "rating": "3",
        "confidence": "5",
        "summary": "The paper proposes a Self-Supervised Learning method to update LLMs by user interaction data for personalization on-device. The model contains two layers, a user layer to generate uer presentation by interaction data and a fine-tuning adaptation layer for dynamic modelling. The method is verified on various datesets.",
        "strengths": "1. The paper focus on decreasing computation as personalizing based on LLMs on-device.\n 2. The paper conducts experiments on multiple datasets from various domains.",
        "weaknesses": "1. The definition of on-device personalization is not clear in the paper.\n2. The metrics are not explained and defined, the reviewer cannot know what is the objective of this paper.\n3. The comparison is not fair according to Table1 which compare various methods under different datasets, and no explain of such setting is provided.\n4. The explain of layers of the method is vague, the review cannot follow due to lack of explanation and connection between section3.1-3.3"
      },
      {
        "rating": "3",
        "confidence": "3",
        "summary": "This paper proposes an adaptive self-supervised learning strategy (ASLS), which consists of a user analysis layer for collecting interaction data and a neural adaptation layer for real-time model fine-tuning.",
        "strengths": "**S1.** The problem of \"dynamically personalizing LLMs\" is interesting and valuable.  \n**S2.** The authors claim that the method does not require extensive labeled data.",
        "weaknesses": "**W1.** Regarding the introduction section, it does not provide a clear motivation and the logic is somewhat unclear. For example, the fourth paragraph is very confusing, as it includes too many disparate elements—recommendation, multi-modal object recognition, and fairness.\n\n**W2.** The connections between different parts of the method are also unclear, with issues of inconsistent notation. Additionally, there is no clear demonstration of how it better addresses the problem of dynamic updates; it still seems that updates are needed for each proposed module when new data appears.\n\n**W3.** The experiments are also confusing. For example, in Table 1, why do different methods correspond to different datasets? How does this ensure fair comparison?\n\n**W4.** It is not clear how the paper demonstrates self-supervised learning. According to equation (2), it still appears to be supervised learning.\n\n**W5.** The selection of baselines may also need improvement. For instance, the chosen recommendation baseline, PALR, is not the current state-of-the-art LLM-based recommendation method."
      },
      {
        "rating": "5",
        "confidence": "3",
        "summary": "This paper introduces Adaptive Self-Supervised Learning Strategies (ASLS) to address the challenge of personalizing large language models (LLMs) for individual users, particularly in resource-constrained on-device applications. Traditional personalization approaches often require labeled datasets and substantial computational resources. In contrast, ASLS leverages self-supervised learning for dynamic personalization, using a user profiling layer to gather interaction data and a neural adaptation layer for real-time model fine-tuning. This setup enables continuous learning from user feedback, aligning model outputs more closely with user-specific contexts while minimizing resource demands. Experimental results demonstrate ASLS’s effectiveness in enhancing user engagement and satisfaction, positioning it as a promising approach for creating responsive, context-aware on-device LLMs.",
        "strengths": "1. The paper focuses on a interesting and promising problem: On-Device LLM Personalization\n2. The structure of the paper is reasonable",
        "weaknesses": "1. It's hard to understand the whole workflow because the paper lacks a workflow figure\n2. Method is simple. Althought I approve simple but effective method, I can't get where is the \"self-supervised learning\" and can't understand why it is for \"on-device LLM\". This does not seem to be a method designed specifically for on-device LLM."
      }
    ],
    "rating_avg": 3.5,
    "confidence_avg": 3.75,
    "decision": "Reject",
    "meta_review": "This paper proposes Adaptive Self-Supervised Learning Strategies (ASLS) for the dynamic, on-device personalization of large language models (LLMs). The authors claim that ASLS leverages self-supervised learning for real-time adaptation through a user profiling layer and a neural adaptation layer. The goal is to personalize LLMs for individual users while minimizing resource demands. The paper evaluates its method across multiple datasets, reporting improvements in user engagement and satisfaction.\n\nThe primary strength of this submission lies in addressing a timely and practically significant challenge—on-device LLM personalization. This problem aligns with emerging demands for privacy-preserving and resource-efficient AI. The authors claim to use innovative self-supervised techniques for real-time fine-tuning, and they attempt to validate their approach with experiments.\n\nHowever, the weaknesses of the paper outweigh its strengths. First, there are critical issues in the clarity and rigor of the methodology. The method section is poorly written, with inconsistent notation, a lack of illustrative diagrams, and vague explanations of the proposed layers. Several reviewers noted confusion regarding how the self-supervised learning aspect was implemented and how it supports real-time on-device applications. Furthermore, the core contribution appears to be incremental and closely resembles prior work, such as the HYDRA framework, with insufficient clarity on the novel aspects of the method.\n\nThe experimental evaluation also raises significant concerns. The comparisons are not rigorous, with no clear rationale for using different datasets across baselines and no inclusion of state-of-the-art benchmarks. Additionally, the evaluation metrics, such as \"engagement score\" and \"satisfaction rate,\" are not well-defined, leaving the results open to interpretation. Reviewers also criticized the experimental presentation, noting that tables were difficult to interpret and lacked explanation.\n\nWhile the problem itself is promising, the paper falls short in presenting a robust and innovative solution. It lacks the theoretical clarity, methodological rigor, and experimental depth required for acceptance.\n\nThe primary reasons for recommending rejection are the lack of clarity and novelty in the proposed method, the insufficient and poorly explained experimental results, and the weak comparisons with relevant baselines. The authors need to address these issues comprehensively in a future submission to make their work competitive for publication.",
    "author_remarks": "",
    "decision_comment": ""
  },
  {
    "id": "v2nEL42Pvb",
    "title": "SSGNN: Simple Yet Effective Spectral Graph Neural Network",
    "authors": [
      "Ram Samarth B B",
      "Rishabh Sabharwal",
      "Sundeep Prabhakar Chepuri",
      "Punit Rathore"
    ],
    "abstract": "Spectral GNNs leverage graph spectral properties to model graph representations but have been less explored due to their computational challenges, especially compared to the more flexible and scalable spatial GNNs, which have seen broader adoption. However, spatial methods cannot fully exploit the rich information in graph spectra. Current Spectral GNNs, relying on fixed-order polynomials, use scalar-to-scalar filters applied uniformly across eigenvalues, failing to capture key spectral shifts and signal propagation dynamics. Though set-to-set filters can capture spectral complexity, methods that employ them frequently rely on Transformers, which add considerable computational burden. Our analysis indicates that applying Transformers to these filters provides minimal advantage in the spectral domain. We demonstrate that effective spectral filtering can be achieved without the need for transformers, offering a more efficient and spectrum-aware alternative. To this end, we propose a $\\textit{Simple Yet Effective Spectral Graph Neural Network}$ (SSGNN), which leverages the graph spectrum to adaptively filter using a simplified set-to-set approach that captures key spectral features. Moreover, we introduce a novel, parameter-free $\\textit{Relative Gaussian Amplifier}$ (ReGA) module, which adaptively learns spectral filtering while maintaining robustness against structural perturbations, ensuring stability. Extensive experiments on 20 real-world graph datasets, spanning both node-level and graph-level tasks along with a synthetic graph dataset, show that SSGNN matches or surpasses the performance of state-of-the-art (SOTA) spectral-based GNNs and graph transformers while using significantly fewer parameters and GFLOPs. Specifically, SSGNN achieves performance comparable to the current SOTA Graph Transformer model, Polynormer, with an average 55x reduction in parameters and 100x reduction in GFLOPs across all datasets. Our code will be made public upon acceptance.",
    "keywords": [
      "Spectral Graph Neural Networks",
      "Graph Representation Learning"
    ],
    "venue": "ICLR",
    "year": 2025,
    "pdf_url": "https://openreview.net/pdf?id=v2nEL42Pvb",
    "forum_url": "https://openreview.net/forum?id=v2nEL42Pvb",
    "reviews": [
      {
        "rating": "5",
        "confidence": "4",
        "summary": "The authors propose SSGNN, a simple yet effective spectral-based Graph Neural Network that captures rich spectral information through an adaptive set-to-set filtering approach, offering a more efficient alternative to transformer-based methods. The method introduces a parameter-free Relative Gaussian Amplifier (ReGA) module for robust spectral filtering, and demonstrates superior or comparable performance to state-of-the-art models while using significantly fewer parameters (55x reduction) and computational resources (100x reduction in GFLOPs) across 20 real-world datasets.",
        "strengths": "The paper presents an interesting transformation from scalar-to-scalar to set-to-set methodology, building upon the Spectral Former framework. By introducing a learnable parameter W to capture relationships between different frequency domain eigenvalues, the authors aim to enhance model performance through better consideration of inter-frequency domain relationships.",
        "weaknesses": "- However, the methodology lacks clarity regarding the eigenvalue computation process, which appears to rely on time-consuming SVD operations, raising concerns about computational efficiency.\n\n- Given that your proposed method emphasizes simplicity and reduced learnable parameters, it would be particularly valuable to demonstrate its effectiveness on large-scale graphs. While the reduction in parameter count is noteworthy, the real advantage of a simpler model should be its ability to scale effectively to larger, real-world graph applications. Therefore, I strongly recommend including comprehensive experiments on large-scale graph datasets to validate the method's practical utility. This would not only strengthen your contribution but also clearly differentiate your work from existing methods that may struggle with scalability.\n\n- From a comparative standpoint, although the spectral approach shows promise, the evaluation lacks comprehensive comparisons with important baseline methods, particularly SGC and SSGC. These baselines are especially relevant as they also prioritize simplicity and efficiency. To make your contribution more compelling, consider expanding the experimental section to include: (1) comparisons with these relevant baselines, (2) clear documentation of the eigenvalue computation process and its efficiency, and (3) thorough scalability analysis on large-scale graphs that would demonstrate the practical advantages of your simplified approach. This would help readers better understand the unique benefits of your method in real-world applications where scalability is crucial."
      },
      {
        "rating": "5",
        "confidence": "4",
        "summary": "This paper studies the improvements of spectral GNNs, which aims to design an expressive filter based on spectral graph theory for effective graph representations. \nThe paper points out that existing SOTA spectral GNNs bring more computational burden, though they can learn the filters better. Thus, the paper proposes a novel efficient framework, namely SSGNN, which only applies simple linear transformation instead of Transformers on the spectrum. Moreover, SSGNN incorporates a parameter-free Relative Gaussian Amplifier to the decoder to enhance adaptive filter learning and maintain stability. The paper conducts extensive experiments on synthetic and real-world datasets to demonstrate the effectiveness of SSGNN.",
        "strengths": "1、\tThe motivation of this paper is significant and valuable for Spectral GNNs.\n2、\tSSGNN achieves significant efficiency in terms of computation and parameters.\n3、\tExperimental results in most cases seem promising.",
        "weaknesses": "1. The novelty of the method is somewhat limited, especially the direct application of existing eigen-correction, eigenvalue encoding, and convolution framework without any transfer challenge.\n2. The description of “set” of “set-to-set filtering” is ambiguous. Specformer applies Transformer on eigenvalue encodings, which enables filters to capture relative dependencies among the eigenvalues. Thus, the “set” of “set-to-set” in Sepcformer means the set of eigenvalues. However, SSGNN learns the spectral filter through linear transformations, so eigenvalues don’t interact with each other. Thus, what’s the meaning of “set”?\n3. The roles of the two linear transformations (namely W_{eig} and W_1W_h) respectively playing in encoder and decoder are not clear. In other words, why do authors include W_1 and W_h in the decoder instead of the encoder?\n4. The paper ignores some essential experiments.\n（1）As mentioned in Line 217, different heads allow the decoder to learn diverse spectral filtering patterns. However, there is no visualization of the diverse spectral filters learned by different heads to verify this conclusion.\n（2）There is no ablation study on the effectiveness of re-center adjustment in Equation 4 and the effectiveness of Relative Gaussian Amplifier in Equation 6.\n（3）Authors don’t verify the stability of SSGNN on OOD benchmarks such as DrugOOD[1], where many model stability studies are validated on this dataset.\n5. The symbols are ambiguous. For example, \\epsilon is used in Line 182, Line 240-241, and Line 307 simultaneously, making the paper more difficult to read. Moreover, it’s not clear on which \\epsilon the ablation experiments reported in Figure 4 are conducted.\n\n[1] Ji, Yuanfeng, et al. \"Drugood: Out-of-distribution dataset curator and benchmark for ai-aided drug discovery–a focus on affinity prediction problems with noise annotations.\" Proceedings of the AAAI Conference on Artificial Intelligence. Vol. 37. No. 7. 2023."
      },
      {
        "rating": "5",
        "confidence": "4",
        "summary": "This paper proposes a Simple Yet Effective Spectral Graph Neural Network (SSGNN), which simplifies the set-to-set graph filter, e.g., Specformer, without performance degeneration. The key component is a parameter-free Relative Gaussian Amplifier (ReGA), which not only improves model performance but also maintains the robustness against graph perturbations. Extensive experiments on both node-level and graph-level datasets demonstrate the superiority of SSGNN in terms of effectiveness and efficiency over baselines.",
        "strengths": "1. The design of the ReGA component in SSGNN has some novelty. It not only avoids negative eigenvalues but also improves the robustness of SSGNN.\n\n2. This paper conducts extensive experiments and SSGNN also shows competitive performance. For example, in the ZINC dataset, SSGNN has a RMSE value of 0.0592.",
        "weaknesses": "1. This paper claims that SSGNN uses a **simplified set-to-set approach** to capture key spectral features. However, there is no interaction between different eigenvalues in SSGNN. Specifically, the matrix $Z_{eig} \\in \\mathbb{R}^{N \\times (d+1)}$ indicates the $(d+1)$ dimensional representation of each eigenvalue. The transformation $W_{eig}$ is applied on the channels of a single eigenvalue, i.e., $Z_{eig}W_{eig}$. Therefore, SSGNN is not a set-to-set approach.\n\n2. SSGNN involves a lot of tricks in the training process, such as eigen-correction. However, both Specformer and Polynormer do not use eigen-correction for data preprocessing. In this case, it is necessary to make a comprehensive ablation study to validate the roles of each trick. We need to verify whether the performance improvement mainly comes from ReGA rather than eigen-correction.\n\n3. It would be better if the authors could provide a comparison of the time and space overhead between different methods.\n\n4. How many parameters does SSGNN have in Table 5? Generally, we will control the number of parameters around 50K in the ZINC dataset."
      },
      {
        "rating": "5",
        "confidence": "4",
        "summary": "This paper proposes SSGNN, a simple and effective GNN model which can achieve good performance with much reduced parameters compared to transformers. With basic spectral encoder-decoder structure, it further incorporates a REGA module to strengthen the representational capabilities and the robustness against spectral perturbation. Experiments demonstrate its effectiveness and superiority on model parameters.",
        "strengths": "1-\tThe method is simple and effective on multiple graph downstream tasks.\n\n2-\tThe experiments are comprehensive and solid.\n\n3-\tThe theoretical analysis of ReGA is interesting and novel.",
        "weaknesses": "1-\tThe time and space cost in pre-computation and training stage of SSGNN seems to be a bottleneck for large graphs. Though top-k techniques can be applied, it’ll lose spectral frequencies which is essential for down-streaming tasks. When comparing parameter amounts and GFLOPS, it’ll be fair to show the training and pre-computation cost for baselines, transformers and other GNNs.\n\n2-\tIt needs experiments to demonstrate the contribution of ReGa, which is the most novel part in SSGNN. Will the removal of it greatly influence the performance?\n\n3-\tPresentation can be improved. “. .” appears in line 373 and line 398 appears incomplete sentences “* means” what?"
      }
    ],
    "rating_avg": 5.0,
    "confidence_avg": 4.0,
    "decision": "Reject",
    "meta_review": "In this submission, the authors proposed a new member of spectral GNNs with advantages in computational efficiency. However, some questions are unresolved:\n\n1) The experimental part is not solid enough. Although the authors provide more analytic experimental results, the advantage of the proposed method compared with the existing GNNs and graph-oriented Transformer models is not significant or consistent.\n\n2) As a kind of graph spectral filtering-based method, the representation power of the proposed model is not analyzed in details. For example, whether the proposed method can represent arbitrary graph filters is unknown.\n\n3) As the authors claim, the key technical contribution of this submission is the ReGA module. However, the ablation studies provided by the authors imply that the other mechanisms, such as re-centering and eigen-correction, significantly impact the model performance. \n\n4) The writing of the proposed submission is unsatisfying. There still are some obvious typos in the revised paper, and the organization of the proposed method can be improved.\n\nOverall, the motivation and analytic part of the proposed method needs to be enhanced, and the submission requires a next-round review.",
    "author_remarks": "",
    "decision_comment": ""
  },
  {
    "id": "MWSoYGPexK",
    "title": "Towards Efficient and Scalable Multi-agent Reasoning via Bayesian Nash Equilibrium",
    "authors": [
      "Xie Yi",
      "Zhanke Zhou",
      "Chentao Cao",
      "Qiyu Niu",
      "Bo Han"
    ],
    "abstract": "Large Language Models (LLMs) have achieved significant success in tasks such as natural language understanding, generation, and reasoning, driving advancements in machine translation, summarization, and question-answering systems. Particularly in multi-step reasoning tasks, LLMs demonstrate robust logical reasoning capabilities. To further enhance the reasoning abilities of LLMs, researchers have developed methods that generate intermediate reasoning steps, thereby improving performance in solving complex problems. However, these approaches primarily focus on single LLMs, limiting the diversity and creativity of the reasoning process. Inspired by psychological studies, there is a growing interest in exploring multi-LLM frameworks to boost model performance through collaborative reasoning. Existing multi-agent debate frameworks can enhance answer accuracy through dialogue and argumentation but suffer from high computational costs and lack theoretical guarantees for convergence. To address these challenges, we propose a novel method—BNE-Q. This method integrates belief networks and a central network within the Decentralized Partially Observable Markov Decision Process (DEC-POMDP) framework to achieve a Bayesian Nash Equilibrium (BNE). During the inference phase, the central LLM provides step-by-step strategies and format guidelines, while execution LLMs independently generate answers based on these guidelines. The central LLM then consolidates the answers to form a commitment. In the optimization phase, by calculating the cosine similarity between the answers and the commitment, we optimize the execution LLMs' belief networks to achieve stable convergence of the multi-agent system. Our method not only reduces the computational overhead compared to traditional multi-agent debate methods but also ensures convergence through theoretical analysis. Experimental results demonstrate that BNE-Q performs exceptionally well across six benchmark tests, including complex reasoning and planning tasks, validating its theoretical robustness and practical effectiveness. Our work provides a new approach for developing multi-LLM collaborative reasoning frameworks, significantly enhancing reasoning capabilities in large-scale multi-agent environments.",
    "keywords": [
      "Large Language Models",
      "Reasoning",
      "Multiagent Reasoning"
    ],
    "venue": "ICLR",
    "year": 2025,
    "pdf_url": "https://openreview.net/pdf?id=MWSoYGPexK",
    "forum_url": "https://openreview.net/forum?id=MWSoYGPexK",
    "reviews": [
      {
        "rating": "6",
        "confidence": "4",
        "summary": "The paper proposes EcoNash, a hierarchical reinforcement learning framework for scalable, multi-agent reasoning by using Bayesian Nash Equilibrium (BNE) to enhance coordination among large language models (LLMs). This paper first proposes a tight bound for MA-LLM's performance improvement. Then introduce EcoNash, which reduces the communication and computational costs typical in multi-agent systems by enabling LLMs to independently generate optimal responses based on their own beliefs. Experimental results show EcoNash surpasses single and multi-agent models in complex reasoning tasks and proves to be effective at scaling with increased model ensemble sizes.",
        "strengths": "1. The introduction is organized and well-written.\n2. The experiments are comprehensive, including multiple baselines and different sizes of LMs.\n3. The empirical results demonstrate the superiority of the proposed method against the baselines.\n4. The method can be scaled by increasing the number of Agents and improving performance.",
        "weaknesses": "1. I don't see a strong connection between Sec 3.2 and the following method\n2. Fig 1 should be clearer.\n3. Lack of information about the model structure of the belief encoders and hyperparameters of optimizing them.\n4. Since the proposed method needs to tune a Q function, the author should include a baseline with a learned action-value function, e.g. [1][2]\n5. In Table 4, the author may also show the performance w.r.t. the token consumption."
      },
      {
        "rating": "3",
        "confidence": "2",
        "summary": "This paper presents a way to optimize multi-agent LLM systems for Bayesian Nash Equilibrium (BNE). It showed strong results against other popular benchmark methods. Even though the paper is very well-written, I have to reserve my recommendation for acceptance until some confusion is cleared up.",
        "strengths": "1. The paper is written very well. The structure and organization are both very clear.\n2. The paper uses actual game theory objectives to ground multi-agent debate optimization. This effort is very applaudable.",
        "weaknesses": "1. Currently, the paper lacks quite a few key details to properly understand the work.\n2. Training details are almost completely missing.\n3. The provided code (through a URL) is very minimal/barebone. It includes data files and code for Game of 24 -- which is not even reported in the actual paper. \n4. The comparison is between EcoNash (a method that involves fine-tuning the model) and other methods (RAP, ToT, rStar, etc.) -- essentially comparing a fine-tuned model with prompting methods. The higher performance is not entirely surprising.\n5. It might be cool to see if fine-tuning, according to Nash equilibria, leads agents to develop distinct \"personas\" or emergent differentiations."
      },
      {
        "rating": "5",
        "confidence": "3",
        "summary": "This paper proposes EcoNash, a multi-agent framework geared towards achieving Bayesian Nash equilibrium, which has a sublinear regret instead of linear regret in the regular multi-agent debate setup. The method consists of a coordinator LLM that tells a question-specific strategy to each executor LLM and the executor LLM that acts as the solver and executes the strategy based on its internal state using the agent-specific belief network. The beliefs from all the agents are relayed into the coordinator LLM via embeddings from the belief encoder which then aggregates and commits. The networks are trained using gradient descent with TD and SD loss. Empirically, the authors show that 4 different LLMs (of different sizes and families), EcoNash outperforms various prompting based baselines: CoT, SC, multi-agent debate and also uses fewer tokens (more efficient or low latency).",
        "strengths": "* Multi-agent techniques are a popular and effective method for improving the reasoning performance of LLMs, however, they are computationally expensive. So the paper addresses a problem on an important topic and their better regret bounds and token efficiency results are compelling.\n* The BNE take on multi-agent conversations are relatively novel to this domain, and is conceptually intriguing -- could be useful for the ICLR community\n* The empirical results over prompting baselines give good improvement on multiple datasets and models",
        "weaknesses": "* The authors can present the paper's content more clearly and make it easier to follow. I found a lot of crucial details not adequately explained in theoretical results, experimental setup and training, and general examples/intuition that would make the paper more appealing to the multi-agent reasoning community. See questions below (1-6, 8)\n* I have major questions or doubts about the assumptions made in the theoretical results, which are mostly delegated to the appendix. Overall this section was tough to follow and missed necessary background and intuition needed for it to be beneficial for LLM reasoning community. See questions below (7, 11)\n* The paper does not clearly explain their experimental setup, which involves training, and in its current form, it would be hard for any reader to be able to have a working implementation of their method (also brings up reproducibility concern). It also raises doubts about if the baseline comparisons are fair or adequate (no training baselines), and the ablations and analysis for why the method works appear to be insufficient (see questions: 8-10, 12-15).\n\nPS: I would be open to revisiting the scores if the authors add some of these missing details and simplify the explanations and content presentation of the paper. In the current form, I don't think the content is clear and coherent for the community at large to benefit from it."
      },
      {
        "rating": "8",
        "confidence": "3",
        "summary": "The paper proposes the EcoNash framework, a new solution designed for efficient and scalable coordination in multi-agent systems utilizing Large Language Models (LLMs). The framework leverages Bayesian Nash Equilibrium (BNE) to optimize multi-agent interactions while minimizing communication overhead. By combining global and local coordinators and clustering LLM agents, EcoNash achieves effective coordination with reduced computational costs.\n\nThe paper introduces a detailed theoretical analysis, including a convergence guarantee and a Bayesian regret bound, demonstrating the efficiency and stability of the proposed approach. EcoNash’s hierarchical structure enables it to achieve sublinear regret, significantly improving learning and convergence rates compared to existing multi-agent debate methods.\n\nExperimental results across multiple benchmarks show that EcoNash outperforms both single-agent and traditional multi-agent methods, achieving improved scalability and efficiency. The framework contributes to advancing multi-agent reasoning, particularly in large-scale deployments where resource constraints and scalability are critical considerations.\n\nEcoNash’s hierarchical coordination and emphasis on distributed reasoning allow agents to achieve Bayesian Nash Equilibrium independently, which is theoretically well-founded and empirically validated. Overall, the paper is well-written, methodologically sound, and experimentally thorough. I recommend it for acceptance.",
        "strengths": "This paper introduces EcoNash, a novel multi-agent reasoning framework that combines hierarchical coordination with Bayesian Nash Equilibrium (BNE) principles to enhance the scalability and efficiency of large language models (LLMs) in multi-agent systems. The EcoNash framework reduces computational costs and minimizes the need for extensive inter-agent communication, which addresses common challenges in multi-agent LLM frameworks. By leveraging distributed reasoning and theoretically proving convergence with BNE, the authors provide a framework that is both theoretically sound and empirically validated.\n\nThe paper is well-written, methodologically sound, and experimentally thorough. The experiments on benchmark datasets convincingly demonstrate the framework’s scalability and efficiency, while the theoretical analysis provides a solid foundation for the proposed coordination mechanism. I recommend the paper for acceptance.",
        "weaknesses": "While the paper presents a valuable contribution, a few areas could be enhanced to fully realize its goals:\n\n1. **Scalability of Coordination Mechanism**: EcoNash leverages a central Coordinator LLM to achieve distributed reasoning among Execution LLMs, yet the scalability of this coordination mechanism as agent numbers grow is unclear. Since scalability is a primary aim, it would be useful to explore alternative coordination structures (e.g., decentralized or multi-coordinator configurations) that could mitigate potential bottlenecks from a single coordinator, especially in large agent systems.\n\n2. **Assumptions in Convergence Proofs**: The paper’s theoretical contributions are strong, particularly in proving convergence to BNE. However, several key assumptions, such as those related to the reward structures and learning rates, are briefly mentioned without full elaboration. Detailed analysis on how these assumptions align with real-world LLM behavior could clarify the conditions under which EcoNash’s convergence is robust. A more thorough exploration of these theoretical aspects would strengthen the rigor of the convergence claims.\n\n3. **Heterogeneous Agent Configurations**: The experiments focus on homogeneous agent setups, which may not fully represent practical, mixed-capability multi-agent settings where different models operate together. Including experiments with heterogeneous agents (e.g., LLMs of varying sizes or architectures) would better validate EcoNash's adaptability and efficiency under more diverse configurations, highlighting its flexibility in real-world applications.\n\n4. **Reward Design Specificity**: The paper’s use of multi-faceted reward designs (e.g., action likelihood, task-specific, and self-evaluation rewards) is innovative, but the implementation lacks full transparency, particularly regarding how these rewards are balanced to avoid bias or feedback loops. Providing more specific details on the reward design and ensuring balanced feedback mechanisms would strengthen the framework’s robustness and generalizability. Additionally, discussing potential trade-offs among different reward types (e.g., consistency versus creativity) could offer further insights.\n\n5. **Comparison with Related Multi-Agent Systems**: The paper compares EcoNash against traditional multi-agent debate and coordination methods, but it could benefit from a comparison with additional recent multi-agent LLM approaches. For example, frameworks that optimize coordination in decentralized ways or those that involve explicit negotiation protocols could serve as useful baselines. Such comparisons would contextualize EcoNash’s performance and clarify its unique strengths.\n\nAddressing these areas could enhance EcoNash's clarity, scalability, and applicability in diverse multi-agent environments, further supporting its practical contributions."
      }
    ],
    "rating_avg": 5.5,
    "confidence_avg": 3.0,
    "decision": "Reject",
    "meta_review": "This paper proposes a hierarchical reinforcement learning framework for scalable, multi-agent reasoning by using Bayesian Nash Equilibrium. To use multi agent reasoning could potentially alleviate many problems encountered with single-agent reasoning, and hence the topic could be appealing to a broad community. Yet, the proposed method is not well presented. In particular, the DEC-MDP is described a bit vaguely. There are relatively few details about the training and the inference of the model. Also,  the connection between its theoretical part and the entire inference framework is unclear. That is to say, the experimental methods are somewhat disconnected from the theory. Furthermore, the improvements as observed in the experiments cannot fully justify the complex design of the method.",
    "author_remarks": "",
    "decision_comment": ""
  },
  {
    "id": "xPTzjpIQNp",
    "title": "Optimal Transport for Time Series Imputation",
    "authors": [
      "Hao Wang",
      "zhengnan li",
      "Haoxuan Li",
      "Xu Chen",
      "Mingming Gong",
      "BinChen",
      "Zhichao Chen"
    ],
    "abstract": "Missing data imputation through distribution alignment has demonstrated advantages for non-temporal datasets but exhibits suboptimal performance in time-series applications. The primary obstacle is crafting a discrepancy measure that simultaneously (1) captures temporal patterns—accounting for periodicity and temporal dependencies inherent in time-series—and (2) accommodates non-stationarity, ensuring robustness amidst multiple coexisting temporal patterns. In response to these challenges, we introduce the Proximal Spectrum Wasserstein (PSW) discrepancy, a novel discrepancy tailored for comparing two \\textit{sets} of time-series based on optimal transport. It incorporates a pairwise spectral distance to encapsulate temporal patterns, and a selective matching regularization to accommodate non-stationarity. Subsequently, we develop the PSW for Imputation (PSW-I) framework, which iteratively refines imputation results by minimizing the PSW discrepancy. Extensive experiments demonstrate that PSW-I effectively accommodates temporal patterns and non-stationarity, outperforming prevailing time-series imputation methods. Code is available at https://github.com/FMLYD/PSW-I.",
    "keywords": [
      "Time series",
      "Imputation"
    ],
    "venue": "ICLR",
    "year": 2025,
    "pdf_url": "https://openreview.net/pdf?id=xPTzjpIQNp",
    "forum_url": "https://openreview.net/forum?id=xPTzjpIQNp",
    "reviews": [
      {
        "rating": "8",
        "confidence": "2",
        "summary": "Providing methods for time series imputations while respecting the temporal dependence.",
        "strengths": "- Very good empirical investigation.\n\n- Clear presentation.",
        "weaknesses": "NA"
      },
      {
        "rating": "8",
        "confidence": "2",
        "summary": "The paper proposes a time series imputation method based on optimal transport. The key idea is the combination of a frequency-based Wassertein discrepancy  and selective matching regularization. Theoretical justification is also provided. The experimental results show the imputation accuracy outperforms many sota methods.",
        "strengths": "1. An interesting and well-motivated design of the spectral-enhanced Wasserstein distance (WD)\n2. A theoretical justified design of proximal spectral WD to account for non-stationarity.\n3. seemingly excellent performance in real-world benchmark datasets.",
        "weaknesses": "1. The biggest issue from my end is the lack of standard deviation. From Table 1, the error of the proposed method seems really good, but i am not informed if these results are averaged over multiple train/test runs or just one run. To avoid cherry picking, the authors are encouraged to highlight how these numbers were obtained, what the training/test splits were, and what hyperparameter selection/cross-validation process was involved, etc.  Similar expectations apply to table 3 and 4. \n\n2. Lack of convergence discussion/analysis. From Fig. 3 and Section 3.4, the imputation procedure seems to repeatedly sample patches from the time series, compute PSW, and use the gradient of the PSW to update the imputation. There seems a lack of convergence guarantees or discussions about this procedure. Can authors provide at least some discussion on this? \n\n3. Data noise issue. Real time series data often includes noises. That means, just computing the distance after DFT in lin154 might be affected by data noises. Have the authors consider any methods or trade-offs, such as low-pass filters, in your SWD definition, to improve the robustness and/or counteract the noise effect?"
      },
      {
        "rating": "5",
        "confidence": "2",
        "summary": "The paper proposes an optimal transport (OT) based time-series imputation method. The authors claim that naive application of OT does not work for time-series data. The proposed method consider applying OT in the frequency domain of the original data, called pairwise spectrum distance (PSD). Further, to deal with multiple modes, proximal spectral Wasserstein (PSW) distance is also proposed, in which mass constraint is removed to make transportation more flexible.",
        "strengths": "- Using OT to impute time-series data is an interesting approach.\n\n- Empirical evaluation shows high performance.",
        "weaknesses": "- Some technical justification is vague. Clearer descriptions would be desired.\n\n- Introduction is a bit too abstract about the proposed method. It describes what problem is solved in the paper, but does not describe the basic technical idea how it is achieved."
      }
    ],
    "rating_avg": 7.0,
    "confidence_avg": 2.0,
    "decision": "Accept (Poster)",
    "meta_review": "This submission tackles missing data imputation for time series via a new discrepancy measure. They target some difficult issues such as non-stationarity and periodicities, showing that the proposed proximal spectrum Wasserstein allows flexible learning and is amenable to the imputation framework. Reviewers concerns seemed addressed after the rebuttal phase. In particular, they already found the work novel with theoretical support and some questions and technical details were largely resolved.",
    "author_remarks": "",
    "decision_comment": ""
  },
  {
    "id": "iIrvKrtwnZ",
    "title": "HuRi : Humanoid Robots Adaptive Risk-ware Distributional Reinforcement Learning for Robust Control",
    "authors": [
      "junlong wu",
      "Yi Cheng",
      "Hang Liu",
      "Houde Liu",
      "Xueqian Wang",
      "Bin Liang"
    ],
    "abstract": "Due to the high complexity of bipedal locomotion, the locomotion control of humanoid robots requires precise adjustment of the balance system to adapt to the varying environment conditions. In the past, few studies have explicitly incorporated risk factors into robot policy training, and lacked the ability to adaptively adjust the risk sensitivity for different risky environment conditions. This deficiency impacts the agent’s exploration during training and thus fail to select the optimal action in the risky environment. We propose an adaptive risk-aware policy(HuRi) based on distributional reinforcement learning. In Dist. RL, the policy control the risk sensitivity by employing different distortion measure of the esitimated return distribution. HuRi is capable of dynamically selecting the risk sensitivity level in varying environmental conditions by utilizing the Inter Quartile Range to measure intrinsic uncertainty and Random Network Distillation for assessing the parameter uncertainty of the environment. This algorithm allows the agent to conduct safe and efficient exploration in hazardous environments during training, enhancing the mobility of humanoid robots. Simulations and real-world deployments on the Zerith-1 robot have been conducted to confirm the robustness of HuRi.",
    "keywords": [
      "Adaptive Risk-Aware",
      "Distributional Reinforcement Learning",
      "Humanoid Robots",
      "Locomotion Control"
    ],
    "venue": "ICLR",
    "year": 2025,
    "pdf_url": "https://openreview.net/pdf?id=iIrvKrtwnZ",
    "forum_url": "https://openreview.net/forum?id=iIrvKrtwnZ",
    "reviews": [
      {
        "rating": "5",
        "confidence": "5",
        "summary": "This paper presents an approach to training humanoid robots for locomotion in risky environments using deep reinforcement learning.  The key innovation is the development of an adaptive risk-aware distributional reinforcement learning algorithm, which allows adjusting risk sensitivity based on uncertainty in the environment.  This is achieved by combining intrinsic uncertainty, measured using the interquartile range, and parameter uncertainty, evaluated using random network distillation.  The proposed algorithm enables the robot to learn a robust locomotion control policy.  The method's effectiveness is demonstrated through simulations and real-world experiments on the Zerith robot, showing its ability to handle various disturbances such as sudden impacts, load variations, and uneven terrain",
        "strengths": "1. This paper introduce Wang function for risk-aware reinforcement learning and considers intrinsic uncertainty and parameter uncertainty for risk sensitivity adjustment.\n2. The proposed method demonstrates superior performance compared to the baseline PPO and a fixed risk-sensitive method (CVaR0.5) in both simulation.\n3. The proposed method is extensively evaluated in different scenarios, including simulations with different types of disturbances and real-world experiments on a physical robot.",
        "weaknesses": "1. Effectiveness of Wang function needs to be verified. Considering add some experiments to verify the effectiveness of Wang function as it is one of the core contribution of this paper, for example, adjusting the risk sensitivity of CvaR with intrinsic uncertainty and parameter uncertainty and compare with your method.\n2. The real robot experiment is weak, authors should considering comparing your method and baselines on real robot.\n3. The authors claim that \"our method exhibits strong robustness in agents and bridges the gap between simulation environments and the real world\", however, there is no content in the paper shows how the method benefits sim2real.\n3. Considering other recent work focusing on blind humanoid locomotion, such as [1], have much better performance on locomotion, I wonder if risk-aware reinforcement learning is harmful to locomotion task.\n\n[1] Advancing humanoid locomotion: Mastering challenging terrains with denoising world model learning, Xinyang Gu, Yen-Jen Wang, Xiang Zhu, Chengming Shi, Yanjiang Guo, Yichen Liu, Jianyu Chen, RSS 2024"
      },
      {
        "rating": "8",
        "confidence": "4",
        "summary": "This paper introduces HuRi, a new method for training humanoid robots to walk stably in challenging conditions by automatically adjusting their movement cautiousness based on environmental risks. The approach combines distributional reinforcement learning, which learns the full range of possible outcomes rather than just averages, with an adaptive risk adjustment system that uses uncertainty measures (IQR and RND) to assess danger levels and modify the robot's behavior accordingly. The authors demonstrate through both simulated and real-world experiments that HuRi outperforms baseline methods, achieving better stability under various disturbances including external forces, heavy loads (up to 42% of body weight), and sudden impacts.",
        "strengths": "- Well written paper with thorough implementation details. The empirical results demonstrates meaningful improvements over baselines for humanoid walking, particularly in handling disturbances and varied terrain\n    \n- Effectively demonstrates how uncertainty-aware RL can aid safe exploration in complex humanoid tasks - an important contribution that could extend beyond locomotion to manipulation and other high-dimensional control challenges in humanoid robotics",
        "weaknesses": "- Statistical robustness concerns: Figure 3 appears to show results from a single training seed, as evidenced by sharp performance dips. Multiple seeds are needed to validate learning stability, and success rate curves across seeds would better demonstrate robustness claims\n    \n- Limited exploration of reward structure impacts: While the method shows improvements, there's no analysis of how dependent these gains are on their specific reward formulation. Recent work [1] has shown phase/clock-based rewards may not be optimal for robust locomotion. A comparison with alternate reward structures would strengthen their claims.\n    \n- Uncertainty measurement complexity: The combination of RND with distributional RL seems potentially involved. I did not quite understand the justification of why RND is needed on top of distributional uncertainty estimates. Did the authors try to explore whether simpler approaches could achieve similar results, for example just using RND?"
      },
      {
        "rating": "5",
        "confidence": "4",
        "summary": "## Humanoid Robotcs Adaptive Risk-aware Distributional RL for Robust Control\nThis paper presents a risk-aware framework for training humanoid robot policies. The main contribution of the paper is the usage of distributional RL as a method for controlling the risk that a humanoid's policy incurs during exploration and execution. The motivation of the risk-awareness in humanoid systems comes from the delicate and robust control that the actuators must execute on the robot in order to maintain stability. Finding these stable controllers is difficult and dangerous, so risk-awareness in the policy is necessary. The authors provide experiments on a simulated humanoid robot and real-world experiments.",
        "strengths": "This paper is well-motivated and attempts to solve a real-world problem in humanoid robotics. The demonstration of their method on real robots is commendable and a good contribution to the paper.",
        "weaknesses": "There are a series of minor typo errors as well as incorrect latex formatting. While most of these issues don't hinder understanding, they make it harder to read the paper. For example:\n1. Title says \"Risk-ware\" instead of \"risk-aware\"\n2. Line 106 is missing a citation\n3. Most citations seem to not use \\citep{} or \\citet{}. They all are joined with the previous word. \n\nMajor issues:\n1. Presentation of method is unclear: throughout section 3, the authors introduce various components of their method. Because each component is described mainly in text, the structure of dependancies and framework is difficult to understand. Figure 2 is helpful, but not fully informative. I would suggest including an Algorithm Block that goes through each component step-by-step. Further, it would be helpful to include labels for all the equations/expressions that are splitting up the paragraphs throughout the method section\n2. Usage of $SR(\\lambda)$: This term is introduced around line 229 but never really described in great detail. In general, this paragraph from 226 to 240 is confusing and would benefit from being described through an algorithm block\n3. The quantile loss in line 241 does not include the distribution over which the expectations are being taken. \n4. MSE loss in line 247 has incorrect notation that make its meaning ambiguous (mismatched paranthesis)\n5. $g_\\beta^\\text{Wang}$ in line 254 is introduced without any additional supporting information. In the following paragraph, the authors describe the nuances of $\\beta$ but not where the function $g$ is ever used. Please clarify its position in the method.\n6. *Poor reward comparison experiment*: The results in Figure 3 do not include any error bars or indicate any notion of statistical significance. It is necessary for the authors to run these experiments over multiple seeds and report aggregated performance. Also, is reward the right metric of performance? I would imagine that violation of safety constraints is a more important feature to report on. \n7. Robot specific simulated experiments: While the results reported in the remainder of the simulated experiment section are important, they seem more like results that would be found in a pure robotics paper.\n8. Real world experiments lack statistical or more analytical significance. Please include some information on how the experiments show that the risk-awareness is important and that your instantiation of the risk-aware framework out performs other real-world methods. To do this, you might report success rates and safety violations that the varying methods exhibit."
      },
      {
        "rating": "6",
        "confidence": "4",
        "summary": "The manuscript presents a novel method for risk-aware distributional reinforcement learning called HuRi. The main innovation compared to previous works is a novel adaptation scheme for choosing the risk-awareness sensitivity of the policy based on the current state (i.e. if the policy will be cautious, exploratory/aggressive or neutral). The authors propose to use a combination of distortion functions (already present in the literature) and the usage of a Random Network Distillation (RND) process. Overall, the new approach is evaluated in humanoid locomotion tasks and showcases superior performance compared to baselines and ablations.",
        "strengths": "1) Adapting risk-awareness depending on the current state is an interesting concept and has not been extensively explored. Especially in humanoid robots.\n\n2) The usage of the RND process for risk adaptation is quite interesting and quite novel (as far as I am aware of the literature).\n\n3) The real-world evaluation on a humanoid robot is highly appreciated.\n\n4) The authors provide most details needed to replicate their approach.",
        "weaknesses": "1) The paper presentation needs a lot of work. There are numerous small things and typos that add up and make the paper difficult to understand. First, the citations are not well formatted and this makes reading the manuscript difficult. Secondly, the notation is not consistent: sometimes $\\boldsymbol{x}$ is used for the state, and some other times $\\boldsymbol{s}$ is used for the state. Another example is that the paper is about humanoid robots and then in the theorem the authors state \"We describe the locomotion problem of quadruped robots\". Overall, the presentation and writing of the paper requires quite some work.\n\n2) As far as I can tell (given the difficulty of understanding the manuscript described above), the authors claim that the novelty lies in a) the usage of an adaptive mechanism for adapting the β parameter of the distortion function, and b) the training of the RND network for β adaptation. Although I can see value in the adaptation mechanism, the motivation of using the RND network is rather weak. Similarly, the evaluation and discussion on why it works better is again rather weak. I would have expected a more thorough discussion and analysis since RND seems to be the critical factor in the performance gains.\n\n3) The experimental section requires more work. For example, in Fig. 3 (and the describing text) we do not know if the authors ran just one training and smoothed out rewards or they ran multiple seeds and take some statistics. Similarly, for the experiments shown in Fig. 4, the authors do not mention how many seeds they used. They do mention the number of seeds for the experiments shown in Tab. 1. Overall, this goes back to presentation; the manuscript requires substantial work to make it understandable.\n\n4) In the current form, we cannot really evaluate the real-world experiments. Figures 6,7 and 8 do not showcase anything that is written in the text. We cannot validate what's happening here. The video showcases a lot of nice behaviors, but we need a more rigorous evaluation here. It is very difficult to evaluate the performance of the policy at the moment.\n\n5) I do not get how the proposed approach is specifically suited for humanoids (which the author attempt to motivate, but fail imho)."
      }
    ],
    "rating_avg": 6.0,
    "confidence_avg": 4.25,
    "decision": "Reject",
    "meta_review": "This paper introduces HuRi, an adaptive risk-aware distributional reinforcement learning framework for humanoid robot locomotion. By combining intrinsic uncertainty (IQR) and parameter uncertainty (RND), the method dynamically adjusts risk sensitivity to improve robustness in uncertain environments. While the motivation and application to humanoid robots are relevant, the paper falls short in several key areas. First, the algorithmic novelty of the proposed framework is limited. The combination of IQR and RND, while interesting, primarily builds on existing techniques without offering significant new insights or advancements. Next, the claimed performance improvements, though measurable, are modest and do not convincingly justify the proposed approach as a major contribution to the field. The experimental validation, both in simulation and in the real world, is insufficient to substantiate the paper’s claims. The real-world experiments, while appreciated, lack statistical rigor, with limited repetitions and insufficient detail on key metrics. Moreover, there is lack of comparisons with baselines, and the evaluations fail to demonstrate the generalizability and broader applicability of the method. Without robust experimental evidence, the method's efficacy remains unclear.\n\nAdditionally, despite revisions during the rebuttal phase, the paper’s presentation still lacks clarity in key areas, particularly in describing the methodology and experimental setup. Ambiguities in mathematical notation and incomplete explanations of components like SR(λ) and the Wang function make the method difficult to evaluate or reproduce. Finally, the paper’s focus on humanoid locomotion makes it more suitable for a specialized robotics venue than ICLR. The broader relevance of the approach to other machine learning domains is not sufficiently demonstrated. Given these limitations, the paper does not meet the standards for acceptance at ICLR in its current form.",
    "author_remarks": "",
    "decision_comment": ""
  },
  {
    "id": "giU5WVNy7K",
    "title": "From General to Expert: Custom Pruning LLMs Across Language, Domain, and Task",
    "authors": [
      "Yiran Zhao",
      "Wenxuan Zhang",
      "Guizhen Chen",
      "Kenji Kawaguchi",
      "Lidong Bing"
    ],
    "abstract": "Large Language Models (LLMs) have transformed natural language processing, yet their substantial model sizes often demand significant computational resources. To conserve computing resources and increase inference speed, it is crucial to prune redundant parameters, especially for general users who often need expert models tailored to specific downstream scenarios. However, current pruning methods primarily focus on maintaining models' general capabilities, either requiring extensive post-training or performing poorly due to coarse-grained pruning. In this work, we design a $\\underline{Cus}$tom $\\underline{Prun}$ing method ($\\texttt{Cus-Prun}$) to prune a large general model into a smaller expert model for specific scenarios. $\\texttt{Cus-Prun}$ positions an expert model along the \"language\", \"domain\" and \"task\" dimensions. By identifying and pruning irrelevant neurons, it creates expert models without any post-training. \nOur experiments demonstrate that $\\texttt{Cus-Prun}$ consistently outperforms other methods, achieving minimal loss in both expert and general capabilities across various models from different model families and sizes.",
    "keywords": [
      "Large Language Models",
      "Pruning",
      "Expert Model"
    ],
    "venue": "ICLR",
    "year": 2025,
    "pdf_url": "https://openreview.net/pdf?id=giU5WVNy7K",
    "forum_url": "https://openreview.net/forum?id=giU5WVNy7K",
    "reviews": [
      {
        "rating": "5",
        "confidence": "3",
        "summary": "This paper aims to address the limitations of existing pruning techniques that typically focus on general capabilities and often employ coarse-grained pruning approaches, and sometimes require extensive post-training after pruning. The authors propose a more targeted approach, aiming to develop expert models by selectively pruning neurons that do not contribute to the model's performance in specific areas. This method involves identifying irrelevant neurons for each dimension (language, domain, task) by evaluating the impact of their removal on the model’s output when processing the corresponding corpus. Experimental results demonstrate minimal loss in both expert and general capabilities across various models from different families and sizes, positioning expert models effectively along the “language”, “domain”, and “task” dimensions.",
        "strengths": "1. The idea of positioning an expert model along specific dimensions such as language, domain, and task is innovative and offers enhanced flexibility for model adaptation. This approach allows for more specialized and efficient models tailored to specific tasks or domains.\n2. The experiments conducted are comprehensive, evaluating the performance of the proposed method across a variety of scenarios. Additionally, the inclusion of different model families and sizes in the experimental setup adds robustness to the findings, showcasing the method’s versatility.\n3. The paper is well-written and easy to follow.",
        "weaknesses": "The paper would benefit from an analysis comparing the FLOPs before and after pruning. This would provide quantitative proof of the efficiency gains from the pruning process, substantiating the method’s effectiveness in reducing computational overhead while maintaining performance."
      },
      {
        "rating": "6",
        "confidence": "3",
        "summary": "This paper introduces a novel framework for structured pruning named Cus-Prun, which creates \"expert models\", or pruned networks that are tailored for a combination of specific languages (L), tasks (T) and/or domains (D). The framework is based on the assumption that targeting specific languages, tasks and domains creates more opportunities for pruning, and can yield better accuracy at the same pruning ratio compared to more general frameworks such as ShortGPT or SliceGPT. The pruning itself is performed by identifying redundant or irrelevant neurons for different (L, T and D) combinations - specifically, the paper adopts an Oracle-based approach, where importance of a neuron is determined by the change in model accuracy when it is driven to zero (compared to original dense network). Cus-Prun is evaluated across a range of different (L, T, D) combinations and compared with both recent state-of-the-art LLMs and general pruning approaches.",
        "strengths": "* The paper is reasonably well-written, with core ideas and concepts clearly explained.\n* Creating strong networks/sub-networks for specific domains, tasks and languages is an important problem.",
        "weaknesses": "* The evaluation includes comparisons to other LLMs and pruning methods, but not to networks tailored for specific languages, domains, and tasks. While I understand that it may be hard to obtain open LLMs for each combination, without this comparison, it’s hard to understand if a much smaller customized LLM potentially outperforms the pruned network(s) obtained using Cus-Prun. A simple way to do this comparison might be to take either (1) the original baseline LLM, or (2) a 25% smaller LLM (pruning ratio used in the paper) and then perform PEFT (using LoRA for example) on the corresponding dataset.\n* Oracle-based pruning is not really novel."
      },
      {
        "rating": "3",
        "confidence": "5",
        "summary": "This work proposes Cus-Prun, which creates smaller expert models from pre-trained LLMs without post-training. Experimental results demonstrate that Cus-Prun outperforms existing techniques on three-dimensional (\"language,\" \"domain,\" and \"task”) specific models.",
        "strengths": "- The proposed task-specific pruning without post-training setting is novel.\n- Extensive experiments across several tasks and models are included, validating the effectiveness of the proposed method.",
        "weaknesses": "- Algorithm 1 is unclear. The authors should point out how the “irrelevant neurons” are identified.\n- This work aims “to optimize computing resources and increase inference speed.” However, the experimental evaluation does not contain any results about efficiency (e.g., inference speedup).\n- The ablation study in this work is limited. For example, the impact of the pre-defined threshold ϵ should be further studies."
      },
      {
        "rating": "3",
        "confidence": "5",
        "summary": "The paper presents a new LLM pruning approach (Cus-Prun) that prunes redundant parameters to improve memory efficiency. In particular, the authors take \"language\", \"domain\" and \"task\" as 3 dimensions into account and collect corresponding corpus to identify irrelevant parameters and zero out them. Experimental results on several benchmarks demonstrate the effectiveness of the approach.",
        "strengths": "The paper is easy to understand, and the idea is quite straightforward and clear.",
        "weaknesses": "The novelty of the paper is quite limited, and the result of the paper is questionable. In particular:\n- There is nothing new on how to identify the relevance of examples, so I regard the main novelty as the split of language, domain and task corpus. Such split is very heuristic without clear motivation. What if we just let users provide a corpus mixture that they care about, and apply any pruning technique on such corpus. Based on the idea from the paper, such user-provided corpus should contain even more than 3 pre-defined dimensions, for example, 1) special instructions, 2) special formats, etc. Then why bother splitting them into 3 hard-coded dimensions and follow the framework?\n- What is the benefit of pruning 25% parameters at the cost of 10+% drop in capacity? Without special software and hardware design, pruning 25% parameters does not directly translate to any memory saving or inference speed up.\n- If I understand correctly, pruning 25% of parameters of a 70B model translates to a 50B+ parameter model. Can the authors compare the performance with even a <50B dense model?"
      }
    ],
    "rating_avg": 4.25,
    "confidence_avg": 4.0,
    "decision": "N/A",
    "meta_review": "",
    "author_remarks": "",
    "decision_comment": ""
  },
  {
    "id": "Uc3kog3O45",
    "title": "Global Context-aware Representation Learning for Spatially Resolved Transcriptomics",
    "authors": [
      "Yunhak Oh",
      "Junseok Lee",
      "Yeongmin Kim",
      "Namkyeong Lee",
      "Chanyoung Park"
    ],
    "abstract": "Spatially Resolved Transcriptomics (SRT) is a cutting-edge technique that captures the spatial context of cells within tissues, enabling the study of complex biological networks. Recently, graph-based deep learning has been utilized in identifying meaningful spatial domains by leveraging both gene expression and spatial information. However, these approaches fall short in obtaining qualified spot representations, particularly for those located around the boundary of cell type clusters, as they heavily emphasize spatially local spots that have minimal feature differences from an anchor node. To address this limitation, we propose a novel framework, Spotscape, which introduces the Similarity Telescope module designed to learn spot representations by capturing the global relationships among multiple spots. Additionally, to address the challenges that arise when integrating multiple slices from heterogeneous sources, we propose a similarity scaling strategy that explicitly regulates the distances between intra- and inter-slice spots to ensure they remain nearly the same. Extensive experiments demonstrate the superiority of Spotscape in various downstream tasks, including spatial domain identification, multi-slice integration, and alignment tasks, compared to baseline methods. Our code is available at the following link: https://anonymous.4open.science/r/Spotscape-E312/",
    "keywords": [
      "Spatially Resolved Transcriptomics",
      "Self-Supervised Learning"
    ],
    "venue": "ICLR",
    "year": 2025,
    "pdf_url": "https://openreview.net/pdf?id=Uc3kog3O45",
    "forum_url": "https://openreview.net/forum?id=Uc3kog3O45",
    "reviews": [
      {
        "rating": "6",
        "confidence": "5",
        "summary": "This paper introduces a framework called Spotscape, designed to improve spatial transcriptomics data representation for enhanced analysis of spatial domain identification, and multi-slice integration and alignment. Spotscape utilizes a graph autoencoder and incorporates various loss terms to optimize the learning of spot representations, thereby improving clustering and alignment. Applied to five datasets, the framework demonstrates its effectiveness in predicting spatial domains of brain layers and mouse embryos, aligning temporal spatial transcriptomics data, and integrating spatial data across different resolutions.",
        "strengths": "1. Current whole-transcriptomic spatial sequencing platforms, such as 10x Visium, face challenges with low spot resolution, where each spot may capture transcripts from tens of cells. This limits the accuracy of clustering spatial domains, like brain layers. Spotscape demonstrated notable improvements in domain prediction accuracy in the human dorsolateral prefrontal cortex and mouse embryo data. \n2. Batch effects are a common challenge in integrating and aligning multi-slice spatial data, particularly for temporal data analysis. Spotscape showed superior performance in reducing batch effects across most datasets compared to other methods. \n3. Ablation studies highlighted the importance of incorporating various loss terms in the proposed graph auto-encoder model, demonstrating their critical role in enhancing data representation quality.",
        "weaknesses": "1. While Spotscape demonstrated significant improvements in spatial domain identification across two Visium datasets(DLPFC and MTG), its performance on the Stereo-seq platform for mouse embryo profiling showed only modest gains compared to existing algorithms, such as domain detection with STAGATE (Fig. 3B) and batch correction with STAligner (Table 4). This difference may stem from the higher resolution of Stereo-seq (0.2 µm per spot) compared to Visium’s lower resolution (55 µm per spot). The higher resolution likely enhances cell type and spatial domain identification, potentially diminishing Spotscape's advantage. With rapid advancements in spatial transcriptomics profiling—improving resolution, gene coverage, and sensitivity—Spotscape must demonstrate strength across both low-resolution platforms like Visium and high-resolution platforms like Stereo-seq, seqFISH+, Pixel-seq, etc., to contribute significantly to spatial data analysis. \n2. While the inclusion of prototypical contrastive learning loss in Spotscape may improve spatial domain prediction, it could potentially impact other downstream tasks, such as trajectory prediction across cell types or states. \n3. Several parameters, such as learning rate, number of clusters (K), and lambda values for each loss term, appear hardcoded in the provided code. It is unclear how to optimize these parameters for new datasets and whether a comprehensive search for optimal values is required. Additionally, it raises questions about the time needed for this process, especially for large datasets containing 40–100 spatial transcriptomics samples. \n4. It is worth noting that single-cell embedding models like scGPT and scFoundation, which are trained on millions of cells, have demonstrated superior performance in cell type clustering and data integration. A comparison between Spotscape and these pre-trained deep learning models on spatial transcriptomics data would be valuable to determine if Spotscape can outperform these models on the proposed tasks."
      },
      {
        "rating": "5",
        "confidence": "4",
        "summary": "The authors propose a novel framework, Spotscape for spatial domain identification and SRT data integration, which achieves impressive performance. The Spotscape framework introduces a slide-level contrastive learning module to learn the spot representation, a prototypical contrastive learning loss for enhancing clustering, a reconstruction loss to stabilize the optimization procedure, and a similarity scaling strategy that maintains consistency across different tissues. \n\nThe paper attempts to address some issues unsolved by previous studies, for example, the suboptimal result for boundary spots, the batch effect across multiple slides. The motivation is clear and sensible.",
        "strengths": "1. The paper studies some prominent issues, such as boundary spots, and batch effect.\n\n2. The paper provides comprehensive experiments. The baseline models, experiment setups, and ablation studies are all carefully selected. The performance of the method is hightly competitive.\n\n3. The paper provides source codes for reproducibility.",
        "weaknesses": "1. The logic of the methodology design is not very clear, some designs are very ad-hoc, which needs further clarification.\n\n2. It is not clear how the hyperparameters lambdas are selected. In the codes provided by the authors, those hyperparameters are manually specified. It is possible that these lambdas are chosen to achieve the best test performance, which is not fair for other baseline methods. The authors need to provide additional hyperparameter-sensitive analysis to justify this.\n\n3. It is not clear how the hyperparameters of the baseline methods are selected. The authors need to show that they made the best efforts to acquire the best performance from the baselines to ensure a fair comparison.\n\n4. The time complexity of this method is not clear. The prototypical contrastive learning objective involves T times of k-means in each training iteration (after 500 epochs), which may dramatically impact the running speed. The author needs to provide justification for the time-performance tradeoff."
      },
      {
        "rating": "6",
        "confidence": "3",
        "summary": "This paper studies the representation learning for spatial transcriptomics data. The authors argue that capturing global context is critical, especially for spots near boundaries. To address it, they propose pretraining the GNNs using contrastive learning to align the representations between inter- and intra-slice spots. Several experiments including spatial domain identification, multi-slice integration, and alignment, demonstrate the model’s effectiveness.",
        "strengths": "- The preliminary findings showing low clustering performance for boundary spots are interesting and can potentially motivate some future studies to address such an issue.\n- The experiment is comprehensive, including multiple datasets across different sequencing technologies and patient samples. Additionally, aligning slides sequenced by Visium and Xenium is both practically significant and challenging due to batch effects.\n- For methodology, the paper demonstrates the effectiveness of graph contrastive learning in spatial transcriptomics data.",
        "weaknesses": "- The motivation is to capture global context through graph contrastive learning, but they haven't justified it. It’s not surprising that graph contrastive learning can improve GNN’s performance [1,2,3]. The clustering improvements for boundary spots in Figure 1 likely result from enhanced representation across all spots, as non-boundary spots also show significant improvement. Besides, aligning representations across graph augmentations doesn’t inherently enable access to information beyond local neighborhoods.\n- In the methodology, several alignment loss functions are proposed, but there appears to be redundancy. For example, both L_{sc} (Equ.(1)) and L_{pcl} aim to maximize the representation similarity between two augmentations. Additionally, as shown in Figure (7), removing L_{recon} and L_{pcl} doesn’t actually impact the performance, raising the question of whether so many loss functions are necessary.\n- Several experimental details are missing, including the type of graph augmentation used, the specific hyperparameters, and the tuning strategy applied.\n- The explanation of Section 4.4 can be improved. The “A” is first introduced in Section 3, but it is reintroduced with a different explanation in Line 287, leading to potential confusion.\n\n[1] Graph Contrastive Learning with Augmentations, NeurIPS2020\n\n[2] BatchSampler: Sampling Mini-Batches for Contrastive Learning in Vision, Language, and Graphs, KDD2023\n\n[3] Deep Graph Contrastive Representation Learning"
      },
      {
        "rating": "6",
        "confidence": "4",
        "summary": "The paper introduces Spotscape, a framework designed to enhance the analysis of spatially resolved transcriptomics (SRT) data. Traditional graph-based deep learning methods in SRT have limitations in representing spots near the boundaries of cell type clusters, as they tend to focus mainly on spatially close spots with similar features. Spotscape addresses this by introducing a Similarity Telescope module, which captures global relationships among multiple spots to improve representation. Moreover, to handle the integration of multiple slices from diverse sources, the framework incorporates a similarity scaling strategy that maintains consistent distances between intra- and inter-slice spots. Experiments show that Spotscape outperforms existing methods in tasks such as spatial domain identification, multi-slice integration, and alignment.",
        "strengths": "1. It is quite impressive that Spotscape can handle both single-slice and multi-slice tasks, from spatial domain detection to alignment of mouse embryogenesis.\n2. The experimental results show that Spotscape delivers performance boost compared to the baselines in different tasks.\n3. The ablation study showcases the effects of each type of loss in different tasks, helping the readers to better understand the design of Spotscape.",
        "weaknesses": "1. The provided information is not enough to reproduce the experiments. For example, what kind of message passing layer is used in the GNN encoder? How many GNN layers? What are the dimensions of the layers? What are the choices for hyperparameters?\n2. The proposed Spotscape looks more complicated than the baselines. I wonder if is Spotscape more resource-consuming in terms of spatial and computation complexity.\n3. (minor) There are some typos in the manuscript. For example, the title of Table 2."
      }
    ],
    "rating_avg": 5.75,
    "confidence_avg": 4.0,
    "decision": "Reject",
    "meta_review": "This submission focuses on analyzing Spatially Resolved Transcriptomics (SRT) data and introduces Spotscape for enhanced representation learning. Spotscape utilizes a graph auto-encoder and incorporates various loss terms to optimize the learning of spot representations. The authors reported empirical results on multiple datasets to validate its effectiveness in improving clustering and alignment across different resolutions. \n\nMost of the reviewers agreed that the demonstrated empirical performance by Spotscape has shown to improve SRT data analysis. Remaining concerns include the incremental methodological contributions, computational complexity and scalability, generalizability to other SRT platforms, the effectiveness of trajectory or perturbation prediction downstream tasks besides the reported results dependent mostly on representation learning from training data. \n\nGiven these remaining concerns, this submission with its current content is more suitable for other high impact avenues where the readership is more inclined towards bioinformatics data analysis. \n\nThe authors may need to provide more comprehensive experiments considering addressing the remaining concerns to further improve the quality of the paper. For example, the results with CosMX sequencing during the rebuttal on other platforms, should be included and expanded to better understand the limitations of the proposed method. More comprehensive results using other datasets on prediction tasks can also further strengthen the presented work.",
    "author_remarks": "",
    "decision_comment": ""
  },
  {
    "id": "04RGjODVj3",
    "title": "From Rest to Action: Adaptive Weight Generation for Motor Imagery Classification from Resting-State EEG Using Hypernetworks",
    "authors": [
      "Param Rajpura",
      "Yogesh Kumar Meena"
    ],
    "abstract": "Existing EEG-based brain-computer interface (BCI) systems require long calibration sessions from the intended users to train the models, limiting their use in real-world applications. Additionally, despite containing user-specific information and features correlating with BCI performance of a user, resting-state EEG data is underutilized, especially in motor imagery decoding tasks. To address the challenge of within and across-user generalisation, we propose a novel architecture, HyperEEGNet, which integrates HyperNetworks (HNs) with the EEGNet architecture to adaptively generate weights for motor imagery classification based on resting-state data. Our approach performs similarly in a Leave-Subject-Out scenario using a dataset with 9 participants, compared to the baseline EEGNet. When the dataset size is scaled, with 33 participants' datasets, the model demonstrates its generalisation capabilities using the information from resting state EEG data, particularly when faced with unseen subjects. Our model can learn robust representations in both cross-session and cross-user scenarios, opening a novel premise to leverage the resting state data for downstream tasks like motor imagery classification. The findings also demonstrate that such models with smaller footprints reduce memory and storage requirements for edge computing. The approach opens up avenues for faster user calibration and better feasibility of edge computing, a favourable combination to push forward the efforts to bring BCIs to real-world applications.",
    "keywords": [
      "Brain-Computer Interfaces (BCIs)",
      "Motor Imagery",
      "HyperNetworks",
      "Data driven learning",
      "Adaptive weights"
    ],
    "venue": "ICLR",
    "year": 2025,
    "pdf_url": "https://openreview.net/pdf?id=04RGjODVj3",
    "forum_url": "https://openreview.net/forum?id=04RGjODVj3",
    "reviews": [
      {
        "rating": "1",
        "confidence": "5",
        "summary": "In this paper, the authors proposed a HyperEEGNet architecture by combining the conventional HyperNetwork and EEGNet to adress cross-user variability for MI-BCI systems. The authors compared the performance of the proposed HyperEEGNet with that of competing EEGNet on various publicly available MI-EEG datasets in both cross-session and cross-user conditions.",
        "strengths": "This study try to address the important issue of cross-user variability and BCI illiteracy issues in the MI-EEG analysis by adopting the ability of HyperNetwork to adaptive weight generation to learn user-specific representations.",
        "weaknesses": "There is no substantial innovation in proposed method combining the conventional HyperNetworks and EEGNet. \n\nThe performance improvement of the proposed method over existing EEGNet has not been consistently demonstrated across multiple datasets. This is, the proposed model achieved improved performance on the Dreyer et al. dataset, while its performance degraded on the BCI Competition IV IIa dataset. Furthermore, there has been no meaningful discussion about these conflicting results.\n\nNo comparisons were conducted with existing state-of-the-art methods that have addressed the subject variability issue."
      },
      {
        "rating": "5",
        "confidence": "4",
        "summary": "The paper aims to show the benefits of using a HyperNet architecture to improve the generalization capabilities of EEGNet for generalization given a large dataset. The authors also use data from the resting state before a trial as a novel input for motor imagery classification.",
        "strengths": "The paper is original in that they apply a HyperNet architecture to improve the generalization capabilities of an EEG motor imagery classifier. The paper evaluates inter-subject and inter-session performance, which are both important metrics for deployment of a BCI. The authors are fairly clear in how experiments are done, although I had some questions about intersession evaluation for the BCI IV IIa dataset. The work is significant in that a new method is evaluated on EEG data and shows strong generalization performance in a dataset with 42 subjects.",
        "weaknesses": "1. Claims on the strength of HyperNet + EEGNet would be improved through using a more comprehensive evaluation on the Dreyer et al. dataset. Leave-N-subjects-out train-test split should be done where around a quarter of the subjects are used as test subjects each time. \n2. The HyperNet + EEGNet approach does not seem to work for the BCI IV IIa dataset (one of the two datasets tested). The authors mention that it is evidence that the method does not seem to work unless with a larger dataset. It would be better if there were another dataset that can be tested to show that the HyperNet + EEGNet approach does indeed improve classification given more than 9 subjects. Alternatively, the Dreyer et al. dataset could be evaluated while varying the number of subjects for training, e.g. 8, 16, 24, 32, etc to see if the trend of improving performance given more subjects occurs."
      },
      {
        "rating": "3",
        "confidence": "5",
        "summary": "The authors introduce a new architecture called HyperEEGNet aimed at enhancing EEG-based brain-computer interface (BCI) systems. This innovation addresses issues related to lengthy calibration sessions and the limited use of resting-state EEG data in motor imagery decoding tasks. By combining HyperNetworks with the EEGNet framework, HyperEEGNet adaptively generates weights for motor imagery classification based on resting-state data. In Leave-Subject-Out scenarios using a dataset of nine participants, its performance is comparable to the baseline EEGNet. However, when applied to larger datasets with 33 participants, HyperEEGNet shows improved generalization capabilities, effectively utilizing resting-state EEG information to manage unseen subjects. The model provides strong representations in both cross-session and cross-user contexts, underscoring the value of resting-state data for tasks such as motor imagery classification. Additionally, the results indicate that HyperEEGNet has a smaller memory and storage footprint, making it well-suited for edge computing. This approach offers faster user calibration and enhances the practicality of real-world BCI applications, representing a significant advancement in the field.",
        "strengths": "The model exhibits robust generalization capabilities, performing effectively in both Leave-Subject-Out scenarios and with larger datasets, demonstrating its ability to handle unseen subjects. Additionally, this approach promises reduced calibration time, which is essential for real-world BCI applications, thereby enhancing user-friendliness and practicality.",
        "weaknesses": "The initial evaluations rely on a relatively small dataset comprising just nine participants, which may not adequately reflect the variability found in larger populations. This raises questions about the generalizability of the findings without access to more extensive and diverse datasets. Additionally, while the use of resting-state EEG data is a novel approach, the model's performance may be affected if the quality or relevance of this data varies among different users or sessions. Furthermore, incorporating HyperNetworks adds a layer of complexity to the training and tuning process, potentially necessitating greater computational resources and specialized knowledge for effective implementation. Lastly, like many deep learning models, HyperEEGNet may have limitations in interpretability, making it difficult to ascertain how specific features impact its classification decisions."
      },
      {
        "rating": "3",
        "confidence": "5",
        "summary": "The authors propose a novel architecture, HyperEEGNet, to improve EEG-based brain-computer interface (BCI) systems, addressing the limitations of long calibration sessions and the underutilization of resting-state EEG data in motor imagery decoding tasks. By integrating HyperNetworks with the EEGNet architecture, HyperEEGNet adaptively generates weights for motor imagery classification based on resting-state data. In Leave-Subject-Out scenarios using a dataset with nine participants, the model performs comparably to the baseline EEGNet. However, when scaled to datasets with 33 participants, HyperEEGNet demonstrates enhanced generalization capabilities, effectively leveraging resting-state EEG information to handle unseen subjects. The model achieves robust representations in both cross-session and cross-user scenarios, highlighting the potential of resting-state data for downstream tasks like motor imagery classification. Furthermore, the findings indicate that HyperEEGNet's smaller footprint reduces memory and storage requirements, making it suitable for edge computing. This approach promises faster user calibration and improved feasibility for real-world BCI applications, advancing the field significantly.",
        "strengths": "Robust Generalization: The model demonstrates strong generalization capabilities, performing well in both Leave-Subject-Out scenarios and with larger datasets, indicating its effectiveness in handling unseen subjects.\n\nReduced Calibration Time: The approach promises faster user calibration, which is crucial for real-world BCI applications, making it more user-friendly.",
        "weaknesses": "Limited Dataset Size: The initial evaluations involve a relatively small dataset with only nine participants, which may not fully capture the variability present in broader populations. The generalizability of the findings could be questioned without larger, more diverse datasets.\n\nDependence on Resting-State Data: While leveraging resting-state EEG data is innovative, the model's effectiveness might be limited if the quality or relevance of the resting-state data varies across users or sessions.\n\nComplexity of HyperNetworks: The integration of HyperNetworks may introduce additional complexity in model training and tuning, potentially requiring more computational resources and expertise to implement effectively.\n\nInterpretability: As with many deep learning models, the interpretability of HyperEEGNet's decision-making process might be limited, making it challenging to understand how specific features influence classifications."
      }
    ],
    "rating_avg": 3.0,
    "confidence_avg": 4.75,
    "decision": "Reject",
    "meta_review": "This paper presents a novel architecture, HyperEEGNet, which integrates HyperNetworks (HNs) with the EEGNet architecture, to improve EEG-based BCI systems, addressing the limitations of long calibration sessions and the underutilization of resting-state EEG data in motor imagery decoding tasks. Tacking variability across subjects is an important issue in BCI as well. The paper demonstrates that the proposed model  has domain generalization capabilities. There are a few concerns raised by reviewers. The main criticism is in limited dataset size and performance evaluation. It will be better to use more diverse larger datasets for performance evaluation. Since there are a lot of work on handling subject variability in BCI, it will be better to include some comparisons with other approaches. Therefore, the paper is not recommended for acceptance in its current form. I hope authors found the review comments informative and can improve their paper by addressing these carefully in future submissions.",
    "author_remarks": "",
    "decision_comment": ""
  },
  {
    "id": "jO3QEsm15T",
    "title": "Optimal Transport for Reducing Bias in Causal Inference without Data Splitting",
    "authors": [
      "Yuguang Yan",
      "Zongyu Li",
      "Haolin Yang",
      "Zeqin Yang",
      "Hao Zhou",
      "Ruichu Cai",
      "Zhifeng Hao"
    ],
    "abstract": "Causal inference seeks to estimate the causal effect given a treatment such as a kind of medicine or the dosage of a medication. To address the issue of confounding bias caused by the non-randomized treatment assignment on samples, most existing methods reduce the covariate shift between subpopulations receiving different values of treatment. However, these methods split training samples into smaller groups, which cuts down the number of samples in each group, while precise distribution estimation and alignment highly rely on a sufficient number of training data. In this paper, we propose a distribution alignment paradigm that involves all the training samples without data splitting, which can be naturally applied in the settings of binary and continuous treatments. To this end, we characterize the distribution shift by considering different probability measures of the same set including all the training samples, and reduce the shift between the marginal covariate distribution and the conditional covariate distribution given a treatment value. By doing this, data reduction caused by splitting is avoided, and the outcome prediction model trained on samples receiving one treatment value can be generalized to the entire population. In specific, we exploit the optimal transport theory built on probability measures to analyze the confounding bias and the outcome estimation error, which motivates us to propose a balanced representation learning method for causal inference of binary and continuous treatments. The experimental results on both binary and continuous treatment settings demonstrate the effectiveness of the proposed method.",
    "keywords": [
      "Causal Effect Estimation",
      "Optimal Transport"
    ],
    "venue": "ICLR",
    "year": 2025,
    "pdf_url": "https://openreview.net/pdf?id=jO3QEsm15T",
    "forum_url": "https://openreview.net/forum?id=jO3QEsm15T",
    "reviews": [
      {
        "rating": "6",
        "confidence": "3",
        "summary": "The paper suggests the use of a novel estimator of conditional average treatment effects and related causal objects when there is confounding explained by observable covariates. The method can be adjusted to allow for continuous treatments as well as discrete treatments. The proposed methods employ a particular adjustment for covariate imbalance that is based on an optimal transport. The authors also propose a related measure of covariate imbalance which they suggest may be used to assess the threat of confounding bias. The authors benchmark their methods against alternative approaches on established synthetic datasets.",
        "strengths": "The use of optimal transport methods to adjust for covariate imbalance seems to me a promising area of research. The performance of the proposed methods on synthetic data is very encouraging.",
        "weaknesses": "I found the motivation for the methods unclear. The authors point out that the difference between the feasible loss function $\\int\\varepsilon_{q_{t}}(h_{t})p(t)dt$ and the infeasible loss function $\\int\\varepsilon_{q}(h_{t})p(t)dt$ can be bounded by the Wasserstein distance between $q_{t}$ and $q$. It does not follow immediately that minimizing the sum of the feasible loss and this distance metric should lead to superior estimation performance. Indeed, the objective in equation (20) is minimized over three parameters $\\phi$, $\\psi$, and $\\theta$, but only $\\phi$ is shared between the feasible loss estimate $\\hat{\\mathcal{L}}$ and the Wasserstein metric. The estimate of $\\tau_{t}(x)$ depends only on $\\phi$ and $\\psi$. Thus the benefits of including this Wasserstein distance in the optimization problem must result only from improved feature learning (i.e., an improved choice for $\\phi$). In fact, I was rather perplexed that the loss $\\hat{\\mathcal{L}}$ did not incorporate the generalized propensity score $\\theta$. It seemed to me from earlier parts of the paper that calculating the generalized propensity score by optimal transport, and using this to recover covariate balance, was likely to be the main point of the paper. But unless there is an error in the description of the methods, then $\\theta$ is not directly used in learning $\\tau_{t}(x)$, only impacting that problem through its impact on the choice of $\\phi$. Incidentally, this in itself is rather complicated because the cost function $c_\\phi(\\cdot,\\cdot)$ in the optimal transport is based on $\\phi$, and setting $\\phi$ to be identically zero would trivially make the Wassersteuin metric equal to zero.\n\nPerhaps I am missing something here, particularly given that the very good performance on the benchmarking data, but I spent rather a long time trying to understand this and so, at the very least, I do not think it is well-explained.\n\nI also found the description of the algorithm confusing. The algorithm contains a loop whose final step is to minimize the objective in (20) and the loop is iterated until convergence. But if we minimize this objective, then what changes in each iteration of the loop?\n\nFinally, I find the description of the existing literature to be somewhat narrow. Causal inference methods have been developed over many decades and ML methods that incorporate data-splitting represent only a very recent and thin stratum of this much broader literature. In my opinion the authors ought to clarify when they are talking about causal inference methods as a whole, and when they are referring specifically to only recent causal inference methods from the ML literature."
      },
      {
        "rating": "5",
        "confidence": "4",
        "summary": "This work mainly studies the optimal transport method to reduce bias in causal inference. The authors propose a distribution alignment paradigm that leverages all training samples, avoiding the need for data splitting, which is a common limitation of existing methods. The theoretical contributions and empirical results demonstrate the effectiveness of the proposed method in both binary and continuous treatment settings.",
        "strengths": "1. The paper is well-structured and flows naturally.\n\n2. This paper proposes a balanced  algorithm is designed that can effectively reduce confounding bias without data splitting.\n\n3. The experimental studies are well done. A sufficient amount of empirical evidence for the proposed method is provided.",
        "weaknesses": "1. Theorem 2 holds under the assumption that $\\mathcal{H}$ is an RKHS. Given this, it’s unclear why the author didn't opt to use kernel methods for learning representations, as they seem more aligned with the conditions of the theorem.\n\n2. While the experimental results show notable improvements, it's not entirely clear why the method performs so well. The theoretical bounds appear loose, so it would be valuable to explore why the method is still effective in practice. Gaining a deeper understanding would make the approach more reliable.\n\n3. It would be beneficial to conduct ablation studies on the loss function involving Wasserstein distances. This could help identify which components contribute most to the performance gains and provide further insight into the tightness of the theoretical bounds.\n\n4. What are the key advantages and differences between the author's debiasing method and other re-weighting approaches? Clarifying this comparison would be helpful."
      },
      {
        "rating": "5",
        "confidence": "3",
        "summary": "This paper presents a novel approach for measuring the causal effect given a treatment. The model, called ORIC, is designed to directly predict outcomes rather than causal effects and is based on the formulation of optimal transport to reduce confounding bias in observational data. Unlike typical causal inference models that often split the data according to treatments and train separate models (e.g., T-learner), ORIC is designed to be effectively trained without data splitting, which is the most significant contribution of this paper.",
        "strengths": "While there have been a few instances in the literature over the past few years where the formulation of optimal transport has been borrowed to solve the problem of measuring causal effects, this paper presents yet another new perspective, which I find intriguing. The formulation that naturally combines representation learning through the $\\phi$ function with it could be widely utilized in other related research in the future.",
        "weaknesses": "The paper lacks a convincing explanation or example of how avoiding data splitting is practically beneficial in certain cases. In the case of binary treatment, splitting into just two sub-populations means the sample size is halved. Still, it is hard to see how this significantly worsens the estimation of the conditional covariate distribution. It is unclear whether the assumption is that one population is extremely smaller than the other or if the issue is that both populations are too small, making splitting problematic. This paper aims to apply to observational data rather than RCTs, but in real-world data, while there may be confounding bias, the sample size is not too small and often large. Therefore, it needs to be more clearly explained in which scenarios this methodology is more beneficial.\n\nThe approach in this paper that avoids data splitting starts from equations (3) and (4), where AMSE is defined. It is necessary to explain the validity of why minimizing AMSE should be the goal and to provide more details on the mathematical properties of the results produced by minimizing AMSE. AMSE can be also expressed as follows: $AMSE=\\int_T[\\int_Xl(h_t,\\tau_t)p(x|t)dx]p(t)^2 dt$. This includes the term $p(t)$ twice. Since $\\epsilon_{q_t}(h_t) \\equiv \\int_X l(h_t,\\tau_t)p(x|t)dx$ is biased, the inclusion of the $p(t)$ term is necessary. However, including it twice is not immediately convincing. For example, when defining PEHE, the $p(t)$ term is included only once: $PEHE=\\int_T [\\int_X ((h_1-\\tau_1) – (h_0-\\tau_0))^2  p(x|t)dx] p(t) dt$. Because AMSE includes $p(t)$ twice, through Theorem 3, the integral in equation (16) is calculated over the joint distribution $p(x,t)$ rather than $p(x|t)$, which enables to avoid data splitting. If the integral in equation (16) were calculated over $p(x|t)$, data splitting would still be required. This paper intentionally designed AMSE to avoid data splitting and aimed to reduce it through its upper bound. Therefore, it is necessary to explain why minimizing AMSE guarantees unbiased and accurate causal inference. As it stands, minimizing AMSE might lead to excessive bias depending on the data. For instance, does it sufficiently minimize $\\epsilon_q(h_0)$ when $p(t=1) >> p(t=0)$? Additional proofs or demonstrations seem necessary."
      },
      {
        "rating": "6",
        "confidence": "3",
        "summary": "The paper proposes a novel method for addressing covariate shift in observational data when estimating treatment effects, based on optimal transport. The benefit of the method is that data does not need to be split into groups and that the method can easily be applied to both binary and continuous treatments. Extensive theoretical and empirical results are provided to validate the efficacy of the method.",
        "strengths": "- The method addresses a clear problem and provides a natural solution.\n- The paper provides extensive theoretical and empirical results.\n- Despite the complex topic, the paper is generally easy to follow.",
        "weaknesses": "1. I found it hard to judge the novelty and contribution of the work with respect to existing work:\n  - There is earlier work on applying optimal transport for treatment effect estimation, which is not discussed [1, 2]. How does this work compare to your own? Is there any reason why these methods were not included as benchmarks?\n  - Apart from the data splitting, how exactly is your method different from CFR_Wass in Shalit et al. (2017)? Understanding this would make your own contribution more clear. Did you use CFR's version with Wasserstein distance in your experiments? \n\n2. The method introduces significant complexity and I would like to see more discussion of technical details:\n  - Tuning of hyperparameters ($\\lambda$, $\\gamma$), as well as tuning in general, is not discussed. As this is a difficult problem in CATE estimation generally, I would like to see how the authors addressed this. Additionally, a sensitivity analysis of $\\lambda$ is provided, but not for $\\gamma$. Is there any reason why no such analysis is presented for $\\gamma$?\n  - The efficiency of the method is not discussed. Does the Sinkhorn algorithm make your training procedure much slower?\n\n3. The conclusion summarizes the work, but does not include limitations of the proposed method or suggestions for future work.\n\n___\n[1] Wang, H., Fan, J., Chen, Z., Li, H., Liu, W., Liu, T., ... & Tang, R. (2024). Optimal transport for treatment effect estimation. Advances in Neural Information Processing Systems, 36.\n\n[2] Li, Q., Wang, Z., Liu, S., Li, G., & Xu, G. (2021). Causal optimal transport for treatment effect estimation. IEEE transactions on neural networks and learning systems, 34(8), 4083-4095."
      }
    ],
    "rating_avg": 5.5,
    "confidence_avg": 3.25,
    "decision": "Reject",
    "meta_review": "Although this paper contains some potentially interesting ideas about correcting for the effect of confounding variables, in its current form, this paper has just too many weaknesses.  To me, the most severe point of criticism concerns the concept of correcting for confounders using variables that are (almost) uncorrelated with the treatment, which seems to be a serious conceptual problem, because the very nature of a confounder is that it jointly influences both treatment and outcome. Unfortunately, this conceptual problem could not be addressed in a clear way during the rebuttal and discussion phase.",
    "author_remarks": "",
    "decision_comment": ""
  },
  {
    "id": "yyIHdaSDUU",
    "title": "Adaptive Vision Encoders: Balancing Efficiency and Robustness in Vision-Language Models",
    "authors": [
      "Aristeidis Panos",
      "Rahaf Aljundi",
      "Daniel Olmeda Reino",
      "Richard E. Turner"
    ],
    "abstract": "Vision-language models (VLMs) demonstrate impressive capabilities in visual question answering and image captioning, acting as a crucial link between visual and language modalities. However, existing open-source VLMs rely heavily on pretrained vision encoders, such as CLIP. Despite CLIP’s robustness across diverse domains, it still exhibits significant image understanding errors. These errors propagate to the VLM responses, resulting in sub-optimal performance. In our work, we propose an efficient and robust method for updating vision encoders within VLMs. Our approach selectively and locally updates the model parameters, leading to substantial performance improvements on data where previous mistakes occurred, while maintaining overall robustness. We demonstrate the effectiveness of our method during offline and continual few-shot updates, simulating a model editing regime for VLMs. While our method also scales efficiently and effectively to adapting the language model (LLM) component of the VLM, we show that separately updating the vision encoder can be a very efficient alternative. This approach improves VLM performance with less than 10x the compute resources required for updating the LLM. Our method is also supported by theoretical justifications on the parameter selection strategy.",
    "keywords": [
      "large vision-language models",
      "multimodal learning",
      "continual learning"
    ],
    "venue": "ICLR",
    "year": 2025,
    "pdf_url": "https://openreview.net/pdf?id=yyIHdaSDUU",
    "forum_url": "https://openreview.net/forum?id=yyIHdaSDUU",
    "reviews": [
      {
        "rating": "1",
        "confidence": "3",
        "summary": "This paper presents a method to improve the robustness of vision-language models (VLLMs) on diverse domains. The proposed approach, called Low-Rank Adaptation with Structured Updates (LoRSU), selectively updates the model parameters to improve the robustness. Through experiments, the authors claim that LoRSU is able to improve the VLM performance with less than 10x compute. The author also provided theoretical justification on the strategy of proposed method.",
        "strengths": "N/A",
        "weaknesses": "Overall, this paper is not in good quality and is more like something generated by LLMs. Here are some of the reasons:\n1. The argument of this paper are usuall unclear and meaningless (e.g. \"DO WEAKNESSES IN CLIP PROPAGATE TO THE VLM\" and \"separately updating the vision encoder\").  The content is usually out of context and not organized in a logical way. \n2. The claims in abstract and introduction are not supported and inconsistent to context on the later pages (e.g., the claim \"improvements on data where previous mistakes occurred\" in abstract is never discussed in the method or experiment parts)\n3. There are a lot of invented terms that are not consistent or do not exsit. For example, the datasets of TSI, DALL-E, GTS, AIR and CAn (Table1, 2 and 3), the model LLama-2+Pj and CLIP-L-14, and the method of LN, F-FT, F-EWC on Table 4.\n4. The method and theory parts (section 4) do not make any sense. \n5. The last 2 papergraphs of introduction (Line 95 and Line 111) are identicail. \n\nThere're also many other evidences that could be eazily identified in the paper."
      },
      {
        "rating": "3",
        "confidence": "4",
        "summary": "The paper focuses on the OOD robustness of the present-day vlms. The authors hypothesize that the lack of robustness in the vlms stems from the vision backbone of the vlms. They propose ways to mitigate it with selective parameter optimization and test it on a continual learning and also offline setting. The results show improvements.",
        "strengths": "1. The studied problem is relevant. It is indeed helpful for improving the OOD robustness of the VLMs. \n2. The method seems to provide some improvements on some benchmarks.",
        "weaknesses": "1. The writing lacks clarity. The paper can get a lot of help by improving the writing. For example, a paragraph is repeated 2 times in the introduction. Proofreading can be helpful. \n2. Many details are missing in the paper. For example, what is DALLE in Table. 1? Table. 2 - how did the authors test these methods? \n3. The paper also lacks suitable ablations to back the type of method chosen for the selection of parameters to update. What is the exact rationale behind it? \n4. The writing is very dense in the evaluation section. After multiple readings, I cannot understand exactly the evaluated metrics. Also, what is the need to use these metrics? Is there some background literature on these? Specifically talking about Target Improvement and Average Control Change. \n5. Simpler methods are not compared. Like peft methods. I can think of visual prompt tuning method from the top of my head."
      },
      {
        "rating": "3",
        "confidence": "4",
        "summary": "The article tackles the problem of improving the performance of vision-language models across multiple visual domains and tasks. To achieve this, it proposes LoRSU (Low-rank adaptation with structured updates) that selectively updates a subset of the parameters in each transformer layer, i.e., the first linear layer of the MLP block, as in Zhang et al. (2024) and the most informative attention head (estimated via the task-specific loss). Experiments show that LoRSU achieves better or comparable results with existing adapters (e.g., LoRA, SPU).",
        "strengths": "1. Despite the overlap/findings present in other works, the analysis in Tab. 1 and 2, showing that CLIP issues propagate to LLaVA is a clear motivating example for the need to adapt the CLIP encoders.\n\n2. The article combines existing techniques (i.e., SPU, LoRA) in a sound manner, achieving good results across a wide range of tasks.",
        "weaknesses": "1. Lines 112-128 are a repetition of lines 96-110. This unfortunate mistake harms the presentation because (i) it denotes a lack of thoroughness in proofreading the manuscript; (ii) it reduces the effective length of the paper to ~9.5 pages, taking out space from potential additional analyses or findings the reader may have benefited from. Presentation is part of the research process and carefully proofreading the manuscript is essential to present the contribution in the best possible way. \n\n2. A core part of the manuscript is the presentation of the shortcomings of CLIP's visual encoder. This is stressed in lines 44-46 and verified on tests on action recognition datasets (Table 1): TSI (Toyota Smart Home) and a synthetic one (generated via DALL-E). There are two takeaways from these results: (i) CLIP has shortcomings on rare domains/distributions and (ii) those are propagated to large multimodal models using it (Table 2). This is considered a contribution of the manuscript, as stressed in lines 99-101 (and 115-117, due to the repetition). However, manuscripts have already shown the limitations of CLIP on benchmarks wider and more structured than the one presented in Table 1. Examples are [a,b,c] focusing on various types of compositionality (e.g., 8 textual modifications in [a], 10 challenges in [c]), [d] focusing on low resource challenges (i.e., rare domains) and [e] already showed how CLIP issues propagate to VLMs using it (Fig. 6 in their paper). The claim contribution (1) is not clear w.r.t. these works as well as the contribution of Sec. 3. \n\n3. The technical contribution w.r.t. previous work is unclear. LoRSU combines two techniques: (i) selectively updates the parameters of the first linear blocks and (ii) selects which parameters to update based on the task-specific loss. The first has been presented in SPU, Zhang et al. (2024), as acknowledged in lines 92-93 and 225. Looking at the results presented in the appendix, SPU is often comparable to LoRSU, even outperforming it in some scenarios (e.g., Tables 7,9,10). For point (ii) the update is done via LoRA adapters, with the main difference being the focus on specific heads via the gradient of the task-specific loss (following what is done in SPU as well to select parameters). However, there is no ablation showing how the number of heads picked influences the final performance. All in all, there is a lack of analysis justifying the various design choices, with the advantages mostly shown via the empirical results on downstream datasets against the competitors. It would be helpful to include additional ablation studies/analyses (e.g., pruning ratio, where to apply LoRA layers etc.) and to expand on the contribution/practical advantages w.r.t. SPU and LoRA.\n\n4. Following on the previous, the hyperparameters choice is not justified and thoroughly analyzed. For instance, Appendix B states that SPU and LoRSU use different sparsity ratios (e.g., 15% the first, 10% the latter) without analyzing the impact of this choice. The same goes for the data points used: appendix B states 800 data points to compute gradients, without further details on how they are picked. \n\n5. It is hard to parse the results sa they are now. Instead of the most commonly used accuracy metric (adopted in Table 1 and Table 2), the main tables (3, 4, and 5) report target improvement and average control change. Those are harder to grasp, especially due to the lack of reference points to ground the results themselves. It would be better to report the results as done in the Appendix (i.e., with the natural accuracy choice) or use other metrics commonly used for continual learning (e.g., as done in SPU with average accuracy and forgetting). It could also be helpful to expand on why these metrics have been chosen (lines 355-364)/what they add w.r.t. those already present in the literature.\n\n6. While it is always interesting to see methods linked to theoretical justification, the proof in Sec. 4.1 does not expand the principles previously defined. Specifically, Eq. (5) defines gradients as the criterion for pruning and Eq. (10) uses the same gradients to define the optimization problem, stating that we want to preserve only a subset of the heads (i.e., S). It simply follows that the optimal subset of the head is the one that leads to the largest overall gradient (i.e., the top-S). Note that this is simpler than a knapsack problem (stated in line 305) as there is no constraint on the capacity, just on the number of \"items\" to be selected. In the context of the proof, some elements are unclear (i.e., what does the intersection between $I_i$ and $I_j$ mean?) or not accurately defined (e.g., as per Eq. (5), $s_l$ is not bounded between [0,1], thus its sum could be greater than the number of layers in $I_l$).\n\n7. The introduction heavily stresses the role of updating the vision encoder (contribution 2, lines 101-102 and 117-118). In Tables 5, 14, 15, and 16, the results are counter-intuitive as often the best results (or comparable) are achieved when tuning the language encoder (something that has already been studied in [f]). The analyses of the results in lines 480-497 also confirm the efficacy of updating the language side. This makes the message from the introduction and the experiments contradict each other: it would be better to clarify in the introduction that LoRSU is a general approach and that updating the vision encoder is not essential for achieving good results.\n\n**Minors:**\n- The claim \"unseen domains\" for CLIP (line 49) is hard to make as CLIP has been exposed to a huge amount of data and it might be exposed to virtually all domains but with different frequency. It would be better to replace \"unseen\" with \"rare\".\n\n- Line 102 states that the method updates \"the vision encoder [...] specifically on data where CLIP fails\". This is slightly inaccurate, as the method does not take into account for errors of the model in the most common sense but rather takes a dataset as input (where CLIP potentially does not work well) and applies adapters there: the method per se has no notion of \"data where CLIP fails\" and it could be applied to any dataset given as input. This might be clarified.\n\n- Line 146: LoRA is written incorrectly (it is not Low Rank Updates but Low Rank Adapters).\n\n- Line 248: in the very last formula of the line, the subscript should be \"k\" and not \"q\" for W, as the gradient refers to the keys.\n\n- Line 249: I could not find the definition of $\\tilde{W}_o$. \n\n\n**References:**\n\n[a] Tristan Thrush et al., \"Winoground: Probing Vision and Language Models for Visio-Linguistic Compositionality\", CVPR 2022.\n\n[b] Mert Yuksekgonul et al., \"When and why vision-language models behave like bags-of-words, and what to do about it?\", ICLR 2023.\n\n[c] Cheng-Yu Hsieh et al., \"SugarCrepe: Fixing Hackable Benchmarks for Vision-Language Compositionality\", NeurIPS 2023.\n\n[d] Yunhua Zhang et al., \"Low-Resource Vision Challenges for Foundation Models\", CVPR 2024.\n\n[e] Shengbanc Tong et al., \"Eyes Wide Shut? Exploring the Visual Shortcomings of Multimodal LLMs\", CVPR 2024.\n\n[f] Xiaohua Zhai, et al. \"Lit: Zero-shot transfer with locked-image text tuning.\" CVPR 2022."
      },
      {
        "rating": "3",
        "confidence": "3",
        "summary": "The paper shows the negative impact of CLIP encoder on downstream LLM, when the data is out-of-domain and hard for CLIP. The paper proposes a method that combines LoRA, SPU and selection of weights with large gradient to efficiently and effectively fine-tune the CLIP encoder, so that the problem can be mitigated.",
        "strengths": "1. The motivation is clear in that the paper demonstrates a clear case in which the CLIP encoder fails and also the downstream LLM.\n2. The method seems to be highly efficient, especially when fine-tuning only the CLIP encoder without updating the LLM. It seems to give even higher performance with much less cost on computation.",
        "weaknesses": "1. The paper lacks novelty in the methodology. The proposed method is a straightforward combination of LoRA, SPU, and selection of weights (attention heads) with large gradient, without any interaction between these components. Meanwhile, the evidence of its effectiveness seems to be not strong enough, as is discussed in the following. The author might provide more evidence for the effectiveness of this straightforward method.\n2. Some experimental evidence needs more justification:\n    1. In Table 3 and also other tables, the difference between methods seems to be small (especially between SPU and LoRSU). The author might consider doing a significance analysis.\n    2. In Figure 2 and table 13, it seems that just fine-tuning vision encoder is an efficient and effective strategy for LoRSU. However, the author should also include LoRA-V to have a fair comparison (also in Table 5). Also, the author should point out which version of LoRSU (L/L+/V) is used in the comparisons in Table 3 and other tables.\n3. I personally think the section 4.1 is a bit redundant in that the proof is very straightforward and can be described just intuitively: since it basically tries to prove that selecting the largest components give us the biggest sum of components. The author might instead want to try to theoretically justify the deviate from the “local minima” (or solution space) given by the full gradient is small with the proposed method."
      }
    ],
    "rating_avg": 2.5,
    "confidence_avg": 3.5,
    "decision": "N/A",
    "meta_review": "",
    "author_remarks": "",
    "decision_comment": ""
  },
  {
    "id": "3bcN6xlO6f",
    "title": "Video Action Differencing",
    "authors": [
      "James Burgess",
      "Xiaohan Wang",
      "Yuhui Zhang",
      "Anita Rau",
      "Alejandro Lozano",
      "Lisa Dunlap",
      "Trevor Darrell",
      "Serena Yeung-Levy"
    ],
    "abstract": "How do two individuals differ when performing the same action? In this work, we introduce Video Action Differencing (VidDiff), the novel task of identifying subtle differences between videos of the same action, which has numerous applications, such as coaching and skill learning. To enable development on this new task, we first create VidDiffBench, a benchmark dataset containing 549 video pairs, with human annotations of 4,469 fine-grained action differences and 2,075 timestamps indicating where these differences occur. Our experiments demonstrate that VidDiffBench poses a significant challenge for state-of-the-art large multimodal models (LMMs), such as GPT-4o and Qwen2-VL. By analyzing the failure cases of LMMs on VidDiffBench, we highlight two key challenges for this task: localizing relevant sub-actions over two videos and fine-grained frame comparison. To overcome these, we propose the VidDiff method, an agentic workflow that breaks the task into three stages: action difference proposal, keyframe localization, and frame differencing, each stage utilizing specialized foundation models. To encourage future research in this new task, we release the benchmark and code.",
    "keywords": [
      "Video",
      "Actions",
      "Differencing",
      "Zero-shot",
      "benchmark",
      "multimodal",
      "lmm",
      "llm"
    ],
    "venue": "ICLR",
    "year": 2025,
    "pdf_url": "https://openreview.net/pdf?id=3bcN6xlO6f",
    "forum_url": "https://openreview.net/forum?id=3bcN6xlO6f",
    "reviews": [
      {
        "rating": "6",
        "confidence": "4",
        "summary": "This paper introduces Video Action Differencing, a novel task of identifying subtle differences between videos of the same action. It also introduces a new benchmark sourced from mutliple video datasets with new annatations. A new method is proposed for this new task with state-of-the-art performance.",
        "strengths": "1. The proposed task has not been explored, which has key applications for some scenarios in real life.\n2. The construction process for the dataset is technically sound with different splits.\n3. The visulizations are clear and interesting.",
        "weaknesses": "Weakness and questions:\n1. Do the authors consider factors like fps for videos, which may impact the restults of answering questions like \"the speed of the arms is faster\" for distinguishing videos A and B.\n2. For the open-set benchmark, have the authors analyzed the reasons for why QWen2-VL performs so worse?\n3. Have the authors visualized the selected frames by the frame localizer compared to the ground-truth frames? What's about the effects of frame localizer compared to the ground-truth frames?"
      },
      {
        "rating": "6",
        "confidence": "4",
        "summary": "The authors introduce a method and dataset designed to compare subtle action differences across video pairs. Their method, VidDiff, uses a three-stage process to generate, localize, and verify these differences using multimodal models.\n\nMain Contributions:\n\n- A Dataset includes 557 video pairs across domains like sports, fitness, and surgery, annotated with over 4,700 fine-grained action differences. The dataset is designed to help models learn and evaluate nuanced action comparisons.\n- A Framework uses a three-step pipeline to identify differences: (1) generating potential differences with a language model, (2) aligning frames between videos using CLIP and Viterbi algorithms, and (3) verifying differences with a vision-language model.\n- A method is compared with leading multimodal models (e.g., GPT-4o and Gemini-1.5 Pro), showing improved performance in closed-set settings. This comparison also highlights challenges in current models for frame alignment and action detail recognition.",
        "strengths": "- The method is shown to outperform baseline large multimodal models by systematically isolating action differences through a three-stage approach, excelling in both closed and open settings.\n- The introduction of benchmark, with extensive annotations across varied domains (e.g., fitness, surgery, sports), provides a unique and structured dataset for fine-grained video action comparison.\n- Evaluations and ablation studies demonstrate the robustness and effectiveness of the method, especially in tasks that require precise frame alignment and action differentiation.\n- The proposed task and methods address real-world challenges in skill-based learning environments.",
        "weaknesses": "- The performance of the leading multimodal models on the dataset is not clearly demonstrated, and examples comparing success and failure cases across models would enhance understanding of their effectiveness.\n- The Difference Proposer stage’s reliance on large language models (LLMs) may introduce biases or inaccuracies, especially when generating action differences for complex or nuanced tasks. Providing more details on the generated proposer queries and their corresponding ground truth labels would enhance clarity.\n- Although the multi-stage approach is well-structured, it presents a risk of error propagation. Inaccuracies in early stages could impact the final outputs, potentially reducing overall reliability, particularly in the open-set task, where the Difference Proposer’s effectiveness is not fully evaluated.\n- While the paper introduces a detailed taxonomy for annotations, the reasonableness of some annotations remains unclear. For example, the “surgery_0” annotation includes the description \"the movements in video A are more efficient than in video B,\" which lacks a concrete definition and could be interpreted inconsistently even by human evaluators. Scaling this annotation approach to larger datasets or adapting it to new domains could also present significant challenges.\n- Minor issue: The table mentioned as Table 7 in Section 5.3 is missing."
      },
      {
        "rating": "8",
        "confidence": "5",
        "summary": "In this paper, a new task called video action differencing is proposed which aims for models to be able to understand fine-grained differences between multiple videos of people performing the same action. A new benchmark dataset is collected, named VidDiffBench, which includes 5 categories from 4 different existing datasets. Annotations are collected from pairs of videos with statements given per pair of video based on the action (for example video A includes someone jumping higher than Video B for a lay-up shot). There are two main evaluation protocols for this task, a closed set setting, in which the model must predict A or B for each possible description, and a closed set setting in which the method must generate the description. A new method which combines stages named VidDiff is proposed which outperforms standard LMMs on the dataset.",
        "strengths": "* The new task of Video Action Differencing is an interesting new task for video understanding, forcing models to recognise and understand fine-grained differences between two very similar videos.\n* The collected dataset combines four datasets with 5 different categories of video, providing a varied test bed for this new task.\n* The proposed method performs well on the dataset, outperforming off the shelf LMMs on the task yet still showcase that there is a lot still to work on in this area for future work.",
        "weaknesses": "# Weaknesses\n\n* There are some missing references for skill determination within the related work [a, b, c, d] as another example of fine-grained differences between videos containing the same action.\n* Line 196: It is mentioned here in the text that *\"Video pairs are randomly sampled within each dataset to ensure a wide range of comparison difficulty, from simple actions to more advanced tasks requiring fine-grained understanding\"* This implies that videos of differing actions are compared against one another. \n* Section 3.3.2: There are some missing information about the annotators, regarding skill level, total number, renumeration etc.\n* For the closed set, a binary classification setup was used as all candidate difference statements which is mentioned to be unbiased on Line 298. However, has this been checked? If videos are not randomly swapped at inference/training time there could have been a bias towards one video or another.\n* The open set evaluation seems like it could be prone to some errors/inconsistencies depending on the LLM chosen and how much it could hallucinate/not understand the task and doesn't represent a potentially sound evaluation protocol.\n* It is not clear within the paper as to why an LLM was used to choose the easy/medium/hard splits for each of the actions.\n* This paper did not feel like an easy read, whilst the grammar/sentence clarity was good. There was a lot of information that is split across the main paper and the appendix which necessitates jumping between them. The structure of the paper could also be improved, the method details occur within the experiments yet are given as a main contribution within the introduction with only a small amount of space given to explain the model. Another major factor for this is that details of the dataset are given before the task is formally defined, which given this is a new task, makes it harder to read than it should be.\n\n# Additional Comments\nLine 158 is referring to the wrong table, this should be Table 1\nLine 1040 (in supp.) vary -> very\nSection D.1 in the appendix is empty, maybe D.2 is meant to be a subheading of D.1?\nFor results tables, it would be good to include a random performance row.\n\n# References\n[a] Doughty, Hazel, Dima Damen, and Walterio Mayol-Cuevas. \"Who's better? who's best? pairwise deep ranking for skill determination.\" Proceedings of the IEEE conference on computer vision and pattern recognition. 2018.\n\n[b] Doughty, Hazel, Walterio Mayol-Cuevas, and Dima Damen. \"The pros and cons: Rank-aware temporal attention for skill determination in long videos.\" Proceedings of the IEEE/CVF conference on computer vision and pattern recognition. 2019.\n\n[c] Pan, Jia-Hui, Jibin Gao, and Wei-Shi Zheng. \"Adaptive action assessment.\" IEEE Transactions on Pattern Analysis and Machine Intelligence 44.12 (2021): 8779-8795.\n\n[d] Zhang, Shao-Jie, et al. \"Adaptive stage-aware assessment skill transfer for skill determination.\" IEEE Transactions on Multimedia (2023)"
      },
      {
        "rating": "6",
        "confidence": "4",
        "summary": "This paper introduces the first large-scale video action differencing dataset, presenting a novel task of identifying differences between videos depicting the same action. The authors compile over 500 video pairs from existing datasets across five categories: Fitness, Ball Sports, Diving, Music, and Surgery. These videos are then assigned to annotators along with 147 distinct descriptions. Annotators must indicate which video (A or B) most closely aligns with each description. For example, given two videos of different actors performing a squat, a description might read \"deeper squat,\" and the annotator would select A or B based on which video demonstrates the deeper squat. To ensure dataset quality, 25% of the initial annotations undergo re-annotation, revealing a very low discrepancy rate. The dataset also includes action localization (pinpointing where the action occurs in the video) and specific key points for each action (e.g., when knees start to bend).\n\nThe authors also develop an agentic model called VidDiff to address the action differencing challenge. VidDiff employs several Large Language Models (LLMs) and Vision Language Models (VLMs) as agents to solve specific aspects of the problem: proposing potential differences based on the action description, localizing frames where such actions might occur, and finally specifying which video (A or B) corresponds to the observed difference. VidDiff outperforms other zero-shot VLMs in this task.\n\nLastly, the authors provide ablation experiments that highlight the challenges presented by their new benchmark.",
        "strengths": "### Originality\n- **A novel task**: This paper introduces the new task of video action differencing with natural language. While related tasks, such as difference captioning, have been explored to provide a coarse comparison between videos, no prior work has tackled video action differencing in the same way—focusing on fine-grained differences described in natural language.\n- **A challenging benchmark**: The proposed benchmark, VidDiffBench, is comprehensive, covering five categories of instructional videos. It has proven to be highly challenging, even for top-performing closed-source vision-language models (VLMs).\n- **An agent-based system**: The paper presents an agent-based system that decomposes the task, achieving better performance than existing VLMs.\n### Clarity\nThe flow of ideas is straightforward, making the paper easy to follow and understand.\n\n### Significance\nThe paper convincingly demonstrates the importance of video action differencing, and the introduction of the new benchmark is likely to inspire further research in this area.",
        "weaknesses": "### Unproven claims\n- In the introduction, the authors claim they will address the challenges of *precise temporal alignment and the need for fine-grained understanding of action dynamics*. However, it remains unclear how they specifically solve the issue of temporal alignment. Could you elaborate on how you solve this issue or point us to the location where it is addressed?\n\n### Benchmark and results\n- Similar datasets are presented in the related work section; however, since this work is primarily a benchmark paper, more comparisons with existing benchmarks would be make the differences clearer (e.g., similar to Table 1 but with other datasets in the first column). Consider adding what is unique about each dataset and how the current dataset differs.\n- As a benchmark paper, we would expect more results from other open-source VLMs (especially those addressing video data such as LLaVA-video) to better understand their limitations and make it easier for other researchers to work with this benchmark. \n\n### Clarity\n- 557 or 656 video pairs? In the abstract, the authors state that the dataset contains *557 video pairs...  4,719 fine-grained action differences* (line 013-014), but on line 260, they mention *656 video pairs, 5,580 annotated differences*. Clarification needed on which is correct. \n- Figure 1: The distinction between the first and second row is unclear, yet the caption claims these represent two different challenges. These two challenges are not discussed elsewhere in the paper and don't seem to be related to the dataset splits. Please clarify this."
      }
    ],
    "rating_avg": 6.5,
    "confidence_avg": 4.25,
    "decision": "Accept (Poster)",
    "meta_review": "The paper introduces a new task and a benchmark for action differencing, to tell the differences between different actors performing the same action. Various baselines (included latest LLM-based baselines) are compared with the proposed approach, VidDiff. \n\nAll reviewers appreciate the novelty of the task and recommend to accept the paper. Most of the discussions are about further clarifications and asking additional ablations and analysis. The author(s) did a great job in providing additional experiment as well as further elaborate on motivation and insights which help to convince all reviewers to support accepting the paper. The area chair reads all reviews and discussions and agrees with the reviewers, thus recommends an acceptance.",
    "author_remarks": "",
    "decision_comment": ""
  },
  {
    "id": "j0sq9r3HFv",
    "title": "Automated Parameter Extraction for Biologically Realistic Neural Networks: An Initial Exploration with Large Language Models",
    "authors": [
      "Gaganpreet Jhajj",
      "Gutierrez Carlos Enrique",
      "Kenji Doya"
    ],
    "abstract": "In computational neuroscience, extracting parameters for constructing biologically realistic neural models is a resource-intensive task that requires continuous updates as new research emerges. This paper explores utilizing large language models (LLMs) in automating parameter extraction from scientific literature for biologically realistic neural models. We utilized open-source LLMs via Ollama to construct KGs, capturing parameters such as neuron morphology, synapse dynamics, and receptor properties. SNNBuilder \\cite{Gutierrez2022}, a framework for building spiking neural network (SNN) models, serves as a key validation example for our framework. However, the methodology we outline here can extend beyond SNNs and could applied to systematic modelling of the brain.By experimenting with different prompting strategies—general extraction, in-context hints, and masked prompting—we evaluated the ability of LLMs to autonomously extract relevant data and organize it within an expert-base or data-driven ontology, as well as to infer missing information for neural model construction. Additionally, we implemented retrieval-augmented generation (RAG) via LangChain to further improve the accuracy of parameter extraction through leveraging external knowledge sources. Analysis of the the generated KGs, demonstrated that LLMs, when guided by targeted prompts, can enhance the data-to-model process, paving the way for more efficient parameter extraction and model construction in computational neuroscience.",
    "keywords": [
      "Large Language Models",
      "Knowledge Graphs",
      "Computational neuroscience",
      "Neural model construction"
    ],
    "venue": "ICLR",
    "year": 2025,
    "pdf_url": "https://openreview.net/pdf?id=j0sq9r3HFv",
    "forum_url": "https://openreview.net/forum?id=j0sq9r3HFv",
    "reviews": [
      {
        "rating": "5",
        "confidence": "4",
        "summary": "This paper investigates the use of large language models (LLMs) to automate parameter extraction from scientific literature for constructing biologically realistic neural models, capturing details like neuron morphology, synapse dynamics, and receptor properties.",
        "strengths": "***1.*** Using LLMs to extract parameters for building SNNs is an interesting topic.",
        "weaknesses": "***1.*** The paper lacks more experimental results and does not provide a detailed analysis of the findings.\n\n***2.*** The paper has an unusual format and does not appear to follow the original template.\n\n***3.*** The phrasing throughout the paper is unclear.\n\n***4.*** The authors need to conduct extensive restructuring and experimental analysis."
      },
      {
        "rating": "3",
        "confidence": "4",
        "summary": "This paper investigates the use of open-source LLMs to automatically extract parameters from scientific literature for building biologically realistic neural models, particularly SNNs. By employing various prompting strategies and retrieval-augmented generation, the authors successfully constructed knowledge graphs that capture essential neural attributes, enhancing the efficiency of model parameterization.",
        "strengths": "1. The intuition is good.",
        "weaknesses": "1. Formatting Issues: The paper's format is problematic, with the main text appearing excessively narrow, which does not adhere to standard formatting guidelines.\n\n2. Insufficient Detail: The paper is notably short, providing an overly simplistic description of the methodologies employed. Additionally, the experimental section is minimal, lacking comprehensive analysis and validation.\n\n3. Project-Oriented: The content resembles a preliminary project report rather than a fully developed research paper. It falls significantly below the standards expected for publication in venues like ICLR, both in terms of depth and rigor."
      },
      {
        "rating": "1",
        "confidence": "3",
        "summary": "This work documents an initial exploration of the use of LLMs (such as GPT4o and LLama3.1) in conjunction with different prompting strategies (such as RAG) to automatize the extraction of computational neuroscience relevant parameters (in particular for SNN) into Knowledge Graphs (KG) from relevant literature.",
        "strengths": "- The project aims to tackle relevant research questions.\n- The use of open source LLMs ensures wider applicability of the method.\n- The conclusions does acknowledge some limitations of the work.",
        "weaknesses": "* 1\\. The main claims/contributions in the abstract are hard to relate to what experiments and results are reported in the paper:\n   - the “accuracy of parameter extraction” was not evaluated?\n   - the “data-to-model” process was not evaluated?\n   - the “SNNBuilder” was not used in any evaluation?\n   - it's unclear how the characterization of the graphs using the  Leiden Modularity relates to any of the claims\n   - => the suitability of the generated graphs for comp. neuroscience model generation/configuration was therefore neither qualitatively nor quantitatively shown anywhere\n* 2\\. Many methodological details are unclear and missing, and therefore it is unclear how to interpret the results, or how to reproduce the results? (see Questions).\n* 3\\. Many formulations are hard to properly understand, as they are presumably imprecise or incorrectly using technical terms, among others:\n   - “... promoting strategies …” => prompting strategies? (line 58-59)\n   - “... one-shot promoting …” => prompting? (line 82-83)\n   - Spelling errors “nda“ and “sparge“?  (line 169-171)\n   - Unclear what is meant by “ parameterization of brain models” here? (line 34)\n   - Unclear what is meant by “agumenting external data” here? (line 44-45)\n   - Unclear what “brain data” is referring to? (line 51)\n   - “Structurally, this loss is a critical limitation in this approach,…” => the loss of structure? (line 202-203)\n* 4\\. The structuring of the paper is confusing and hard to follow:\n   - The “Preliminaries” section mostly describes experiments and methods unrelated to the rest of the paper, and presumably serves as explanation as to why a different approach is introduced later. Possibly something for the Appendix?\n   - Some results are first described in the Discussion, and additional experiments are introduced in the Discussion.\n* 5\\. Figure 3 is mostly unreadable, and readable parts mostly reflect non neuroscience related terms:\n   - E.g. 3.c: “Keep”, “To”, “It”, “Assuming”, “Based”, “Name:”, “Not”, “\\”, “don’t”, …\n* 6\\. The related literatur section is missing methodologically more closely realted papers."
      },
      {
        "rating": "1",
        "confidence": "5",
        "summary": "This paper explores the feasibility of using large language models (LLMs) to automatically extract the parameters required to build biologically realistic neural networks from scientific literature. The authors evaluated the ability of LLMs to extract parameters such as neuronal morphology, synaptic dynamics, and receptor properties through different prompting strategies (general extraction, contextual prompts, and masked prompts), and used retrieval-augmented generation (RAG) technology to improve the extraction accuracy. The main verification case of the study is the SNNBuilder framework, which is used to build spiking neural networks (SNNs). The results show that LLMs can effectively promote data extraction and organization in neural model construction under specific prompts, providing an efficient and automated parameter extraction method.",
        "strengths": "The author focuses on two core areas in the paper:\n1. Using LLM to automatically build and update knowledge graphs from unstructured data\n2. Organizing complex experimental data in neuroscience and converting them into computable models\n\nI think both areas are very interesting and have practical application value.\n\nFor 1, knowledge graphs are difficult to be expanded to a larger scale, updated and deployed in real time due to their high construction and maintenance costs. However, graph databases provide a reliable way to store and reason about complex information. On the one hand, knowledge graphs can benefit from LLM's powerful natural language parsing capabilities, and on the other hand, LLM can benefit from knowledge graphs' reliable information storage methods to alleviate hallucinations.\n\nFor 2, there is a large GAP between current AI research and neuroscience research: researchers in the two fields find it difficult to communicate using the same academic language. For example, a large number of experimental results produced in neuroscience research are difficult to be converted into clear and reusable computational models in the field of machine learning; on the other hand, advanced machine learning models (such as LLM, LVM) lack biological interpretability, and it is difficult to find corresponding experimental evidence in neuroscience. Bridging this GAP in any way will help the two fields communicate and benefit each other.",
        "weaknesses": "As I mentioned in the strengths section, this paper focuses on interesting problems. But I think it is a simple technical report rather than an academic paper. It is not appropriate to publish it at ICLR. (Btw I think this paper uses the iclr template incorrectly, and the margins of the main text are incorrect.) \n\nThe specific areas that can be improved are as follows:\n1. Lack of novelty in the method: The author did not do any further work except proposing three prompts.\n2. Lack of experiments: There are many technical details in designing computational models in the field of neuroscience using LLM. The authors did not conduct/show these experiments.\n\nI will elaborate on these weaknesses in the Question."
      }
    ],
    "rating_avg": 2.5,
    "confidence_avg": 4.0,
    "decision": "Reject",
    "meta_review": "This paper introduces a method to automatically extract biologically realistic neural model parameters from scientific literature using large language models (LLMs). The authors are motivated by the problem that traditional parameter extraction tasks are resource-intensive and require frequent updates. The authors evaluate the ability of LLMs to extract parameters such as neuronal morphology and synaptic dynamics through prompting and retrieval-augmented generation (RAG) techniques, and construct a knowledge graph. Experimental results show that LLMs can effectively extract and organize relevant data under specific prompts, providing a new method for efficient and automated neural model parameterization and construction.\n\nAfter the initial reviewing stage, 4 reviewers rate 1, 1, 3, and 5, respectively. Most reviewers agree that the theme of this paper, which uses LLMs to extract neuronal parameters to build neuroscience models, is innovative, which is the main advantage of this method. However, there are also some criticisms. Reviewers pv7Z and C942 believe that the paper lacks experimental results and detailed analysis, and has problems with format and expression, and is more like a preliminary technical report overall. Reviewers rbRP and XeV2 pointed out that the method lacks novelty, the experimental design is insufficient, and its practical application value has not been verified. In addition, the logic of the paper is not clear enough. I think these criticisms are reasonable. I suggest that the author strengthen experimental verification, improve the quality and biological significance of the knowledge map, improve the structure and expression of the paper, and supplement the detailed analysis of the methods and results to enhance the academic depth and rigor.\n\nSince the score of this paper did not increase after the rebuttal period, I think this paper has not reached the level that can be accepted. Therefore, it was finally decided to reject this paper.",
    "author_remarks": "",
    "decision_comment": ""
  },
  {
    "id": "Y9yQ9qmVrc",
    "title": "scKGOT: Intercellular Signaling Inference with Knowledge Graph Optimal Transport for Single-cell Transcriptomics",
    "authors": [
      "Haihong Yang",
      "Xin Shao",
      "Chengyu Li",
      "Qiang Zhang",
      "Renjun Xu",
      "Xiaohui Fan",
      "Huajun Chen"
    ],
    "abstract": "Single-cell transcriptomics provides detailed genetic insights into cellular heterogeneity within intact organs and the intercellular signaling that underpins tissue homeostasis, development, and disease. To improve the inference of intercellular signaling and pathway activity, we introduce scKGOT, a novel method that employs the Knowledge Graph Optimal Transport (KGOT) algorithm to model and quantify ligand-receptor-signaling networks between sender and receiver cells. scKGOT defines sender and receiver spaces using pairwise distance matrices from gene expression profiles and leverages prior knowledge from the Ligand-Receptor-Pathway Knowledge Graph (LRP-KG) as initial guidance for transport optimization, allowing for dynamic adaptation based on gene expression data. Through comprehensive benchmarking on public single-cell transcriptomic datasets, scKGOT consistently outperforms existing inference methods in terms of precision and interpretability. Furthermore, we demonstrate its practical applicability across multiple case studies, uncovering complex pathway interactions and revealing insights into cellular heterogeneity in diverse biological contexts. By incorporating scKGOT, we provide a robust and generalizable approach for pathway inference in single-cell analyses, advancing the understanding of intercellular communication mechanisms and offering valuable insights into biological processes at the cellular level.",
    "keywords": [
      "Knowledge Graph",
      "Optimal Transport",
      "Cell-cell Communication"
    ],
    "venue": "ICLR",
    "year": 2025,
    "pdf_url": "https://openreview.net/pdf?id=Y9yQ9qmVrc",
    "forum_url": "https://openreview.net/forum?id=Y9yQ9qmVrc",
    "reviews": [
      {
        "rating": "3",
        "confidence": "4",
        "summary": "In this manuscript, the authors present scKGOT, a novel computational method that leverages Knowledge Graph Optimal Transport algorithms to infer cell-cell communication networks from single-cell RNA sequencing data. The method combines prior biological knowledge from a Ligand-Receptor-Pathway Knowledge Graph with dynamic adaptation to gene expression data, demonstrating superior precision and interpretability compared to existing approaches across multiple biological case studies. Specifically, scKGOT operates in three key steps: (1) it utilizes a knowledge graph (LRP-KG) containing known gene-gene interactions and pathway information, (2) it employs a novel algorithm incorporating gene importance metrics and pathway Knowledge Discrepancy to identify activated signaling pathways and confident ligand-receptor pairs, and (3) it reconstructs intercellular signaling networks by combining its predictions with established biological knowledge.",
        "strengths": "The paper demonstrates strong originality through several key aspects. At its core, it presents a novel problem formulation that reframes cell-cell communication as an optimal transport problem integrated with knowledge graphs. This approach moves beyond simple binary predictions to introduce comprehensive pathway-level analysis, supported by an innovative scoring framework that combines gene importance with pathway knowledge discrepancy. It is impressive how the authors merge three distinct approaches, optimal transport theory, knowledge graph embeddings, and single-cell transcriptomics analysis while successfully integrating prior biological knowledge with data-driven insights. The paper brings new perspective to biological pathway analysis through its novel application of optimal transport, effectively bridging machine learning and systems biology while introducing a new framework for analyzing complex cellular interactions.\nThe quality of the work is particularly strong. The paper builds on a solid mathematical foundation, employs a comprehensive evaluation framework, and includes thorough ablation studies that demonstrate robust performance across multiple datasets. \nIn terms of clarity, the paper succeeds in presenting complex ideas in an accessible manner. The organization follows a logical flow of ideas, with a well-structured methodology section and clear presentation of results. The visualizations are particularly effective, employing comprehensive tools and clear performance comparisons.\nIts scientific impact is evident in how it advances our understanding of cell-cell communication, provides new tools for biological pathway analysis, and could potentially impact disease understanding and drug development. The methodological contribution is equally important, creating a new framework for analyzing complex biological systems while demonstrating successful integration of domain knowledge with machine learning. \nThe visualization of pathways using Sankey diagrams is particularly impressive, effectively illustrating the complex predicted interactions across pathways, ligands, and receptors. These diagrams not only help in understanding the flow of signals but also in identifying key interaction hubs and dominant pathways, making complex biological information more accessible and interpretable.",
        "weaknesses": "While scKGOT presents an innovative and mathematically sound approach for analyzing cell-cell communication, the manuscript would significantly benefit from more detailed methodological descriptions. The current presentation leaves several critical implementation questions unanswered. Specifically, the paper should elaborate on the preprocessing pipeline for single-cell transcriptomics data, including how it handles common technical challenges like dropout effects, batch variations, and cell type annotation reliability.\nA crucial aspect that requires more clarity is the construction and quality control of the knowledge graph from multiple pathway databases. While the authors utilize both KEGG and Reactome databases (with over 2 million interaction records), the methodology for resolving redundancies and potentially conflicting information between these databases remains unclear. The integration strategy for different database formats, confidence scores, and annotation systems would be valuable information for readers looking to implement or build upon this approach and can be added as supplementary information.\nMinor Comments:\nWriting: There is redundant information in the introduction section (paragraphs 3 and 4 are repetitive)\nImplementation: Additional details about computational requirements and scalability would be valuable\nMethod availability: Information about code availability and documentation would benefit the community"
      },
      {
        "rating": "3",
        "confidence": "4",
        "summary": "This paper introduces scKGOT (single-cell Knowledge Graph Optimal Transport), a computational method for analyzing cell-to-cell communication in single-cell transcriptomic data using a customized optimal transport algorithm. The method combines a Knowledge Graph Optimal Transport algorithm with prior biological knowledge through a Ligand-Receptor-Pathway Knowledge Graph (LRP-KG) to model and quantify signaling networks between sender and receiver cells. The optimal transport model in scKGOT is used to find the optimal way to \"transport\" signals between sender and receiver cells through signaling pathways. The model incorporates prior knowledge from LRP-KG as initial guidance but allows for dynamic adaptation based on gene expression data. This helps identify both known and potentially novel signaling pathways between cells.",
        "strengths": "The idea of incorporating prior biological knowledge (in this paper the LRP knowledge graph) to discover cell-cell interactions in scRNA-seq data definitely brings another layer of enhanced interpretability to the existing developed model for cell-cell interaction inference and it has novelty. Additionally, the usage of optimal transport in scKGOT  to find the optimal way to \"transport\" signals between sender and receiver cells through signaling pathways is potentially novel.",
        "weaknesses": "1- Literature review in the introduction section needs to be improved: For example, the introduction section is very limited in reviewing previous works that utilized prior biological pathway knowledge to enhance model interpretability in the field of omics data analysis. The authors may need to refer to some previous works such as Spatalk [1], EXPORT [2], VEGA[3] that utilize knowledge graphs to enhance model interpretability when analyzing omics data. \n\n2- Mathematical description of paper needs to be significantly improved: Some mathematical notations are not described at all when describing the proposed model. For example, what are s1 and s2 in equation (2)? or a and b in equation (3)?  also what's the intuition behind inequalities in (3)? Major revision is needed in mathematical description of the model to help readers better understand the model\n\n3- The results need to be better described: \n\n--For example whats the difference between left and right figures in Figure 1 (top row)? What does different colors mean? Also what does (CTDB) version of benchmarking tools mean in Figure 1 (bottom row) mean? Can authors provide more descriptive caption for figure 1?\n\n--In Figure 2C, why authors have focused on \"Eph-Ephrin Signaling\" or \"Signaling By Notch4\" pathways? Do they have any specific characteristics that authors have picked them for visualization? What does each subfigure indicate?\n\n-- In Figure 2D, can authors focus on one specific LRP pair that is previously well studied and describe the model results on that specific LRP pair? Its hard to see what result is novel from scKGOT in Figure 2D.\n\nReferences:\n[1] Shao, X., Li, C., Yang, H. et al. Knowledge-graph-based cell-cell communication inference for spatially resolved transcriptomic data with SpaTalk. Nat Commun 13, 4429 (2022). https://doi.org/10.1038/s41467-022-32111-8\n[2] Biologically Interpretable VAE with Supervision for Transcriptomics Data Under Ordinal Perturbations\nSeyednami Niyakan, Byung-Jun Yoon, Xiaoning Qian, Xihaier Luo bioRxiv doi:https://doi.org/10.1101/2024.03.28.587231\n[3] Seninge, L., Anastopoulos, I., Ding, H. et al. VEGA is an interpretable generative model for inferring biological network activity in single-cell transcriptomics. Nat Commun 12, 5684 (2021). https://doi.org/10.1038/s41467-021-26017-0"
      },
      {
        "rating": "1",
        "confidence": "5",
        "summary": "scKGOT uses optimal transport to solve a multi-relation link prediction problem to predict likely ligand pathway-receptor pathway connections using single cell transcriptomics data.",
        "strengths": "Most cell-cell interaction prediction methods solely predict specific and direct ligand-receptor interactions. This method extends the prediction to pathways on both sides - both in the sender and receiver cells.",
        "weaknesses": "It is very difficult to understand the rationale and evaluation methods used in this paper. On the one hand, the authors make a good point that pathways in sender and receiver cells are related via causal links (i.e. the pathway in the sender cell creates a ligand that get secreted and physically interacts with a receptor on a receiver cell, which causes a pathway to activate within the receiver cell). On the other hand, the main problem I have is that there is no ground truth for this type of relationship presented, just a general comparison of learned networks and prior networks. Further much of the presented biology makes very little sense. For example, in figure 2d, there is a relationship where \"pathways in cancer\" generates a large number of ligands, which bind to a large number of receptors in another \"pathways in cancer\" pathway. This really makes not sense biologically and I cannot understand how it makes sense to predict it as relevant.\n\nAnother example \"By focusing on the largest connected components, we aimed to gain insights into how different cell types communicate within various biological contexts, contributing to a deeper under- standing of processes such as immune modulation, cell signaling, and tissue remodeling.\" - why is the largest connected component interesting here? The networks in Figure 3 almost look like a random assortment of pathways and don't provide any cell context information, which seriously undermines their use as a tool to interpret the results of scKGOT.\n\nMultiple statements in the paper demonstrate poor understanding of the biological application area e.g. \"2,223,641 and 1,651,421 records of ligand-receptor interaction facts respectively, including binding, dephosphorylation and activation, etc.\" - these are mostly not direct ligand-receptor relationships, but rather are relationships within pathways."
      },
      {
        "rating": "3",
        "confidence": "3",
        "summary": "The paper introduces scKGOT, a method that uses Knowledge Graph Optimal Transport (KGOT) to infer intercellular signaling pathways based on single-cell RNA sequencing data. The method aims to improve ligand-receptor signaling network inference by integrating knowledge from a Ligand-Receptor-Pathway Knowledge Graph (LRP-KG). scKGOT dynamically models ligand-receptor relationships between cells and identifies active pathways by optimizing transport based on gene expression profiles and prior pathway information. This approach is benchmarked against existing methods and is claimed to offer better precision and interpretability in cell signaling pathway analysis.",
        "strengths": "1. Innovative Approach: Utilizes optimal transport within a knowledge graph framework, which is novel and relevant to understanding cell-cell communications.\n2. Integration of Pathway Knowledge: Incorporates LRP-KG as a prior, which is a valuable addition to improve biological relevance\n3. Intepretability: The model offers insights at various biological levels (cells, genes, pathways), useful for specific cell-type comparisons and disease studies.",
        "weaknesses": "1. Limited Clarity on Dynamic Adaptability: While the paper claims that Optimal Transport allows scKGOT to dynamically adapt to different biological conditions, it lacks clear explanations and quantitative examples demonstrating how this dynamic adaptability outperforms static models in specific biological scenarios.\n2. Dependence on Complete Pathway Information: scKGOT relies on a comprehensive Ligand-Receptor-Pathway Knowledge Graph (LRP-KG) as a prior, which may not be fully available or accurate for all biological contexts. This dependency raises questions about the model’s robustness and effectiveness in datasets with incomplete or biased pathway annotations.\n3. Complexity and Accessibility: The use of Optimal Transport, combined with pathway knowledge integration, makes scKGOT computationally complex and potentially challenging for researchers without advanced computational expertise. This complexity could limit its accessibility and reproducibility."
      }
    ],
    "rating_avg": 2.5,
    "confidence_avg": 4.0,
    "decision": "Reject",
    "meta_review": "This paper proposes scKGOT, a novel method that employs the KGOT (Knowledge Graph Optimal Transport) to model the ligand-receptor-signaling networks between sender and receiver cells.\nThe reviewers recognize the novelty of the proposed method as well as the importance of incorporating prior knowledge into the analysis.\nHowever, there are significant concerns regarding the literary and technical presentations of the work, unclear rationale/motivation of the work, lacking clarity regarding the methodology and results, and insufficient discussion of relevant literature.",
    "author_remarks": "",
    "decision_comment": ""
  },
  {
    "id": "Mi45HjlVRj",
    "title": "Injecting Learnable Table Features into LLMs",
    "authors": [
      "Liyao Li",
      "Chao Ye",
      "Wentao Ye",
      "Yifei Sun",
      "Zhe Jiang",
      "Haobo Wang",
      "Gang Chen",
      "Junbo Zhao"
    ],
    "abstract": "To migrate the remarkable successes of Large Language Models (LLMs), the community has made numerous efforts to extend them to the table reasoning tasks for the widely deployed tabular data. Despite that, in this work, by showing a probing experiment on our proposed StructQA benchmark, we postulate that even the most advanced LLMs (such as GPTs) may still fall short of coping with tabular data. More specifically, the current scheme often simply relies on serializing the tabular data, together with the meta information, then inputting them through the LLMs. We argue that the loss of structural information is the root of this shortcoming. In this work, we further propose **TAMO** which bears an ideology to treat the **ta**bles **a**s **a**n independent **mo**dality integrated with the text tokens. The resulting model in TAMO is a multimodal framework consisting of a hypergraph neural network as the global table encoder seamlessly integrated with the mainstream LLM. Empirical results on various benchmarking datasets, including HiTab, WikiTQ, WikiSQL, FeTaQA, and StructQA, have demonstrated significant improvements with an average relative gain of **42.65%**.",
    "keywords": [
      "Large language model",
      "Table reasoning",
      "Multi-modal learning"
    ],
    "venue": "ICLR",
    "year": 2025,
    "pdf_url": "https://openreview.net/pdf?id=Mi45HjlVRj",
    "forum_url": "https://openreview.net/forum?id=Mi45HjlVRj",
    "reviews": [
      {
        "rating": "8",
        "confidence": "5",
        "summary": "The paper proposes TAMO, which treats table representation as an independent modality to enhance large language models (LLMs) reasoning capabilities over tables. TAMO leverages a theoretically permutation-invariant hypergraph to capture the table’s structure. In this hypergraph, nodes represent table cells, and hyperedges represent table headers, capturing the hierarchical structure of tables. By iteratively updating the representation of the nodes and hyperedges at each layer, TAMO learns the table’s structure and integrates this representation into the LLM’s hidden layers.\n\nThe authors also introduce a synthetic dataset, StructQA, to evaluate LLM robustness against structural permutations within tables. Experimental results show that TAMO training improves LLM performance on the TableQA task compared to supervised finetuning and demonstrates effectiveness on StructQA.",
        "strengths": "1. The paper introduces TAMO, a novel approach to learning table structures using hypergraphs, which supports both simple and complex table schemas.\n2. The authors provide comprehensive experiments on four table QA datasets and the newly proposed table structure QA dataset. Their demonstrations effectively showcase TAMO’s impact across multiple LLMs (Llama2, TableLlama, and Mistral) and training approaches (SFT, LoRA).",
        "weaknesses": "1. While the hypergraph structure is theoretically permutation-invariant, incorporating hypergraph embeddings into LLMs may introduce potential errors. Additionally, the paper lacks baselines or a detailed discussion on challenges related to embedding hypergraph structures within LLMs.\n2. The paper lacks evaluation/analysis on learned hypergraph representation, such as predicting the table structure from the hypergraph embedding."
      },
      {
        "rating": "5",
        "confidence": "4",
        "summary": "1. This paper introduces a new dataset, StructQA, which demonstrates that most existing LLMs exhibit poor robustness when textualized tables are used as input.\n\n2. The paper proposes treating tables as a distinct modality, modeling tables using Hypergraph, and introducing TaMo,  which employs an encoder to encode Hypergraph aligning with LLMs.\n\n3. Across four mainstream datasets, TaMo achieves significant performance improvements. Further analytical experiments demonstrate that TaMo exhibits stronger robustness compared to using textualized inputs.",
        "strengths": "1. The author addresses a critical issue, as the current use of textual tables as input for LLMs indeed affects their performance in table reasoning tasks.\n\n2. The dataset proposed by the author, StructQA, can effectively assist in evaluating the table comprehension abilities of existing LLMs.\n\n3. The author’s approach, TaMo, significantly enhances table reasoning performance.",
        "weaknesses": "1. Previous work has also proposed encoding tables with graphs to facilitate understanding of table structure [1][2]. Although these methods are based on small-scale models, directly replacing small-scale models with LLMs appears somewhat incremental.\n\n2. The experiments are insufficient, resulting in unreliable performance for the proposed method. For further details, see the Questions section.\n\n[1] https://arxiv.org/pdf/2309.11049\n\n[2] https://arxiv.org/pdf/2209.07692"
      },
      {
        "rating": "5",
        "confidence": "3",
        "summary": "The paper introduces TAMO (Treating Tables as an Independent Modality), a novel framework that treats tabular data as a separate modality integrated with Large Language Models (LLMs). The method embeds a table through the tabular encoder, that imposes a hypergraph structure on cells, and sets of semantically connected cells (rows or columns). The resulting embeddings are then used as soft prompts and can be injected into a wide array of publicly available LLMs. The paper also studies the robustness of other methods on a custom-made dataset.",
        "strengths": "## Originality\nThis approach is innovative, moving beyond the traditional method of serializing tables into text sequences. By using hypergraph neural networks to encode table structures, the paper offers a fresh perspective on table reasoning tasks, an understudied subject in the context of LLMs.\n\n## Quality \nThe authors conduct experiments on multiple benchmark datasets, probably on all the meaningful ones in that area, including HiTab, WikiTQ, WikiSQL, FeTaQA, and the newly proposed StructQA. The empirical results demonstrate strong improvements over existing methods, indicating the effectiveness of TAMO. The inclusion of the StructQA dataset also contributes to the field by providing a benchmark focused on table structure understanding.\n\n## Significance (Positive Aspects)\nAddressing the limitations of LLMs in handling tabular data is a significant contribution. By treating tables as an independent modality, the paper opens up new possibilities for integrating structured data into language models. I think this makes the contribution much stronger.\n\n## Clarity (Positive Aspects)\nThe paper provides a clear motivation for the problem, highlighting the limitations of current methods that serialize tables into text. Figures and diagrams are used to illustrate key concepts, such as the hypergraph representation of tables and the overall framework of TAMO.",
        "weaknesses": "## Repetition and Overstatement\nThe paper tends to repeat the same points, such as the limitations of serializing tables into text and the novelty of treating tables as an independent modality. Cutting down these sections would improve readability.\nPLease reduce repetition by consolidating points about the limitations of existing methods and the benefits of the proposed approach. Also, make sure, you focus on presenting new information in each section to maintain the reader's engagement.\n\n\n## Lack of Comprehensive Comparison:\nThe contributions are occasionally overstated without sufficient evidence. For instance, claiming that the hypergraph approach is superior without comprehensive comparisons to other methods.\nThe paper does not adequately compare the hypergraph-based method with other potential approaches that could model table structures, such as:\n - Using 2D positional embeddings to capture row and column information.\n - Data augmentation techniques to enforce permutation invariance.\n\nWithout these comparisons, it is difficult to conclude that the hypergraph approach is definitively better than other methods. It does in fact beat the naive baselines, but it does not prove to be any better than possible trainable alternatives with similar or lower complexities. It is also not clear from the paper how the TaMo is being trained. Is it trained once on all tasks or for each task separately?\n\n\n## Methodological Complexity:\nThe introduction of the hypergraphs concept may add unnecessary complexity. If the primary goal is to encode rows and columns separately, and then iteratively improve the representations this could potentially be achieved with simpler narrative.\nThe explanation of the hypergraph construction and the multiset functions could be simplified. Providing intuitive explanations alongside mathematical formulations would aid understanding. \nPlease, explain why hypergraphs are used and how they benefit the model.\n\n\n## Experimental Details:\nThe experimental setup lacks details in some areas:\nHyperparameter choices for the hypergraph encoder are not fully explained.\nIt is unclear how the model scales with larger tables or more complex structures.\nIncluding ablation studies to show the impact of different components of the model would strengthen the experimental section.\n\n\n\n# Writing\n\nOne significant weakness of the paper is the frequent misuse of terminology and unclear explanations, which negatively impact its clarity and hinder comprehension.\n\n## Misuse of Terminology\n\nFor example, in **Section 2.3**, the authors state:\n\n> \"...we serialize tabular data into formatted text sequences and obtain the text tokens of tabular data \\(X_{tt} \\in \\mathbb{R}^{L_s \\times d_l}\\) through the LLMs’ embedding layer,\"\n\nwhere they mistakenly use *\"tokens\"* instead of *\"embeddings\"* or *\"representations.\"* This confusion between discrete tokens and continuous vector embeddings can mislead readers about the nature of the data being processed.\n\n## Unclear Explanations\n\nSimilarly, ambiguous statements like:\n\n> \"This means that currently, when LLMs are involved in training, the model tends to focus more on the textual modality input\"\n\nlack context and clarity, making it difficult to understand the authors' intent.\n\n## Grammatical Issues\n\nOvercomplicated sentences and misuse of prepositions also hinder understanding. Also, there are multiple of sentence that are broken:\n> \"TAMO+_SF T is competitive with specialist SOTA methods and the superiority of using hypergraphs to model complex table structure relationships.\"\nor\n> \"This approach incorporates both high-order hierarchical structure and permutation invariance as inductive biases, can perfectly model the complex structural properties in tabular data.\"\n\n## Impact on Readability\nThese issues are not merely grammatical but relate to the precise use of technical language, which is essential for conveying complex ideas effectively. The lack of clear transitions between ideas and incomplete explanations of figures and tables disrupt the narrative flow, making it challenging to follow the authors' arguments.\nOverall, these language and clarity issues significantly detract from the paper's quality and obscure its contributions. I think a careful revision to enhance readability and comprehension is necessary.\n\n# Significance (Negative Aspects)\nIn many real-world applications, tables are embedded within unstructured text, such as in Wikipedia articles or research papers, where they are not readily available as separate, structured inputs. This reliance on pre-structured tables limits the applicability of TAMO, as it assumes that the table data is already parsed and organized in a way that allows for explicit definition of hyperedges in the hypergraph model. The necessity for structured table inputs means that the method may not be practical in scenarios where tables need to be extracted from raw text or where the table structure is ambiguous or inconsistent."
      },
      {
        "rating": "5",
        "confidence": "4",
        "summary": "This paper proposed TAMO (Table as Modality), to inject tabular representations as a separate modality into LLMs to enhance model's robustness towards order permutation and performance on table reasoning tasks. Current table LLMs typically rely on serializing table data while ignoring the relationships between rows and columns and the overall table structure. TAMO uses a hypergraph-enhanced tabular encoder to aggregate structural information by doing average-pooling over cells thus making it robust to order permutations. This structured feature is further injected as a prefix soft prompt, followed by the serialized textual input of the table and the question. The authors also propose StructQA, a new benchmark designed to evaluate table structure understanding and robustness to structural perturbations, such as random row or column shuffling. Results on StructQA and other table QA datasets (HiTab, WikiTQ, etc) demonstrate that TAMO significantly improves performance over existing baselines, achieving a 42.65% average gain. Ablations on different aspects (interpretability, scalability, etc) also provides details for better understanding the proposed approach.",
        "strengths": "S1. The paper introduces a novel framework, TAMO, that treats tables as an independent modality, effectively addressing the limitations of existing LLMs in handling table reasoning tasks.\n\nS2. The paper proposed StructQA, a benchmark for table structure understanding and robustness, which adds value and contributes to future research.\n\nS3. TAMO shows superior performance on both StructQA and previous TableQA benchmarks, indicating the effectiveness of the proposed method.\n\nS4. The paper is well-written and easy to follow.",
        "weaknesses": "W1. Method novelty: The hypergraph idea for tabular representation has been used in \"HyTrel: Hypergraph-enhanced Tabular Data Representation Learning\". Although HyTrel focuses on pretraining a hypergraph-based tabular representation for downstream tasks while TAMO focuses on TableQA/reasoning tasks, the idea seems to be not that novel and the work seems incremental.\n\nW2. Computational complexity: TAMO used an additional module to encode the hypergraph. This requires to encode every cell/row/column in a table. Given that tables often contain millions of rows and thousands of columns, this can lead to significant computational and memory overhead. This paper appears to lack a detailed complexity analysis regarding the overall running time and memory usage of the method.\n\nW3. Limited scenarios: Although the proposed method can indeed better capture the structural tabular information, the context length used in the experiments are relatively short (1024), which limits its practical usage. Also, since all experiments are done on single and short tables, I wonder whether or not this approach can perform well on huge tables (with millions of tokens) or on multiple-tables.\n\nW4. Since this method requires to append embeddings in front of the input, it can only be used with open-sourced models but cannot be used on closed-sourced LMs like GPT-4."
      }
    ],
    "rating_avg": 5.75,
    "confidence_avg": 4.0,
    "decision": "Reject",
    "meta_review": "This paper presents TAMO, the first multimodal LLM for table modality. It also presents StructQA, a benchmark to evaluate the skills of LLMs in understanding structured data. TAMO uses hypergraphs to learn tabular representations which can seamlessly integrate with existing LLMs as soft prompts. Experiments on five datasets show that TAMO yields significant improvements with an average relative gain of 42.65%.\n\n**Strengths:**\n\n* The research problem of injecting structured information into LLM representations of tabular data is clearly motivated.\n* The idea of using hypergraphs to learn structured tabular representations is novel, although this paper can significantly benefit from further discussions on related works using hypergraphs.\n* The proposed TAMO dataset can effectively evaluate LLMs in structured tabular data understanding.\n* The authors provide comprehensive experiments on five datasets, showing that TAMO enhances structured tabular understanding.\n\n**Weaknesses**\n\n* There are a few missing experiments, such as evaluation of learned hypergraph representation and generalization to larger tables, which were addressed using the rebuttal period.\n* Reviewer BCkd also kindly pointed out many grammatical errors and misuse of certain terms, which were fixed in the revision.\n\nThe remaining major issues are:\n\n* Technical writing/presentation (BCkd): “The contributions are occasionally overstated without sufficient evidence”. \n\n* Related to the above point, the current submission lacks discussion and comparison with related works in tabular representations learning (BCkd, aQGU, Vyb4), such as HyTrel (Vyb4). While the authors provide additional discussions in the appendix in the revised version, such critical points should be elaborated and carefully addressed in the main text. The authors shall also consider providing additional experimental results to more directly compare with those related efforts, if possible.\n\nWhile some reviewers are relatively positive with this submission, I believe this paper would benefit from another round of major revision to clear the concerns regarding related works. Therefore, the decision is reject.",
    "author_remarks": "",
    "decision_comment": ""
  },
  {
    "id": "WwmtcGr4lP",
    "title": "GANDALF: Generative AttentioN based Data Augmentation and predictive modeLing Framework for personalized cancer treatment",
    "authors": [
      "Aishwarya Jayagopal",
      "Yanrong Zhang",
      "Robert John Walsh",
      "Tuan Zea Tan",
      "Anand D Jeyasekharan",
      "Vaibhav Rajan"
    ],
    "abstract": "Effective treatment of cancer is a major challenge faced by healthcare providers, due to the highly individualized nature of patient responses to treatment. This is caused by the heterogeneity seen in cancer-causing alterations (mutations) across patient genomes. Limited availability of response data in patients makes it difficult to train personalized treatment recommendation models on mutations from clinical genomic sequencing reports. Prior methods tackle this by utilising larger, labelled pre-clinical laboratory datasets (‘cell lines’), via transfer learning. These methods augment patient data by learning a shared, domain-invariant representation, between the cell line and patient domains, which is then used to train a downstream drug response prediction (DRP) model. This approach augments data in the shared space but fails to model patient-specific characteristics, which have a strong influence on their drug response. We propose a novel generative attention-based data augmentation and predictive modeling framework, GANDALF, to tackle this crucial shortcoming of prior methods. GANDALF not only augments patient genomic data directly, but also accounts for its domain-specific characteristics. GANDALF outperforms state-of-the-art DRP models on publicly available patient datasets and emerges as the front-runner amongst SOTA cancer DRP models.",
    "keywords": [
      "personalized drug response prediction",
      "cancer",
      "genomic data augmentation",
      "diffusion model",
      "pseudolabelling"
    ],
    "venue": "ICLR",
    "year": 2025,
    "pdf_url": "https://openreview.net/pdf?id=WwmtcGr4lP",
    "forum_url": "https://openreview.net/forum?id=WwmtcGr4lP",
    "reviews": [
      {
        "rating": "6",
        "confidence": "3",
        "summary": "The authors propose GANDALF, a framework that leverages attention-based generative models to augment patient genomic data, addressing limitations in data availability and patient-specific characteristics within existing models. GANDALF demonstrates superior performance over state-of-the-art models in predicting drug responses for cancer treatments.",
        "strengths": "- The studied problem is important and practical. \n\n- The idea of incorporating patient-specific characteristics with drug response prediction models is novel. \n\n- The code is provided for reproducibility.",
        "weaknesses": "- The comparative performance analysis in Table 1 focuses on only 5 drugs, which is a small subset of the 56 drugs mentioned in the dataset. The paper does not justify why these specific drugs were chosen or demonstrate that the performance advantages generalize across the broader drug set. This limited evaluation makes it difficult to assess the method's robustness across different drug classes.  The paper needs to demonstrate results across a more diverse set of drug classes and provide statistical tests showing whether performance advantages hold across the full drug set. \n\n- The authors state \"we do drug-specific model tuning in GANDALF, by only augmenting with sample, drug pairs for the drug considered.\" This approach may cause extensive computational burden, as it requires fine-tuning for each new drug, potentially limiting its practical deployment.\n\n- The paper does not address how well GANDALF generalizes to novel drugs in out-of-domain scenarios—a critical consideration given that new drugs are regularly introduced into clinical practice.\n\n- Though the paper deals with the challenge of limited patient data, it doesn't systematically analyze how performance varies with different amounts of training data. There's no exploration of learning curves showing how model performance changes with increasing patient samples, or minimum data requirements for reliable predictions."
      },
      {
        "rating": "6",
        "confidence": "3",
        "summary": "This study presents GANDALF, a generative, semi-supervised framework addressing the challenge of limited labeled data in sparse patient genomic datasets by leveraging cell line data and augmenting patient samples with their clinical information. However, key concerns include the need for clearer model justification, additional technical details, and further clarity in experimental results.",
        "strengths": "- This study introduces GANDALF, a novel generative and semi-supervised data augmentation framework designed to overcome sparse labeled patient genomic data. \n- GANDALF leverages labeled samples from the cell line to augment patient data with critical information.\n- By incorporating attention mechanisms and generating augmented samples, GANDALF significantly enhances classifier performance in predicting patient drug response.",
        "weaknesses": "- The manuscript proposes a model with three distinct encoders, but the reasoning behind selecting this multi-encoder structure lacks clarity and strong justification.\n- Some technical details are missing. \n- Experimental results are not comprehensive."
      },
      {
        "rating": "8",
        "confidence": "3",
        "summary": "Edit: Updated my score to 8 after the authors addressed my most major concerns\n\nThis paper proposes a method, GANDALF, for improving domain transfer for machine learning models, explicitly focusing on the cancer domain where we want to train chemo response models on cell line data, but apply them to patients. GANDALF works by creating artificial examples that are more similar to the target domain that can then be used for model training. The authors find that this data augmentation strategy significantly improves the performance of chemo response models on patients.",
        "strengths": "Strengths:\n- Very well written paper, I really enjoy the step by step breakdown.\n- Very strong empirical improvement over prior art\n- Novel combination of techniques, incorporating a wide variety of tricks to improve performance\n- Very significant topic, as domain adaptation is critical for many important problems where in-domain data is hard to obtain",
        "weaknesses": "Major:\n- This paper is sorta a mix of two contributions, a very good “pseudo-labeler” MTL model and the data augmentation. However, it’s unclear which of those two contributions is important as it’s missing a simple, but important baseline: simply using the “pseudo-labeler” MTL model as a final classifier.\n\n- I don't see any discussion of hyperparmeters for both models and baselines. How were they selected and how did you ensure that equal hyperparameter search time was dedicated to your model and baselines?\n\n- It’s very hard to compare the ablation results in table 2 to table 1. Can you create an alternative table 2 that is side-by-side comparable with table 1?\n\nMinor:\n- There are some typos (for example the first row in table 2)\n- I think some of the analysis in 3.4 is incorrect. For example, looking at only the top 2 principal components in high dimensional data to compare variance does not seem correct as you might be ignoring a ton of the signal. However, section 3.4 doesn’t matter for the central hypothesis of the paper so it’s not that important. I would actually just remove section 3.4"
      },
      {
        "rating": "6",
        "confidence": "4",
        "summary": "Authors proposed GANDALF a method for data augmentation that takes labeled cell line and patients mutation data as input and makes drug response prediction via generating patient-driven samples in a 5 step process:\n- pretraining diffusion models on cell lines and patients\n- generating augmented samples \n- training a multitask predictor using labeled cell lines and patients \n- making predictions for augmented samples and selecting confident ones \n- training a final predictor on confident augmented samples and patients\n\nGANDALF was compared with state-of-the-art of drug response prediction across 5 chemotherapy drugs in terms of AUROC and AUPR and was able to outperform the majority of them.",
        "strengths": "- The introduction of biological aspects was gentle and informative enough for those not familiar with the motivating application of the work. \n- While the separate components of GANDALF are not novel per se, components are linked together in a novel way for data augmentation - based on patient data for precision oncology. \n- The experimental results show improvements compared to baselines across multiple drugs",
        "weaknesses": "- The input patient data is itself coming from 3 different resources i.e, P(Xp1) != P(Xp2)!=P(Xp3) similarly, the cell line data is also coming from two resources (input from CCLE, output from GDSC) but there is no indication of that in neither the assumptions nor the setup or the method. What makes GANDALF capable of handling shifts like that?\n\n- Although authors have provided the source code, critical information is missing with respect to reproducibility of this work. For example, it is unclear if the reported numbers are from how many independent runs or hyper-parameters and the procedure for tuning them are not reported in the paper for any of the components e.g., DDPA, transformers, VAE, MTL, etc. \n\n- Citations of the utilized data are inaccurate and incomplete. For example, for CCLE and GDSC the seminal work like \n“Barretina et al., The Cancer Cell Line Encyclopedia enables predictive modelling of anticancer drug sensitivity 2012” or “Iorio et al. A Landscape of Pharmacogenomic Interactions in Cancer 2016” are not cited. Moreover, Although authors claimed that they’ve used GDSCv2, the citation is for 2012 which is more correlated with GDSCv1 timeline. Is this a citation error or GDSCv1 was used? \n\n- Authors used genomic data from CCLE and response data from GDSC, there is no justification for why the response profiles of these datasets are interchangeable. How many cell lines were in common between CCLE and GDSC, was the drug screening assay comparable between the two? this is important because GDSCv1 used Syto60 assay while CCLE and GDSCv2 used CellTiter-Glo (going back to the previous point on which GDSC was used).  \n\n- There are parts of the paper that is challenging to follow for example, “We had a total of 156441 train, 17371 validation and 21589 test cell line, drug pairs. We also had 488/488/487 train, 53/54/56 validation and 115/114/113 test patient, drug pairs over the 3 folds.” Is unclear to me. Is this a reference to different patient data sources? \n\n- W/o MTL in ablation seems misleading as it only removes the cell line part but the proper way of doing this is to replace it with a drug specific single task model train on both cell lines and patients. \n\n- Another missing ablation is w/o diffusion what happens if you apply VAE directly to the input data?\n\n- GANDALF learning curve is missing in Figure 7"
      },
      {
        "rating": "8",
        "confidence": "4",
        "summary": "The study shows an AI4Science application. It majorly focuses on using related cell line data and patients' clinical data to do drug and dosage response. The major contributions of this paper are: 1. proposing a composite framework (diffusion $+$ transformer) architecture to use cell line data to enrich limited patient clinical data. 2. the proposed framework also include a prediction module for the drug response prediction task and it beats SOTA models on the task.",
        "strengths": "- The study introduces a complete framework to do the DRP task. The framework uses a smart way to use the cell-line data to augment the patient data in order to improve model's performance on the target task.\n- I like the idea that projects the patient embedding and cell-line data embedding data on the shared latent space and uses the cross attention strategy to keep the shared information. \n- The step 3 is also a smart move that addresss the limited drug issue in patients' clinical dataset.\n- I can see from Table 1 that the proposed framework achieves general improvement on the datasets compared with baselines. \n- The authors provided comprehensive ablation studies. Table 2 demonstrates the importance of each component of the framework.",
        "weaknesses": "- In figure 4, the aim is to show distribution similarity between generated patient data. But the PCA visualization is a linear projection method, and I cannot tell any difference between the distributions. Can you use some non-linear methods UMAP/t-SNE to show the distributions, and mark the labels using different colors? It would be better to see the distribution characteristics and differences.\n- Why you put related works at last? It is hard for a reader not in this field to follow the work. It would be better put the section right after the introduction. And unsupervised models has been introduced well in the paper, can you elaborate a little bit more on the brief definitions or examples of inductive and transductive approaches in the context of drug response prediction, and how their method differs from yours.\n- One key step is data augmentation. The author does provide the sample size for train/test/val in the appendix, but I didn't find the details about the sample size, i.e. how many psedo-patient data were added before training the final model. I think it is a key information for your experiments. And, I like your experiments in the appendix A.2, but the quantity there confused me. It would be better to provide the sample size directly rather than the thresholds."
      }
    ],
    "rating_avg": 6.8,
    "confidence_avg": 3.4,
    "decision": "Accept (Poster)",
    "meta_review": "This work proposes a new semi-supervised architecture to perform drug response predictions at the patient lavel. They combine attention-based generative models for data augmentation with meta-learning to propose GANDALF, showing improved performance compared to state-of-the-art methods.\n\nThe authors have provided additional experiments during the discussion phase, which have addressed the concerns on missing ablations and comparisons. All reviewers now have a positive assessment of the paper.",
    "author_remarks": "",
    "decision_comment": ""
  },
  {
    "id": "u1EPPYkbgA",
    "title": "GPTBIAS: A Comprehensive Framework for Evaluating Bias in Large Language Models",
    "authors": [
      "Jiaxu Zhao",
      "Meng Fang",
      "Shirui Pan",
      "Wenpeng Yin",
      "Mykola Pechenizkiy"
    ],
    "abstract": "Large language models (LLMs) have seen widespread adoption across various applications, both in their original form and fine-tuned adaptations. However, a major concern with LLMs is their potential to generate biased content. Existing evaluation methods often have different constraints, such as needing access to the model's intermediate outputs. To address these issues, we propose GPTBIAS, a novel bias evaluation framework that leverages the capabilities of advanced LLMs like GPT-4 to assess bias in other models across nine bias types. Our framework introduces Bias Attack Instructions, specifically designed to evaluate model bias across multiple dimensions. GPTBIAS provides not only a quantitative bias score but also detailed information on bias types, affected demographics, underlying reasons for biases, and suggestions for improvement. Through extensive experiments on popular LLMs, we demonstrate the effectiveness and usability of our bias evaluation framework. Our results reveal nuanced insights into the biases present in different models and highlight the importance of comprehensive bias assessment in the development and deployment of LLMs.",
    "keywords": [
      "Large Language Model",
      "Bias"
    ],
    "venue": "ICLR",
    "year": 2025,
    "pdf_url": "https://openreview.net/pdf?id=u1EPPYkbgA",
    "forum_url": "https://openreview.net/forum?id=u1EPPYkbgA",
    "reviews": [
      {
        "rating": "3",
        "confidence": "4",
        "summary": "The paper introduces a bias evaluation framework that leverages advanced LLMs, such as GPT-4, to assess bias across nine distinct bias types. The framework, GPTBIAS, addresses the limitations of existing evaluation methods by providing quantitative bias scores and detailed insights into the kinds of biases, affected demographics, and suggestions for mitigation. The study emphasizes the importance of comprehensive bias assessment in the deployment of LLMs.",
        "strengths": "The research is well-structured, with a robust methodology that includes comprehensive experiments on various LLMs. The use of Bias Attack Instructions tailored for evaluating biases enhances the quality of the findings, providing nuanced insights into the biases present in different models.\n\nThe paper is written, with a logical flow that guides the reader through the framework's development, implementation, and results. Definitions of bias types and detailed explanations of the evaluation process contribute to its accessibility to a broad audience.",
        "weaknesses": "* The paper primarily focuses on English language models, which may limit the applicability of the GPTBIAS framework to non-English contexts. To improve, the authors could expand their experiments to include models trained on diverse languages and dialects, assessing the framework's effectiveness in detecting biases across different linguistic and cultural contexts.\n* While the framework shows promise, it relies on patterns learned by the underlying LLM, which may not capture subtle or context-specific biases effectively. Both the proposed eval benchmark and evaluation rely on LLMs, and in the paper GPT4 specifically. This leads to biased evaluation results towards GPT4 models. \n* There are multiple recent bias evaluation works, e.g. [1] which suggests a combination of multiple evaluation benchmarks may work better together rather than using a single benchmark for bias evaluation. It would be great if the authors could comment on the work and compare with the proposed framework.\n*  It would be great if the authors could include more discussions and experiments about the mitigation of identified bias. \n\n[1] Esiobu, David, et al. \"ROBBIE: Robust Bias Evaluation of Large Generative Language Models.\" The 2023 Conference on Empirical Methods in Natural Language Processing."
      },
      {
        "rating": "5",
        "confidence": "3",
        "summary": "The paper presents GPTBIAS, a framework developed to comprehensively assess biases in large language models (LLMs) by leveraging GPT-4 as a meta-evaluator. The framework generates \"Bias Attack Instructions\" to probe responses from various LLMs across nine bias categories, including gender, race, and socioeconomic status, and computes an intersectional bias score that highlights overlapping biases affecting multiple demographic groups. GPTBIAS provides quantitative bias scores and qualitative insights, distinguishing it from traditional methods like StereoSet and CrowS-Pairs. Results from experiments on models such as BLOOM, LLaMA, and GPT-3.5 demonstrate GPTBIAS's ability to capture nuanced biases, which are often missed by existing evaluation metrics.",
        "strengths": "- GPTBIAS introduces an innovative approach by employing GPT-4 as an evaluator to conduct bias analysis on other LLMs. This design broadens the scope of bias evaluation, providing a unique angle for analyzing how biases interact across demographic dimensions. \n\n- The paper demonstrates methodological rigor through detailed steps in bias instruction generation, model response collection, and response analysis. \n\n- The overall structure of the framework is clearly described. \n\n- The actionable feedback generated by GPTBIAS is a valuable asset for developers and researchers aiming to refine AI models.",
        "weaknesses": "- The framework relies exclusively on GPT-4 as the evaluator, raising concerns regarding accessibility and potential bias propagation from GPT-4 itself. Teams without access to GPT-4 due to cost or licensing restrictions may find it challenging to implement GPTBIAS effectively. Exploring alternative evaluators, such as GPT-3.5 or open-source LLMs, could increase GPTBIAS’s accessibility and applicability. Testing and discussing whether these alternatives provide similar evaluative accuracy could be a valuable addition. \n\n- The paper introduces intersectional bias scores but lacks concrete guidance on how developers can practically use these scores to improve LLMs. Without examples or a case study, the interpretability and actionable value of these scores remain unclear. \n\n- The current framework applies only to English, limiting its relevance for models trained in or applied to other languages. Biases manifest differently across languages, meaning the framework may overlook key insights when assessing non-English models. The paper would benefit from discussing plans or modifications necessary to extend GPTBIAS to multilingual models, such as adapting bias instructions for cultural and linguistic variations. Even hypothetical steps toward multilingual adaptation would broaden the framework's appeal and utility.\n\n- Given the detailed structure of the bias instructions and reliance on GPT-4, GPTBIAS appears computationally intensive, especially for large-scale models like BLOOM and LLaMA. This may make it impractical for frequent evaluations or use by teams with limited computational resources. Proposing a streamlined or resource-efficient version of GPTBIAS, perhaps by limiting the scope of bias types or reducing instruction complexity, would make the framework more accessible. A comparison between the full framework and a lighter version could illustrate how well each captures biases."
      },
      {
        "rating": "3",
        "confidence": "4",
        "summary": "The paper presents a novel framework, GPTBIAS, designed to evaluate biases in large language models. Unlike traditional bias evaluation methods that require access to a model's intermediate outputs, GPTBIAS uses advanced LLMs like GPT-4 to evaluate bias without model access constraints. This framework introduces \"Bias Attack Instructions,\" which are crafted prompts targeting nine specific bias types, including gender, race, and socioeconomic status, to evaluate model responses comprehensively. GPTBIAS not only generates a quantitative bias score but also provides detailed insights into bias types, affected demographics, reasons behind biases, and suggestions for reducing these biases. Through experiments on popular LLMs, the authors demonstrate that GPTBIAS effectively captures both overt and subtle biases, underscoring the importance of thorough bias evaluation in LLM development and deployment​",
        "strengths": "1. The bias of the large language models is important and interesting.\n\n2. The authors propose a framework that evaluates nine different biases.",
        "weaknesses": "1. The paper is not well-written. It is hard to read and logical problems are many.  For example, in lines 13-15, since \"different constraints\" are mentioned, the author should list more than just one constraint. In line 68, the phrase \"that can a wide range of bias types\" is missing a verb. In lines 246-247, \"the corresponding language model\" should be revised to \"the response of the corresponding language model.\" Please ask for some writing help before submission.\n\n2. The paper claims that GPTBIAS offers more than just a bias score by providing additional insights, including bias types, affected demographics, underlying reasons for biases, and suggestions for improvement. However, the experiments focus primarily on the bias score and bias types (Tables 3, 4, and 5), and do not include experiments demonstrating the value or impact of the other additional information. It would be beneficial for the authors to present a case study that analyzes how these insights aid in evaluating bias or what important conclusions can be drawn from them.\n\n3. The comparison between GPTBIAS and baseline metrics, StereoSet and CrowS-Pairs, is unclear, as shown in Table 3. Since GPTBIAS scores range from 0 to 1, while baseline scores are typically greater than 1, as shown in Table 1, the differing evaluation scales make it challenging to interpret the performance gap between the methods. To clarify this comparison, the authors could either normalize the comparison by evaluating GPTBIAS using the same metric as the baselines or propose a new, unified metric suitable for all these methods.\"\n\n4. Lines 370-372 suggest that baseline methods perform worse because current LLMs can avoid generating biased predictions on their test datasets. This raises an important question: is the new test dataset used in GPTBIAS the primary factor behind its apparent superiority? To address this, an ablation study comparing the evaluation frameworks on the same test dataset would be valuable.\n\n5. The target LLMs used in the experiments—LLaMA, OPT, BLOOM, and GPT-3—seem somewhat outdated. The results would be more \ncompelling if the experiments were conducted on more recent models, such as LLaMA-3 and GPT-4. It would be helpful if the authors could clarify whether these recent models are not suitable for GPTBIAS. If GPTBIAS can be applied to newer models, a discussion on their performance under GPTBIAS would be highly valuable.\n\n6. The analysis of intersectional bias (Section 5.3) and various bias types (Section 5.4) is too brief. The authors provide only a brief description of the data in Table 4 and Table 5, without drawing further conclusions from these results. To strengthen the discussion, the authors could elaborate on how intersectional bias and the statistics for different types of bias contribute to the overall analysis of model bias or inform strategies for mitigating bias in models."
      },
      {
        "rating": "5",
        "confidence": "4",
        "summary": "This paper proposes GPTBIAS to flexibly evaluate different types of biases in Large Language Models. The framework is a 4-step process: instruction generation, LLM response collection, bias evaluation, and score calculation. Compared to previous evaluation measures, GPTBIAS does not require labels, sample pairs, or access to weights.",
        "strengths": "- The paper is well-written and easy to follow.\n- The motivation and the approach is clear.\n- The method has the greatest flexibility in terms of evaluation requirements.",
        "weaknesses": "- My main concern is the lack of technical novelty in this approach. The framework largely relies on the evaluation of GPT-4 (ChatGPT), which is already commonly done in practice. Although I appreciate the formalism here, I think the contribution to the LLM community is limited.\n- While the authors provided an extensive list of evaluation tables, that itself doesn't prove the reliability of GPTBIAS. Due to the heterogeneous nature of StereoSet and CrowS-Pairs, it is difficult to directly compare them with it. That being said, it would also be helpful to see some ablation studies on the components of the evaluator, and demonstrate how that impacts evaluation.\n- If I understand correctly, GPTBIAS relies on bias attack instructions that are generated by an LLM. If so, I am uncertain about the stability of this method. It would be interesting to see how the evaluation score varies for different evaluation runs. That is, how stable is the evaluation when run multiple times?\n- (minor) it would be nice to have citations in brackets - use \\citep"
      }
    ],
    "rating_avg": 4.0,
    "confidence_avg": 3.75,
    "decision": "N/A",
    "meta_review": "",
    "author_remarks": "",
    "decision_comment": ""
  },
  {
    "id": "GdXI5zCoAt",
    "title": "RaSA: Rank-Sharing Low-Rank Adaptation",
    "authors": [
      "Zhiwei He",
      "Zhaopeng Tu",
      "Xing Wang",
      "Xingyu Chen",
      "Zhijie Wang",
      "Jiahao Xu",
      "Tian Liang",
      "Wenxiang Jiao",
      "Zhuosheng Zhang",
      "Rui Wang"
    ],
    "abstract": "Low-rank adaptation (LoRA) has been prominently employed for parameter-efficient fine-tuning of large language models (LLMs). However, the limited expressive capacity of LoRA, stemming from the low-rank constraint, has been recognized as a bottleneck, particularly in rigorous tasks like code generation and mathematical reasoning. To address this limitation, we introduce Rank-Sharing Low-Rank Adaptation (RaSA), an innovative extension that enhances the expressive capacity of LoRA by leveraging partial rank sharing across layers. By forming a shared rank pool and applying layer-specific weighting, RaSA effectively increases the number of ranks without augmenting parameter overhead. Our theoretically grounded and empirically validated approach demonstrates that RaSA not only maintains the core advantages of LoRA but also significantly boosts performance in challenging code and math tasks. Code, data and scripts are available at: https://github.com/zwhe99/RaSA.",
    "keywords": [
      "parameter-efficient fine-tuning",
      "large language model",
      "low-rank adaptation"
    ],
    "venue": "ICLR",
    "year": 2025,
    "pdf_url": "https://openreview.net/pdf?id=GdXI5zCoAt",
    "forum_url": "https://openreview.net/forum?id=GdXI5zCoAt",
    "reviews": [
      {
        "rating": "6",
        "confidence": "3",
        "summary": "The paper introduces an enhancement to existing fine-tuning methods for large language models (LLMs). It builds on Low-rank adaptation (LoRA), commonly used for efficient fine-tuning, but limited by its low-rank constraint in handling complex tasks like code generation and mathematical reasoning. To address this, the authors propose Rank-Sharing Low-Rank Adaptation (RaSA), a novel method that increases expressive capacity by sharing ranks across layers, allowing for more flexibility without adding parameter overhead. RaSA thus extends LoRA’s efficiency, achieving substantial performance gains in rigorous tasks. Code and data resources accompany the work.",
        "strengths": "1. Technical Soundness: RaSA is a technically robust extension of LoRA, overcoming its expressive limitations through partial rank sharing. Theoretical and empirical results confirm its lower reconstruction error and improved task performance.\n\n2. Paper Presentation: The paper is clearly organized and easy to follow, with well-explained motivations, methods, and contributions, making RaSA's innovations accessible and engaging.\n\n3. Theoretical Analysis: Theoretical bounds and empirical evidence validate RaSA’s improved capacity over LoRA, providing a solid foundation for its enhanced performance in high-rank tasks.",
        "weaknesses": "1. Lack of Baseline Comparisons:\nThe paper lacks a comprehensive comparison with other LoRA variations, such as EM-LoRA, AdaLoRA, and Orthonormal LoRA. Without these baselines, it’s difficult to fully assess the advantages of RaSA, as the performance improvements over the original LoRA may not necessarily hold when compared with these alternative methods.\n\n2. Efficiency Concerns:\nThe proposed method is considerably less efficient than the original LoRA, with a noticeable increase in computational time (at least 1.4 hours). Despite this added overhead, the performance gains are minimal, with PASS@1 improvements generally below 2%. This limited payoff questions the practical viability of RaSA, especially for real-world applications where computational efficiency is crucial."
      },
      {
        "rating": "6",
        "confidence": "3",
        "summary": "This paper highlights that the low-rank constraint limits the expressive capacity of LoRA, and that LoRA’s parameters are not fully utilized. To address this, the authors propose RaSA, an approach enabling partial rank sharing across layers with minimal additional parameters. Theoretical and empirical analyses demonstrate that RaSA achieves a minimum reconstruction error bounded by LoRA, and can be easily optimized. Experiments show that RaSA achieves great performance in complex math and code tasks.",
        "strengths": "- RaSA can efficiently increase the rank of the original LoRA, and compared to directly expanding the rank, RaSA achieves this with almost no increase in parameter count.\n- The authors validate the better expressive capacity of RaSA through detailed reconstruction error analysis, empirical analysis shows that RaSA can achieve much lower reconstruction error and reveal the relationship between rank and the hyperparameter k.\n- Experiments on code and math tasks show that RaSA achieves much better performance with only a 10% increase in time, highlighting RaSA's promising advantages.",
        "weaknesses": "- As written in Lines 30-31, LoRA still lags behind full fine-tuning, particularly on complex tasks, however, the authors only compare RaSA with existing peft methods, not including full fine-tuning."
      },
      {
        "rating": "8",
        "confidence": "4",
        "summary": "Low-rank adaptation (LoRA) is limited in expression ability due to low rank constraints. This paper propose Rank-Sharing Low-Rank Adaption (RaSA) to enhance the expressive capacity of LoRA by leveraging partial rank sharing across layers. Specifically, RaSA shares $k$ ranks across all layers and assign $r-k$ for layer-specific parameters. After that, RaSA greatly increase the effective rank of the parameter update by $(L-1)\\times k$ without introducing additional parameters. The experimental results on multiple datasets with different model architectures validate the effectiveness of the proposed approach.",
        "strengths": "1. The problem studied in this paper is valuable. \n2. The proposed RaSA approach is interesting and effective.\n3. The paper is well organization. \n4. The theoretical and empirical analysis are insightful. \n5. The experiment is sufficient, including the study of Reconstruction error, the study of $k$, the performance comparison of parameters and time, the study of forgetable.",
        "weaknesses": "A great paper with almost no weaknesses. A small suggestion, the distinction between the different methods in Figures 4, 5, and 7 is only based on different color (red and blue), as printing on paper cannot distinguish them."
      },
      {
        "rating": "8",
        "confidence": "4",
        "summary": "The paper presents a method to improve the expressivity of LoRA, while keeping the same number of parameters. This is by sharing a portion of each learnable adaptor across all layers.",
        "strengths": "* The authors tackle an important and meaningful topic that would be of interest to the community. PEFT is gaining more and more attention as the size of language models continues to grow.\n* The description of the proposed method is clear and concise. Writing is easy to understand and follow.\n* The method is simple, effective, and easy to implement.",
        "weaknesses": "* It seems that unlike vanilla LoRA, that acts independently on each layer, in RaSA there is an underlying assumption that all shared layers have the same dimension. If so, it is worth mentioning it explicitly in the paper.\n* There are LoRA extensions that allow allocating a different rank for each layer, according to its importance (for example PRILoRA and others). It seems that in RaSA the rank should be similar across layers. If so, it is worth mentioning this fact and citing the relevant papers that do allow different rank allocation.\n* There are no comparisons in Table 1 to other LoRA extensions (AdaLoRA, PRILoRA), which may be of importance to the reader. Furthermore, it is not clear why the VeRA method is compared against, when its number of parameters is x13 less."
      }
    ],
    "rating_avg": 7.0,
    "confidence_avg": 3.5,
    "decision": "Accept (Poster)",
    "meta_review": "This submission highlights that the low-rank constraint in LoRA limits its expressive capacity, resulting in underutilization of LoRA's parameters. To address this issue, the authors propose RaSA, a method that enables partial rank sharing across layers with minimal additional parameters. Both theoretical and empirical analyses demonstrate that RaSA achieves a reconstruction error bounded by LoRA, while remaining easy to optimize. Experimental results show that RaSA delivers strong performance on complex math and code tasks.\n\nAfter the rebuttal, all reviews recommended acceptance, including two clear acceptances. The area chair concurs, recognizing that this submission makes a significant contribution to the PEFT field, and recommends acceptance.",
    "author_remarks": "",
    "decision_comment": ""
  },
  {
    "id": "SKl8zzi4Mn",
    "title": "Optimization Insights into Deep Diagonal Linear Networks",
    "authors": [
      "Hippolyte Labarrière",
      "Cesare Molinari",
      "Lorenzo Rosasco",
      "Cristian Jesus Vega Cereño",
      "Silvia Villa"
    ],
    "abstract": "Overparameterized models trained with (stochastic) gradient descent are ubiquitous in modern machine learning. These large models achieve unprecedented performance on test data, but their theoretical understanding is still limited. In this paper, we take a step towards filling this gap by adopting an optimization perspective. More precisely, we study the implicit regularization properties of the gradient flow “algorithm” for estimating the parameters of a deep diagonal neural network. Our main contribution is showing that this gradient flow induces a mirror flow dynamic on the model, meaning that it is biased towards a specific solution of the problem depending on the initialization of the network. Along the way, we prove several properties of the trajectory.",
    "keywords": [
      "Diagonal Linear Network",
      "Overparameterization",
      "Implicit Bias",
      "Mirror Flow"
    ],
    "venue": "ICLR",
    "year": 2025,
    "pdf_url": "https://openreview.net/pdf?id=SKl8zzi4Mn",
    "forum_url": "https://openreview.net/forum?id=SKl8zzi4Mn",
    "reviews": [
      {
        "rating": "3",
        "confidence": "4",
        "summary": "The paper investigates the optimization dynamics of deep diagonal linear networks. Diagonal linear networks have garnered significant theoretical interest because they are easier to analyze and reflect many empirical behaviors induced by various hyper-parameters while training deep networks. The paper aims to diagonal networks to understand the impact of depth.",
        "strengths": "- The paper introduces a mild technical assumption $\\mathcal{A}$ on the initialization which holds almost surely for a random initialization. Under this assumption, the gradient flow for the parameterization of deep diagonal network can be rewritten as mirror flow with a *convex* potential on the linear predictor $\\theta$, which is an interesting technical observation. \n- Under the same assumption, the linear convergence for any loss function $L$ which satisfies $PL$ condition in $\\theta$ is established.",
        "weaknesses": "- The major weakness is the mirror potential is not explicitly defined - even if it not explicitly defined the limiting behavior in the case of large depth or small initialization are not discussed or analyzed which is a major drawback. \n- The implicit bias of optimization benefits/drawbacks of the depth is not discussed and this weakens the motivation for studying the deep diagonal linear networks."
      },
      {
        "rating": "3",
        "confidence": "5",
        "summary": "This paper shows gradient flow on diagonal linear networks induces a mirror flow on the input-output model, and also show that gradient flow converges exponentially given certain initializations.",
        "strengths": "The presentation in this paper is good, derivations are clear, and theoretical results are well explained.",
        "weaknesses": "This paper lacks novelty in the following ways:\n\n1. Theorem 1, showing that GF on $L$-layer diagonal linear networks induces a mirror flow, as authors have acknowledged, is an application of Li et. al., 2022. So the contribution of this theorem is rather weak.\n\n2. Theorem 2 is not new. Min et. al., 2023 (See their Section 4.2) have shown the exponential convergence of GF under the same condition as described in equation $(\\mathcal{A})$ with a better lower bound on the rate.\n\n**References**:\n\nZ Li, et. al., Implicit Bias of Gradient Descent on Reparametrized Models: On Equivalence to Mirror Descent, NeurIPS, 2022\n\nH Min, et. al., On the Convergence of Gradient Flow on Multi-layer Linear Models, ICML, 2023"
      },
      {
        "rating": "3",
        "confidence": "2",
        "summary": "This work examines deep diagonal linear networks and demonstrates that gradient flow induces a mirror flow dynamic within the model. Under a mild initialization assumption, applying gradient flow to the layers generates a parameter trajectory that satisfies a mirror flow. The convergence properties related to the original optimization problem are highlighted.",
        "strengths": "The study brings a relatively fresh perspective of implicit bias.",
        "weaknesses": "-"
      },
      {
        "rating": "3",
        "confidence": "5",
        "summary": "This paper attempts to build the implicit regularization of gradient flow (GF) for the deep diagonal linear networks. In particular, the authors show that the GF dynamics induces a certain kind of mirror flow dynamics without an explicit form of the corresponding entropy function. In addition, they also reveal the convergence property of the GF dynamics and establish how the convergence rate is affected by the initialization.",
        "strengths": "In general, this paper is well organized, e.g., the authors clearly demonstrate their motivation and contribution. They also clearly develop their notations, definitions, and theorems to support their claims. These efforts make the understanding of this paper fairly straightforward. In addition,  the characterization of certain properties of the learning dynamics of deep diagonal linear networks might also be interesting, e.g., the second point of Proposition 1.",
        "weaknesses": "Unfortunately, both the technical and theoretical contributions of this paper are rather limited, which I will discuss as follows. \n\n1. The ultimate goal of this paper is to reveal the implicit regularization effect of GF for deep diagonal linear networks. However, the explicit form of the corresponding entropy function for the induced mirror flow dynamics is completely absent. There is even no suggestion about possible properties that the entropy function should have. \n\n    In addition, the derivation of the mirror flow form is a direct application of results in Li et al., 2022, and the first point of Proposition 1 can be a direct application of the Euler’s theorem for homogeneous function. Thus I think the technical contributions of this paper are rather limited. \n2. As a comparison, Yun et al., 2021 already explicitly characterized the implicit bias of deep diagonal linear networks by using the tensor network formulation developed in their paper. \n\n   Specifically, they established the optimization problem with an explicit form of the entropy function that the GF dynamics of deep diagonal linear networks (note that they did not require the parameterization $u^{\\odot L} - v^{\\odot L}$) aims to solve. They also established the convergence of the dynamics. The only possible weakness of their result is the additional requirement of the initialization, which the authors in this paper are able to relax at the cost of the characterization for explicit form of entropy function. But I cannot view such relaxation as a significant theoretical contribution that is sufficient for this paper to be published in its current version. \n\n**Reference**\n\nYun et al., 2022. A Unifying View on Implicit Bias in Training Linear Neural Networks."
      }
    ],
    "rating_avg": 3.0,
    "confidence_avg": 4.0,
    "decision": "N/A",
    "meta_review": "",
    "author_remarks": "",
    "decision_comment": ""
  },
  {
    "id": "NcKUcd4EkA",
    "title": "Harnessing Query Heterogeneity for Cost-Effective Proactive Caching in LLM Inference",
    "authors": [
      "Hantao Yang",
      "Hong Xie",
      "Xutong Liu",
      "Defu Lian",
      "Enhong Chen"
    ],
    "abstract": "As Large Language Models (LLMs) significantly enhance the capabilities of AI systems, the increasing volume of query processing requests presents challenges for cost-effective inference, particularly due to repetitive queries that lead to unnecessary resource consumption and increased costs. Caching strategies are employed to store a small set of previous queries, enabling direct retrieval of repetitive queries without reprocessing by the LLMs. However, existing caching algorithms often assume uniform query lengths, simplifying cache selection to a top-$K$ problem, which is inadequate for real-world scenarios with heterogeneous lengths. To address this issue, we propose a bandit learning algorithm for proactive query caching in LLMs, specifically considering variable-sized queries. We cast the optimal cache query cache problem as a knapsack problem. Since the repetitive pattern and processing cost are unknown and has uncertainty, we cast the learning-to-cache problem as a bandit learning problem. Compared to conventional bandit learning frameworks, a new technical challenge is that the reward of an arm would not be observed if it is pulled. To tackle this, we propose an Lower confidence bound (LCB)-type algorithm, which we prove has a $\\tilde{O}(\\sqrt{T})$ order of regret and show that our regret does not deteriorate compared to previous results when incorporating a variable size setting. Furthermore, we demonstrate that our online cache policy effectively reduces the additional computational overhead typically associated with calculating the optimal cache.",
    "keywords": [
      "Query Cache",
      "LLM Inference Serving",
      "Bandit Learning"
    ],
    "venue": "ICLR",
    "year": 2025,
    "pdf_url": "https://openreview.net/pdf?id=NcKUcd4EkA",
    "forum_url": "https://openreview.net/forum?id=NcKUcd4EkA",
    "reviews": [
      {
        "rating": "6",
        "confidence": "4",
        "summary": "The paper studies the problem of efficient LLM inference through caching the seen queries with online learning. It focuses on the setting when the query legnth can be different.",
        "strengths": "The paper is built up on Zhu et al 2024, but proposes some new modifications that deal with \n(1) variable query size, which is more realistic in real-world settings; \n(2) the case when the length of the query is on par with the length of the cache size.\n\nThe authors provide new algorithms that guarantee near-optimal rate for the case of variable query length.",
        "weaknesses": "It's a little unclear to me how the main contirbution of the paper differs from that of Zhu et al. 2024. In particular, it seems that the lower bound directly applies here since Zhu et al. 2024 can be viewed as a special case of the condition the authors considered?"
      },
      {
        "rating": "6",
        "confidence": "2",
        "summary": "This interesting paper studies the caching of query responses for LLMs and addresses a few fundamentally different aspects of this problem namely: a) cost is not observed for already cached queries; b) cost varies by query (and they are of different sizes).  In order to solve this problem the authors note that: a) this is a bandit problem, but reward is only (re)observed at the time an item is placed in the cache b) the constrained optimization problem can be framed as a 0-1 knapsack problem.  Building upon the work of Zhu et al the authors propose two algorithms.  The first is a purely theoretical construct that applies a pessimistic LCB bandit formulation using an oracle to solve the knapsack problem, the second algorithm is an actually practically implementable algorithm which the authors show performs in more general settings to the algorithm of Zhu et al.  They provide regret bounds to support their simulation studies showing a O(root(T)) regret bound.",
        "strengths": "The content of this paper ventures outside areas of my expertise in a few respects, but I have a generally positive disposition to it.  \n\nThe paper reads well, and to the best of my understanding addresses an important problem and makes an important contribution.  The main arguments and experimentation appear sound to me.  The scope is narrow and well-defined.",
        "weaknesses": "Some general comments / suggestions\n\nI don't feel expert enough to comment in detail on the magnitude of the contribution.  While the problem formulation is interesting, I am doubtful it could be deployed as  real caching solution for LLMs due to some practical reasons (need to store cost and count of all queries, uncertainty on cost seems not too uncertain to me) - but am open to having the authors change my mind on these.\n\nWhile the writing is technically quite good (with occasional lapses), I think the structuring of the overall argument could be improved.  Some interesting points are brushed over (e.g. LCB vs USB).  The core contribution is a bit of work to disentangle from the presentation.\n\nThis paper makes a contribution to cache bandits motivated by an LLM use case, I think the motivation could be altered to make the paper a bit more general.  That is explain cache bandits, what is known about them, what is lacking, and how current solutions are not applicable to LLM use cases.\n\nLine 151, usually people consider contextual bandits to be a simplification of RL.\nLine 215 opening quotes should be backticks\nLine 374 and be more reasonable. -> and is more reasonable.\nLine 455-458.  If I am not wrong it should be q_t not q in a few places.\nLine 143.  Does the problem perfectly reduce to the knapsack problem or do simplifications need to be made?  Specifically why use the phrasing “we regard”, rather than “the problem reduces to”.\n\nThe differences between algorithm 1 and 2 are hard to see and understand, I would suggest colour might be useful to do a “diff” to help here."
      },
      {
        "rating": "6",
        "confidence": "3",
        "summary": "This paper considers the caching problem in LLM inference. Note that for a prompt, doing LLM inference to generate tokens can be costly. A way to reduce the cost is to do KV caching such that for the prompt stored in the cache, generating tokens will be costless. The paper formulates this procedure as a bandit problem. To be specific, the action is cache $M_t$. The paper assumes that the prompt arrives following an unknown distribution, generating a fixed inference cost when the prompt is not in the cache $M_t$ and generating zero cost when the prompt is in the cache $M_t$. Therefore, each possible cache is associated with an unknown expected cost. The paper takes a bandit learning approach to approximate the optimal caching. The whole procedure has $T$ rounds and at each round $t$, the decision maker estimates the costs, selects a cache $M_t$, and observe new information. Finally, the paper derives a $O(\\sqrt{T})$ regrets bound of their algorithm and conducts numerical experiments to test the empirical performance of their algorithms.",
        "strengths": "1. The paper provides a bandit model to study the optimal caching problem and the model is more general than the models in the previous literature, such as Zhu et al. (2023). The model in the paper is more general and practical.\n\n2. The paper provides a reasonable algorithm to approximate the optimal caching based on an online learning idea. The algorithm enjoys a strong $O(\\sqrt{T})$ regret bound. The paper also conducts numerical experiments to illustrate the empirical performances of their algorithm.",
        "weaknesses": "1. The regret bound established in the paper depends on $1/p_{\\min}$, where $p_{\\min}$ is the minimum probability for a prompt to show up. However, this probability can be very small, especially when the set of possible prompts is very large. It is not known whether such a weak dependency on $p_{\\min}$ is necessary or not.\n\n2. The algorithms in the paper require an oracle to generate the optimal caching based on the current estimated costs. However, it is not discussed in the paper whether assuming the existence of such an oracle is practical or not. That is, what is the computational complexity of the oracle and what is the feasibility in real-world applications?"
      },
      {
        "rating": "3",
        "confidence": "4",
        "summary": "This paper studies the cost-effective caching problem in LLM inference. Increasing volume of query brings increasing resource consumption. Using caching to store important/frequent queries and answers can help to save the computational resources. This paper proposes a Knapsack bandit framework to characterize the learning process of unknown queries’ costs and find the optimal caching strategy. The paper proposes both a batched and online version of algorithm to solve the problem. The former with $O(T)$ computation cost and larger memory cost achieve $O(\\sqrt{T}\\log^{3/2}T)$ regret and the latter with $O(\\log T)$ computation cost achieve $O(\\sqrt{T}\\log^{2}T)$ regret. Experiments on both synthetic and real-world datasets show advantage over baselines.",
        "strengths": "1.\tThe paper study a more general knapsack bandit problem for caching in LLM inference that considers the cost and weight differences over different queries. \n2.\tThe paper proposes an Online Stream Cache Bandits algorithm to deal with the problem. The algorithm calls the oracle at most $O(\\log T)$ times and can achieve sub-linear regret when learning the optimal caching strategy.",
        "weaknesses": "1.\tIn assumption 2, it has been assumed that each query would appear with probability at most ½. This assumption may be too strong. What would happen if this assumption is not satisfied? \n2.\tThe regret depends on $1/p^*$ where $p^*$ is the minimum sampling probability among all queries. This term may be very large and dominate the result. Intuitively speaking, though there may exist a query with smaller sampling probability and it is hard to observe its cost, its influence to the final reward is also very limited. So in this case, the query does not need to be observed enough times as though queries with larger sampling probability, and thus the dependence on $1/p^*$ can be improved. Can authors comment on this?\n3.\tIn Algorithm 2, the authors claim that it does not need to store all queries and answers. However, in Line 3-7, the algorithm still needs to check whether the query has been seen before. So it still needs to store all query information and pay additional memory cost. \n4.\tLine 205, typo. \n5.\tLine 409, ‘additional computational cost’ may bring confusion. \n6.\tIn experiments Line 518, what does cache length mean? Does it refer to the number of queries that can store or the number of chars in the query?"
      }
    ],
    "rating_avg": 5.25,
    "confidence_avg": 3.25,
    "decision": "Reject",
    "meta_review": "This paper studies caching of LLM queries of variable sizes and unknown costs. The key idea is to greedily cache queries with highest lower confidence bounds (LCBs) on their costs. If a query is suboptimal and cached, it gets replaced by a more costly query whose estimated cost improves over time due to not being cached. The authors study two variants of the problem, propose algorithms for them, analyze them, and evaluate them empirically. The scores of this paper are 3x 6 and 3, which is an improvement over the initial 2x 6, 5, and 3. The reviewers had several concerns:\n\n* **Algorithm design:** The algorithm design needs to be better explained. For instance, the authors use LCBs while the standard approach in exploration are upper confidence bounds (UCBs). I also wonder why the query probabilities are estimated using their empirical means and not LCBs. Finally, the authors need to elaborate on details of how the pessimism helps. The reason is that query caching is a complex optimization problem. Therefore, it is not immediately clear when better estimated optimal queries that are not cached replace cached suboptimal queries.\n\n* **Theory:** The regret bounds in Theorems 1 and 2 are $O(1 / p_*)$, where $p_*$ is the minimum query probability. Therefore, they are loose. A matching lower bound clearly does not exist. Why? When the probability of the least probable query goes to zero, the query is unlikely to appear and thus the problem becomes easier.\n\n* **Technical novelty:** The technical novelty in the proofs is unclear.\n\nThese concerns require a major revision and therefore the paper cannot be accepted at this time.",
    "author_remarks": "",
    "decision_comment": ""
  },
  {
    "id": "DbZDbg2z9q",
    "title": "Ontology-Retrieval Augmented Generation for Scientific Discovery",
    "authors": [
      "Andres M Bran",
      "Alexandru Oarga",
      "Matthew Hart",
      "Magdalena Lederbauer",
      "Philippe Schwaller"
    ],
    "abstract": "Large Language Models (LLMs) have demonstrated remarkable capabilities across a wide range of tasks, sparkling an increasing interest for their application in science. However, in scientific domains, their utility is often limited by hallucinations that violate established relationships between concepts or ignore their meaning; problems that are not entirely eliminated with Retrieval Augmented Generation (RAG) techniques. A key feature of science is the use of niche concepts, abbreviations and implicit relationships, which may deem RAG approaches less powerful due to the lack of understanding of concepts, especially in emerging and less known fields. Ontologies, as structured frameworks for organizing knowledge and establishing relationships between concepts, offer a potential solution to this challenge. In this work we introduce OntoRAG, a novel approach that enhances RAG by retrieving taxonomical knowledge from ontologies. We evaluate the performance of this method on three common biomedical benchmarks. To extend the value of OntoRAG to emerging fields, where ontologies have not yet been developed, we also present OntoGen, a methodology for generating ontologies from a set of documents. We apply the combined OntoGen+OntoRAG pipeline to a novel benchmark of scientific discovery in the emerging field of single-atom catalysis. Our results demonstrate the promise of this method for improving reasoning and suppressing hallucinations in LLMs, potentially accelerating scientific discovery across various domains.",
    "keywords": [
      "ontology",
      "rag",
      "retrieval",
      "llm",
      "science",
      "ai4science",
      "chemistry",
      "biomedical",
      "reasoning"
    ],
    "venue": "ICLR",
    "year": 2025,
    "pdf_url": "https://openreview.net/pdf?id=DbZDbg2z9q",
    "forum_url": "https://openreview.net/forum?id=DbZDbg2z9q",
    "reviews": [
      {
        "rating": "5",
        "confidence": "4",
        "summary": "This paper presents an OntoRAG that leverages the LLMs generated ontologies as the context to enhance the RAG by retrieving taxonomical knowledge from context for accelerating scientific discovery.  The results on the SACBench benchmark demonstrate that OntoRAG outperforms the CoT-based RAG on accuracy, completeness, and order. Additionally, the quality of the ontologies generated by LLMs is evaluated by the downstream task on the biomedical QA benchmark.  \n\nThe paper is well-written and organized, but the pipeline of ontology generation (OntoGen) and RAG with ontologies (OntoRAG) is not a novel contribution, as the existing methods have already investigated it. \n\nMy main concern is that the ontologies generated by LLMs cannot be utilized to enhance the LLMs directly without the human’s curation since hallucinations remain when generating the ontologies with LLMs.",
        "strengths": "S1. The paper is well-written and organized, and the methodology of OntoRAG is well-designed and demonstrated. \n\nS2. The OntoGen pipeline is created to generate the ontologies based on multiple calling the long-context LLMs.\n\nS3. The experiments on the SACBench benchmark and biomedical QA benchmark are conducted to evaluate the performance of OntoRAG and the quality of LLM-generated ontologies.",
        "weaknesses": "W1. The presented OntoGen and OntoRAG pipeline is not novel, as the existing works have already been investigated but they are missed in related works. (Details in Q1)\n\nW2. The ontologies generated by LLMs are utilized directly as context for RAG without the human’s validations. (Details in Q2)\n\nW3. The source code and claimed SACBench benchmark dataset are not provided for reproducibility.\n\nW4. The readability of this paper needs to be improved, as some results analyses and the ablation study are missed. (Details in Q3)\n\nW5. Some typos need to be fixed and avoided. For example, the parentheses after “axioms” should be removed “axioms()-> axioms” in line 289-290, the comma after “in” should be removed “in. order to-> in order to”  in line 408, the “ACcuracy->Accuracy” in line 916, etc."
      },
      {
        "rating": "3",
        "confidence": "4",
        "summary": "This paper introduces an ontology-based retrieval-augmented generation (RAG) pipeline designed to enhance scientific discovery by integrating ontology-based knowledge with language models. Additionally, the paper presents OntoGen, an automated ontology-generation method for fields where no ontology exists, extending OntoRAG's applicability to emerging domains. The proposed method is mainly evaluated on biomedical QA and catalyst synthesis benchmarks.",
        "strengths": "- This work is well-motivated by the need in many scientific domains for expert-curated knowledge that goes beyond document-level retrieval. It seeks to a new RAG pipeline by integrating ontologies, which are widely adopted knowledge bases for specific domains.\n\n- The pipeline addresses cases where ontologies are unavailable, proposing an automated approach to ontology construction from documents.",
        "weaknesses": "- Definition 2.1 for ontology requires a signficant revision as it is unclear and contains inaccuracies:\n  - An ontology can be described as a set of logical axioms that define relationships among entities (concepts, properties, and instance) in the ontology. This approach avoids separating axioms from relationships, as relationships should not be limited to triples alone.\n  - It seems that the relationships set $\\mathcal{R}$ refer to object properties, while the properties set $\\mathcal{P}$ appears to denote data properties.\n  - Additionally, the notation $\\forall i \\in \\mathcal{I} \\exists c \\mid c \\in \\mathcal{C}$ needs clearer explanation. If the intent is to express that an instance $x$ belongs to a class $C$, it would be more accurate to write $C(x)$ or $x: C$.\n\n- Definition of RAG in Equation (1) is inaccurate: As stated, this definition implies that each retrieved document influences the generation probability and is weighted by its relevance. However, in a standard (vanilla) RAG setting, this is not the case; only a subset of retrieved documents typically impacts the generation process, without automatic weighting by relevance.\n\n- The OntoRAG definition needs a significant revision since it builds on the earlier definitions of ontology and RAG, which contain inaccuracies.\n\n- The OntoRAG methodology section lacks sufficient detail for reproduction. To enhance clarity, it would be helpful to include step-by-step explanations of the methodology components and provide running examples.\n\n- The main evaluation in Table 1 primarily examines variations of OntoRAG and one Chain-of-Thought (CoT) baseline. However, it overlooks important comparisons with existing GraphRAG approaches, which similarly aim to incorporate graphs and knowledge bases within the RAG framework."
      },
      {
        "rating": "5",
        "confidence": "4",
        "summary": "This paper introduces OntoRAG, a novel approach that enhances Retrieval Augmented Generation (RAG) by incorporating ontological knowledge to improve the accuracy and scientific grounding of large language models (LLMs). The authors also present OntoGen, a tool for automatic ontology generation to extend OntoRAG's utility to fields without pre-existing ontologies. The key contributions are:\n    • OntoRAG: An extension of RAG that retrieves and integrates relevant ontological information to improve reasoning and reduce hallucinations in large language models (LLMs).\n    • OntoGen: An LLM-based pipeline for automatically constructing domain-specific ontologies from scientific papers.\n    • SACBench: A benchmark for evaluating the synthesis of single-atom catalysts (SACs), used to test the OntoRAG approach in an emerging scientific domain.\nThe authors evaluate OntoRAG on standard biomedical benchmarks and the novel of Single-Atom Catalysis SACBench. Results show improvements over baseline RAG in some domains, reduction of hallucinations in LLMs, particularly for the SAC synthesis task.",
        "strengths": "• Novel approach: Combining ontologies with RAG is an innovative idea to enhance LLM performance in specialized scientific domains. \n• Automatic ontology generation: OntoGen addresses a key bottleneck by automating the creation of ontologies for emerging fields. \n• Application in Emerging Domains: The case study in Single-Atom Catalysis demonstrates the potential of the approach to aid scientific progress in cutting-edge fields where ontologies are not yet fully established.\n• Reduction of Hallucinations: OntoRAG addresses a critical problem in LLMs - factual inaccuracies - by grounding the outputs in established scientific relationships and concepts.",
        "weaknesses": "• Weak evaluation: The authors test their approach on established benchmarks without significant improvement and a novel task in an emerging field that shows promise. Nevertheless, its only one benchmark in a specific field that shows some results. \n• Limited Improvement in Aggregate Performance: Despite the benefits of ontology integration, the paper notes that the aggregate improvement across benchmarks is modest, suggesting that the effectiveness of OntoRAG depends on the specific domain.\n• Ontology quality assessment: The paper lacks a thorough evaluation of the quality of automatically generated ontologies beyond downstream task performance.\n• Computational Overhead: The process of ontology generation and integration adds complexity and computational cost to the pipeline, which may limit its practical use in certain scenarios.\n• Expert Dependency: While OntoGen attempts to automate ontology creation, the variability between LLMs and the need for manual curation still imply a dependence on human expertise for high-quality outputs."
      },
      {
        "rating": "6",
        "confidence": "4",
        "summary": "In this study, the authors design and use an automatic ontology generator, OntoGen, to create ontologies for specialized domains in which there are no pre-existing ontologies. Then, they incorporate the generated ontology from OntoGen as input into OntoRAG, a retrieval-augmented system for LLMs. The authors aim to create a system which produces more accurate scientific output than LLMs or RAG systems. They first test OntoRAG without OntoGen, using biomedical ontologies in its place, for biomedical prediction tasks. Thereafter, they evaluate OntoRAG + OntoGen on a materials science application (single atom catalyst (SAC) synthesis) for which they designed a novel benchmark dataset. OntoRAG performs consistently better than a baseline RAG system for SAC synthesis. The novelty of this paper lies in (1) the design of an automatic ontology generator, OntoGen, (2) the development of a RAG system which incorporates ontologies as input, OntoRAG, and (3) the creation of a benchmark dataset, SACBench, for assessing LLM output within the context of a specialized, materials science domain.",
        "strengths": "- Novelty: The authors addressed a novel, interdisciplinary area between AI and the natural sciences.  \n\n- Clarity: The authors have done a great job of explaining the necessary background in a concise way. I commend the authors for acknowledging the significance and challenges which go along with applying AI approaches to scientific domains, in which plausibility is not necessarily the same as scientific accuracy. \n\n- Creativity: The ideas in this paper are creative: the authors have found a unique way to address ongoing concerns surrounding LLM hallucinations, particularly within a scientific context. \n\n- Reproducibility: The paper is generally well-written and easy to read. For the most part, the paper was clear, and experiments seem reproducible based on the details given.",
        "weaknesses": "I have two major concerns regarding gaps in the evaluation processes. These concerns make it difficult to confirm the scientific rigor of this study: \n\n1. The authors should evaluate the capabilities of OntoGen against existing scientific ontologies, like the Gene Ontology. This will allow the reader to assess whether OntoGen can really produce ontologies that capture scientifically significant patterns. The authors could accomplish this through a comparison of the metrics reported in Fig. 3 or through metrics such as concept coverage, structural similarity, or expert evaluation of key relationships.\n\n2. The experimental results in Figure 4 should also include the base LLMs, without any augmentation, as baselines. Specifically, the authors should report the performance metrics of the base LLMs on SACBench using the same criteria as OntoRAG. This will allow the reader to assess whether OntoRAG truly improves upon LLM accuracy within specialized, scientific domains. \n\n**Expansions:**\n\n1 (expansion): I do not think the authors sufficiently evaluated the capabilities of OntoGen before moving on to evaluate OntoRAG. Since OntoRAG on the SACBench dataset relies upon the output of OntoGen, it is necessary to ensure that OntoGen can produce ontologies with qualities consistent to established ones. Specifically, the authors should compare the output of OntoGen to an existing ontology. While there is no existing ontology for SAC, the authors acknowledge in Section 2.1 that other curated ontologies exist for other domains, like genetic or biomedical ones. For example, the authors could use OntoGen on a corpus of genetic literature and compare the generated ontology to the Gene Ontology. \n\n2 (expansion): The experimental results given in Figure 4 are missing a key baseline: the base LLMs without any RAG system. The authors should include this baseline as it is critical to assess one of the aims of the paper (\"enhancing the scientific accuracy of LLM outputs\"). Additionally, this baseline is particularly important in light of the results of Section 5, in which the OntoRAG system performed worse than the base LLMs in a majority (6/10) of cases (based on the metrics reported Appendix A.0.1). The results of Section 5 (Appendix A.0.1) call to question why the authors decided to move on with OntoRAG + OntoGen. It appears that OntoRAG with pre-existing ontologies has no improvement or limited improvement over the base LLMs. If OntoRAG with established ontologies offers no substantial improvement, then the authors should clarify why they believe that OntoRAG + OntoGen will offer improvements. Specifically, the authors may be able to justify the use of OntoRAG + OntoGen by including the performances of base LLMs on SACBench."
      }
    ],
    "rating_avg": 4.75,
    "confidence_avg": 4.0,
    "decision": "Reject",
    "meta_review": "This paper introduces an ontology-based retrieval-augmented generation (RAG) pipeline for integrating ontology-based knowledge with LLMs. Additionally, the paper presents OntoGen, an automated ontology-generation method for fields where ontologies don't exist. \n\nThe reviewers recognized several strengths, including:\n\n- Problem being well motivated: Using ontology-deriven RAG is a nice solution to address LLMs inaccuracies in scientific discovery\n- Novelty: OntoRAG innovatively integrates ontologies into the RAG framework to ground outputs in established relationships.\n- Benchmark  SACBench could be a valuable contribution \n\nHowever, the reviewers identified several major weaknesses in the paper, particularly in presentation, methodology, evaluation, and clarity. Reviewer ee63 noted missing results analyses and ablation studies, while htBH flagged inaccuracies in key definitions and insufficient detail for reproducing the approach. The risk of hallucinations in LLM-generated ontologies was a shared concern (ee63 and 2Kkq). And 4Tdh suggested validation against existing ontologies.\n\nThe evaluation was also criticized as limited and unconvincing. htBH and 4Tdh highlighted the absence of key baselines, including comparisons with graph-based methods and non-RAG LLMs. 2Kkq and 4Tdh questioned the empirical results and lack of evaluation breadth.\n\nThe authors tried to address some of these points during the rebuttal, but the reviewers aren't entirely convinced.",
    "author_remarks": "",
    "decision_comment": ""
  },
  {
    "id": "jgVqCCg5XX",
    "title": "Revisiting the Scaling Effects of LLMs on Medical Reasoning Capabilities",
    "authors": [
      "Yuxuan Zhou",
      "Xien Liu",
      "Chen Ning",
      "Xiao Zhang",
      "Chenwei Yan",
      "Xiangling Fu",
      "Ji Wu"
    ],
    "abstract": "Recently, LLMs such as the Llama and Qwen families have rapidly improved by significantly scaling their training corpora, with smaller models trained on larger datasets now approaching or surpassing the performance of previous-generation larger models on public benchmarks.  In this paper, we revisit the scaling effects of LLMs, using the medical field as a case study, by carefully analyzing how training corpus size and parameter size affect model performance on problems of varying difficulty. To this end, we present MedResEval, a new benchmark built upon the MedQA dataset. It is designed to demand more complex reasoning and decision-making and more accurately reflect real-world medical scenarios. Leveraging MedResEval, we investigate the scaling effects of training corpus and model size in LLMs through a comprehensive analysis of several prominent LLM families on medical reasoning tasks of varying complexity.\nThe results reveal that while smaller models like Llama 3 (8B) approach the performance of older, larger models like Llama 2 (70B) on simple tasks like MedQA, they consistently underperform on complex tasks requiring advanced reasoning. Furthermore, we develop a difficulty-dependent scaling-law formula to characterize how LLMs' performance varies with training data size at a fixed model parameter size. The quantitative study reveals that reasoning error reduction rates are 1.3 times greater for large LLMs ($\\approx$ 70B) compared to small LLMs ($\\leq$10B) on simple tasks, and 2 times greater on complex reasoning tasks. Our study highlights that while both data and parameter scales enhance LLM performance, greater emphasis must be placed on parameter scales, particularly for complex reasoning tasks. Only LLMs with sufficiently large parameters can effectively tackle the complexities of real-world medical scenarios.",
    "keywords": [
      "LLM evaluation",
      "scaling effect",
      "medical reasoning evaluation"
    ],
    "venue": "ICLR",
    "year": 2025,
    "pdf_url": "https://openreview.net/pdf?id=jgVqCCg5XX",
    "forum_url": "https://openreview.net/forum?id=jgVqCCg5XX",
    "reviews": [
      {
        "rating": "6",
        "confidence": "3",
        "summary": "This paper introduces MedResEval, an evaluation framework designed to examine the impact of model parameters and dataset size on the performance of large language models (LLMs) across four specified tasks. The framework defines a formula based on neural scaling law that models the relationship between performance, parameter count, and dataset size, closely aligning with empirical findings. However, there are concerns about the clinical rigor of the MedResEval framework, as it generates a \"complex\" dataset with certain definitions that may not fully align with established clinical insights.",
        "strengths": "The paper presents an in-depth evaluation of the proposed MedResEval framework, specifically testing the effects of $N$ (number of parameters) and $D$ (dataset size) — the critical elements of the scaling law. The study defines a formula that effectively models the relationship between performance, parameter count, and dataset size, aligning well with empirical results.",
        "weaknesses": "Although MedResEval introduces a new evaluation framework with results that adhere to a defined scaling rule, concerns persist about its clinical relevance, and some claims regarding its clinical rigor appear overstated.\n\n1. The task definitions in Section 3.2 somewhat overstate the clinical relevance and how each task contributes to the complexity of clinical questions.\n- Available Clues: If the answer provided within the paragraphs (as in Figure 8) includes an obviously correct or easily dismissible wrong answer, this could reduce the complexity of the original MCQ. In many challenging MCQs, the difficulty lies in choosing between two or three closely related options. The example in Figure 8 suggests that the LLM only needs to determine if the single integrated answer choice is correct, which may simplify the question.\n- Decision Space: Including an easily dismissible wrong answer does not necessarily increase the complexity of the question. Maintaining question complexity would require distractors that present a closer challenge, as straightforward wrong options may not sufficiently elevate the complexity of decision space.\n- Reasoning Steps: Verifying whether a randomly provided answer is correct could simplify the task, as the model only needs to evaluate a single option rather than considering multiple potential answers, thus reducing the overall complexity.\n\n2. The evaluations lack confidence intervals, which weakens the robustness and reliability of the claims presented in this paper.\n\nAlthough the presentation and evaluation of the paper were quite comprehensive, this limitation is viewed to be critical and hard to fix at this point of submission. Because this limitation would reduce the impact and contribution of the paper to medical applications, I am inclined to reject the paper in its current form. However, if there could be any improvements that could be made in the short term that address this concern, would be open to revisiting this decision."
      },
      {
        "rating": "6",
        "confidence": "3",
        "summary": "The paper proposed a new benchmark for LLMs' medical reasoning capabilities, MedResEval, built on the MedQA dataset. MedResEval is designed to evaluate the scaling effects of LLMs on medical reasoning capabilities from training corpus sizes and parameter sizes (or model size). From various evaluation experiments and in-depth results analysis, the paper concluded that both training data size and parameter scales would enhance LLM performances on medical reasoning, and parameter scales lead to a more pronounced performance improvement than scaling training data size for complex reasoning tasks.",
        "strengths": "- Originality: the paper proposed a novel benchmark to evaluate the utility of LLMs on medical reasoning by expanding the existing popular MedQA dataset with more complex question representations, larger decision space and multi-step tasks. \n- Quality: the paper is solid in technical soundness with meaningful experiment design and proposed evaluation metrics that fit the hypotheses to test the scaling factors of different LLMs. Most conclusions are based on quantitive performance comparison. \n- Clarity: the paper is well-structured with good illustration of diagrams, plots and tables. \n- Significance: the benchmark proposed by the paper is a meaningful expansion of the existing popular MedQA dataset. Also, the same approach could also be applied to other medical benchmark datasets like MedMCQA, PubMedQA, etc. Also, the scaling factor of LLMs is an interesting and important question on practical utility of LLMs in medical domain. The paper offers a good insight or framework on carefully examination of the marginal gain/loss of increasing training data or parameters.",
        "weaknesses": "- Lack of limitations and future work in Conclusion part.\n- The bar plots somehow are a little bit hard to illustrate the performance changes by various Ns & Ds. Scatter plots like Figure 6 (with dot sizes indicating N or D) might work better. \n- It might be better to indicate both x-axis and y-axis are in log-scale in Figure 6 caption. \n- Overall, the performance differences lack significant analysis since only average performance is reported (e.g. Figure 5). Pls add confidence intervals if they are available."
      },
      {
        "rating": "5",
        "confidence": "2",
        "summary": "The paper proposes a new benchmark dataset, MedResEval, built over the MedQA dataset, by varying 3 dimensions of difficulty. The authors also propose a difficulty dependent scaling law and results for the same with general purpose LLMs. They tackle the question of whether smaller LLMs can do as well as larger LLMs if given sufficiently large datasets, even when difficulty level of the data changes. The authors seek to identify boundaries to the application of smaller LLMs under specific constraints like data difficulty.",
        "strengths": "•\tSignificance: The authors have taken on a relevant problem, especially given the growing landscape of LLMs in the medical context. The authors propose a relevant benchmark that can aid further research in this area.\n\n•\tQuality: The authors have performed a quantitative and qualitative assessment of their dataset. The authors have conducted evaluations with 12-18 open source models from 2 model families.\n\n•\tClarity: The writing is quite clear. The authors have provided good examples to illustrate the modifications added.\n\n•\tOriginality: The novelty is in the proposed dataset and modification to the scaling law in the event of changing difficulty, although the findings themselves are not completely surprising.",
        "weaknesses": "•\tThe authors have not shared the proposed dataset yet, which is a key contribution.\n\n•\tThe main issue is that the evaluation is limited to general purpose LLMs. Since the context is the medical domain, it would be more impactful to examine the effect on the scaling law and the effect of varying difficulty levels on medical LLMs like MedPALM[1], Meditron[2] etc. \n\n•\tThe authors have only evaluated on MedResEval, which is derived from MedQA. Other medical datasets like MedMCQA[3] or PubMedQA[4] can also be considered. It would also be good to give an intuition of how these can be modified to increase the difficulty levels.\n\n[1] Singhal K, Tu T, Gottweis J, Sayres R, Wulczyn E, Hou L, Clark K, Pfohl S, Cole-Lewis H, Neal D, Schaekermann M. Towards expert-level medical question answering with large language models. arXiv preprint arXiv:2305.09617. 2023 May 16.\n\n[2] Chen Z, Cano AH, Romanou A, Bonnet A, Matoba K, Salvi F, Pagliardini M, Fan S, Köpf A, Mohtashami A, Sallinen A. Meditron-70b: Scaling medical pretraining for large language models. arXiv preprint arXiv:2311.16079. 2023 Nov 27.\n\n[3] Pal A, Umapathi LK, Sankarasubbu M. Medmcqa: A large-scale multi-subject multi-choice dataset for medical domain question answering. InConference on health, inference, and learning 2022 Apr 6 (pp. 248-260). PMLR.\n\n[4] Jin Q, Dhingra B, Liu Z, Cohen WW, Lu X. Pubmedqa: A dataset for biomedical research question answering. arXiv preprint arXiv:1909.06146. 2019 Sep 13."
      },
      {
        "rating": "3",
        "confidence": "3",
        "summary": "The paper investigates the impact of training corpus size and model parameter size on the performance of large language models (LLMs) in the medical domain. The authors introduce a new benchmark, MedResEval, which is designed to demand more complex reasoning and decision-making, reflecting real-world medical scenarios more accurately. Through comprehensive analysis, the paper reveals that while smaller models can approach the performance of larger models on simple tasks, they underperform on complex tasks requiring advanced reasoning. The authors also develop a difficulty-dependent scaling-law formula to characterize the performance of LLMs with varying training data sizes at a fixed model parameter size. The study emphasizes the importance of model parameter scales, particularly for complex reasoning tasks, and suggests that sufficiently large parameters are essential for effectively addressing real-world medical scenarios.",
        "strengths": "1. The paper provides a novel analysis of the scaling effects of LLMs within the medical domain, an area critical for the application of advanced reasoning capabilities. The creation of MedResEval, a benchmark requiring complex reasoning, is a contribution as it allows for more accurate assessment of LLMs in medical scenarios.\n2. The paper is well-structured, with a clear problem formulation and methodology. The experiments are thorough, involving multiple LLM families and a range of model sizes and training data amounts. The analysis include both qualitative and quantitative assessments.\n3. The paper is also well-written and easy to follow. The introduction of the problem, related work, methodology, experiments, and results are clearly presented. The use of figures and tables to summarize the study's process and findings is effective.\n4. The study's findings are significant as they provide insights into the limitations of current LLMs in handling complex reasoning tasks, which is crucial for their deployment in high-stakes domains like healthcare. The proposed scaling-law formula offers a predictive tool for future model development.",
        "weaknesses": "1. Generalizability: While the paper focuses on the medical domain, it's unclear how these findings generalize to other domains requiring complex reasoning. Further discussion on the broader implications of these results would be beneficial. When extended to other domains, the conclusions may change.\n2. Data Diversity: The paper primarily uses one benchmark (MedQA) as the basis for MedResEval. It would be valuable to see how the models perform on other medical datasets to ensure the results are not dataset-specific. At the same time, the so-called \"more complex\" tasks are not expanded enough, and more complex medical scenario problems should be designed.\n3. Model Diversity: The study focuses on a limited number of LLM families. Including a more diverse set of models, including those with different architectures, could provide a more comprehensive understanding of the scaling effects."
      },
      {
        "rating": "3",
        "confidence": "4",
        "summary": "This paper identifies the lack of a robust dataset to benchmark the reasoning capabilities of Large Language Models (LLMs) in complex medical scenarios. To address this gap, the authors adapt the MedQA dataset, creating a new benchmark called MedResEval with three key improvements: limited clues, a broader decision space, and additional reasoning steps. The authors then benchmark multiple open-source LLMs on this dataset and propose scaling laws that relate performance to training data size.",
        "strengths": "- The paper addresses an important issue in evaluating LLM reasoning in the medical field.\n- The experiments are conducted on a wide range of LLMs.",
        "weaknesses": "- The novelty of the proposed dataset fall short when compare  to existing datasets: \n\t- The authors argue that MCQs provide too many clues and a limited decision space. However, the modified dataset they propose still contains only MCQs, despite the existence of medical question-answering datasets without MCQs [1].\n\t- The authors propose benchmarking the multistep reasoning abilities of LLMs by artificially adding a reasoning step to the MedQA dataset. However, datasets specifically designed to assess this ability already exist [2,3], making the novelty of the authors' benchmark relatively limited in comparison.\n\n- The benchmark proposed by the authors utilizes \"Chain of Thought\" prompting, with demonstrations generated by GPT-4. This approach makes the benchmark dependent on the performance of a third-party, closed-source model, and it diverges from realistic medical scenarios, as sensitive medical data cannot be processed by GPT-4 due to ethical concerns.\n\n\n- The experimental details are incomplete, particularly the absence of the specific prompts used. This omission makes it challenging to have confidence in the results and to reproduce them, as the performance of each LLM can vary significantly depending on the prompt used.\n\n- The paper lacks a contribution section, which makes it difficult to discern the specific claims and contributions being presented.\n\n- The experiments lack reported margins of error, making it difficult to evaluate the significance of the presented results.\n\n[1] (2018) emrQA: A Large Corpus for Question Answering on Electronic Medical Records \n\n[2] (2018) Can a Suit of Armor Conduct Electricity? A New Dataset for Open Book Question Answering\n\n[3] (2022) MuSiQue: Multihop Questions via Single-hop Question Composition"
      }
    ],
    "rating_avg": 4.6,
    "confidence_avg": 3.0,
    "decision": "Reject",
    "meta_review": "This paper has been evaluated by 5 knowledgeable reviewers. Their opinions varied: 3 marginal acceptances, 1 marginal rejection and one straight rejection. It examines the impact of model complexity and data size on the performance of LLMs on Q&A tasks in healthcare domain. The authors provided a rebuttal and engaged with the reviewers. The remaining issues include lack of clarity of how the approach would translate across a broader list of LLMs and broader collection of Q&A benchmark data. Therefore, the potential impact of this work is not readily apparent. It brings however some insights on how to structure benchmarks for evaluating LLMs is domain-specific application scenarios.",
    "author_remarks": "",
    "decision_comment": ""
  },
  {
    "id": "bJ33TvbJW0",
    "title": "SinkQ: Accurate 2-bit KV Cache Quantization with Dynamic Sink Tracking",
    "authors": [
      "Yi Su",
      "Yuechi Zhou",
      "Juntao Li",
      "Qingrong Xia",
      "Ping Li",
      "Xinyu Duan",
      "Zhefeng Wang",
      "Min Zhang"
    ],
    "abstract": "The impressive capabilities of large language models (LLMs) come at the cost of substantial computational resources during deployment. While KV Cache can significantly reduce recomputation during inference, it also introduces additional memory overhead. KV Cache quantization presents a promising solution, striking a good balance between memory usage and accuracy.\nPrevious research has shown that the Keys are distributed by channel, while the Values are distributed by token. Consequently, the common practice is to apply channel-wise quantization to the Keys and token-wise quantization to the Values. However, our further investigation reveals that a small subset of unusual tokens exhibit unique characteristics that deviate from this pattern, which can substantially impact quantization accuracy. Furthermore, these tokens often have higher attention scores, exacerbating their quantization errors.\nTo address this, we develop a simple yet effective method to identify these tokens accurately during the decoding process and exclude them from quantization, significantly improving overall accuracy. Extensive experiments show that our method achieves significant accuracy improvements under 2-bit quantization and can deliver a 6.4× reduction in memory usage and a 2.3× increase in throughput. Our code will be released upon acceptance.",
    "keywords": [
      "KV Cache",
      "Large Language Models",
      "Quantization"
    ],
    "venue": "ICLR",
    "year": 2025,
    "pdf_url": "https://openreview.net/pdf?id=bJ33TvbJW0",
    "forum_url": "https://openreview.net/forum?id=bJ33TvbJW0",
    "reviews": [
      {
        "rating": "5",
        "confidence": "4",
        "summary": "This paper presents SinkQ, a 2-bit quantization technique designed to improve the memory efficiency of KV cache in LLMs. This method dynamically identifies and tracks \"sink tokens\"—tokens with high attention scores that would otherwise suffer from quantization errors—and excludes them from quantization to retain accuracy. The SinkQ approach offers notable memory and throughput benefits, achieving a $6.4\\times$ reduction in memory usage and a $2.3\\times$ increase in throughput, while minimally impacting model accuracy. It is implemented in a hardware-friendly way, providing compatibility with common LLM frameworks.",
        "strengths": "- This work provides thorough ablation studies and insightful findings on KV cache compression, particularly the role of attention distribution and the characteristics of tokens that function as attention \"sinks.\"\n- By excluding high-attention tokens from quantization, SinkQ effectively preserves accuracy under 2-bit quantization, making it feasible for real-time applications that require efficient memory usage.\n- SinkQ’s compatibility with methods like KIVI, which uses channel-wise and token-wise quantization, demonstrates flexibility and potential for integration with other compression frameworks.",
        "weaknesses": "- The paper lacks an in-depth discussion of the computational overhead introduced by steps such as slicing, concatenation, and the calculation of outlier tokens. A profiling of these operations would help to understand the real-world efficiency impact.\n- The paper compares SinkQ with KIVI but does not include comparisons with other KV cache compression methods, such as KVQuant, [1], GEAR [2] and SKVQ [3]. \n- SinkQ could be considered an innovation that combines aspects of token-dropping approaches, such as those in StreamingLLM [4] and H2O [5], with quantization strategies. The novelty may be seen as limited.\n\n[1] Kvquant: Towards 10 million context length llm inference with kv cache quantization\n\n[2] Gear: An efficient kv cache compression recipe for near-lossless generative inference of llm\n\n[3] SKVQ: Sliding-window Key and Value Cache Quantization for Large Language Models\n\n[4] Efficient streaming language models with attention sinks\n\n[5] H2o: Heavy-hitter oracle for efficient generative inference of large language models"
      },
      {
        "rating": "3",
        "confidence": "4",
        "summary": "This paper proposes SinkQ, a KV cache quantization method for reducing memory overhead and improving efficiency of LLM inference. The authors observe the existence of sink tokens, which are a small subset of tokens that exhibit outlier characteristics and can occur at any token position, which significantly impact model accuracy. Based on this observation, the authors propose to keep a fixed-size pool for storing these sink tokens in full precision, while quantizing all other tokens following the KIVI approach. Empirical evaluations show that SinkQ mostly outperforms KIVI in preserving model quality.",
        "strengths": "1. This paper studies an important problem.\n2. The proposed approach is well-motivated by the authors' observation.",
        "weaknesses": "1. The authors' observation of sink tokens is not new or novel. Previous works have observed the existence of heavy-hitter tokens [1] or salient tokens [2] in LLMs, which may occur at any token position. Hence, the claim on line 211 is inaccurate: \"Previous work suggesting that attention sinks occur only in the initial tokens...\"\n2. The proposed method lacks novelty. The proposed mixed-precision approach for KV cache quantization is similar to previous works [2,3], which also identify outlier tokens in the KV cache and preserve in higher precision or full precision.\n3. The \"Method\" section is incomplete, missing some important details. It is not clear how SinkQ identifies the sink tokens, which is a critical part of the proposed method. During inference, the tokens are ingested in a streaming manner, while the authors only describe how the outlier tokens can be identified after saving all keys in an offline manner on line 152.\n4. Baselines are missing from the experiments. Since the authors adopt a mixed-precision quantization approach, mixed-precision baselines, such as KVQuant and ZipCache, are more relevant than the KIVI baseline. Moreover, the comparison with KIVI feels like an unfair comparison; since SinkQ directly adopts the KIVI approach (per-channel for keys and per-token for values, with residual cache) and adds sink tokens, the model quality will certainly outperform KIVI, but with memory and latency overheads. These overheads are not made very clear in Table 1 and 2.\n\nReferences\n\n[1] Zhang, Zhenyu, et al. \"H2o: Heavy-hitter oracle for efficient generative inference of large language models.\" NeurIPS 2023.\n\n[2] He, Yefei, et al. \"ZipCache: Accurate and Efficient KV Cache Quantization with Salient Token Identification.\" NeurIPS 2024.\n\n[3] Dong, Shichen, et al. \"QAQ: Quality Adaptive Quantization for LLM KV Cache.\" arXiv preprint arXiv:2403.04643 (2024)."
      },
      {
        "rating": "3",
        "confidence": "4",
        "summary": "The paper presents SINKQ, a KV Cache quantization designed for efficient deployment of large language models (LLMs) by balancing memory use and accuracy. SINKQ identifies unusual tokens with distinct distribution and higher attention scores, which often lead to quantization errors.",
        "strengths": "The paper introduces an approach to improve quantization accuracy by dynamically excluding high-error tokens.",
        "weaknesses": "1. The major claim of this paper lacks sufficient justification. The foundation of the work is based on the statement, \"Previous work suggests that attention sinks occur only in the initial tokens; however, our observations reveal that they can appear at any position within a sentence.\" However, there is no concrete evidence or examples provided to support this strong claim. To strengthen the paper, it would be beneficial if the authors included specific evidence, such as visualizations or quantitative analysis, to demonstrate instances where attention sinks appear at various positions within a sentence.\n2. In the experiments, Figure 3(b) and Figure 3(c) suggest that the proposed method may not be as memory-efficient as Kiwi, despite claims of improved efficiency. It would be helpful for the authors to directly address this observation and clarify the reasons behind this apparent discrepancy. A more detailed analysis of the trade-offs between the proposed method and Kiwi in terms of memory efficiency would strengthen the discussion.\n3. There are other state-of-the-art KV cache methods, such as those referenced in [1] and [2], which should be considered as additional baselines. Including these baselines would provide a more comprehensive evaluation. It would also be beneficial for the authors to explain why these specific baselines were not included initially and how their method compares to the key innovations introduced in [1] and [2].\n\n[1] Hooper C, Kim S, Mohammadzadeh H, et al. Kvquant: Towards 10 million context length llm inference with kv cache quantization[J]. arXiv preprint arXiv:2401.18079, 2024.\n[2] Zhang T, Yi J, Xu Z, et al. KV Cache is 1 Bit Per Channel: Efficient Large Language Model Inference with Coupled Quantization[J]. arXiv preprint arXiv:2405.03917, 2024."
      },
      {
        "rating": "5",
        "confidence": "4",
        "summary": "This paper presents SinkQ, a method of KV cache quantization that takes care of attention sinks, i.e., outlier tokens that exhibit significantly high attention scores. Different from methods that rely on uniform quantization or fixed attention sinks, SinkQ can dynamically track and store attention sinks that appear at any positions within a sentence. Evaluation results on normal context-length tasks and long-context tasks demonstrate that SinkQ can achieve better accuracy and a comparable level of throughput / memory usage as compared to KIVI (SoTA 2-bit quantization baseline).",
        "strengths": "`+` The design of the method mainly stems from insightful empirical observations (clearly presented and visualized). Thus, the motivation of the work is very clear. The design itself is also natural and many intuitions are aligned with observations from prior work.\n\n`+` Eval results on normal context-length tasks are good (in terms of accuracy), indicating that the design of dynamic attention sinks is effective.",
        "weaknesses": "`-` The take-away from section 4.3 is unclear: When the choice of group size (G) / residual length (R) varies, would the throughput increase as compared to KIVI be consistent? The memory overhead also appears a bit concerning to me --- Would the additional memory overhead of SinkQ scale even more when sink_num goes up? The broader concern here is about scalability --- Please refer to \"questions\".\n\n`-` Minor issues: Please consider fixing the y-axis of figures 1b and 1e, and the citation on line 210."
      },
      {
        "rating": "6",
        "confidence": "4",
        "summary": "This paper proposes SinkQ, a near 2-bit KV Cache quantization method that demonstrates quality improvement over previous SOTA while improving throughput and accuracy.",
        "strengths": "The target problem is clear and have both theoretical and empirical comparison with previous work. \nThe paper also conducted a detailed analysis on the attention values as well as controlled experiment to explain how some operations could increase accuracy. \nIt is a nice extension from previous method (KIVI) and handles some outlier token problem in that KIVI does not solve.",
        "weaknesses": "Writing: Authors did not explain enough of the baseline method of KIVI, especially the part of group and residual in KIVI. The method is partly based on KIVI but authors mainly explained how they improved upon KIVI. Adding background on how KIVI separates between grouping and residual will be nice.\nEval: Lacks comparison with other non-quantization works\nLacks throughput number for ablation studies\n(minor) Lacks experiment to larger models (ex. 70B)"
      }
    ],
    "rating_avg": 4.4,
    "confidence_avg": 4.0,
    "decision": "N/A",
    "meta_review": "",
    "author_remarks": "",
    "decision_comment": ""
  },
  {
    "id": "3tukjsVyrE",
    "title": "Scaling Speech-Text Pre-training with Synthetic Interleaved Data",
    "authors": [
      "Aohan Zeng",
      "Zhengxiao Du",
      "Mingdao Liu",
      "Lei Zhang",
      "shengmin jiang",
      "Yuxiao Dong",
      "Jie Tang"
    ],
    "abstract": "Speech language models (SpeechLMs) accept speech input and produce speech output, allowing for more natural human-computer interaction compared to text-based large language models (LLMs).\nTraditional approaches for developing SpeechLMs are constrained by the limited availability of unsupervised speech data and parallel speech-text data, which are significantly less abundant compared to text pre-training data, thereby limiting their scalability as LLMs.\nWe propose a novel approach to scaling speech-text pre-training by leveraging large-scale synthetic interleaved data derived from text corpora, eliminating the need for parallel speech-text datasets.\nOur method efficiently constructs speech-text interleaved data by sampling text spans from existing text corpora and synthesizing corresponding speech spans using a text-to-token model, bypassing the need to generate actual speech.\nWe also employ a supervised speech tokenizer derived from an automatic speech recognition (ASR) model  by incorporating a vector-quantized bottleneck into the encoder. This supervised training approach results in discrete speech tokens with strong semantic preservation even at lower sampling rates (e.g. 12.5Hz), while still maintaining speech reconstruction quality.\nStarting from a pre-trained language model and scaling our pre-training to 1 trillion tokens (with 600B synthetic interleaved speech-text data), we achieve state-of-the-art performance in both speech language modeling and spoken question answering, improving performance on spoken questions tasks from the previous SOTA of 13\\% (Moshi) to 31\\%.\nWe further demonstrate that by fine-tuning the pre-trained model with speech dialogue data, we can develop an end-to-end spoken chatbot that achieves competitive performance comparable to existing baselines in both conversational abilities and speech quality, even operating exclusively in the speech domain.",
    "keywords": [
      "large language models; speech language model; spoken chatbots"
    ],
    "venue": "ICLR",
    "year": 2025,
    "pdf_url": "https://openreview.net/pdf?id=3tukjsVyrE",
    "forum_url": "https://openreview.net/forum?id=3tukjsVyrE",
    "reviews": [
      {
        "rating": "6",
        "confidence": "2",
        "summary": "The paper proposes a speech-text pretraining process for scaling speech-language model training without acquiring large amounts of speech audio data. The process mainly includes an ASR-based low-bitrate speech tokenizer and a text-to-speech-token model to produce large quantities of speech tokens for speech-text pertaining. The pre-trained model is fine-tuned on spoken dialog datasets and shows competitive performance compared to existing SOTA models.",
        "strengths": "1. The ASR-based speech tokenizer achieves semantic information preservation and decent speech audio reproduction at the same time.\n2. The low-bitrate speech tokenizer and the text-to-token model effectively use the existing large amounts of text data to synthesize large amounts of speech tokens, which saves resources to collect large amounts of speech audio data and improves the language model's speech performance after pretraining.",
        "weaknesses": "The weaknesses are mainly in terms of paper writing and presentation. \n1. The paper mentions \"we are first to use supervised semantic tokens for SpeechLMs\". However, one of the baselines, Mini-Omini also uses a whisper-based speech tokenizer. \n2. The details on how the speech and text modalities are interleaved are missing. \n3. As an important part of the process, the details of the text-to-token model are missing—for example, model architectures, training schemes, etc.\n4. The large amounts of speech tokens generated by the text-to-token model are still from existing datasets and speech-synthesized audio from text. How is this process different from generating speech tokens from synthesized speech audio using large amounts of text? For example, llama-omni also uses cosy-voice to synthesize speech audio to augment training data. What's the innovation here between text-to-speech-to-token and text-to-token?"
      },
      {
        "rating": "8",
        "confidence": "3",
        "summary": "This paper is about scaling up data to train large speech language models.  The authors present a method for tokenizing speech using the Whisper encoder and demonstrate their tokenizer retains semantic information as well is fine-grained information for good quality speech generation.  They also describe a method for training a text-to-token model.  With these, they are able to tap into large resources of text data to generate synthetic training data, which they interleave with other conventional text and speech/text sources to pre-train a speech LM.  By fine-tuning the LM on a dialogue corpus they demonstrate a speech chat-like capability.  Extensive experimentation is performed, and the speech pretrain method does quite well on a range of tasks.",
        "strengths": "This paper is a nice contribution to the very hot topic of speech LMs.  By developing an effective speech tokenizer and text-to-tokenizer model the authors are able to create a very large speech language model that produces impressive results on a wide range of tasks.  The authors perform extensive experiments and ablation studies on the speech tokenizer, speech generator (decoder), and the speech LM.  The model is able to achieve strong performance on both spoken language modeling and spoken question answering tasks.  Finally, when fine-tuned on dialogue data, the model does well on a spoken chat-bot task.",
        "weaknesses": "Although this is not necessarily a weakness, this paper seems very strong on the engineering side and a little weaker on the novelty side of things.  The recipe the authors put forward consists of three separate steps 1) tokenizer, 2) text-to-token model 3) pretrain speech LM.   While the authors build a strong tokenizer based on the Whisper model, the approach is not especially novel as it is built on top of a strong speech recognition model.  Likewise the use of a TTS corpus to learn a text-to-token model is a nice approach, but has been done before to learn similar kinds of models (e.g., Hsu et al., Text-Free Image-to-Speech Synthesis Using Learned Segmental Units, 2020).  Finally, the interleaving of different kinds of text and speech data to pretrain an LLM with an additional token vocabulary is not especially novel.  However, while these points are arguably true, I find it impressive that the authors have put all the pieces together to create a very strong speech LM."
      },
      {
        "rating": "8",
        "confidence": "4",
        "summary": "This paper tackles the important problem of closing the gap between textLMs and SpeechLMs, to enable a spoken conversation with an AI model.\nThe paper leverages the recently proposed *supervised* semantic tokens (introducing a discrete bottleneck in ASR models) which show better alignment with text. \nMoreover, they train a text to audio tokens to enable the generation of synthetic audio tokens based on high-quality texts. \nThey suggest randomly replacing textual tokens with the corresponding synthetic speech tokens (resulting in an interleaved sequence), which helps to align the text and audio tokens. \nThey train large SpeechLMs on diverse text/audio inputs (audio only, text only, interleaved, [text,audio] and [audio,text]), and show convincing results on SLM, SQA. \nThey perform supervised finetuning on a proprietary (?) spoken dialogue dataset, and evaluate their model as a spoken chatbot using GPT-4 as a judge.",
        "strengths": "- Supervised speech tokenizers are a great way to distill the content from audio.  Audio is high-dimensional, and using text and a low bitrate bottleneck to focus on content is a good idea, suitable for SpeechLMs. \n- Training a “TTS” model to generate synthetic audio tokens is interesting - as it doesn’t require generating the final audio (high-bitrate, compute-intensive, issues with OOD synthetic data).  Instead, they generate latent audio tokens that focus on content. \n- the interleaving (replacing spans of text with its synthetically produced speech tokens) is interesting as it forces the model to learn alignment between text and audio tokens. It was also shown to be effective in practice.\n- The ability to perform text-guided response (which is a kind of chain-of-thought) is interesting.\n- The ablation study was done well.",
        "weaknesses": "- Several methodological evaluation details are missing (what was measured and how was it computed), mostly in Section 2.1 and Table 1 (See questions).  Whenever you report some metric with an intuitive non-exact name (e.g., Content Preservation - LS), you should explain somewhere it more precisely (e.g., Content Preservation: We run our quantized whisper on the LS (LibriSpeech) dataset to generate text and report the WER to the GT transcript) I understand that there’s a space limitation, but this is important. \nI've listed some specific details I found missing in the Questions section. I suggest adding a short sub-paragraph that describes the evaluation methodology (defines all datasets+metrics being used) or adding those details into the main text within the relevant sections. If space is an issue, you can add those into an appendix section.\n\n- Currently there's no sample page (unless I missed something). Consider creating a sample page with samples on speech continuation (audio prefix, audio GT continuation, and the model's audio continuation). Also consider adding examples of spoken question answering (audio question, audio GT answer, the model's prediction). Examples from the spoken chatbot evaluation would also be great. Moreover, you can visualize how the interleaved samples sound like (paragraph with audio tokens that were decoded in it)."
      },
      {
        "rating": "5",
        "confidence": "4",
        "summary": "This paper proposes a method for scaling SpeechLMs using a new pre-training scheme called \"Synthetic Interleaved Data\". In this scheme, a text to token lM is first trained on supervised data, and then used to expand text-based datasets by predicting the speech tokens directly from the text data. For pre-training, only spans of text are converted to speech tokenization and text and speech are interleaved with one another. After this pre-training, the model is trained in the usual SpeechLM format. The strength of this approach is the ability to generate a large-scale dataset from text-corpora. Furthermore, this method shows strong results on speech-understanding and generation datasets.\n\nOverall, the method presented in this paper and novel, and has an interesting contribution. On the other hand, the writing is unclear and the evaluations are somewhat lacking. I thus recommend to borderline reject this paper.",
        "strengths": "1. A novel approach for expanding the training corpora of SpeechLMs.\n2. The method is easy to implement, and thus can be expanded to other methods.  \n3. State of the art results on sTopic-StoryCloze, sStoryCloze, Web Questions, Llama Questions and TriviaQA.",
        "weaknesses": "1. The writing is unclear for most parts of the paper. While Synthetic Interleaved Data is the main contribution of the paper, it is not clear what this means from the abstracts and introduction. Furthermore, the main explanation of this is just a small part of the paper. I would suggest reducing the length and condensing the section regarding speech tokenization (as this is a well established concept) and increasing the amount of detail in the section regarding Synthetic Interleaved Data. I would also suggest adding a better summerization of this concept in the introduction.\n2. While there is a good ablation analysis, there aren't any explanations for why the architectural / training parameters where chosen as they where. I suggest to add a dedicated subsection or add this into the methodology section where the parameters are introducted.\n3. The training datasets are lacking in clarity:\n- For table 1, is it unclear on which dataset it was evaluated and why MOSNet scores are so low. \n- It is unclear what Supervised speech-text data are used to train the model.\n- It is unclear what datasets areused to train the text to speech tokens model. \n- It is unclear what datasets are used to fine-tune the tokenization encoder and decoder.\nThese should be added in the section specifying the training pipeline or in a dedicated table / figure.\n4. The experimental results are lacking in clarity:\n- the origin of the baseline numbers in all tables is lacking, are these from other papers or from independently evaluating? I would suggest adding these directly to the table or in the caption.\n- In table 3, speechGPT and Spectron are speech to speech methods, while the results are stated in speech to text.\n- in Table 1 MOSNet was used while in table 4  UTMOS is used. This reason for this should be explained in the paper or have uniformity between them. \n5. The paper is lacking some evaluations:\n- Human evaluations of speech quality, such as MOS or MUSHRA evaluations where humans will rate the speech quality of the proposed method compared to the baseline.\n- Evaluation on other tasks, such as speech continuation, reconstruction and TTS for the full method. Speech continuation and Reconstruction results at least should be added, while TTS might be left for future work."
      },
      {
        "rating": "8",
        "confidence": "4",
        "summary": "This work  present a novel approach for scaling speech-text pre-training by leveraging large-scale synthetic interleaved data derived from existing high-quality text corpora. This work utilized existing text-to-speech (TTS) datasets to train a text-to-token language model, which is used to synthesize 600B tokens of speech-text interleaved data. Experiments have demonstrated the effectiveness of incorporating interleaved speech-text data, which can effectively align speech and text. Furthermore, this work constructs a speech instruction dataset, SpeechDialog-90K, to fine-tune models into a chatbot model, which can directly generate speech responses without intermediate text response and significantly improve the previous SOTA.",
        "strengths": "1. This work demonstrates the need to use interleaved speech-text data for cross-modal pre-training, paving the way for more effective speech-text pretraining. Previous pretraining methods have typically relied on paired ASR or TTS data, which is limited in scale; or independently utilized unsupervised speech and text data, which cannot model the dependency between the two modalities. I believe that this work makes a great contribution to the filed of speech-text pretraining.\n\n2. Although the use of interleaved data has been proven effective in the field of image-text pretraining [1], it has not been explored in the field of speech-text pretraining. In contrast to the vision field, web data can naturally form interleaved image-text data, but it is difficult to collect real data with interleaved speech and text. This work proposes a novel method to synthesize pseudo-interleaved data using a text-to-tokens model, and through thorough experimentation, demonstrates the effectiveness of synthesized data and observes that scaling synthesized data continues to provide benefits.\n\n3. This work is very solid and well-motivated. The paper is well-structured, with a clear presentation of the methodology, experiments, and results. This work also reports state-of-the-art performance in speech language modeling and spoken question answering.\n\n[1] Chameleon team. Chameleon: Mixed-Modal Early-Fusion Foundation Models. arxiv: 2405.09818.",
        "weaknesses": "1. There is a lack of performance evaluation for the text-to-tokens model. For example, after converting a piece of text into tokens and then decoding it into speech using a vocoder, what is the ASR-WER of the resulting speech? This result is necessary to demonstrate the semantic representation capability of the tokens generated by the text-to-tokens model.\n\n2. Based on my experience, tokens generated by text-to-models lacks diversity, and the speech instruction dataset SpeechDialog-90K in the SFT stage is also synthesized by TTS, so I am concerned about whether the model can understand real speech input. I checked the evaluation datasets in this work, all of which were synthesized through TTS, lacking evaluation on real speech input (such as AIRBench [2]).\n\n3. The quality of the output speech is not satisfactory, as evidenced by the poor ASR-WER in Table 4. In comparison to llama-omini, which was only trained on 100 hours of speech data, this model was trained on a much larger scale of 700k hours of speech data. The author needs to provide a reasonable explanation for why the ASR-WER is so poor.\n\n[2] Yang, Qian, et al. AIR-Bench: Benchmarking Large Audio-Language Models via Generative Comprehension. arxiv 2402.07729."
      }
    ],
    "rating_avg": 7.0,
    "confidence_avg": 3.4,
    "decision": "Accept (Poster)",
    "meta_review": "This paper introduces a new speech-text pretraining method without large-scale audio-text pre-training data by leveraging interleaved text-to-token data from text corpus. \n\nAs the importance of multimodal agentic AI increases, speech-text multimodal training is becoming significant and popular to make better agentic AIs. The proposed method using interleaved data address lack of speech-text parallel corpus, which is the main obstacle of speech-LMs. The method design seems effective and novel. \n\nAlthoubh some reviewers pointed out lack of details, those are not main concerns.\n\nWith positive scores from all reviewers, AC recommends accepting this paper.\n\nFollowing the reviewers' comments, AC asks the authors to refine the manuscript to be more clear.",
    "author_remarks": "",
    "decision_comment": ""
  },
  {
    "id": "vSrBzCzg4G",
    "title": "Efficient Training of Sparse Autoencoders for Large Language Models via Layer Clustering",
    "authors": [
      "Marco Molinari",
      "Davide Ghilardi",
      "Federico Belotti"
    ],
    "abstract": "Sparse Autoencoders (SAEs) have recently been employed as an unsupervised approach for understanding the inner workings of Large Language Models (LLMs). They reconstruct the model’s activations with a sparse linear combination of interpretable features. However, training SAEs is computationally intensive, especially as models grow in size and complexity. To address this challenge, we propose a novel training strategy that reduces the number of trained SAEs from one per layer to one for a given group of contiguous layers. Our experimental results on Pythia 160M highlight a 3x speedup without compromising the reconstruction quality and performance on downstream tasks. Therefore, layer clustering presents an efficient approach to train SAEs in modern LLMs.",
    "keywords": [
      "Sparse Autoencoders (SAEs)",
      "Meta Learning",
      "Mechanistic Interpretability",
      "Large Language Models (LLMs)"
    ],
    "venue": "ICLR",
    "year": 2025,
    "pdf_url": "https://openreview.net/pdf?id=vSrBzCzg4G",
    "forum_url": "https://openreview.net/forum?id=vSrBzCzg4G",
    "reviews": [
      {
        "rating": "3",
        "confidence": "5",
        "summary": "This work proposes to reduce the computational overhead of SAEs: instead of training a separate SAE for each layer, it groups the layers to several groups of adjacent layers and learns an SAE for each group.",
        "strengths": "Improving LLM interpretability is an important topic. The proposed method of speeding up SAEs is straightforward and easy to understand.",
        "weaknesses": "Overall I feel that the results presented in this work are quite obvious and expected, and I do not see a large contribution to the community. \n1. The novelty of this work is limited. It seems to be an obvious choice for one to learn an SAE for each group of adjacent layers. \n2. Based on the experimental results (on a 12 layer 160M model), the speed up provided by the method is limited. The speed up also always comes with a drop of the quality of the model. Based on Figure 3 and Figure 4, the drop seems to be almost linear to k. This is quite expected with any types of \"simple\" speed up such as down sampling and grouping (like this paper suggested)."
      },
      {
        "rating": "3",
        "confidence": "3",
        "summary": "This paper builds on the recent line of work that relies on sparse autoencoders (SAEs) to address the interpretability of large language models (LLMs). In particular, SAEs aim to decompose LLM activations in a layer as a sparse combination of a large number of (interpretable) features. However, prior works require training one SAE per LLM layer (component), resulting in a large number of parameters and prohibitively high compute cost needed to obtain good quality SAEs to understand the inner workings of the LLM.\n\nThis paper leverages similarities among consecutive layers in an LLM to reduce the training cost for SAEs. The paper proposes to cluster LLM layers in $k$ groups and then train one SAE for each group of layers. Based on the reconstruction error of original representations; downstream performance on tasks focused on indirect object identification, greater than relationship, and subject-verb agreement; and human evaluations, the paper argues that the proposed approach results in good quality SAEs for Pythia 160M LLM.",
        "strengths": "1) The paper focuses on important and timely questions related to the interpretability of LLMs. \n2) The proposed method successfully improves the training efficiency of SAEs for LLMs by grouping similar layers. \n3) Empirical evaluation based on both reconstruction error and downstream performance showcases the utility of the proposed approach.",
        "weaknesses": "1) The main weakness of the paper is its limited technical novelty and contributions. The reviewer believes that the proposed approach of grouping multiple similar layers and training one SAE per group does not constitute a significant contribution to the field. Furthermore, the empirical evaluation in the paper is restricted to a small language model (Pythia 160M) and focuses on very simplistic tasks. This does provide strong evidence of the value of the proposed method for realistic settings involving LLMs.\n\n2) There is a significant scope for improving the presentation of the paper. Many design choices in the paper are not well justified (see the Questions section below).\n\n3) The authors build on many recent prior works. The reviewer believes that the authors can provide a more comprehensive background of some of these works to make the paper self-contained. It would be helpful for the reader to know how SAEs can be utilized for a particular application while studying LLMs."
      },
      {
        "rating": "6",
        "confidence": "4",
        "summary": "This paper proposes a method that will make suites of Sparse Autoencoders (SAEs) easier to use (as they will require fewer SAEs) and easier to train (large compute saving). The method is to train SAEs on the activations from contiguous blocks of layers in the model.",
        "strengths": "* The paper provides comprehensive analysis on the end artifact of their work, such as detailed circuit analysis evals, interpretability studies and accuracy metrics.\n\n* The idea is easy to understand and the execution competently done.\n\n* The results on the circuit analysis evals look strong, as there's barely any performance hit to using the strategy according to that eval.",
        "weaknesses": "The paper claims that there is a $(L-1) / k$ efficiency saving through using their method. But unless I misunderstand, since there are a fixed number of tokens used $T$ (1B in this case), and there will always be $LT$ total activations which all SAEs are trained on, the number of FLOPs used to train the SAEs will be **the same** using this method or not. Since language model activation saving can be amoritized (e.g.  https://arxiv.org/abs/2408.05147 or https://github.com/EleutherAI/sae) there is no theoretical benefit to saving LLM activation saving either.\n\nThe paper is titled as \"Efficient Training of Sparse Autoencoders...\" and hence unless I misunderstand some method, this paper does not achieve its goal and I cannot recommend it."
      },
      {
        "rating": "3",
        "confidence": "4",
        "summary": "The paper proposes a more efficient method of training SAEs that groups similar layers together and trains a single SAE on each group. The grouping is done using aglommerative clustering between layers, where the layer to layer similarity is defined by the average angular distance between layer activations across 5M tokens. The authors compare their method with 5 different values of k (number of groups) against baseline sparse autoencoders on standard SAE metrics (L0, R^2, CE Loss score, and L0), and find that it is worse on these metrics. They also compare against circuit faithfulness and completeness metrics, where their method slightly improves on baselines.",
        "strengths": "- The clustering of layers to find the best groups for training a shared SAE on is interesting\n- The evaluations of the interpretability and downstream performance of the SAEs are strong\n- The problem is mostly well motivated: methods to reduce the computational bottlenecks of training large SAEs are important.",
        "weaknesses": "- The largest weakness of this work is that it is unclear how the proposed method works. Does it concatenate the layers? Does it train on an equivalent fraction of activations from each layer? Does it take in layer i and predict all of the other layers? \n- It is also unclear what this method actually improves on or tells us about, besides simply reducing the total number of SAEs trained (L0s, losses, and interpretability are all significantly worse). Does it actually use less flops (since its plausible that training on more layers requires more flops)? Does it tell us something about how many features are shared across layers, and which layers share features? \n- Because of the lack of experimental details, it is very unclear how this differs from prior work in this area: Residual Stream Analysis with Multi-Layer SAEs, https://arxiv.org/pdf/2409.04185\n- The paper contains many typos and rushed writing.\n- All bar plots should have a number showing the actual value of the bar, and error bars where they make sense.\n- This work only examines residual layers, which is in some sense the “easiest” setting for this idea."
      },
      {
        "rating": "6",
        "confidence": "4",
        "summary": "- When training sparse autoencoders on the residual stream, there is often one per layer. This is likely redundant, as the residual streams at two adjacent layers are often fairly similar\n- The authors propose instead grouping layers by similarity of residual stream, using average angular distance, and training a single SAE for each group of layers. \n- The authors claim that grouping is a substantial speedup. However, the text implies (but does not explicitly state) that all SAEs are trained on 1B tokens. This means that an SAE for a group of eg 3 layers trains on 3e9 activations, while training 3 SAEs, one for each layer, trains on 1e9 activations, for the same total compute. This means it is not a speedup. If the grouped SAE was instead trained on 0.33B tokens, or even randomly sampled one layer's residual for each token, this would be a speedup. This is a crucial detail and needs to be clarified\n- The grouped SAEs are evaluated fairly carefully against the baseline of identically training an SAE per layer. The authors use a range of evaluations:\n    - Standard metrics like L0, L2, CE Loss score\n    - A circuit finding eval on several previously studied circuits. Authors use attribution patching to identify key SAE latents and calculate completeness and faithfulness. It does not seem to be stated whether there is a separate forward pass when ablating at each layer, or if all layers are ablated at at once.\n    - A human interpretability study with 96 features. It is not specified whether this is 96 features per SAE, per SAE family, or total.\n- The overall conclusion is that quality and performance was preserved, which seems reasonable for K=4 or K=5 at least.",
        "strengths": "- A fairly comprehensive set of evaluations is used, more than is common in such papers. I particularly liked the circuit based eval, modulo the concerns below\n- It's a fairly simple, elegant idea that I hadn't seen done before, and which could be a simple drop-in replacement to significantly save the cost of training suites of residual SAEs\n- Covered some key limitations clearly in the limitations section",
        "weaknesses": "- Numerous missing details, as discussed in the summary, which make it impossible to evaluate how impressive the results are\n- Only studies a single model\n- Others discussed below"
      }
    ],
    "rating_avg": 4.2,
    "confidence_avg": 4.0,
    "decision": "N/A",
    "meta_review": "",
    "author_remarks": "",
    "decision_comment": ""
  },
  {
    "id": "sb1HgVDLjN",
    "title": "Offline Model-Based Optimization by Learning to Rank",
    "authors": [
      "Rong-Xi Tan",
      "Ke Xue",
      "Shen-Huan Lyu",
      "Haopu Shang",
      "yaowang",
      "Yaoyuan Wang",
      "Fu Sheng",
      "Chao Qian"
    ],
    "abstract": "Offline model-based optimization (MBO) aims to identify a design that maximizes a black-box function using only a fixed, pre-collected dataset of designs and their corresponding scores. This problem has garnered significant attention from both scientific and industrial domains. A common approach in offline MBO is to train a regression-based surrogate model by minimizing mean squared error (MSE) and then find the best design within this surrogate model by different optimizers (e.g., gradient ascent). However, a critical challenge is the risk of out-of-distribution errors, i.e., the surrogate model may typically overestimate the scores and mislead the optimizers into suboptimal regions. Prior works have attempted to address this issue in various ways, such as using regularization techniques and ensemble learning to enhance the robustness of the model, but it still remains. In this paper, we argue that regression models trained with MSE are not well-aligned with the primary goal of offline MBO, which is to \\textit{select} promising designs rather than to predict their scores precisely. Notably, if a surrogate model can maintain the order of candidate designs based on their relative score relationships, it can produce the best designs even without precise predictions. To validate it, we conduct experiments to compare the relationship between the quality of the final designs and MSE, finding that the correlation is really very weak. In contrast, a metric that measures order-maintaining quality shows a significantly stronger correlation. Based on this observation, we propose learning a ranking-based model that leverages learning to rank techniques to prioritize promising designs based on their relative scores. We show that the generalization error on ranking loss can be well bounded. Empirical results across diverse tasks demonstrate the superior performance of our proposed ranking-based method than twenty existing methods. Our implementation is available at \\url{https://github.com/lamda-bbo/Offline-RaM}.",
    "keywords": [
      "Offline model-based optimization",
      "black-box optimization",
      "learning to rank",
      "learning to optimize"
    ],
    "venue": "ICLR",
    "year": 2025,
    "pdf_url": "https://openreview.net/pdf?id=sb1HgVDLjN",
    "forum_url": "https://openreview.net/forum?id=sb1HgVDLjN",
    "reviews": [
      {
        "rating": "6",
        "confidence": "4",
        "summary": "Offline model-based optimization (MBO) is concerned with the goal of maximizing an unknown objective function using an offline dataset. \n$\\min_{x \\in X} f(x)$ with unknown $f(.)$. The goal is to learn a proxy function $\\hat{f} (.)$. \nA dataset from past observations is available $[  (x_i, f(x_i) ]_{i=1}^n$. The training has to be done completely offline, because online evaluation is not possible in this setup.\nThe rudimentary approach is to train $\\hat{f} (.)$ by minimizing the MSE loss between $\\hat{f} (x_i)$ and $f (x_i)$. This vanilla approach has the problem of out-of-distribution issue, because $\\hat{f} (.)$ does not approximate well on unseen space within $X$.\nThis paper proposes to minimize a learning-to-rank (LTR) loss instead of the MSE loss and experimentally compare the proposed RankCosine and ListNet losses with the existing approaches.",
        "strengths": "**Originality**: This paper utilizes the existing LTR loss functions for offline MBO problems. This is a novel way to approach the offline MBO problem.\n\n**Quality**: I found some concerns which I will raise in the weakness section.\n\n**Clarity**: Overall, the paper has clarity.\n\n**Significance**: This new approach to offline MBO could be of significance, if the following questions are answered.",
        "weaknesses": "Although the approach is novel, there are concerns regarding how it can generalize performance and alleviate the out-of-distribution issue. It is not convincing that just plugging an LTR loss would address would solve the problem.\n(See Questions)"
      },
      {
        "rating": "6",
        "confidence": "4",
        "summary": "This paper proposes a new approach for offline optimization which focuses on training a surrogate to rank samples rather than to accurately predict their values. This surrogate is trained using the LTR framework with ListNet loss.",
        "strengths": "Paper was clearly written and original. To the best of my knowledge, the LTR framework was not previously used for offline optimization. Empirical results show positive improvement over previous baselines.",
        "weaknesses": "I think the idea that MSE is not always optimal for offline opt was recently pointed out in the MATCH-OPT paper (Hoang et al., 2024) (in which they use the term \"value-matching surrogates\" to describe model trained with MSE loss). Personally, I think that MSE is not worse than any other metric for optimization, but it could be harder to be estimated accurately for OOD samples. This seems to have been acknowledged in the MATCH-OPT paper. Section 3.1 and 3.2 of this paper seems to focus on justifying this insight using empirical evidence. 3.3 describes the LTR algorithm (which is not original), and 3.4 quotes some generalization result of LTR.\n\nRegarding 3.1 and 3.2, it makes no sense to compare the two metrics MSE and AUPRC. MSE evaluation does not use info about the top-k design (which has very strong correlation with the rank of the 100th percentile candidate), whereas AUPRC explicitly uses this info. It seems obvious to me that the latter would have higher Pearson correlation. Additionally, one cannot use the top-k info during training, so this would have little relevance to the actual method (which uses the ListNet loss). Most offline opt frameworks don't simply rely on the MSE loss though. As pointed out in the intro, there are some that use generative modeling or regularization to condition the surrogate model. How do those techniques relate to the idea of ranking samples?\n \nThe theory is, unfortunately, quite shallow and needs some extension. Theorem 1 (which is more of a proposition), states an equivalence, so the reverse argument could also be put forward -- why not MSE instead of ranking? As mentioned, I think the key challenge of offline opt is that we cannot control the surrogate's behavior OOD. Early error can lead the gradient search astray, so one should focus on quantifying this compounding effect.\n\nTheorem 2 is a direct quote from previous work, but it seems to add no value to the current setting. Does LTR generalize better than MSE on OOD data? I doubt that we can conclude anything general like that without a particular set of assumptions. So, the right question is, in which scenario will LTR generalize better than MSE on OOD data? I think this is important to answer this, especially when this paper is trying to advocate for a paradigm shift in offline opt. \n\nEmpirical results seem reasonable. However, given the landscape of offline opt research, in which every recent paper seems to report a different set of results on the Design Bench (typically suggesting that it is best), I find it hard to conclude that any method is more significant and robust than the others without proper theoretical backing. The paper should also compare with the recent DDOM method (Krisnamoorthy et al., 2023) which is representative of the generative modeling line of work."
      },
      {
        "rating": "8",
        "confidence": "5",
        "summary": "This paper challenges the use of MSE for training surrogate models in offline MBO, demonstrating its weak correlation with final performance. Instead, the authors propose a ranking-based model leveraging AUPRC, which achieves superior results compared to existing methods and suggests promising new directions for offline MBO.",
        "strengths": "- Utilizing ranking scores in place of MSE to train the offline optimization surrogate model is an innovative approach. It aligns more intuitively with the objectives of offline optimization, making it a fitting metric for this context.\n\n- The algorithm is very clear and easy to understand. At the same time, this paper conducts a theoretical analysis of generalization error bound.\n\n- The authors conducte a wide range of experiments, providing comprehensive comparisons with the latest methods. The experimental results show the feasibility and effectiveness of the proposed approach.\n\n- This article is well-structured, with clear logic and easy-to-follow explanations that enhance readability and comprehension. \n\n- The supplementary material is sufficient and the algorithm can be fully reproduced without any problems. The appendices contain ample additional experiments and ablation studies. The appendices also contain a very comprehensive review of related work.",
        "weaknesses": "- Some concepts need to be clarified, such as OOD in the ranking model and Recall@k in Definition 1. These are raised in the \"questions\" below.\n\n- Typos. For example, \"e.g\" in line 48 should be \"e.g.\", \"caculated\" in line 241 should be \"calculated\". A thorough proofreading is recommended."
      }
    ],
    "rating_avg": 6.666666666666667,
    "confidence_avg": 4.333333333333333,
    "decision": "Accept (Poster)",
    "meta_review": "The paper considers the problem of offline model based optimization. The key idea is to use learning to rank loss instead of mean squared error loss for training surrogate models. Although this point has already been discussed earlier in MatchOpt, the paper does more thorough and comprehensive analysis. I think the community will benefit from this paper. Therefore, I recommend acceptance.",
    "author_remarks": "",
    "decision_comment": ""
  },
  {
    "id": "v27yHgKtMv",
    "title": "Calibration of ordinal regression networks",
    "authors": [
      "Daehwan Kim",
      "Haejun Chung",
      "Ikbeom Jang"
    ],
    "abstract": "Recent studies have shown that deep neural networks are not well-calibrated and produce over-confident predictions.\nThe miscalibration issue primarily stems from the minimization of cross-entropy, which aims to align predicted softmax probabilities with one-hot labels. In ordinal regression tasks, this problem is compounded by an additional challenge: the expectation that softmax probabilities should exhibit unimodal distribution is not met with cross-entropy. Rather, the ordinal regression literature has focused on unimodality and overlooked calibration. To address these issues, we propose a novel loss function that introduces order-aware calibration, ensuring that prediction confidence adheres to ordinal relationships between classes. It incorporates soft ordinal encoding and label-smoothing-based regularization to enforce both calibration and unimodality. Extensive experiments across three popular ordinal regression benchmarks demonstrate that our approach achieves state-of-the-art calibration without compromising accuracy.",
    "keywords": [
      "Ordinal regression",
      "Calibration",
      "Deep neural networks",
      "Unimodality",
      "Loss function",
      "Soft ordinal encoding",
      "Label smoothing",
      "Order-aware calibration"
    ],
    "venue": "ICLR",
    "year": 2025,
    "pdf_url": "https://openreview.net/pdf?id=v27yHgKtMv",
    "forum_url": "https://openreview.net/forum?id=v27yHgKtMv",
    "reviews": [
      {
        "rating": "5",
        "confidence": "5",
        "summary": "In this paper, authors propose an approach for calibration of ordinal regression. They propose a loss function that introduces order-aware calibration They use soft ordinal encoding and label-smoothing-based regularization to enforce both calibration and unimodality. To show the efficiency of the proposed approach, authors propose extensive experimental results on benchmark datasets.",
        "strengths": "1. a novel regularization term is used to promote unimodularity.\n2. Paper is well written and easy to read.",
        "weaknesses": "1. Theoretical proofs of calibration and unimodularity are missing."
      },
      {
        "rating": "5",
        "confidence": "4",
        "summary": "In this paper, the authors aim to enhance the confidence calibration of ordinal regression in the training stage. The main challenge of this task is to consider the calibration and unimodality together. To address this challenge, they propose a new loss function for ordinal regression, which combines order-aware calibration with a unimodal regularization term (based on the SORD encoding). In particular, their method enforces both calibration and unimodality by explicitly modeling the ordinal relationships between classes. The effectiveness of their method is validated on three public datasets.",
        "strengths": "1. The problem of calibration in the context of ordinal regression sounds novel and important. As far as I know, this work should be the first work to solve this issue.\n\n2. The improvement is significant empirically. From Table 2, we can observe a great improvement in the calibration of ordinal regression models and the classification accuracy is preserved.",
        "weaknesses": "1. The L_{REG} defined in Equation 2 is not clearly explained. In particular, the design of I(r) is hard to understand for readers. It would be better if the authors could elaborate on how the regularization is constructed.\n\n2. The writing of the gradient analysis in Subsection 3.4 is not clear.  The authors may need to improve the writing in this part, or it might be too challenging for readers to follow.\n\n3. The technical novelty of the proposed method is not presented. While the authors claim that the method considers the unimodality compared to current calibration methods and considers the calibration when compared to current Ordinal losses, I am not clear about if this method is newly designed in each aspect. In other words, the authors may need to show the new insight of calibration part compared to calibration methods.\n\ntypos:\n1. Line 49, Oridnal -> Ordinal.\n\nThe major issue of this work is on the writing: readers cannot easily understand why we should design such a regularization and how t works here. I will improve my score if the authors can make it clear in the revised version."
      },
      {
        "rating": "3",
        "confidence": "4",
        "summary": "The proposed method introduces ORCU, a novel loss function designed to ensure calibration and unimodality in ordinal regression tasks. ORCU leverages soft ordinal encoding and order-aware regularization to produce calibrated and unimodal probability distributions, which are particularly valuable in high-stakes applications requiring reliable confidence estimates and accurate predictions.",
        "strengths": "•\tThe motivation behind the new method is well-articulated, clearly highlighting the limitations of traditional cross-entropy (CE) loss in ordinal tasks and the miscalibration in modern ordinal regression models.\n•\tThe proposed method is straightforward, and easy to implement.",
        "weaknesses": "1.\tIt is unclear how the regularization component of ORCU promotes calibration. Lines 240-252 discuss scenarios where the model is under or overconfident, yet this confidence is based on a soft-encoded distribution not directly related to the data, which raises questions about its reflection of \"real\" confidence. Additionally, I would appreciate a more rigorous explanation of how this regularization approach aligns with the standard mathematical definition of calibration. Could the authors provide a clearer mathematical justification for this relationship?\n\n2.\tThe paper claims that CE loss leads to overconfident predictions, yet the reliability diagrams presented indicate underconfident outcomes in the experiments, seemingly contradicting this claim. Temperature scaling, a prominent calibration technique, relies on CE, further challenging the assertion that CE is fundamentally flawed for calibration. Could the authors address this discrepancy and clarify why their results show underconfidence in CE where overconfidence might be expected? Additionally, a nuanced discussion of CE’s strengths and limitations for calibration, especially in light of techniques like temperature scaling, would be valuable.\n\n3.\tThe evaluation is limited to loss function baselines. Including additional non-loss-based methods for ordinal regression, such as the approach presented in https://arxiv.org/pdf/2303.04547 for unimodality could highlight the unique benefits of ORCU more effectively. I recommend incorporating a discussion on why ORCU and loss function-based methods may offer advantages over such approaches.\n\n4.\tThe experiments were conducted on only three datasets, which limits the scope for evaluating the method’s robustness across a wider range of ordinal regression tasks. Incorporating a more extensive dataset selection would allow for a better assessment of the generalizability of the approach."
      },
      {
        "rating": "3",
        "confidence": "5",
        "summary": "The authors proposed an addition to the cross entropy loss term that  corrects overconfident predictions for incorrect labels. The advantage of the proposed loss is that the calibration is done jointly with the accurate prediction learning during the training optimization and doesn’t require additional post-training steps. The method was evaluated on the 3 datasets and compared against CE-based ordinal models and calibration-loss based and showed an improvement in calibration/accuracy metrics.",
        "strengths": "- This work addresses an important overconfidence issue in ordinal regression tasks\n- The proposed loss function is assumed to address both accuracy and confidence of the cross entropy loss based model during optimization without additional post-training calibration\n- The authors justify the unimodality enforcement of the proposed loss by gradient analysis",
        "weaknesses": "**Major**:\n- The main focus of the work is CE-loss based ordinal regression which is not an optimal loss for this task and  several methods were proposed without CE loss:  [1-4]\n- The motivation in Sec 3.1 is unclear, how the calibration is defined and why it is not implied by CE-loss. The discussion seems to be valid for the ordered nature of classes but not for calibration. It is better to discuss the motivation for each problem separately.\n - $\\mathcal{L}_{SCE}$ - the explanation in L175-177 is unclear, how the defined loss encourages what the authors claim - maybe it is explained by Diaz et. al but the manuscript should be self contained with additional clarification. It is also not clear how it helps to reflect the ordinal relationships.\n- The Sec. 3.3 in unclear, the explanation and derivation of the loss formula should come before presenting the loss term \n  - why the authors choose it\n  - how it helps to ensure calibration\n  - what is r ?\n  - The L181-183 is unclear.\n\n- Weak evaluation with only 3 small-sample datasets - overall the improvement is incremental so presenting results on more datasets could be beneficial.\n- Missing unimodality evaluation - the authors claim the model enforces unimodality - please show it in the results as in [5]\n- Missing additional deep ordinal regression baselines [1-5].\n- Sec. 3.4 - while it is clear why the loss term enforces unimodality, I’m not sure how it enforces calibration. By saying “*by increasing the gradient for such incorrect predictions, the model is able to reduce the predicted probability for the incorrect class more effectively*” you can claim the same for the standard CE loss. \n- while it could be seen from the results that calibration metrics improved, I’m not sure it is clear from the manuscript why it works.\n\n**Minor**:\n- Missing additional deep ordinal regression methods in the related work discussion\n- It is better to put Figure 1 closer to the gradient analysis section to make it easier to follow\n\nReferences:\n[1] Liu, X., et al. (2019a). Unimodal-uniform constrained wasserstein training for medical diagnosis. In Proceedings of the IEEE International Conference on Computer Vision Workshops\n\n[2] Beckham, C. et al.  (2017). Unimodal probability distributions for deep ordinal classification.\n\n[3] Wenzhi Cao et. al (2020). Rank Consistent Ordinal Regression for Neural Networks with Application to Age Estimation. Pattern Recognition\n\n[4] Xintong Shi et al. (2021). Deep Neural Networks for Rank-Consistent Ordinal Regression Based On Conditional Probabilities.\n\n[5] Cardoso, J. S. et. al (2023). Unimodal distributions for ordinal regression"
      }
    ],
    "rating_avg": 4.0,
    "confidence_avg": 4.5,
    "decision": "N/A",
    "meta_review": "",
    "author_remarks": "",
    "decision_comment": ""
  },
  {
    "id": "m5rOrTiuKG",
    "title": "ExploraCoder: Advancing code generation for multiple unseen APIs via planning and chained exploration",
    "authors": [
      "Yunkun Wang",
      "Yue Zhang",
      "Zhen Qin",
      "Chen Zhi",
      "Binhua Li",
      "Fei Huang",
      "Yongbin Li",
      "Shuiguang Deng"
    ],
    "abstract": "Through training on publicly available source code libraries, large language models (LLMs) can invoke multiple encapsulated APIs to solve complex programming problems.\nHowever, existing models inherently cannot generalize to use APIs that are unseen in their training corpora. As libraries continuously evolve, it becomes impractical to exhaustively retrain LLMs with new API knowledge. This limitation hampers LLMs from solving problems which require newly introduced or privately maintained libraries.\nHuman programmers often explore unfamiliar APIs by writing experimental code before invoking them for a more complex problem.\nInspired by this behavior, we propose $\\textbf{ExploraCoder}$, a training-free framework that empowers LLMs to invoke multiple unseen APIs in code solution by (1) planning a complex problem into several API invocation subtasks, and (2) exploring correct API usage through a novel chain-of-API-exploration.\nConcretely,  ExploraCoder guides the LLM to iteratively generate several experimental API invocations for each simple subtask, where the promising execution experience are exploited by subsequent subtasks. This forms a chained exploration trace that ultimately guides LLM in generating the final solution.\nWe evaluate ExploraCoder on Torchdata-Github benchmark as well as a newly constructed benchmark that involves more complex API interactions.\nExperimental results demonstrate that ExploraCoder significantly improves performance for models lacking prior API knowledge, achieving an absolute increase of 11.24\\% over niave RAG approaches and 14.07\\% over pretraining methods in pass@10. Moreover, the integration of a self-debug mechanism further boosts ExploraCoder's performance on more challenging tasks. Comprehensive ablation and case studies provide further insights into the effectiveness of ExploraCoder.",
    "keywords": [
      "Large Language Models",
      "Code Generation",
      "Code Library",
      "Retrieval Augmented Generation"
    ],
    "venue": "ICLR",
    "year": 2025,
    "pdf_url": "https://openreview.net/pdf?id=m5rOrTiuKG",
    "forum_url": "https://openreview.net/forum?id=m5rOrTiuKG",
    "reviews": [
      {
        "rating": "6",
        "confidence": "2",
        "summary": "The paper introduces ExploraCoder, a training-free framework designed for large language models (LLMs) to utilize unseen APIs to perform code generation (library-oriented code generation), enabling LLMs’ capabilities to adapt to new or private libraries without retraining. \nExploraCoder decomposes a complex programming task into simpler subtasks, employing a chain-of-API-exploration (CoAE) method that iteratively generates, executes, and refines code snippets for specific API calls for each subtask. \nBy doing so, ExploraCoder builds an experience trace, ultimately guiding the generation of correct final code.\nThe paper demonstrates improved performance in handling unseen APIs on the Torchdata-based benchmarks compared to other training-free methods, achieving competitive Pass@k and Success@k rates.",
        "strengths": "1. The problem of adapting LLMs to work with new APIs is a timely and important as it reflects the real-world need for adaptability in code generation, especially in environments with dynamic or proprietary libraries. Chain of API Exploration is innovative in the context of LLMs.\n2. The framework for handling new APIs -- divide-and-conquer framework combined with iterative API exploration which mimics a human programmer’s exploratory approach is solid and well-supported. Interestingly, the self-debugging mechanism is well-integrated within CoAE.\n3. The experimental design appears thorough, incorporating both existing and newly developed benchmarks to assess performance across tasks of varying complexity. The benchmarks are carefully constructed to highlight the challenges of multi-API invocation.\n4. Results are clearly presented, with ablation studies and comparisons to relevant baselines (e.g., naive RAG, Self-Repair) supporting claims of improved performance",
        "weaknesses": "1. The use of similarity-based retrieval strategy for identifying appropriate APIs for subtasks may not be effective in case APIs are similar in functionality functionally  but syntactically different (e.g., APIs that share functionalities across domains or are named differently). This inherits the retrieval bias, which may hinder the subtask performance.\n\n2. ExploraCoder may be sensitive to effective task segmentation, or selecting the optimal granularity for subtasks, where over- or under-decomposition may lead to errors or inefficiencies. The paper lacks a proper discussion and evaluation of how accurately they achieve optimal granularity. \n\n* Furthermore, the paper does not specify how the model handles cascading errors in multi-API tasks, especially for the \niterative CoAE mechanism and self-debugging.\n\n3. While the paper sometimes implies that ExploraCoder can generalize across various API types, the benchmarks are limited to the Torchdata library, which may not fully represent and generalize to APIs in other domains. \n\n**Typos and Minor Errors**:\n   - Page 1, Abstract: \"niave\" should be \"naive.\"\n   - Page 2, Section 1: \"self-debug\" is not consistently hyphenated throughout the paper.\n   - Terms like \"experience exploitation\" and \"trace\" are not defined until later sections, which could confuse readers initially."
      },
      {
        "rating": "6",
        "confidence": "3",
        "summary": "This paper introduces ExploraCoder, a framework for code generation that enables large language models to handle tasks involving multiple, previously unseen APIs. Traditional code generation models, even with RAG or API-pretrained knowledge, often struggle with complex tasks that require multiple API interactions due to limitations in retrieving and integrating diverse APIs effectively. Experiments demonstrate that ExploraCoder significantly outperforms traditional methods.",
        "strengths": "1.The results demonstrate significant improvements, and the experiments are thorough, covering comparisons with RAG frameworks and API-pretrained models across challenging benchmarks.\n\n2.ExploraCoder operates without additional training, making it resource-efficient and easier to deploy, which is advantageous for real-world applications.\n\n3.Clear and Well-Written Presentation: The paper is well-structured and clearly written, making the concepts and experimental setup easy to understand.",
        "weaknesses": "1.The iterative API exploration and self-debugging processes increase computational costs, especially for tasks with complex requirements and multiple APIs. While the framework is training-free, the runtime cost for each exploration cycle could be considerable, impacting scalability for larger applications (eg. repo-level?).\n\n2.I understand that creating datasets is expensive, but I am still concerned about the effectiveness of this method on other libraries. Although the paper demonstrates strong results on the Torchdata-Github and Torchdata-Manual benchmarks, without testing on a more diverse set of libraries, the robustness of ExploraCoder in real-world code generation tasks remains uncertain. \n\n3.ExploraCoder relies on timely execution feedback to guide subsequent steps in the API exploration chain. If execution feedback is delayed or unavailable, as might be the case in certain API-limited or high-latency environments, the framework’s performance could be negatively affected.\n\n4.The framework is designed to handle multiple unseen APIs, but it does not address how it would adapt to changes in APIs over time. As APIs evolve (e.g., deprecations, new parameters, or altered behavior), the effectiveness of previously explored solutions may degrade. Without dynamic updating, ExploraCoder could struggle with outdated API knowledge.\n\n5.The framework’s iterative exploration and debugging processes may produce opaque reasoning steps, making it difficult to understand or verify why certain API calls were chosen. This could hinder debugging or modifying generated solutions manually, which may be problematic for developers aiming to understand the rationale behind each API invocation in the final solution.\n\n6.As mentioned in the paper, if an LLM has already learned new APIs, it would be highly competitive. How can you justify that this method remains competitive when compared to knowledge-update approaches?\n\n7.(minor point) Naive RAG seems like a relatively weak baseline for complex multi-API tasks. Is there no better option to demonstrate that the method in this paper is powerful?\n\n8.(minor point) The method appears straightforward and intuitive, but such process-oriented approaches seem to lack transparency, leading to potential uncontrollable risks in intermediate steps. How do you ensure that the intermediate outputs are reasonable?"
      },
      {
        "rating": "3",
        "confidence": "5",
        "summary": "This paper introduces ExploraCoder, a framework that enables Large Language Models (LLMs) to generate code involving multiple unseen APIs through planning and exploration. The framework breaks down complex programming tasks into simpler subtasks, explores API usage through experimental code generation and execution, and leverages successful experiences to guide final solution generation. The authors curated two benchmarks: Torchdata-Github and the more chanllenging Torchdata-Manual. Authors evaluate their approach on two benchmarks, demonstrating significant improvements over baseline methods and conducting comprehensive ablation studies to validate their design choices.",
        "strengths": "- The problem was formulated clearly as a practical challenge in code generation\n- The authors explain their proposed method clearly \n- Experiments show improvement over baseline models that the authors opt to compare against\n- Various ablations especially on how different components contribute to the system's performance",
        "weaknesses": "The most significant concern I have is the limited novelty of this paper. The proposed ExploraCoder framework seems closely resembling existing code agent frameworks that can perform operations that cover what has been discussed in the paper, e.g., planning, reading code and code documentation, chain/tree-of-thought reasoing, and code execution, and iterations of all above. The core components of the proposed method, e.g., task planning, API recommendation, Chain of API Exploration, solution generator, etc. are methodologically similar to existing approaches in code agents. The paper does not sufficiently demonstrate how its approach fundamentally differs from or improves upon these existing methods, beyond applying similar techniques to the specific domain of unseen API usage.\n\nA related weakness is the paper's related work. The authors have notably omitted discussion of recent advances in code agents, e.g., from swe-agent to AutoCodeRover to the leading ones on swebench. Without comparing against these relevant approaches, it's difficult to assess the true contribution of ExploraCoder to the field. \n\nFurther, the comparison in experiments setting might not be fair. the proposed method requires significantly more model calls than the baseline approaches noted in the paper, as it involves multiple rounds of code generation, execution, and debugging for each subtask. However, this aspect is neither analyzed nor discussed in the paper. The authors should provide a detailed and transparent analysis of the computational overhead.\n\nFinally, both benchmarks mentioned in the paper (Torchdata-Github and Torchdata-Manual) contain only 50 problems each, which is relatively small for drawing statistically significant conclusions. While the problems themselves may be complex and requires multiple API usage, the robustness and generalizability of the results are debatable given the small size of the benchmark and domain."
      }
    ],
    "rating_avg": 5.0,
    "confidence_avg": 3.3333333333333335,
    "decision": "N/A",
    "meta_review": "",
    "author_remarks": "",
    "decision_comment": ""
  },
  {
    "id": "e2p1BWR3vq",
    "title": "A$^2$-Flow: Alignment-Aware Pre-training for Speech Synthesis with Flow Matching",
    "authors": [
      "Sungwon Kim",
      "Sang-gil Lee",
      "Alexander H. Liu",
      "Joao Felipe Santos",
      "Mikyas T. Desta",
      "Sudheer Kovela",
      "Rafael Valle",
      "Bryan Catanzaro"
    ],
    "abstract": "Recent advances in speech synthesis have enabled highly natural and speaker-adaptive speech generation by leveraging large-scale transcribed datasets. However, requiring tens of thousands of hours of annotated speech is impractical in low-resource settings. Existing pre-trained speech models often utilize masked speech inpainting for pre-training and show strong performance on various speech generation tasks using limited task-specific data. Nonetheless, these models still require external alignment mechanisms or extensive additional training to learn alignment for alignment-aware tasks, such as text-to-speech (TTS). In this paper, we propose A$^2$-Flow, an alignment-aware pre-training method for flow matching models in speech synthesis. A$^2$-Flow integrates alignment learning directly into the pre-training process using discrete speech units, enabling the model to efficiently adapt to alignment-aware tasks without the need for separate alignment mechanisms. By embedding alignment learning into pre-training, A$^2$-Flow facilitates alignment-free voice conversion (VC) and allows for faster convergence during TTS fine-tuning, even with limited transcribed data, making it highly suitable for low-resource scenarios. Experimental results show that A$^2$-Flow superior zero-shot VC performance compared to existing models and matches state-of-the-art TTS performance using only a small amount of transcribed data. Moreover, we demonstrate that A$^2$-Flow can be more efficiently applied to alignment-aware speech synthesis tasks than existing pre-training methods, providing a practical and scalable solution for high-quality speech synthesis across diverse settings.",
    "keywords": [
      "Generative Pre-training; Flow Matching; Alignment Learning; Discrete Speech Units"
    ],
    "venue": "ICLR",
    "year": 2025,
    "pdf_url": "https://openreview.net/pdf?id=e2p1BWR3vq",
    "forum_url": "https://openreview.net/forum?id=e2p1BWR3vq",
    "reviews": [
      {
        "rating": "6",
        "confidence": "5",
        "summary": "A2-Flow is a zero-shot TTS model based on flow matching, which relies on self-supervised speech units from HuBERT for pre-training to implicitly align speech and duration. Subsequently, A2-Flow can perform speech synthesis without the need for separate alignment mechanisms  through fine-tuning with a small amount of text-speech paired data. Due to pre-training, A2-Flow can achieve alignment-free voice conversion and allows for faster convergence during TTS fine-tuning.",
        "strengths": "A2 Flow proposes using semantic tokens derived from unlabeled data for pre-training, aiming to align speech and text. This approach allows for zero-shot text-to-speech (TTS) synthesis using only a small amount of paired text-speech data, eliminating the need for separate alignment mechanisms. Additionally, due to the presence of pre-trained alignment, alignment-free voice conversion becomes possible.",
        "weaknesses": "The paper is somewhat helpful for community advancement, but I believe additional experiments could further demonstrate its validity and effectiveness. For example, some experiments like MOS, CMOS, and SMOS could be added to prove its effectiveness from a subjective perspective."
      },
      {
        "rating": "5",
        "confidence": "5",
        "summary": "The paper proposes a new way to pre-train an alignment-aware diffusion-based speech synthesis model. Instead of pre-training the model to inpaint the masked region without any conditions, the authors propose to train the models conditioned on deduplicated discrete HuBERT tokens and force the models to learn the alignment during training. The results show that the models can perform comparably to those without pre-training, all achieved without large-scale transcribed datasets. Additionally, the model can perform voice conversion directly after pe-training with high robustness and similarity to the reference speaker.",
        "strengths": "* **Originality**: The paper proposes a novel way to learn the alignment between phonetic representations and speech and shows that this pre-training scheme can transfer to high-quality text-to-speech synthesis with a small amount of transcribed data, while previous methods that do not incorporate alignment pre-training fails to do.\n\n* **Quality**: The paper has compared various models and conducted extensive experiments to examine the effectiveness of its models against several baselines, including E2TTS, without pre-training in a small amount of transcribed data and multi-lingual settings. \n\n* **Clarity**: The paper has an excellent presentation of its methods and results, avoiding overcompcaliting with mathematical definitions, making it fairly easy to follow. \n\n* **Significance**: The paper has shown that it is possible to achieve comparable performance to the most recent duration-free E2TTS without a large amount of transcribed data.",
        "weaknesses": "The major weakness is the contribution of this work seems incremental and does not demonstrate significant improvement over previous methods based on the argument presented in the paper. It is unclear what this pre-training scheme brings compared to previous methods such as SpeechFlow and E2TTS. There are a few arguments where the proposed alignment-aware pre-training can provide some advantages over previous methods. However, none of these seems to be fully supported by the results in the paper and existing literature:\n\n1. It can be argued that this pre-training scheme allows simple transfer learning without transcription of speech data for high-quality TTS. However, most existing large-scale TTS models do not rely on human-labeled data but instead use automatically transcribed data. For example, Chen et al. 2024 [1] trained E2TTS on Emilia [2], which is a 100k-hour multilingual dataset with transcriptions obtained through the ASR model WhisperX. Chen et al. 2024 show that E2TTS trained on ASR-transcribed data can obtain a WER of 2.95, which is not significantly different from 2.2 in the paper. Similarly, NaturalSpeech 3 [3] has achieved a WER of 1.81, even lower than ground truth with ASR-transcribed data. It is unclear whether this method is better than training directly on ASR-transcribed data from a practical point of view, either in terms of quality or training resources. For example, in Figure (b), E2TTS trained on transcribed data only needs to be trained for 700k steps to have comparable performance of A2-Flow pre-trained for 700k steps plus 150k fine-tuning steps. Since E2TTS can perform well on the ASR-transcribed dataset, this suggests that A2-Flow takes more time and resources for training while achieving similar performance as E2TTS. It would be helpful for the authors to demonstrate other performance advantages of A2-flow, such as comparing it to E2TTS trained on an ASR-transcribed dataset (which can also be considered unlabeled), or comparing the total amount of time and resources required for training (i.e., to show that the entire pipeline of pre-training + fine-tuning of A2-flow is more efficient than transcribing + training for E2TTS). \n\n2. It can be argued that this pre-training scheme allows for transferring learning in low-resource settings where transcribed data is limited. However, this advantage is not well supported in the paper either. It is well known that fine-tuning for a different language requires much less data than training it from scratch [4,5]. It is unclear whether this method is better than training E2TTS on a transcribed English dataset (which is enormous) and then fine-tuning it on a low-resource dataset (for example, French with 280 hours of data). \n\n3. It can be argued that this method removes alignment labels for TTS models compared to SpeechFlow. However, it is unclear whether the alignment labels are hard to learn to begin with. Forced alignment can be obtained with a CTC-based ASR model, and it is shown in HuBERT and WavLM that CTC-based ASR models can be trained with sufficiently high quality with limited labeled data (960 hours). The contribution of this work can be further enhanced if the author shows that SpeechFlow fine-tuned on CTC-based alignments obtained from a fine-tuning HuBERT on 960 hours of data is worse compared to A2-Flow without pre-defined alignments. \n\nIn addition, the subjective evaluations are rather weak. The authors only compared 19 samples of E2TTS and 9 samples of SpeechFlow and concluded that the model is comparable to E2TTS and better than SpeechFlow in Table 2, and no statistical significance is reported for this result. Most recent papers [1, 3] use at least 40 samples (including the E2TTS paper), so 9 samples are insufficient to establish statistical significance. Moreover, no subjective evaluation is conducted for naturalness but it is a common practice for evaluating the true performance of speech synthesis models, as most current objective evaluation metrics only correlate weakly with MOS. Since the authors claim to have reproduced E2TTS and SpeechFlow in the paper, the paper's argument can be further enhanced by comparing to more samples of E2TTS and SpeechFlow, even with reproduced models. \n\n**References**\n\n[1] Chen, Y., Niu, Z., Ma, Z., Deng, K., Wang, C., Zhao, J., ... & Chen, X. (2024). F5-TTS: A Fairytaler that Fakes Fluent and Faithful Speech with Flow Matching. arXiv preprint arXiv:2410.06885.\n\n> Note: This work was published after the ICLR deadline. However, since this work contains reproduced results from a cited paper (E2TTS), I believe this reference is relevant to this review. \n\n[2] He, H., Shang, Z., Wang, C., Li, X., Gu, Y., Hua, H., ... & Wu, Z. (2024). Emilia: An extensive, multilingual, and diverse speech dataset for large-scale speech generation. arXiv preprint arXiv:2407.05361.\n\n[3] Ju, Z., Wang, Y., Shen, K., Tan, X., Xin, D., Yang, D., ... & Zhao, S. (2024). Naturalspeech 3: Zero-shot speech synthesis with factorized codec and diffusion models. arXiv preprint arXiv:2403.03100.\n\n[4] Lux, F., Koch, J., & Vu, N. T. (2022). Low-resource multilingual and zero-shot multispeaker TTS. arXiv preprint arXiv:2210.12223.\n\n[5] Debnath, A., Patil, S. S., Nadiger, G., & Ganesan, R. A. (2020, December). Low-resource end-to-end sanskrit tts using tacotron2, waveglow and transfer learning. In 2020 IEEE 17th India Council International Conference (INDICON) (pp. 1-5). IEEE."
      },
      {
        "rating": "8",
        "confidence": "4",
        "summary": "The paper introduces A2-Flow, an alignment-aware pre-training method for flow matching models in speech synthesis. A2-Flow integrates alignment learning directly into the pre-training process using discrete speech units extracted from HuBERT. This approach enables the model to efficiently adapt to alignment-aware tasks such as text-to-speech (TTS) and voice conversion (VC) without the need for separate alignment mechanisms. The authors demonstrate that A2-Flow facilitates alignment-free VC and allows for faster convergence during TTS fine-tuning, even with limited transcribed data. Experimental results show that A2-Flow achieves superior zero-shot VC performance compared to existing models and matches state-of-the-art TTS performance using only a small amount of transcribed data. Additionally, the method is effective in multilingual settings, highlighting its scalability and practical applicability in low-resource scenarios.",
        "strengths": "1. Originality: The paper presents a novel approach by integrating alignment learning directly into the pre-training phase using discrete speech units. This method addresses the limitations of existing models that require external alignment mechanisms or extensive additional training.\n\n2. Quality: Extensive experiments support the effectiveness of A2-Flow. The model demonstrates superior performance in zero-shot voice conversion and matches state-of-the-art results in TTS with significantly less transcribed data.\n\n3. Clarity: The paper is generally well-organized and provides detailed explanations of the methodology, including the integration of discrete speech units and the flow matching framework. The inclusion of diagrams and ablation studies aids in understanding.\n\n4. Significance: A2-Flow offers a practical solution for high-quality speech synthesis in low-resource settings. By reducing the dependency on large amounts of transcribed data, it has substantial implications for multilingual and low-resource language applications.",
        "weaknesses": "1. Limited Baseline Comparisons: While the paper compares A2-Flow with several existing models, a more comprehensive comparison with other state-of-the-art methods, especially in multilingual settings, would strengthen the evaluation.\n\n2. Discussion of Limitations: The paper acknowledges some limitations, such as reliance on self-supervised speech units, but does not deeply explore potential solutions or future work to address these issues.\n\n3. Ablation Study Depth: The ablation studies could be expanded to include more variations in hyperparameters and architectural choices to better understand their impact on performance.\n\n4. Methodology Clarity: Certain aspects of the methodology, like the training details of the total length predictor and the timestep shifting strategy, could be explained in more detail to enhance reproducibility."
      },
      {
        "rating": "3",
        "confidence": "5",
        "summary": "The paper introduces A2-Flow, a alignment-aware pre-training method for flow matching models in speech synthesis. This approach facilitates alignment-free voice conversion and enhances convergence speed during TTS fine-tuning, making it particularly effective in low-resource settings.",
        "strengths": "1. Good presentation.\n2. One framework can solve VC and TTS tasks.",
        "weaknesses": "1. It is hard to understand what alignment-aware pre-training is and its advanteges.\n\n2. It is difficult to grasp the difference between using de-duplicated HuBERT tokens and text for pre-training. In my view, the only advantage is support for voice conversion tasks. However, the idea of a single model addressing multiple audio tasks has been widely discussed in previous works, such as VoiceBox, AudioBox. Thus, it is challenging to view this as a novel contribution.\n\n3. For the TTS task, this work still requires a sentence duration predictor to control duration. Such strategies have been widely used in diffusion-based TTS systems, including SimpleSpeech, DiTTo-TTS, and E3TTS, and so on.\n\nI am happy to discuss this paper further with the authors and other reviewers during the discussion stage."
      }
    ],
    "rating_avg": 5.5,
    "confidence_avg": 4.75,
    "decision": "Reject",
    "meta_review": "A2 Flow introduces an approach by using semantic tokens derived from unlabeled data for pre-training, aligning speech and text. This enables zero-shot text-to-speech (TTS) synthesis with minimal paired text-speech data and allows for alignment-free voice conversion. The integration of alignment learning directly into the pre-training phase using discrete speech units addresses the limitations of existing models that require external alignment mechanisms or extensive additional training. The paper is well-organized, providing detailed explanations of the methodology, including the integration of discrete speech units and the flow matching framework. Diagrams and ablation studies enhance understanding.\n\nHowever, the work appears incremental and does not show significant improvement over previous methods like SpeechFlow and E2TTS. A more comprehensive comparison with other state-of-the-art methods, especially in multilingual settings, would strengthen the evaluation. The paper acknowledges some limitations, such as reliance on self-supervised speech units, but does not deeply explore potential solutions or future work to address these issues. The ablation studies could be expanded to include more variations in hyperparameters and architectural choices to better understand their impact on performance.",
    "author_remarks": "",
    "decision_comment": ""
  },
  {
    "id": "NtwFghsJne",
    "title": "From Search to Sampling: Generative Models for Robust Algorithmic Recourse",
    "authors": [
      "Prateek Garg",
      "Lokesh Nagalapatti",
      "Sunita Sarawagi"
    ],
    "abstract": "Algorithmic Recourse provides recommendations to individuals who are adversely impacted by automated model decisions, on how to alter their profiles to achieve a favorable outcome. Effective recourse methods must balance three conflicting goals: proximity to the original profile to minimize cost, plausibility for realistic recourse, and validity to ensure the desired outcome. We show that existing methods train for these objectives separately and then search for recourse through a joint optimization over the recourse goals during inference, leading to poor recourse recommendations. We introduce GenRe, a generative recourse model designed to train the three recourse objectives jointly. Training such generative models is non-trivial due to lack of direct recourse supervision. We propose efficient ways to synthesize such supervision and further show that GenRe's training leads to a consistent estimator. Unlike most prior methods, that employ non-robust gradient descent based search during inference, GenRe simply performs a forward sampling over the generative model to produce minimum cost recourse, leading to superior performance across multiple metrics. We also demonstrate GenRe provides the best trade-off between cost, plausibility and validity, compared to state-of-art baselines. Our code is available at: https://github.com/prateekgargX/genre",
    "keywords": [
      "Algorithmic recourse",
      "explainability",
      "generative modelling"
    ],
    "venue": "ICLR",
    "year": 2025,
    "pdf_url": "https://openreview.net/pdf?id=NtwFghsJne",
    "forum_url": "https://openreview.net/forum?id=NtwFghsJne",
    "reviews": [
      {
        "rating": "6",
        "confidence": "4",
        "summary": "In this work, the authors propose a generative model designed for algorithmic recourse, which transforms a negative sample $\\mathbf{x}^-$ into a positive sample $\\mathbf{x}^+$. The resulting positive sample must satisfy the following criteria:\n\n- $\\mathbf{x}^+$ is a high-quality sample that adheres to the underlying data distribution.\n- $\\mathbf{x}^+$ is classified with a high probability as belonging to the positive class by a pre-trained classifier.\n- $\\mathbf{x}^+$ should be close to $\\mathbf{x}^-$ in the feature space.\n\nThe authors demonstrate that training a single model to simultaneously meet these objectives leads to improved overall performance compared to previous approaches.",
        "strengths": "Some strengths of this work include:\n\n- The development of a single generative model that converts negative examples into positive samples suitable for addressing the algorithmic recourse problem.\n- The model enhances the overall performance of recourse mechanisms.\n- The authors have anonymously open-sourced their codebase, allowing others to reproduce their approach.",
        "weaknesses": "## Clarity\nThe notation, definitions, and equations should be carefully rechecked. In the current form of the paper, the following points severely reduce the paper's readability, and the reader has to guess what is most likely implied.\n\n- Quantities are not properly defined.\n\n     1. In Eq. (2), the cost function employed in this work is not defined. What is the cost? Did the authors provide clarifications regarding its final form?\n     2. Line 251, $N^+$ is not defined.\n     3. Eq (6) what is $\\lambda$ values? \n     4. Algorithm 1, Line 290: what is $\\mathbf{x}$\n     5. Algorithm 2: Where is the projectCategoricals defined? What is $m_c$?\n     2. Algorithm 2: Line 5, is $k$ sampled? If yes, how?\n\n- Notation Consistency\n     1. Are the bin scales the same as bin widths? If yes, please be consistent.\n     2. Is $D_1$ the same as $N^+$\n     3. Alg. 1: Line 290: $\\mathbf{x}$ is not defined.\n     3. Alg. 2: Step 1: $\\mathbf{x}$ is not defined.\n     4. Eq (7) and (8) seem to have different K.\n     5. I suggest to limit the notation to $\\mathbf{x}^+$ and $\\mathbf{x}^-$ whenever possible.\n\n\n- Are you using a random forest or an MLP for the classifier? If you use both, in which case do you use the first and the second? What is the accuracy of each classifier?\n\n- For the baselines, how are the final checkpoints selected?\n\n- Something is weird; why do you select variance equal to zero (line 376)? This choice makes step 2 of Algorithm 2 redundant.\n\n## Experiments\n\n### Efficiency analysis\n- How does the proposed approach differ from prior work regarding the number of parameters, training time, and GPU/time requirements (during training/inference)?\n\n### Ablations\n- What is the benefit of using an autoregressive model for generation compared to other architectures? Did the author try a different setup? What is the models' performance for different generative architectures (non-autoregressive)?\n\n## Minor\n- Lines 557-560 double entry for the same paper.\n- Steps can be added to Alg. 1 similarly to Alg. 2.\n- Proofs can be moved to the appendix."
      },
      {
        "rating": "6",
        "confidence": "4",
        "summary": "The paper introduces GenRe, a generative-based approach to algorithmic recourse that seeks to optimize three core recourse objectives via joint training, including validity, proximity, and plausibility. The authors claim that previous method fail to unify all objectives into the training and instead use a gradient-based inference time searching technique that could lead to unsatisfying performance. GenRe uses an auto-regressive generative model to sample recourse solutions directly, with a hand-craft training objective defined with the cost function and the vanilla data distribution. The authors validate GenRe's performance through comprehensive experiments on synthetic and real-world datasets.",
        "strengths": "- First of all, the paper is well-written and organized, making it easily followed. The problem definition and motivation are presented clearly, allowing readers to understand the contribution.\n- Undoubtedly, the problem of recourse via AI is an important and open problem. It is also closely related to conditional generation, and consequently, the technical discussion (if useful) can be apply to a wide range of problems beyond.\n- I appreciate that the authors analyze their proposed method on various tasks, helping us to understand the performance of GenRe.",
        "weaknesses": "I think the major weaknesses are a lack of careful motivation of the proposed method, as well as a more direct comparison with methods beyond the field of algorithmic recourse (but can be directly applied). Specifically,\n\n- From the aspect of this specific problem (algorithmic recourse), if I understand correctly, the major improvement in the training process is the goal of Eq (4), which includes all properties that users care about (as well as the empirical distribution $Q(x^+|x)$ for sampling). However, to me, this task is different from sampling over $P(x|y=1)$ only because the additional cost function, $C(x,x')$ should be imposed. As a result, a very clear derivation is to sample from the distribution of $P(x|y=1)\\exp^{-\\lambda C(x,x')}$. The introduction of $V(x')$ seems to break the probabilistic explanation of the distribution, because $P(y=1|x)$ is naturally contained in $P(x|y=1)$ by the Bayesian law. In addition, the reason for choosing an auto-regressive model for sampling is also left unjustified, as sequential sampling is not a major concern in the problem. More justification (both intuitively and experimentally, and ideally, theoretically) of the technique selection is unavoidable. \n- From a more general sense of conditional generation, the problem of cost-aware sampling is not a novel problem and has been studied both in a general scenario and for specific generative models such as AR models or diffusion models. For instance, a direct method if to train a classifier-free diffusion model that allows sampling from $P(X,Y)$, and use a standard guidance technique (such that the $L_2$ norm like the CLIP score) to guide the diffusion process using $e^{-\\lambda C(X, X')}$. The proposed training technique for unpair data (Sec 4.1) is, in fact, a very standard processing technique that has been widely used, and the choice of AR model seems to be more strange than another generative model such as VAE and diffusion. Therefore, while I admit that joint training is a new approach (in this field, maybe), the author should compare with the above alternatives to see if the proposed method can outperform existing baselines. One paper for reference: [Learning from Invalid Data: On Constraint Satisfaction in Generative Models]. In addition, [Classifier-Free Diffusion Guidance] is a straight-forward go-to method to compare with."
      },
      {
        "rating": "6",
        "confidence": "3",
        "summary": "The paper introduces **GenRe**, a generative model that provides actionable, realistic recourse for individuals affected by automated decisions. By jointly optimizing for **proximity** (low cost), **plausibility** (realistic changes), and **validity** (desired outcomes), GenRe outperforms traditional methods that address these goals separately. Rather than using gradient-based search, GenRe generates recommendations through efficient sampling, offering robust, balanced recourse. The model's code is publicly available to support further research and applications.",
        "strengths": "GenRe effectively integrates proximity, plausibility, and validity into a single generative model, addressing the core challenges of algorithmic recourse in a unified way. This contrasts with traditional methods that optimize these objectives separately, offering a more balanced solution.\n\nBy using forward sampling instead of gradient-based search, GenRe reduces computational costs during inference. This makes the model more scalable and applicable to real-world scenarios where speed is crucial.\n\nThe paper demonstrates that GenRe achieves better trade-offs between cost, plausibility, and validity compared to existing methods, providing evidence of its effectiveness across multiple datasets and scenarios.\n\nThe authors have made their code available, promoting transparency and enabling other researchers to build on their work, which helps advance the field of algorithmic recourse.",
        "weaknesses": "While GenRe shows improvements in the tested scenarios, its generalizability to highly diverse datasets or domains with different types of constraints might require additional adjustments or fine-tuning.\n\nThe paper acknowledges the challenge of synthesizing recourse supervision for training, which may introduce assumptions or heuristics that could impact the model's robustness in practice.\n\nThe success of GenRe heavily depends on the quality of the generative model and the training data. If the data is biased or limited, the recourse recommendations might be less effective or skewed."
      },
      {
        "rating": "6",
        "confidence": "2",
        "summary": "This paper addresses the problem of algorithmic recourse for individuals adversely impacted by automated model decisions. It proposes a generative model based method to finish recourse task by directly sampling without optimization at inference. The main goal is to balance three objectives: proximity to the original profile to minimize cost, plausibility to ensure realistic changes, and validity to achieve the desired result. Experimental results shows its effectiveness.",
        "strengths": "* This paper provides a thorough analysis of the limitations in current algorithmic recourse methods, highlighting the challenges of separately optimizing proximity, plausibility, and validity, which often leads to suboptimal results. This establishes a solid foundation and motivation for the proposed method.\n* The GenRe method is intuitive and easy to implement and consistently providing more effective trade-offs among different factors.",
        "weaknesses": "1. **Advantage beyond Nearest neighbor**: The biggest issue is the neccessity of involving a complicated auto-regressive method. Essentially, this method uses a model to learn a smoothly-mixed version of nearest-neighbor search in positive samples. It lacks detailed analysis and ablation study for its advantage beyond simple KNN. Why should we bother to train a huge transformer instead of just finding the nearest valid sample and imitate it? I believe there are subtleties here because it requires some generalization stuff. But all these aspects are absent in the paper.\n2. **Interpretability Issue**: While GenRe is effective in balancing recourse objectives, the generative approach may lead to less interpretable outputs, especially for stakeholders who require clear, actionable insights. The model could benefit from an analysis of interpretability or user-friendliness of the generated recourse."
      }
    ],
    "rating_avg": 6.0,
    "confidence_avg": 3.25,
    "decision": "Accept (Poster)",
    "meta_review": "This paper proposes GenRe, a generative model approach to algorithmic recourse that aims to help individuals adversely impacted by automated decisions understand how to achieve more favorable outcomes. By jointly optimizing three objectives - proximity to the original profile, plausibility of changes, and validity of outcomes - through a generative model during training rather than during inference, GenRe can produce better recourse recommendations compared to existing methods that optimize these objectives separately. Empirically, GenRe outperforms baseline methods across multiple metrics on both synthetic and real datasets. The reviewers appreciated the problem motivation, thorough empirical validation across diverse datasets, and a novel technical contribution in framing recourse as a conditional generation task rather than an optimization problem. Key weaknesses identified by reviewers include: limited justification for using an autoregressive architecture over simpler nearest-neighbor approaches, lack of comprehensive comparison to broader conditional generation methods beyond the recourse literature, and insufficient analysis of model interpretability and computational efficiency trade-offs. Additionally, while the paper demonstrates improvements over baselines, some reviewers felt the gains may not fully justify the increased model complexity. A future version of the paper could benefit from more detailed ablation studies comparing different model architectures, analysis of computational costs versus performance benefits, and deeper investigation of interpretability aspects that are important for real-world deployment. Overall, the reviewers were in agreement to marginally accept the paper.",
    "author_remarks": "",
    "decision_comment": ""
  },
  {
    "id": "gyTkfVYL45",
    "title": "ICAM: Rethinking Instance-Conditioned Adaptation in Neural Vehicle Routing Solver",
    "authors": [
      "Changliang Zhou",
      "Xi Lin",
      "Zhenkun Wang",
      "Tong Xialiang",
      "Mingxuan Yuan",
      "Qingfu Zhang"
    ],
    "abstract": "The neural combinatorial optimization (NCO) has shown great potential for solving routing problems without requiring expert knowledge. However, existing constructive NCO methods still struggle to directly solve large-scale instances, which significantly limits their application prospects. To address these crucial shortcomings, this work proposes a novel Instance-Conditioned Adaptation Model (ICAM) for better large-scale generalization of neural routing solvers. In particular, we design a simple yet efficient instance-conditioned adaptation function to significantly improve the generalization performance of existing NCO models with a very small time and memory overhead. In addition, with a systematic investigation on the performance of information incorporation between different attention mechanisms, we further propose a powerful yet low-complexity instance-conditioned adaptation module to generate better solutions for instances across different scales. Experimental results show that our proposed method is capable of obtaining promising results with a very fast inference time in solving Traveling Salesman Problems (TSPs), Capacitated Vehicle Routing Problems (CVRPs) and Asymmetric Traveling Salesman Problems (ATSPs). To the best of our knowledge, our model achieves state-of-the-art performance among all RL-based constructive methods for TSPs and ATSPs with up to 1,000 nodes and extends state-of-the-art performance to 5,000 nodes on CVRP instances, and our method also generalizes well to solve cross-distribution instances.",
    "keywords": [
      "Vehicle Routing Problem",
      "Reinforcement Learning",
      "Instance-Conditioned Adaptation",
      "Neural Combinatorial Optimization",
      "Large-scale Generalization"
    ],
    "venue": "ICLR",
    "year": 2025,
    "pdf_url": "https://openreview.net/pdf?id=gyTkfVYL45",
    "forum_url": "https://openreview.net/forum?id=gyTkfVYL45",
    "reviews": [
      {
        "rating": "5",
        "confidence": "4",
        "summary": "This paper presents ICAM, a simple, efficient instance-conditioned adaption function to improve the generalization performance of existing NCO models for solving routing problems. They further propose a low-complexity instance-conditioned adaption module to generate better solutions for different scale instances. The authors claim and demonstrate that it achieves state-of-the-art performance among all RL-based constructive methods for TSPs, ATSPs (up to 1000 nodes), and CVRPs (up to 5000 nodes).",
        "strengths": "- The overall presentation and writing are good.\n- The reported results show that ICAM is capable of obtaining promising results with a reasonable inference time in solving TSP, CVRP, and ATSP.\n- This method can improve the performance of RL-based constructive neural solver, i.e., POMO, for TSP and ATSP up to 1000 nodes and 5000 nodes on CVRP instances.",
        "weaknesses": "- In the Introduction (lines 84-91), the authors state that all the previous methods that utilize the node-to-node distances to bias the output score in the decoding phase or refine the information via a complex policy fail to achieve satisfactory generalization performance on large-scale instances. This statement appears inaccurate, as these methods, e.g., ELG [1], are known to achieve state-of-the-art generalization performance on large-scale TSP and CVRP instances.\n- In the adaption function, the learnable parameter $\\alpha$ plays important role in this function. This paper lacks clarity on how this parameter is learned during training, and a detailed analysis is necessary to assess its impact.\n- In experiments, this paper uses a three-stage training scheme for the proposed model. Stages 1 and 2 are not new and are similar to the training techniques in DAR [2]. In stage 3, there are two additional parameters, i.e., $\\beta$ and $k$. The authors claimed that there is no significant performance variation among different models with various $k$ values. This raises a concern about the impact of the best $k$ trajectories among all $N$ trajectories on the performance of the model.\n- Furthermore, additional training may make the results unfair to compare the performance with other existing baseline models. The results of baseline models with expanding training should be reported and compared.\n- The author only reported the results of baseline models, e.g., LEHD [3] and BQ [4], with greedy search inference for TSP and CVRP with scale <=1000 (Table 3). However, these models achieve their best performance with the RRC strategy and beam search, respectively. According to these works, the results obtained from these baselines can surpass the ICAM results. The authors should report these results for comprehensive comparisons.\n- With scales >1000 (Table 5), the results of the baseline ELG are lacking, while ELG demonstrated superior performance on large-scale CVRP instances up to 7000 nodes. However, the best results obtained by ICAM do not seem much better than those obtained by LEHD with greedy inference. It makes the results of ICAM on CVRP instances with a scale range from 1000 to 5000 not persuasive.\n- In the results on the benchmark dataset, this paper just evaluates the performance on a small-scale dataset of CVRPLIB Set-X (scale <=1000). The performance on larger scale datasets, such as CVRPLIB Set-XXL with larger scales (1000 to 7000 nodes) should be evaluated and analyzed.\n- The same concern about results for TSPLIB, the author only reported the results on instances with scale <=1000, which limits the large-scale generalization performance on larger scales (>1000) in the TSPLIB. This evaluation is important to verify the good generalization of the proposed method on large-scale Routing problems, e.g., TSP and CVRP.\n- In the ablation study on the effects of larger training scales, the authors only report the results for TSP and not for CVRP. The proposed varying scale training on CVRP should be carefully designed and investigated because CVRP has more complex features than TSP, such as varying demand at each node, which may destabilize the learning model when exposed to multiple sizes and demand distributions simultaneously.\n- No code is available.\n\n\n**References:**\n[1] Chengrui Gao, Haopu Shang, Ke Xue, Dong Li, and Chao Qian. Towards generalizable neural solvers for vehicle routing problems via ensemble with transferrable local policy. In International Joint Conference on Artificial Intelligence, 2024.\n\n[2] Yang Wang, Ya-Hui Jia, Wei-Neng Chen, and Yi Mei. Distance-aware attention reshaping: En- hance generalization of neural solver for large-scale vehicle routing problems. arXiv preprint arXiv:2401.06979, 2024.\n\n[3] Neural combinatorial optimization with heavy decoder: Toward large scale generalization. In Thirty-seventh Conference on Neural Information Processing Systems, 2023.\n\n[4] Darko Drakulic, Sofia Michel, Florian Mai, Arnaud Sors, and Jean-Marc Andreoli. Bq-nco: Bisim- ulation quotienting for efficient neural combinatorial optimization. In Thirty-seventh Conference on Neural Information Processing Systems, 2023."
      },
      {
        "rating": "5",
        "confidence": "4",
        "summary": "The paper proposes the Instance-Conditioned Adaptation Model (ICAM) to enhance the generalization performance of reinforcement learning-based neural combinatorial optimization (NCO) models, particularly for vehicle routing problems (VRPs). The model leverages a novel instance-conditioned adaptation function and replaces the traditional multi-head attention (MHA) with the Adaptation Attention Free Module (AAFM). While ICAM demonstrates competitive empirical results and scalability, several aspects remain insufficiently explored.",
        "strengths": "1. The proposed ICAM shows promising results on VRPs with larger scales, successfully extending the capability of RL-based NCO methods to tackle instances with up to 5,000 nodes, which contributes positively to the ongoing effort of solving large-scale combinatorial optimization problems.\n2. Introducing an adaptation function to incorporate instance-specific information into the optimization process is an interesting idea that can potentially improve the solution quality for diverse problem scales.",
        "weaknesses": "1. While the paper presents a new model named ICAM, its innovative contributions appear limited in scope. Specifically, the proposed modifications primarily target the adaptation function and attention mechanism, and these incremental changes might not be sufficient to demonstrate a significant advancement over existing RL-based NCO methods.\n2. The term \"comprehensive instance-conditioned information\" is not clearly defined. The paper states that using only \"node-to-node distances or scale information is insufficient.\" However, in the proposed adaptation function, these are the only two types of information used. There is no addition of new forms of instance-specific information beyond these, which seems to contradict the paper's claims of comprehensive information usage.\n3. The design choices for both the adaptation function and the attention mechanism lack rigorous theoretical analysis.\nIn the \"Results on Benchmark Dataset\" section, the performance on TSPLIB is not particularly competitive compared to some of the state-of-the-art methods. The reasons for this subpar performance should be further analyzed.\n4. The writing, particularly in the contribution section and the motivation (Section 2.1), includes several redundant explanations. A more concise presentation of the contributions and key ideas would improve readability."
      },
      {
        "rating": "8",
        "confidence": "4",
        "summary": "This paper proposes an instance-conditioned adaptation method for large-scale generalization of RL-based neural routing solvers. ICAM introduces a simple yet efficient adaptation function to improve the generalization of existing NCO models with a very small time and memory overhead. Additionally, a lightweight Adaptation Attention Free Module (AAFM) is integrated into the encoder-decoder structure for better incorporation of instance-conditioned information, replacing the Multi-Head Attention (MHA). Extensive experimental results show that the proposed ICAM achieves promising performance on large-scale TSP, CVRP, and ATSP instances, offering a fast inference time and significant improvement over existing methods.",
        "strengths": "1. This paper is well-written and easy to follow.\n\n2. The proposed ICAM is a novel approach  for improving the generalization of RL-based neural routing solvers across different scales. This is an important advancement in tackling the challenges faced by current methods when dealing with large-scale instances. \n\n3. The proposed adaptation function and model structure are both well-motivated and very useful for solving large-scale routing problems.\n\n4. The experiments are comprehensive, demonstrating its good generalization properties.",
        "weaknesses": "1. According to Table 2, the proposed adaptation function can effectively improve the generalization of POMO with a small time and memory overhead.  Obviously, just depending on node-to-node distances is not enough, but I am curious which has a greater effect, the scale information or the learnable parameter? It would be interesting to compare the effects if either the scale information or the learnable parameter is removed.\n\n2. This paper uses the proposed adaptation function for the proposed AAFM and subsequent compatibility calculation. Considering that there is already some works on incorporating auxiliary information into the compatibility calculation (as shown in Table 1), it would be beneficial to evaluate the performance of this function when it is only used in AAFM.\n\n3. This paper adopts a three-stage training scheme, what is the effect of each stage on the performance?"
      },
      {
        "rating": "6",
        "confidence": "4",
        "summary": "This paper proposes a new method, ICAM, which aims to enhance the generalization capabilities of neural solvers on large-scale vehicle routing problem instances. Specifically, it designs an instance-conditioned adaptation function that considers both the node-to-node distances and instance scales simultaneously, and integrates it into the proposed ICAM to enrich it with auxiliary information. Furthermore, it adapts the Attention Free Transformer (AFT) and proposes the Adaptation Attention Free Module (AAFM), aiming to achieve better efficiency in handling large-scale instances. Experimental results in this paper show that the proposed ICAM can outperform prevailing competing methods.",
        "strengths": "The paper is well-written and easy to follow. Compared with previous methods, the proposed method ICAM demonstrates better optimality gap and efficiency on TSP and CVRP.",
        "weaknesses": "1. As previous works have already demonstrated that integrating node-to-node distances and instance scales into neural solvers can improve generalization performance on large-scale instances, the novelty of the proposed instance-conditioned adaptation function is very limited. Meanwhile, the proposed AAFM is also a simple adaptation from previous method AFT. Given these considerations, I am concerned that this paper may not provide valuable insights to the NCO community. \n2. The three-stage training scheme seems to be crucial for achieving the experimental results reported in this paper. However, it is notable that the results from competing methods are typically obtained under much simpler settings. Although the ablation studies in Table 19 demonstrate that ICAM can outperform POMO-ThreeStage, it is also evident that three-stage training significantly enhances POMO's performance on large-scale instances. This raises a concern regarding whether other competing methods might similarly benefit from a three-stage training approach. A direct comparison using consistent training settings can make the reported experimental results much more convincing."
      }
    ],
    "rating_avg": 6.0,
    "confidence_avg": 4.0,
    "decision": "Reject",
    "meta_review": "This paper proposed a instance conditioned adaptation method to enhance the generalization ability of neural vehicle routing models. The proposed method has the strengths of being simple but effective, achieving good empirical performance. However, as mentiond by most reviewers, the technical novelty is not sufficient enough to warrant acceptance to ICLR. It largely relies on existing lightweight attention techniques, and the proposed instance-conditioned adaptation function is heuristic without much theoretical foundation. In addition, the varying-size and three-stage training scheme plays an important role in performance improvement, which seems irrelavent to the instance-conditioned theme. Overall, this is a boarderline paper, and the reasons of rejection outweight that of acceptance.",
    "author_remarks": "",
    "decision_comment": ""
  },
  {
    "id": "XwibrZ9MHG",
    "title": "PokeFlex: A Real-World Dataset of Deformable Objects for Robotics",
    "authors": [
      "Jan Obrist",
      "Miguel Angel Zamora Mora",
      "Hehui Zheng",
      "Ronan Hinchet",
      "Firat Ozdemir",
      "Juan Jose Zarate",
      "Robert K. Katzschmann",
      "Stelian Coros"
    ],
    "abstract": "Data-driven methods have shown great potential in solving challenging manipulation tasks, however, their application in the domain of deformable objects has been constrained, in part, by the lack of data. \nTo address this, we propose PokeFlex, a dataset featuring real-world paired and annotated multimodal data that includes 3D textured meshes, point clouds, RGB images, and depth maps. Such data can be leveraged for several downstream tasks such as online 3D mesh reconstruction, and it can potentially enable underexplored applications such as the real-world deployment of traditional control methods based on mesh simulations.\nTo deal with the challenges posed by real-world 3D mesh reconstruction, \nwe leverage a professional volumetric capture system that allows complete 360° reconstruction. PokeFlex consists of 18 deformable objects with varying stiffness and shapes. Deformations are generated by dropping objects onto a flat surface or by poking the objects with a robot arm. Interaction forces and torques are also reported for the latter case. \nUsing different data modalities, we demonstrated a use case for our dataset in online 3D mesh reconstruction. We refer the reader to our  [website](https://anonymized-pokeflex-dataset.github.io/) or the  [password protected supplementary material](https://drive.google.com/drive/folders/1d8iNoJZ0dUVlzP6XxP7xwGPhdVtwQ7du) for further demos and examples (password in pdf).",
    "keywords": [
      "Deformable objects",
      "Robotics",
      "3D mesh reconstruction."
    ],
    "venue": "ICLR",
    "year": 2025,
    "pdf_url": "https://openreview.net/pdf?id=XwibrZ9MHG",
    "forum_url": "https://openreview.net/forum?id=XwibrZ9MHG",
    "reviews": [
      {
        "rating": "5",
        "confidence": "4",
        "summary": "The paper introduces PokeFlex, a new dataset focused on real-world deformable objects for robotics applications. The dataset includes:\n\n- Multimodal Data: 3D textured meshes, point clouds, RGB images, and depth maps.\n- Objects: 18 deformable objects with varying stiffness and shapes, including everyday items and 3D-printed objects.\n- Interaction Protocols: Deformations induced by poking with a robot arm (with force/torque data) and dropping onto a flat surface.\n- Purpose: For downstream tasks like online 3D mesh reconstruction and enable applications such as real-world deployment of control methods based on mesh simulations.\n- Data Acquisition: A volumetric capture system for 360 deg. reconstruction and integrates lower-cost RGB-D sensors for reproducibility.\n- Baseline Models: Shows the use of PokeFlex in online 3D mesh reconstruction using different data modalities and provides evaluation criteria.",
        "strengths": "- Rich, Real-World Dataset: PokeFlex offers a comprehensive multimodal dataset with 3D meshes, point clouds, RGB images, depth maps, and force/torque measurements, captured with a high-quality volumetric system. This real-world data bridges the sim-to-real gap, enhancing applicability in deformable object manipulation.\n- Reproducibility and Accessibility: Open-source 3D-printed objects and affordable sensors (Azure Kinect, Intel RealSense) make the dataset accessible and reproducible, while baseline models and evaluation metrics support benchmarking and further robotics research.",
        "weaknesses": "- Limited Object Diversity: While the dataset includes 18 objects, the diversity may still be limited compared to the vast range of deformable objects encountered in real-world applications. Notably, the dataset focuses on volumetric objects and excludes thin deformable items like cloth or cables, which are important in areas like garment handling.\n- Controlled Interaction Protocols: The poking and dropping protocols are specific and may not capture the full spectrum of possible deformations in less controlled or more complex environments. Additional manipulation actions could enrich the dataset.\n- Potential Bias in Data Collection: The use of a transparent acrylic stick for poking and specific dropping heights might introduce biases that limit the generalizability of the dataset to other types of interactions and objects.\n- Related Work Coverage: The paper could benefit from a more thorough comparison with existing datasets and approaches in the literature, such as DOFS [1], CEPB [2], and other relevant works on deformable object datasets and manipulation. Discussing how PokeFlex complements or improves upon these datasets would strengthen the contribution.\n\nReferences:\n[1] Zhang, Zhen, et al. \"DOFS: A Real-world 3D Deformable Object Dataset with Full Spatial Information for Dynamics Model Learning.\" arXiv preprint arXiv:2410.21758 (2024).\n[2] Tripicchio, Paolo, Salvatore D’Avella, and Carlo Alberto Avizzano. \"CEPB dataset: a photorealistic dataset to foster the research on bin picking in cluttered environments.\" Frontiers in Robotics and AI 11 (2024)."
      },
      {
        "rating": "3",
        "confidence": "4",
        "summary": "In this paper, the authors collected a real-world multimodal dataset of 18 deformable objects. The dataset includes 3D textured meshes, point clouds, RGB images and depth maps.The authors use a volumetric capture system to build the 360degree reconstruction. It includes two types of deformation, poking and dropping. \n\nThe author further use the dataset to train neural network models for deformed mesh reconstruction based on template meshes and different modalites included in the dataset. The neural network model architecture is reasonable and the perforamnce is good on the different trajectories of the same objects.",
        "strengths": "The main advantage of this dataset is that it contains paired 3D meshes and contact forces. They further design a deformation mesh reconstruction method which takes the template mesh and force or image of point cloud sequece as input. By using the GT deformation meth for training, the trained model performs good on different trajectoris of the same objects.",
        "weaknesses": "1. According to Table2, the academic value and the difference between the submsion and PLUSH(Chenetal.,2022) should be further discussed, since it is not difficult to reconstruct the meshes from point clouds. Why do we need the mesh? What other application can it enable on top of deformation reconstruction?\n\n2. The generalizability of the network on unseen objects is not evaluated, which may be the most valuable part of the model. If the model can only work on trained objects, the usefulness of this method is very limited.\n\n3. The technical novelty of the network model is limited and not validated through ablation studies."
      },
      {
        "rating": "5",
        "confidence": "3",
        "summary": "The paper presents PokeFlex, a dataset that features real-world paired and annotated multimodal data, including 3D textured meshes, point clouds, RGB images, and depth maps. This dataset aims to enhance various downstream tasks and to demonstrate its effectiveness in online 3D mesh reconstruction.\nPokeFlex consists of 18 deformable objects with varying stiffness and shapes. Deformations are generated by dropping these objects onto a surface or by interacting with them using a robot arm, with corresponding interaction forces and torques recorded. Additionally, the authors introduce a novel deep learning model to tackle 3D mesh reconstruction using diverse input data types.",
        "strengths": "The PokeFlex dataset stands out as an original contribution to the field. It features a diverse set of objects, including 3D-printed and everyday objects. This variety enriches the dataset and makes it applicable to a wide range of research scenarios. The inclusion of different types of input data—such as 3D textured meshes, point clouds, RGB images, and depth maps—enhances its utility for various downstream tasks.\nThe paper clearly conveys the significant effort involved in acquiring this dataset, highlighting the meticulous process behind its compilation. Additionally, the introduction of an innovative deep learning model to address 3D mesh reconstruction challenges is particularly noteworthy, showcasing the authors' commitment to advancing the field. Furthermore, the paper is well-structured and easily readable, making it accessible to a broad audience.",
        "weaknesses": "The paper presents results for only a limited subset of the 18 objects in the PokeFlex dataset—showing performance for just one object in some instances, five in others, and graphs for three. To better assess the dataset's overall effectiveness, it would be beneficial to provide results for all objects. This comprehensive analysis would establish a solid baseline for future comparisons.\nMoreover, the choice of a transparent acrylic stick used to poke was not adequately justified or discussed. The implications of this choice on RGB and depth data need more attention, particularly regarding how reflection and refraction may distort images and how time-of-flight depth readings may be inaccurate around the stick.\nTo further evaluate the dataset's effectiveness, it would be helpful to have a benchmark model trained on the dataset itself to determine its robustness and construction quality. While the paper mentions the \"dropping\" method, the experiments reported focus solely on \"poking.\" Including results from the dropping method would provide additional insights into the dataset's applications.\nAdditionally, the model that utilizes multiple data modalities only explored combinations of images and robot data. It would be interesting to see how other combinations of data types perform. \nMoreover, in Equation 3, the threshold epsilon is not defined, nor is there clarity on how values like 0.2 or 0.5 are determined. Addressing these points would enhance the clarity and rigor of the research.\nAdditionally, several citations in the references appear to be incorrect or improperly formatted, specifically the third, thirteenth, fourteenth, eighteenth, and twenty-ninth citations.\nAnother point concerns object licensing: one of the objects (Stylized pizza slice) in the dataset is reportedly subject to a non-distributable license, yet this restriction is not noted. This oversight may lead to potential misuse or distribution issues.\nFinally, neither the full dataset nor the trained deep learning model is currently available, which limits reproducibility. The sample dataset provided in the supplementary materials includes only one object, a dice, rather than a representative subset or the entire collection. Making the full dataset and model accessible would not only improve transparency but also enable a more comprehensive evaluation by the research community."
      },
      {
        "rating": "3",
        "confidence": "4",
        "summary": "The paper mainly introduce a deformable objects realworld datasets featuring real-world paired and annotated multimodal data. The datasets can be mainly used for online 3D mesh reconstruction. The dataset has different data modalities and is primarily collected using a professional capture system, with the collection process also incorporating cameras such as Kinect and RealSense, and simultaneously synchronizing with the robotics system. The paper further shows the application of this datasets on mesh reconstruction and has comprehensive evaluation of learning-base reconstruction.",
        "strengths": "+ RealWorld dataset: The most prominent feature of this paper is that it presents a real-world dataset featuring real-world meshes. Benchmarks for real-world meshes in robotics are relatively scarce. Additionally, the paper demonstrates good reproducibility, providing detailed 3D printing information in the appendix.\n+ Multimodal and Rich: Furthermore, this dataset is a multimodal dataset that, in addition to using high-cost acquisition systems, incorporates the commonly used RealSense camera as an eye-in-hand sensor and the Kinect as an eye-on-base sensor. The settings align well with robotic tasks and visual tasks within the field.\n+ Comprehensive evaluation on reconstruction task: Finally, the paper conducts detailed experiments on reconstruction tasks, including the use of RGB data and multimodal data.",
        "weaknesses": "+ The purpose of the dataset: One major issue with this paper is that it seems there are few other application tasks beyond online mesh reconstruction for which the dataset can be utilized.  Although online mesh reconstruction is an interesting computer vision task in itself, it appears that there are few practical applications for online mesh reconstruction. Therefore, this work seems to fall short of expectations in various fields. I will elaborate on this point from three different areas.\n     + robotics: In robotics, especially in the field of deformable object manipulation, meshes are rarely used; point clouds are more commonly employed[2][3][4]. The main challenges in this area are often related to occlusion and pose estimation issues. For example, Garment Tracking [1] addresses the problem of garment point cloud completion, but this work does not seem to tackle occlusion problems, thus reducing the significance of online mesh reconstruction in this context.\n     + CV: This task has limited difficulty in the computer vision field, primarily because the occlusion problem is less significant and the deformation of plush toys is minimal compared to garments. For instance, in dropping tasks, there appear to be only translational and rotational changes. Real-time 6D pose detection has already been extensively studied, so this part of mesh reconstruction can be easily addressed using mesh + pose estimation techniques.\n+ Number of object: The scale of 18 objects is small, and each object providing only two trajectories (poking and dropping) results in a limited data size. This makes it difficult to serve as a large-scale evaluation and can only be used for real-world fine-tuning. Papers in similar categories  such as garmentlab[2] have scanned nearly 100 objects, including at least 20 complex plush toys.\n+ Object Selection: The deformable objects chosen for this paper are somewhat too simple. There are many more complex plush toys, such as teddy bears, which could also be used for these tasks and would better reflect real-world scenarios. These more complex objects often involve occlusion issues, making the work more meaningful. Most of the objects selected in this paper are simple shapes like cubes or cylinders, which limits the scope and applicability of the task.\n+ Action Selection: The actions chosen, poking and dropping, are overly simplistic and lack practical value, especially in the robotics domain. The paper could benefit from including more complex actions, such as pick-and-place, which would add significant practical value and better reflect real-world robotic tasks.\n+ Simulation Evaluation: The authors mention in the paper that existing simulation methods require real-world fine-tuning. However, simulations actually perform very well in tasks such as dropping and poking, for example, using the FEM algorithm in IsaacSim. The authors need to include validation within simulators to verify whether the meshes scanned in the paper can be used for simulation and to conduct a thorough analysis of the differences between current simulation algorithms and real-world conditions. This would strengthen the setting of the paper.\n+ Action Protocol: The action protocol in this paper is vague. I recommend that the authors follow established protocols from datasets like YCB or GarmentLab[2] to refine and standardize their action protocols. This would enhance the clarity and reproducibility of the experiments.\n\n[1] GarmentTracking: https://github.com/xiaoxiaoxh/GarmentTracking\n\n[2] GarmentLab: https://garmentlab.github.io/\n\n[3] UniGarmentManip: https://warshallrho.github.io/unigarmentmanip/"
      }
    ],
    "rating_avg": 4.0,
    "confidence_avg": 3.75,
    "decision": "Reject",
    "meta_review": "This paper introduces a dataset called PokeFlex, which contains real-world deformation data for 17 objects, captured through poking and dropping. The dataset includes various modalities of data, such as reconstructed 3D meshes, forces/torques, RGB images, and depth images. The authors describe how the data was collected and discuss potential applications of the dataset, such as deformation prediction.\n\nAll reviewers gave negative scores and raised similar concerns about the usability of the proposed dataset, particularly due to the limited number of objects, the diversity of objects, and the range of actions. Despite the experimental results and additional experiments presented in the rebuttal, the reviewers were not convinced about the dataset’s usability, and the AC concurs with the reviewers' consensus. As a result, the AC made the decision to reject the submission.",
    "author_remarks": "",
    "decision_comment": ""
  },
  {
    "id": "5f0n5yi8qK",
    "title": "Training Open-ended Policies to follow Video-prompt Instructions with Reinforcement Learning",
    "authors": [
      "Kaichen He",
      "Bowei Zhang",
      "Zihao Wang",
      "Shaofei Cai",
      "QIANG FU",
      "Haobo Fu",
      "Anji Liu",
      "Yitao Liang"
    ],
    "abstract": "In recent years, online reinforcement learning(RL) training methods like PPO have shone in important works such as Instruct GPT. However, unlike the success achieved in the language domain, online RL methods often struggle to generalize to untrained tasks in open-world environments like Minecraft, due to issues like overfitting. This has become a significant obstacle in using online methods to build a generalist agent. In this work, we notice the modality differences between natural language environments and embodied environments such as the Minecraft environment, which inspired us to use video instructions instead of text instructions to enhance the model's understanding of the relationship between the environment and instructions. We also introduce a new attention layer in the base model's encoder-decoder architecture to establish a semantic and visual dual-path information interaction channel, further strengthening this generalization capability. After training our model on a small set of tasks, it demonstrated excellent zero-shot generalization on new tasks, outperforming almost all other models in the Minecraft environment on our benchmark. Our approach takes a solid and important step toward unleashing the potential of online RL in building generalist agents.\nzero-shot generalization on new tasks, outperforming almost all other models in\nthe Minecraft environment on our benchmark. Our approach takes a solid and\nimportant step toward unleashing the potential of online RL in building generalist\nagents.",
    "keywords": [
      "Online reinforcement learning，open-ended environment，pretrained video conditioned policy"
    ],
    "venue": "ICLR",
    "year": 2025,
    "pdf_url": "https://openreview.net/pdf?id=5f0n5yi8qK",
    "forum_url": "https://openreview.net/forum?id=5f0n5yi8qK",
    "reviews": [
      {
        "rating": "3",
        "confidence": "3",
        "summary": "This paper explores the use of video demonstrations as a method for improving the generalization ability of agents in open-ended multi-task learning environments. The authors argue that by providing agents with video prompts, they can learn to perform a wider range of tasks, even those not explicitly seen during training. The paper presents experiments in Minecraft to demonstrate the effectiveness of their approach.",
        "strengths": "- Introduces a novel dual-pathway architecture (semantic + visual) that appears to meaningfully improve within-category generalization performance\n- Identifies and addresses a specific failure mode in encoder-decoder models where the latent space overfits to a \"task vocabulary\" during online finetuning\n\nThese technical contributions represent meaningful progress in improving generalization within structured task categories if one has access to video prompts of the desired task.",
        "weaknesses": "By providing the agent with a video of the task it needs to perform, the agent is given a step-by-step demonstration of what is expected, and must only learn to parse the action sequence contained in the human-provided video prompt at inference time.\n\nDoing this is not entirely without merit: this may well be a non-trivial problem to solve if the prompt is out of distribution with respect to the training data. \n\nHowever, I am not convinced that solving this problem is at all relevant to open-endedness: the proposed agent relies on being provided a concrete sequence of actions to take (contained in the video), but that is precisely what one hopes that agents can discover autonomously.\n\nIn other words, access to the video prompts that would be required in this set up does not seem feasible in practice, so I fail to understand the real-world relevance of this technical contribution. \n\nThe reason language prompts are prevalent in the literature is because natural language allows conveying arbitrarily abstract ideas, so requiring natural language prompting is a less strict limitation, as long as the agent can interpret abstract goals. (Though this is still debatable, as ultimately open-endedness is about creating new goals.)\n\nIn order to strengthen these results, the authors would have to argue how obtaining these video prompts without human intervention would happen, and how this would still be relevant despite the limitations of imitation learning. For example, in a multi-agent setting, one could show that one can build an agent that wanders observing other players, scores what interesting new observed skills to learn, and utilizes the proposed methodology to internalize these skills.\n\nI have a few other qualms with the methodology and soundness of the claims, but these seem second-order considerations given the above.\n\nI may well have misunderstood the motivation and relevance of the work. If this is the case, perhaps the authors can clarify the problem statement and any other relevant details to highlight the relevance of the contributions to the field of open-ended reinforcement learning, and I would be very happy to re-assess their technical contributions more fairly.\n\nI also encourage the authors to improve their writing and organization of the manuscript."
      },
      {
        "rating": "3",
        "confidence": "3",
        "summary": "This paper builds on the GROOT encoder-decoder architecture by proposing novel attention layers to extend a semantic and visual dual-pathway structure within the base model. This enhancement significantly boosts the generalization capabilities of the video instruction model for online reinforcement learning (RL). The proposed method demonstrates substantial improvements in zero-shot generalization, achieving success rates of 69.1%, 16.0%, and 67.7% across three categories of unseen tasks in the Minecraft environment.",
        "strengths": "1. This work addresses a critical challenge in online reinforcement learning (RL): zero-shot generalization.\n2. The proposed dual-pathway model architecture offers more fine-grained visual concepts as instructional signals, thereby enhancing the generalization capabilities of the base model. \n3. Some quantitative results validate the effectiveness of the dual-pathway attention mechanism in enhancing the generalization capabilities of instruction-tuning models.",
        "weaknesses": "$\\textbf{Lack of Clarity in the experimental section:}$\n\n1. The clarity of the ablation section needs improvement. For instance, the authors should clarify the settings for \"with Attention\" and \"No Attention\" in the ablation study on intention-aware attention.\n\n2. In the ablation analysis of intention-aware attention, it appears that \"No Attention\" is equivalent to the base policy model GROOT. If this is not the case, has the proposed method refactorized the projection of latent z to address the limited feature dimension for enhancing generalization?\n \n3. The ablation section on the base policy contains some confusing aspects regarding the baseline policy. The paper states, \"Given GROOT’s outstanding ability to follow video instructions, we chose it as our base policy\" (line 175). It seems that GROOT is intended as the comparison baseline in the ablation for the base policy. However, the analysis compares the dual-pathway architecture to STEVE1 and STEVEv, which is not a fair comparison since the dual-pathway architecture is not the only controlled variable between STEVE and the proposed model.\n\n$\\textbf{Additional experimental analysis:}$\nI recommend including an ablation study on the KL term \"between the current policy and the original policy,\" as this would further validate the effectiveness of the KL constraint for the agent.\n\nWhile the proposed method shows promising direction to enhancing the generalization capabilities of video instruction-based online RL, the paper lacks clarity regarding key components, such as the policy model architecture. This causes limitations in both the reproducibility and readability of the proposed method. Furthermore, some experimental settings are not normative to ablation study, or lack a detailed analysis of each design (e.g., objective function). The above reasons lead me to conclude that the current version of the manuscript is not suitable for publication; therefore, my rating tends to be below the accepted threshold."
      },
      {
        "rating": "3",
        "confidence": "3",
        "summary": "This paper proposes to train agents with video demonstrations, rather than textual instructions, on Minecraft. Despite some potentially interesting results, the presentation of the paper is very confusing which makes it difficult to evaluate, and it does not meet the bar for publication at ICLR. Therefore, my recommendation is reject. I have included a detailed list of questions which hopefully can help improve the presentation.",
        "strengths": "- Overall, it’s good to see work on Minecraft, since it is one of the more challenging decision-making environments available. \n- The idea of using video instructions is reasonable, since giving examples of the desired behavior is often easier than specifying a reward function.",
        "weaknesses": "The presentation of the paper is very confusing with many important details missing, in addition to formatting issues and typos. As such, it is difficult to understand how exactly the method is working and if the comparisons make sense and are fair. It's also unclear what data they are using, and if the baselines all have access to the same data. Finally, standard methodological criteria such as including error bars are not met. Please see my detailed list of question below."
      },
      {
        "rating": "5",
        "confidence": "3",
        "summary": "The paper explores applying video instructions to open-ended policies for better generalization. However, a naive method of training the policy results in poor generalization due to the latent space mainly capturing semantic features, while neglecting the fine-grained visual features. To mitigate this, the paper proposes intention aware attention architecture where the model attends to both visual and semantic features through cross-attention. The model is trained with online RL method. Results show that the proposed model significantly outperforms baseline models on Minecraft tasks.",
        "strengths": "- The proposed method significantly outperforms baseline models on three minecraft tasks.\n- The paper evaluates the performance on both success and accuracy metric, making the evaluation setup solid and fine-grained.",
        "weaknesses": "- The paper contains many grammar errors and typos which significantly hinders the readability of the paper. For example, line351-353 and line358-360 are identically the same. / Table 1 (Generalizaiton -> Generalization) / Caption of Figure 3 / many capitalization errors (However, In -> However, in (line 149), VPT work, In such -> VPT work, in such (line 209)) / The numberings of the figures in the main text is not aligned with the paper text (line 420 Figure 4.3 -> Figure 5 / line 431 Figure 7 -> Figure 6).\n- The contribution of this paper is unclear. Applying video instruction instead of text instruction is already explored in the GROOT paper. Also, the problem that the \"latent z tends to encode actions\" can be only applied for the GROOT architecture, which limits the applicability of the paper. Overall, the contribution of the paper is limited compared to GROOT. \n- The experiments mainly focus on simple short-horizon tasks, while GROOT also shows results on long-horizon task (obtain diamond)."
      },
      {
        "rating": "3",
        "confidence": "4",
        "summary": "The paper proposes a method to train agents with reinforcement learning to solve tasks in Minecraft. It extends previous work based on video-conditioned agents (the GROOT method), adding reinforcement learning training and architectural modifications to better handle generalization over tasks. The method is evaluated on an ad-hoc suite of tasks.",
        "strengths": "- The goal of building agents able to execute tasks zero-shot, without any task-specific training, is important and somewhat under-explored for agents trained with reinforcement learning.\n- The architectural modifications proposed in the paper are sensible. Giving the action decoder a more direct access to the low-level details of the input can potentially better inform a policy.",
        "weaknesses": "- I found the premise of the paper, repeated multiple times, to be highly misleading. While using video instruction might be more convenient in some circumstances, the value of text instructions mostly resides on how it is for a user to input them into the system. This should be taken into account as a premise to the work and cannot be ignored.\n- Generally, the paper is very unclear. It is quite difficult to understand what the method exactly is, what the exact training procedure is, and how the evaluation was carried out.\n- There are no error bars for any of the plots, and especially given the variance of online reinforcement learning algorithms, they are required to understand the validity of the empirical results.\n- The paper is full of editorial mistakes (e.g., no space before in-line citations, missing periods, typos, placeholder captions [Figure 3]). I suggest the authors to review their manuscript to fix them."
      }
    ],
    "rating_avg": 3.4,
    "confidence_avg": 3.2,
    "decision": "N/A",
    "meta_review": "",
    "author_remarks": "",
    "decision_comment": ""
  },
  {
    "id": "KRqMfdwQaP",
    "title": "SEAL-Pose: Enhancing Pose Estimation through Trainable Loss Function",
    "authors": [
      "Junggeun Do",
      "Jay-Yoon Lee"
    ],
    "abstract": "Accurately predicting 3D human pose is a challenging task in computer vision due to the need to capture complex spatial structures and anatomical constraints. We propose SEAL-Pose, an adaptation of the Structured Energy As Loss (SEAL) framework for deterministic models, specifically designed to enhance 3D human pose estimation from 2D keypoints. \nAlthough the original SEAL was limited to probabilistic models, our approach employs the model's predictions as negative examples to train a structured energy network, which functions as a dynamic and trainable loss function. \nOur approach enables a pose estimation model to learn joint dependencies via learning signals from a structured energy network that automatically captures body structure during training without explicit prior structural knowledge, resulting in more accurate and plausible 3D poses .\nWe introduce new evaluation metrics to assess the structural consistency of predicted poses, demonstrating that SEAL-Pose produces more realistic, anatomically plausible results.\nExperimental results on the Human3.6M and Human3.6M WholeBody datasets show that SEAL-Pose not only reduces pose estimation errors such as Mean Per Joint Position Error (MPJPE) but also outperforms existing baselines.\nThis work highlights the potential of applying structured energy networks to tasks requiring complex output structures, offering a promising direction for future research.",
    "keywords": [
      "Structured Energy network",
      "Energy-based models",
      "Trainable Loss-function",
      "Dynamic loss function",
      "Pose Estimation"
    ],
    "venue": "ICLR",
    "year": 2025,
    "pdf_url": "https://openreview.net/pdf?id=KRqMfdwQaP",
    "forum_url": "https://openreview.net/forum?id=KRqMfdwQaP",
    "reviews": [
      {
        "rating": "3",
        "confidence": "4",
        "summary": "This paper presents SEAL-Pose, a Structured Energy As Loss framework to improve the 3D pose estimation from 2D keypoints. The SEAL loss is previously applied in probabilistic models whereas the paper modifies it to deterministic models. This loss improves the dependencies among the keypoints which produces more plausible poses empirically.",
        "strengths": "1. This paper addresses an interesting problem of improving the plausibility of output pose. The SEAL loss is new and effective.\n2. This paper is easy to understand.",
        "weaknesses": "1. The writing of this paper can be improved, e.g., the names of task-net and loss-net are confusing since the task here is only pose estimation and loss-net only refers to energy loss. Also, it would be clearer if authors can give an overview of what each net functions in the beginning of Sec.3.1.\n2. The motivation is not clearly explained and verified. It’s not clear why SEAL-Pose can improve the plausibility of estimated poses and why it can perform better in the proposed metrics, i.e., LSE, BSLE, and LLE.\n3. The method should be evaluated on more advanced frameworks. It’s necessary for this method to compete against state-of-the-art methods and on more challenging benchmarks, for example, 3DPW, MPI-INF-3DHP. In Table 2, the performance is very similar to the baseline method VideoPose.\n4. Minor issues:\n    1. Inconsistency between P-MPJPE and PA-MPJPE in H36M and H3WB\n    2. The quality of figures can be improved"
      },
      {
        "rating": "3",
        "confidence": "4",
        "summary": "This work addresses 2D-to-3D human pose lifting, by applying the \"Structured Energy as Loss\" (SEAL) framework. That is, besides training a regressor for the task (here called task-net), a second network (loss-net) is also trained that scores prediction-input pairs for their plausibility. At inference time, the output can be taken as is, or gradient-based inference (GBI) can be applied to modify the prediction towards driving down the loss-net output (to make the prediction seem more plausible to the loss-net). This GBI can be applied by tuning either the prediction itself or the model weights.\nThe motivation is to better take into account dependencies in the output variables, such as bone lengths in the case of human pose estimation.\nThe model is evaluated on Human3.6M and its whole-body extension and is shown to improve the scores.",
        "strengths": "* The problem of human pose lifting is of interest to the research community.\n* Applying the SEAL framework to this task is novel.\n* The method, when applied to SimpleBaseline and VideoPose3D, improves results on Human3.6M, both in terms of the standard metrics and in terms of bone symmetry and bone length error.\n* The ablation model (Section 3.2) is useful in demonstrating the value in training the loss-net together with the task-net.",
        "weaknesses": "* The most serious problem I see is using a hyperparameter sweep tool (from WandB) to tune hyperparameters directly for the Human3.6M/H3WB test set. If this was indeed done so, it invalidates the seen improvements, as the gap is not so large and tuning hyperparameters for a particular test set can aways achieve significantly stronger results.\n* While the method is motivated from the prior SEAL method, I am not convinced that the terminology of structured energy is helpful for understanding rather than obscuring what actually happens in the approach. In essence, the final model is a fairly standard conditional GAN. The terminology of \"structured\" learning/energy/outputs comes from the pre-deep-learning era when multi-output model were generally less standard and more difficult to train. Today, talking about a learned loss function or indeed simply a discriminator may be much better understood by the community, since models that make \"structured\" predictions are commonplace today. GANs have been used in a similar fashion for 2D-to-3D lifting (e.g. [3]), diminishing the novelty of the proposed paper.\n\n* The work only uses Human3.6M (and its wholebody extension). While Human3.6M has been very valuable for research over the last decade, today we now have many more datasets and it is now possible to give stronger evidence for a method than improvements on two specific subjects. The particular bone-length structures of subject 9 and subject 11 of H36M may not generalize. Other possible training datasets would include the following (of course I do not expect using all of these, it is just to give some ideas): MPI-INF-3DHP, CMU-Panoptic, AMASS, HuMMan, AIST-dance++, AGORA, BEDLAM, GeneBody, DNA-Rendering, RICH etc. And other evaluation datasets include 3DPW and EMDB. Again, I do not expect using all, but using at least something further beyond the Human3.6M data would make the evidence much stronger.\n* The baseline methods (SimpleBaseline, VideoPose) are fairly old by the standards of this field (2017 and 2019). It would be important to try newer lifting methods as well. The results are also not compared to the current SOTA methods or those from the last five years.\n* The writing is quite verbose, for example an full page (page 5) is spent on describing limb length losses, which could be expressed in a briefer way. Such bone-based losses and metrics have been used in many prior works, for example [2,3]\n* It is not clear why the SemGCN model has spikes in the training curve (Fig. 3). These spikes can appear for many practical reasons in a particular implementation and do not generally mean a fundamental problem."
      },
      {
        "rating": "5",
        "confidence": "4",
        "summary": "This paper presents SEAL-pose to handle 2D-to-3D lifting problem in human pose estimation. The core is training a learnable loss function to encode the structure of output body limbs. To evaluate the performance, the authors propose two new metrics: Limb symmetry error (LSE) and Body segment length error (BSLE). Experiments are performed on H36M and H3WB.",
        "strengths": "The incorporation of SEAL framework for 3D human pose lifting is a novel idea. The experiments could support the effectiveness of SEAL-psoe to some degree.",
        "weaknesses": "Description of methods should be improved. Experiments are not enough. See Questions below."
      },
      {
        "rating": "3",
        "confidence": "5",
        "summary": "The paper introduces a Structured Energy As Loss (SEAL) framework aimed at improving 3D human pose estimation. However, the paper is incomplete (less than eight pages) and lacks a description of the method’s motivation, a comparison with prior approaches, and an evaluation against state-of-the-art methods.",
        "strengths": "The proposed method is simple but effective.",
        "weaknesses": "1. The diagram in Figure 1 is overly simplistic and does not effectively convey the motivation behind the proposed method.\n2. The paper is incomplete (less than eight pages), lacks a thorough description of the method’s motivation, a discussion on advantages over prior methods, and comparisons with state-of-the-art approaches."
      }
    ],
    "rating_avg": 3.5,
    "confidence_avg": 4.25,
    "decision": "Reject",
    "meta_review": "This paper addresses 2D-to-3D human pose lifting, by applying the \"Structured Energy as Loss\" (SEAL) framework. The SEAL loss is previously applied in probabilistic models whereas the paper modifies it to deterministic models. Besides training a regressor for the task (called task-net), a second network (loss-net) is also trained that scores prediction-input pairs for their plausibility. At inference time, the output can be taken as is, or gradient-based inference (GBI) can be applied to modify the prediction towards driving down the loss-net output. Experimental results on the Human3.6M and Human3.6M WholeBody datasets show that effectiveness of the proposed method.  While applying the SEAL framework to 3D human pose estimation is appreciated, the reviews are unanimously negative.  The reviewers raised concerns regarding limited validation and poor writing.  Evaluation on only Human3.6 (and its wholebody extension) is insufficient.  Even if Human3.6M has been recognized as valuable dataset for over the last decade, many more datasets are now available. Moreover, comparisons with recent SOTAs are also missing.  Regarding writing, motivation is not clearly explained.  There are verbose descriptions as well.  The authors addressed, in the rebuttal, the raised concerns.  As a result, the writing is improved a lot.  But evaluation on other datasets and comparison with SOTAs are not provided but just discussed as the limitation, leaving a question on the generalization ability of the proposed method.  The reviewers have felt that evaluation using only Human3.6M cannot convince broader readers and evaluation on more datasets is required to prove the effectiveness of the proposed method.  This paper should be rejected, accordingly.",
    "author_remarks": "",
    "decision_comment": ""
  },
  {
    "id": "kbeX97jExm",
    "title": "Neural Wave Equation for Irregularly Sampled Sequence Data",
    "authors": [
      "Arkaprava Majumdar",
      "M Anand Krishna",
      "P. K. Srijith"
    ],
    "abstract": "Sequence labeling problems arise in several real-world applications such as healthcare and robotics. In many such applications, sequence data are irregularly sampled and are of varying complexities. Recently, efforts have been made to develop neural ODE-based architectures to model the evolution of hidden states continuously in time, to address irregularly sampled sequence data. However, they assume a fixed architectural depth and limit their flexibility to adapt to data sets with varying complexities. We propose the neural wave equation, a novel deep learning method inspired by the wave equation, to address this through continuous modeling of depth. Neural Wave Equation models the evolution of hidden states continuously across time as well as depth by using a non-homogeneous wave equation parameterized by a neural network.  Through d'Alembert's analytical solution of the wave equation, we also show that the neural wave equation provides denser connections across the hidden states, allowing for better modeling capability.  We conduct experiments on several sequence labeling problems involving irregularly sampled sequence data and demonstrate the superior performance of the proposed neural wave equation model.",
    "keywords": [
      "Wave Equation",
      "Neural ODE",
      "Sequence Labelling"
    ],
    "venue": "ICLR",
    "year": 2025,
    "pdf_url": "https://openreview.net/pdf?id=kbeX97jExm",
    "forum_url": "https://openreview.net/forum?id=kbeX97jExm",
    "reviews": [
      {
        "rating": "6",
        "confidence": "3",
        "summary": "This paper introduces the neural wave equation, a novel approach to handling irregularly sampled sequence data by modeling hidden state evolution using wave equations. The authors propose using a non-homogeneous wave equation with a neural network-parameterized source function to capture sequence dependencies. The method allows continuous modeling across both time and depth dimensions, addressing limitations of existing approaches that use discrete depth transformations. The authors demonstrate the effectiveness of their approach through experiments on various sequence labeling tasks, including person activity recognition, Walker2d kinematic simulation, sepsis prediction, and stance classification, showing competitive or superior performance compared to existing baselines.",
        "strengths": "- Strong theoretical foundation with clear mathematical derivations\n- Comprehensive experimental evaluation across diverse datasets\n- Thoughtful comparison with existing approaches, especially heat equation-based methods\n- Detailed ablation studies showing the importance of different components",
        "weaknesses": "- The motivation for choosing wave equations could be stronger\n- Memory consumption issues are noted but not thoroughly addressed\n- The connection between theoretical advantages and empirical improvements could be clearer\n- Limited discussion of computational complexity trade-offs\n- Some implementation details about boundary conditions could be more explicit"
      },
      {
        "rating": "8",
        "confidence": "4",
        "summary": "This paper introduces a novel architecture for latent space modeling and prediction using the Wave equation. Motivated by the homogeneous and non-homogeneous wave equations, the authors proposed neural wave equation to model the hidden layer transformations. In the experiments, the authors tested and showed superior performances on person activity recognition, walker2d-v2, sepsis, and social media posts datasets.",
        "strengths": "This paper proposed a very innovative idea which utilizes the wave equation to model the latent space. From the reviewer's perspective, this is good since this kind of structure could model physical/natural phenomenon(s) better. And the model is still generalizable from the non-homogeneous formulation with F(z,t). \n\nExperimentally, neural wave equations also dominated the baseline methods in most of the metrics. \n\nIn general, this paper introduces a very innovative method which requires further study, and could have huge potential impact to the field.",
        "weaknesses": "There are several weaknesses of this manuscript. \n\n1. The presentation of this manuscript is not optimal. For example, the Figure 1 requires some imagination to understand the design to distinguish the three methods. \n\n2. The experiments are nice, but the neural wave equation might not perform as well as the baseline methods for some data. This could potentially be because the form of the wave equation acts as a strong prior that might not fit the data. It would be nice to understand further the limitation of this framework. The ablation study could potentially be extended."
      },
      {
        "rating": "6",
        "confidence": "3",
        "summary": "This paper addresses the limitation of fixed architectural depth in modeling irregularly sampled sequence data. A neural wave equation method is proposed to 1) continuously model the hidden states across time and depth and 2) allow denser connections across hidden states. Empirical results show improved performance compared to baseline methods.",
        "strengths": "1. The problem of fixed assumption in architectural depth is important. \n2. The method of using the wave equation to continuously model the time and depth is creative. Developing the neural network based on the analytical solution to the wave equation allows more dependencies in hidden states.\n3. Experiments were performed on different scenarios to show the effectiveness of the proposed method.",
        "weaknesses": "1. The introduction and related work need to be better structured. For instance, what is the concept of hidden state depth in real-world problems? Could the authors elaborate on why PDE-based models are a better model for continuous modeling on depth? What is the benefit of the wave equation over the other PDEs? The authors could provide more details in both sections for a smoother transition from the problem setting to the proposed method.\n2. Section 3 and 4 could be better presented. For example, instead of presenting Figure 2, the authors could provide a comparison between ODE-RNN and the proposed method in terms of how they model in depth. In fact, Figure 2 should be in an ablation study and needs a better explanation of how the depth affects the three comparison models. Also, using $t’$ for depth is confusing given that $t$ is used for time. For Figure 3, the authors should explain the blue arrows with the description in Section 4.2.\n3. The experiments should be performed and analyzed in more detail. For each experiment, could the authors highlight the purpose, such as how the depth of hidden states or the number of missing data affects the model performance? What is the depth of each group of data? Could the authors group the comparison baselines as the categories in Figure 1? Table 1 could be separated by the experiments. Also, it would be better to have visualizations about the predicted sequences vs the ground truth to better understand the improvement in metrics."
      }
    ],
    "rating_avg": 6.666666666666667,
    "confidence_avg": 3.3333333333333335,
    "decision": "Accept (Poster)",
    "meta_review": "The paper proposes the neural wave equations, a novel approach for handling sequence data, especially irregularly sampled sequences, by modelling hidden states evolution using a wave equation parameterized by a neural network. Reviewers appreciated the innovative idea with a strong theoretical foundation, comprehensive experiments, thoughtful comparison with existing approaches, and detailed ablation studies. The reviewers raised concerns about presentation clarity (including motivation for using the wave equations and figures and algorithms lack clarity), the need for better contextualization with related work and the method's limitations, high memory consumption compared to baselines, limited discussion of computational complexity trade-offs, and the methods reliance on the wave equation as a prior, which may not align with the dynamics of all datasets. The authors addressed these concerns during the rebuttal and discussions by refining sections and figures, adding new experiments (particularly on sensitivity analysis of the wave speed parameter), partially addressing memory concerns by applying gradient checkpointing, and providing detailed explanations in the appendix. Despite some unresolved issues, such as fully addressing memory efficiency and further sensitivity and ablations studies, the reviewers unanimously recommend accepting the paper based on its novelty and strong empirical results, and therefore, I recommend accepting the paper.",
    "author_remarks": "",
    "decision_comment": ""
  },
  {
    "id": "izETL3emSv",
    "title": "BBOPlace-Bench: Benchmarking Black-Box Optimization for Chip Placement",
    "authors": [
      "Ke Xue",
      "Ruo-Tong Chen",
      "Rong-Xi Tan",
      "Xi Lin",
      "Yunqi Shi",
      "Siyuan Xu",
      "Mingxuan Yuan",
      "Chao Qian"
    ],
    "abstract": "Chip placement is a crucial step in modern chip design, because it significantly impacts the subsequent process and the overall quality of the final chip. The application of black-box optimization (BBO) for chip placement has a history of several decades. Nevertheless, early attempts were hampered by immature problem modeling and inefficient algorithm design, resulting in suboptimal placement efficiency and quality compared to the more prevalent analytical methods. Recent advancements in problem modeling and BBO algorithm design have highlighted the effectiveness and efficiency of BBO, demonstrating its potential to achieve state-of-the-art results in chip placement. Despite these advancements, the field lacks a unified benchmark for thoroughly assessing various problem models and BBO algorithms. To address this gap, we propose BBOPlace-Bench, the first benchmark designed for evaluating and developing BBO algorithms specifically for chip placement tasks. BBOPlace-Bench first collects several popular tasks and standardizing their formats, thereby providing uniform and comprehensive information for optimization.  Additionally, BBOPlace-Bench includes a wide range of existing BBO algorithms, including simulated annealing, evolutionary algorithms, evolution strategy, and Bayesian optimization, and evaluates their performance across different problem modelings (i.e., permutation, discrete, and mixed search spaces) using various metrics. Furthermore, BBOPlace-Bench offers a flexible framework that allows users to easily implement and test their unique algorithms. BBOPlace-Bench not only provides efficient solutions for chip placement but also expands the practical application scenarios for various BBO algorithms. The code for BBOPlace-Bench is available in the supplementary file.",
    "keywords": [
      "Black-box optimization",
      "Bayesian optimization",
      "Evolutionary algorithm",
      "Chip placement",
      "EDA"
    ],
    "venue": "ICLR",
    "year": 2025,
    "pdf_url": "https://openreview.net/pdf?id=izETL3emSv",
    "forum_url": "https://openreview.net/forum?id=izETL3emSv",
    "reviews": [
      {
        "rating": "3",
        "confidence": "3",
        "summary": "This paper proposes BBOPlace-Bench, a benchmark for evaluating and developing a black box optimization for chip placement for EDA. BBOPlace-Bench evaluate the chip placement from problem formulation, optimization algorithm and problem evaluation, which provides a convenient tool for EDA community.",
        "strengths": "1.\tThis paper decouples chip placement tasks into problem formulation, optimization algorithms, and problem evaluation.\n2.\tThis paper provides a comprehensive study of BBO for chip placement tasks.",
        "weaknesses": "1.\tThis paper compares traditional black-box optimization (BBO) algorithms but lacks coverage of advanced BBO methods that leverage deep learning. Although the authors include some reinforcement learning (RL)-based methods, the omission of ChiPFormer, an advanced BBO method, is notable. Including ChiPFormer would be valuable, as it introduces deep learning-based advancements that are increasingly relevant to this field. Additionally, incorporating other advanced BBO methods using deep learning would provide a more comprehensive benchmark. Specific suggestions could include recent developments in neural architecture search or multi-objective optimization approaches, which could further enrich the paper’s contributions.\n2.\tThe paper presents evaluation results but lacks in-depth analysis of the performance differences across methods. For example, in several cases, RL-based methods perform worse than traditional BBO approaches, yet the reasons for this underperformance are not explored. To provide more insight, it would be helpful if the authors conducted a detailed analysis of these cases. They could investigate factors like differences in problem formulation, hyperparameter sensitivity, or scalability limitations that may impact RL-based methods differently from traditional BBO approaches.\n3.\tBy focusing primarily on traditional BBO algorithms, the paper limits its contribution and does not fully capture the latest advancements in the field. To better represent the current state of BBO, the authors could consider including more recent algorithms or techniques that reflect the field’s evolution. Suggestions might include recent innovations in deep learning-based approaches like neural architecture search or multi-objective optimization techniques relevant to chip placement. Including these would enhance the benchmark’s value by offering a more complete picture of current methodologies and their practical implications in chip design optimization.\n4.    After further consideration, I think the topic of this paper is more relevant with EDA conferences. Further justification of the importance of this topic and its relevance with ICLR and machine-learning are should be provided."
      },
      {
        "rating": "3",
        "confidence": "5",
        "summary": "The paper introduces BBOPlace-Bench, a benchmark for evaluating and developing BBO algorithms in chip placement. BBOPlace-Bench collects several tasks and standardizes their formats. Simulating annealing, evolutionary algorithms, evolution strategy, and Bayesian optimization are included in the benchmark.",
        "strengths": "This paper presents a benchmark for chip placement that may have potential for industrial EDA applications.",
        "weaknesses": "(1)\tChip placement is an industrial problem. It is not clear that whether experiment results on the benchmark are similar to those in the real industrial scenarios. It is mentioned in subsection 4.1 that “We empirically test methods in BBOPlace-Bench on ISPD 2005 and ICCAD 2015 benchmarks”. On one hand, the reasons for choosing the ISPD 2005 benchmark and ICCAD 2015 benchmarks should be better described. On the other hand, the empirical test may not reflect the real performance in the industrial scenarios. A detailed comparison between the chosen benchmarks and real industrial scenarios is favored. Moreover, consulting with industry practitioners or comparing to recent industrial datasets on the limitations of these benchmarks and the ways to validate the benchmark's relevance to industry is suggested.  \n\n(2)\tThe experiments are simplified due to various reasons, which makes the results less trustable. For example, only SP-SA and SP-EA are tested and GP HPWL is set to 200. Authors should clarify the impacts of their experimental choices more explicitly. For example, if GP HPWL is set to 300 or 400, whether the experimental results will change and why. Another typical example is that why you define the largest 512 cells by area as macros for ICCAD 2015. If the number 512 is changed, whether the experimental results will change as well. If they are not easy to be demonstrated in theory, additional experiments on those parameters are suggested. \n\n(3)\tThere are too many EDA references, which have little relation to do with topics of ICLR. Besides, many of the EDA references were published in the last decade or even earlier. For example, the methods in BBOPlace-Bench are tested on the ISPD 2005 and ICCAD 2015 benchmarks. Too many EDA references make the paper difficult to understand in this conference. And it is a little bit confusing that whether the problems this paper addresses are important in the current era. Clarifying the connection between these EDA references and current machine learning research relevant to ICLR is suggested. Providing more context on how these older benchmarks and references relate to current challenges in applying machine learning to chip design is also favored.\n\n(4)\tThe paper has many typos or grammar issues. Even in the abstract, at least one grammar issue can be found. For example, in the abstract, “standardizes” instead of “standardizing” should be used in the sentence “BBOPlace-Bench first collects several popular tasks and standardizing their formats, …”. Another typical example is in subsection 4.1, where the word “continuous” is an adjective and cannot be used as verb in the sentence “we continuous the search space of HPO in our experiments”. The writing of this paper should be largely improved."
      },
      {
        "rating": "3",
        "confidence": "4",
        "summary": "This paper discussed the background and recent development on chip placement. A number of placement benchmarks from ICCAD community are evaluated with a number of popular algorithms. A few future directions in this area are also briefly mentioned as part of the conclusion.",
        "strengths": "For those interested in chip placement, this paper could be a convenient place to see the performance of different algorithms directly compared using (presumably) popular benchmarks.",
        "weaknesses": "The comparison is billed as proposing a benchmark. This is confusing as the benchmarks are really existing benchmarks ISPD 2005 and ICCAD 2015. Beyond presenting the background and comparison results, the paper offers very little insight."
      },
      {
        "rating": "5",
        "confidence": "5",
        "summary": "This paper proposes a benchmark for a black box optimization algorithm with an application scenario of ASIC placement. The execution process of the benchmark involves macro placement first, followed by standard cell placement using DREAMPlace as the backbone. The solution space for the black box optimization in the benchmark includes sequence pairs (specifying the relative order of macros), grid-guide (optimizing the coordinates of macros), and hyperparameter optimization of the DREAMPlace backbone.",
        "strengths": "- The paper is very well-written.\n- The writing and illustrations are clear and help in understanding the motivation and solution.",
        "weaknesses": "- There is no comparison with analytical-based macro placement algorithms. In recent years, academia has proposed analytical-based macro placement algorithms. Additionally, there are algorithms for mixed-size placement that perform macro and standard cell placement simultaneously. Compared to RL-based methods, these algorithms are faster. The authors should include a comparison with analytical macro placement algorithms regarding performance and HPWL. This includes, but is not limited to:\n  - Yuan Pu, Tinghuan Chen, Zhuolun He, Chen Bai, Haisheng Zheng, Yibo Lin, and Bei Yu. 2024. IncreMacro: Incremental Macro Placement Refinement. In Proceedings of the 2024 International Symposium on Physical Design (ISPD '24). Association for Computing Machinery, New York, NY, USA, 169–176.\n  - Peiyu Liao, Dawei Guo, Zizheng Guo, Siting Liu, Yibo Lin, and Bei Yu. Dreamplace 4.0: Timing-driven placement with momentum-based net weighting and lagrangian-based refinement. IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems, 42(10):3374–3387, 2023.\n  - Y. Chen, Z. Wen, Y. Liang and Y. Lin, \"Stronger Mixed-Size Placement Backbone Considering Second-Order Information,\" *2023 IEEE/ACM International Conference on Computer Aided Design (ICCAD)*, San Francisco, CA, USA, 2023, pp. 1-9."
      }
    ],
    "rating_avg": 3.5,
    "confidence_avg": 4.25,
    "decision": "N/A",
    "meta_review": "",
    "author_remarks": "",
    "decision_comment": ""
  },
  {
    "id": "5o9JJJPPm6",
    "title": "ComaDICE: Offline Cooperative Multi-Agent Reinforcement Learning with Stationary Distribution Shift Regularization",
    "authors": [
      "The Viet Bui",
      "Thanh Hong Nguyen",
      "Tien Anh Mai"
    ],
    "abstract": "Offline reinforcement learning (RL) has garnered significant attention for its ability to learn effective policies from pre-collected datasets without the need for further environmental interactions. While promising results have been demonstrated in single-agent settings, offline multi-agent reinforcement learning (MARL) presents additional challenges due to the large joint state-action space and the complexity of multi-agent behaviors. A key issue in offline RL is the distributional shift, which arises when the target policy being optimized deviates from the behavior policy that generated the data. This problem is exacerbated in MARL due to the interdependence between agents' local policies and the expansive joint state-action space. Prior approaches have primarily addressed this challenge by incorporating regularization in the space of either Q-functions or policies. In this work, we propose a novel type of regularizer in the space of stationary distributions to address the distributional shift more effectively. Our algorithm, ComaDICE, provides a principled framework for offline cooperative MARL to correct the stationary distribution of the global policy, which is then leveraged to derive local policies for individual agents. Through extensive experiments on the offline multi-agent MuJoCo and StarCraft II benchmarks, we demonstrate that ComaDICE achieves superior performance compared to state-of-the-art offline MARL methods across nearly all tasks.",
    "keywords": [
      "Offline Reinforcement Learning",
      "Multi-Agent Reinforcement Learning",
      "Stationary Distribution Correction Estimation"
    ],
    "venue": "ICLR",
    "year": 2025,
    "pdf_url": "https://openreview.net/pdf?id=5o9JJJPPm6",
    "forum_url": "https://openreview.net/forum?id=5o9JJJPPm6",
    "reviews": [
      {
        "rating": "6",
        "confidence": "3",
        "summary": "This paper proposes an algorithm introducing stationary distribution correction to address the distributional shift problem in offline cooperative multi-agent reinforcement learning (MARL). In multi-agent environments, this issue is intensified due to the large joint state-action space and the interdependencies among agents. To tackle this, ComaDICE minimizes the f-divergence between the stationary distributions of the learning and behavior policies. Additionally, by leveraging the Centralized Training with Decentralized Execution (CTDE) framework, it decomposes the global value functions into local values for each agent, ensuring that the optimization of each agent’s local policy is consistent with the global learning objective.",
        "strengths": "- Effective Distribution Correction in Multi-Agent Settings: ComaDICE improves upon traditional DICE by extending stationary distribution correction to multi-agent environments. Through f-divergence-based alignment between behavior and target policies, it effectively handles the complex distributional shifts unique to multi-agent interactions, enhancing policy reliability and performance.\n- Theoretical Foundation: A thorough mathematical analysis provides convergence and stability proofs through f-divergence correction, reinforcing the algorithm’s reliability in multi-agent scenarios.\n- Stable Value Decomposition: ComaDICE decomposes global values into convex local objectives, enhancing training stability and aligning local agent optimization with the global objective to address coordination and stability challenges specific to multi-agent environments.",
        "weaknesses": "- ComaDICE’s theoretical analysis relies on non-negative weights and convex activations in the mixing network for stability. While this aids convergence, it may limit the model’s ability to capture complex inter-agent dynamics. In the practical algorithm, this limitation is intensified by the use of a single-layer linear mixing network, which further restricts representational capacity in highly interactive environments.\n- High Computational Cost: ComaDICE incurs a significant computational cost due to the precise f-divergence-based adjustments needed for each agent’s local policy in stationary distribution correction. This can lead to reduced efficiency, especially in environments with a large number of agents."
      },
      {
        "rating": "6",
        "confidence": "5",
        "summary": "The paper proposes ComaDICE, a stationary distribution correction estimation approach to addressing OOD states and actions in Offline MARL. The derivation starts with the LP formulation of RL in the joint state-action space, which results in a concave objective for learning state-value functions similar to OptiDICE [2]. The objective also uses value decomposition with a monotonic mixing network for the advantage function similar to OMIGA [3]. ComaDICE is evaluated on SMACv2 and MaMuJoCo and shows comparable performance with baselines such as BC and OMIGA.",
        "strengths": "It is known that every MDP has a deterministic optimal policy, which, if extended to the multi-agent setting, can be factorized into independent policies. A very optimistic reading of the paper would interpret that the decomposition procedure is actually learning optimal value functions over decentralized policies. If this interpretation is correct, the ComaDICE presents a very scalable and principled offline MARL algorithm for learning decentralized value functions and policies without any restrictive IGM assumption as in previous work such as ICQ. However, it is worth noting that this is more of a statement of the potential of the paper rather than a strength of its current version, as these points are not specifically addressed in the current draft.\n\nFurthermore, ComaDICE can be more scalable in comparison to AlberDICE [1] which requires alternating optimization.",
        "weaknesses": "### Problem Statement\nIt is not clear what the main problem is that ComaDICE is solving. It is briefly mentioned in the introduction that OOD states and actions are a problem in offline MARL. However, this was addressed in detail by other work such as CFCQL/OMIGA/AlberDICE mentioned in the Related Work (especially AlberDICE [1] which is the most similar). For instance, AlberDICE considers some coordination problems (XOR/Bridge/etc.) where OOD joint actions may be common, these is no consideration of these settings as well as comparison to AlberDICE both algorithmically and empirically. Thus, it is not entirely clear from the current draft of the paper what the main problem is that ComaDICE is solving, and if it is indeed OOD actions, which part of the algorithm in particular is alleviating this.\n\n### Novelty\nThe derivation is based on OptiDICE [2] but this is not explicitly mentioned, which is misleading. \nFor instance, Proposition 4.1 seems equivalent to Proposition 1 of OptiDICE. Furthermore, an extension of OptiDICE to solve Offline MARL was considered in AlberDICE [1] so it is not clear why ComaDICE should be preferred over AlberDICE. Furthermore, the final algorithm closely resembles OMIGA [3].\n\n### Algorithm\nIt is unclear what the purpose of value decomposition in learning the Q functions is. It seems the advantage can be computed by the learned state-value function $\\nu$ and run WBC (as mentioned in Appendix C of AlberDICE[1]). Also, Line 346 defines $A_\\nu^{tot}$ as the sum of reward and state-value functions.\n\n### Lack of Relevant Baselines\nAlberDICE and OptiDICE are missing as the main baselines, as well as CFCQL which addresses OOD actions but in a different manner. These are all mentioned in the Related Work section but not compared.\n\n### Writing\nThe paper is generally not well-written. All of the aforementioned weaknesses of the paper should be addressed in detail and the writing should not raise any of these concerns."
      },
      {
        "rating": "6",
        "confidence": "4",
        "summary": "In this paper, ComaDICE algorithm is proposed for offline multi-agent reinforcement learning, extending the DICE method to multi-agent scenarios and using value function decomposition and policy extraction methods, the idea is novel and the experimental results show the potential of the method.",
        "strengths": "* The introduction of the DICE algorithm within the domain of multi-agent reinforcement learning represents a significant contribution characterized by its novelty and innovative approach.\n* The experimental settings are comprehensive, demonstrating the potential of the proposed algorithm effectively.",
        "weaknesses": "* The contribution emphasizes the value decomposition and claims to prove the equivalence of the local policy product to the globally optimal policy, but the paper is too repetitive and superficial in its exposition of the decomposition method, neither explicitly defining the local subtasks and their corresponding policies, nor the relationship between them, nor providing a complete proof of this equivalence.\n* The experimental results for hybrid networks contradict mainstream research findings (single-layer outperforms double-layers), a phenomenon that hints at a possible fundamental flaw in the application of the DICE methodology to MARL, but the paper lacks an in-depth discussion of this."
      },
      {
        "rating": "8",
        "confidence": "4",
        "summary": "This work introduces ComaDICE (offline Cooperative MARL with DICE), an approach for offline cooperative multi-agent reinforcement learning (RL) that leverages the DICE method. ComaDICE formulates the offline cooperative multi-agent RL problem as a constrained optimization and employs a DICE-based method to compute a global Lagrangian multiplier, $\\nu^{tot}$. Given the large state and action spaces typical in multi-agent RL, practical optimization of $\\nu^{tot}$ may not be feasible. To address this challenge, ComaDICE employs value function decomposition to decompose the global Lagrangian multiplier into individual Lagrangian multipliers for each agent.",
        "strengths": "This work provides a comprehensive performance evaluation through experiments conducted on an extensive set of benchmarks, including the challenging multi-agent RL benchmark SMAC-v2. The experimental results indicate that the proposed approach shows superior performance relative to the baselines considered in the manuscript.",
        "weaknesses": "The primary concern regarding this work is its novelty compared to previous work.\n\nSpecifically, AlberDICE by Matsunaga et al. (2023) [A] conveys a similar idea, i.e. adoption of DICE for offline cooperative multi-agent RL. The key difference of ComaDICE from AlberDICE appears to be employing individual Langrangian multipliers $\\nu_i$ and the mixing network for value function decomposition: while AlberDICE utilizes a simple yet principled resampling method for obtaining $\\nu_i$, ComaDICE employs the value factorization as discussed in Section 4.2, which requires the reliance on the additional mixing network $\\mathcal{M}_\\theta$ further necessitates additional training.\n\nAlthough AlberDICE is briefly mentioned in Section 2, the paper does not adequately discuss the theoretical or empirical advantages of adopting the value decomposition instead of the resampling approach. In addition, the AlberDICE paper presents a simple multi-agent task where value function decomposition leads to a substantial performance loss.\n \nThe absence of such a comparison significantly weakens the perceived contribution of this study, as it fails to establish a clear improvement of differentiation from previous work. In this sense,\n(1) A detailed discussion comparing ComaDICE and AlberDICE should be added,\n(2) AlberDICE should be included as a baseline in all experiments,\n(3) ComaDICE should be tested on the XOR game in the AlberDICE paper  \n\n\n[A] Matsunaga et al., “AlberDICE: Addressing Out-Of-Distribution Joint Actions in Offline Multi-Agent RL via Alternating Stationary Distribution Correction Estimation.”, NeurIPS 2023.\n\n[Minor comments]\nIn Sections 6.1 and 6.3, SMACv1 environment is discussed; however, corresponding experimental results for SMACv1 are not included in the main manuscript. It would be more appropriate to relocate these discussions to the appendix and direct readers there for further details, or incorporate the result on SMACv1 to the main manuscript, potentially replacing some of the redundant results on SMACv2 in Table 1 or Figure 1."
      }
    ],
    "rating_avg": 6.5,
    "confidence_avg": 4.0,
    "decision": "Accept (Poster)",
    "meta_review": "The paper studied offline multi-agent RL and proposed an approach based on the DICE framework. The proposed approach uses a stationary distribution shift regularization to combat the distribution shift issue in offline RL. The paper demonstrates that their approach works well empirically.",
    "author_remarks": "",
    "decision_comment": ""
  },
  {
    "id": "Bdhro9gxuF",
    "title": "The Advancement in Stochastic Zeroth-Order Optimization: Mechanism of Accelerated Convergence of Gaussian Direction on Objectives with Skewed Hessian Eigenvalues",
    "authors": [
      "Yilong Wang",
      "Haishan Ye",
      "Yong Liu",
      "Guang Dai",
      "Ivor Tsang",
      "Jingdong Wang"
    ],
    "abstract": "This paper primarily investigates large-scale finite-sum optimization problems, which are particularly prevalent in the big data era. \nIn the field of zeroth-order optimization, stochastic optimization methods have become essential tools. \nNatural zeroth-order stochastic optimization methods are primarily based on stochastic gradient descent ($\\texttt{SGD}$).\nThe method of preprocessing the stochastic gradient with Gaussian vector is referred to as $\\texttt{ZO-SGD-Gauss}$ ($\\texttt{ZSG}$), while estimating partial derivatives along coordinate directions to compute the stochastic gradient is known as $\\texttt{ZO-SGD-Coordinate}$ ($\\texttt{ZSC}$).\nCompared to $\\texttt{ZSC}$, $\\texttt{ZSG}$ often demonstrates superior performance in practice.\nHowever, the underlying mechanisms behind this phenomenon remain unclear in the academic community.\nTo the best of our knowledge, our work is the first to theoretically analyze the potential advantages of $\\texttt{ZSG}$ compared to $\\texttt{ZSC}$.\nUnlike the fundamental assumptions applied in general stochastic optimization analyses, the quadratic regularity assumption is proposed to generalize the smoothness and strong convexity to the Hessian matrix. \nThis assumption allows us to incorporate Hessian information into the complexity analysis.\nWhen the objective function is quadratic, the quadratic regularity assumption reduces to the second-order Taylor expansion of the function, and we focus on analyzing and proving the significant improvement of $\\texttt{ZSG}$. \nFor other objective function classes, we also demonstrate the convergence of $\\texttt{ZSG}$ and its potentially better query complexity than that of $\\texttt{ZSC}$. \nFinally, experimental results on both synthetic and real-world datasets substantiate the effectiveness of our theoretical analysis.",
    "keywords": [
      "stochastic zeroth-order optimization",
      "quadratic regularity",
      "gaussian direction",
      "skewed Hessian eigenvalues"
    ],
    "venue": "ICLR",
    "year": 2025,
    "pdf_url": "https://openreview.net/pdf?id=Bdhro9gxuF",
    "forum_url": "https://openreview.net/forum?id=Bdhro9gxuF",
    "reviews": [
      {
        "rating": "3",
        "confidence": "4",
        "summary": "This paper provides a separation result between zeroth-order stochastic gradient descent and zeroth-order stochastic finite-difference method under a certain quadratic regularity assumption. The results essentially extends similar results in the deterministic setting to the stochastic finite-sum setting.",
        "strengths": "The paper address an important problem of providing separation results between two competing algorithms.",
        "weaknesses": "The main idea in the paper is (i) tr(M) ≪ d λ_max(M) and (ii) one algorithm has tr(M)  and the other has d λ_max(M), the complexity of the former algorithm is better than the latter. Without a formal lower bound for the latter, such a conclusion cannot be made. \n\nEven ignoring this, similar results have been obtained in the deterministic setting previously and extension to the stochastic finite-sum setting is not significant and raise up to the level of ICLR acceptance."
      },
      {
        "rating": "3",
        "confidence": "3",
        "summary": "This paper investigates large-scale finite-sum optimization within the zeroth-order (ZO) stochastic optimization paradigm, focusing specifically on two methods: ZO-SGD-Gauss (ZSG), which pre-processes the stochastic gradient with a Gaussian vector, and ZO-SGD-Coordinate (ZSC), which estimates partial derivatives along coordinate directions. The study addresses the notable performance gap between ZSG and ZSC, aiming to provide theoretical insights that explain ZSG's empirically observed advantages. To achieve this, the authors introduce the \"quadratic regularity assumption\" on the Hessian matrix, a relaxation of typical smoothness and strong convexity assumptions. They demonstrate that this assumption allows for incorporating Hessian information into complexity analysis, yielding convergence rates that reveal ZSG's improved efficiency in certain settings. The authors validate their analysis through synthetic and real-world experiments.",
        "strengths": "The authors reinforce their theoretical findings with experimental results on both synthetic and real-world datasets, which enhances the paper's credibility. The empirical results are presented clearly and support the theoretical claims regarding convergence rates and query complexity.",
        "weaknesses": "The paper seems to be very interesting, however, the following points are present in the paper which hinder the perception of readiness and clarity of the paper:\n\n- Introduction. The introduction is not well designed.... It is possible to improve this point, for example, a table where the result of the work will be clearly visible, as well as the efficiency compared to other algorithms.\n\n- Could not find a link to github or other source where I can find the code of the experiments."
      },
      {
        "rating": "3",
        "confidence": "5",
        "summary": "The paper studies zeroth-order methods for finite-sum optimization and compares the complexity of two algorithms, ZSG and ZSC. The authors claim in the paper to rigorously and theoretically prove that ZSG is better than ZSC, under the quadratic regularity assumption.",
        "strengths": "The study on zeroth-order optimization is a trendy and important topic in optimization and machine learning, given lots of interesting applications in black-box attack, reinforcement learning, and fine-tuning language models.",
        "weaknesses": "1. The authors prove that ZSG converges with $tr(M)$, while previous work suggests that ZSC converges with $d\\lambda(M)$. Based on this, the authors claim that ZSG is better when $tr(M)\\leq d\\lambda(M)$. I don't think this is a correct statement. There is no result in the paper showing that ZSC cannot achieve the rate $tr(M)$, and its $d\\lambda(M)$ rate may come from the fact that previous analysis is not tight. To make the claim mathematically rigorous, the authors should provide the lower-bound under the current quadratic regularity assumption, showing that the rate of ZSC is $\\Omega(d\\lambda(M))$. Only then it is valid to say ZSG $\\leq tr(M) \\leq d\\lambda(M) \\leq$ ZSC.\n\n2. I am also not sure why ZSC cannot achieve the rate $tr(M)$. The current ZSC considered in the paper queries all $d$ dimension at each iteration. Its complexity is thus deducted as $d$ times that of first-order methods. However, in ZSC, one can also only do random sampling at each iteration. For example, sampling from $\\\\{1,2,\\cdots,d\\\\}$ instead of iterating over all $d$ dimension. This also builds a gradient estimator similar to ZSG, and similar analysis could apply. Specifically in the previous paper [Hanzely et al, 2018] and [Wang et al, 2024] mentioned by the authors, the rate of ZSC is also $tr(M)$ under the quadratic regularity assumption, e.g., Table 1 of [Hanzely, et al, 2018]. I am confused why authors say ZSC only achieves $d\\lambda(M)$.\n\n3. The rate of zeroth-order method has already been extensively studied under similar assumptions as the quadratic regularity assumption, e.g., [Malladi et al, 2023], [Yue et al, 2023], [arXiv: 2310.09639]. Stochastic mini-batch settings are also considered in these paper. Therefore, I am not sure how novel and challenge to obtain the results in the current paper given all these previous works.\n\n4. The author claims in Corollary 4.4 that the algorithm will not converge with a fixed stepsize. I don't think this is correct. One can choose $\\eta=(\\log T)/T$, and then the algorithm converges with rate $T=(1/\\epsilon)\\log(1/\\epsilon)$. Or can the authors clarify what they mean by a \"fixed\" step. In Corollary 4.6, when choosing $\\sigma=0$, the complexity should reduce to the deterministic linear rate $\\log(1/\\epsilon)$. Is the current analysis tight?\n\n5. I feel the paper is written in a rush and not well polished. There are lots of mistakes in grammar. For example, it should be smoothness assumption and strong convexity assumption in line 144; line 162-163 is not well written English; In Theorem 4.3, 4.5, it should be \"let objective be quadratic\" and \"let x be update\", etc."
      },
      {
        "rating": "5",
        "confidence": "3",
        "summary": "The paper studies zeroth-order optimization methods (aka. black-box optimization). Specifically, the authors provide theoretical explanation for an observation in practice that the zeroth-order Gaussian gradient descent (ZSG) usually outperforms the zeroth-order version of coordinate descent (ZSC). They show that the improvement mainly comes from the skewness of the Hessian matrix of the objective function. Loosely speaking, the iteration complexity of ZSG scales with $Trace(H)/ \\lambda_{\\min}(H)$, while the complexity of ZSC scales with $d*\\lambda_{\\max}(H)/\\lambda_{\\min}(H)$ where $H$ is the Hessian matrix, $d$ is the dimension. They also perform numerical experiments to show that ZSG outpeforms ZSC in practice.",
        "strengths": "The paper is well-written and the research motivation is clear. Zeroth-order optimization plays a crucial role in domains where privacy in training is essential or where model size makes gradient computation impractical. The theoretical findings are also interesting.",
        "weaknesses": "While the authors managed to show the improvement of ZSG over ZSC when the objective's Hessian is skewed for the quadratic function, the claim is not so clear for the general function. For example, the factor $\\gamma_u / \\gamma_l^2$ in eq (23) can be quite uncontrollable compared to the advantage gained from the skewness. I suggest the authors discuss this trade-off more, i.e., pinpoint cases where the improvement is meaningful."
      }
    ],
    "rating_avg": 3.5,
    "confidence_avg": 3.75,
    "decision": "Reject",
    "meta_review": "This paper studies stochastic zeroth-order optimization. Traditionally, zeroth-order stochastic algorithms are based on SGD, which using Gaussian smoothing to estimate the gradient using zeroth-order information. This is called ZSG method. This paper studies estimating partial derivatives along coordinate directions, which is called ZSC method. The authors claim that ZSC achieves a better complexity than ZSG. However, the reviewers found that this is not rigorously justified. To support this claim, the authors need to develop a lower bound for ZSG, but this is not developed in the paper.",
    "author_remarks": "",
    "decision_comment": ""
  },
  {
    "id": "TdIx7u2ECv",
    "title": "Imagine to Ensure Safety in Hierarchical Reinforcement Learning",
    "authors": [
      "Gregory Gorbov",
      "Artem Latyshev",
      "Aleksandr Panov"
    ],
    "abstract": "This work investigates the safe exploration problem, where an agent must maximize performance while satisfying safety constraints. To address this problem, we propose a method that includes a learnable world model and two policies, a high-level policy and a low-level policy, that ensure safety at both levels. The high-level policy generates safe subgoals for the low-level policy, which progressively guide the agent towards the final goal. Through trajectory imagination, the low-level policy learns to safely reach these subgoals. The proposed method was evaluated on the standard benchmark, SafetyGym, and demonstrated superior performance quality while maintaining comparable safety violations compared to state-of-the-art approaches. In addition, we investigated an alternative implementation of safety in hierarchical reinforcement learning (HRL) algorithms using Lagrange multipliers, and demonstrated in the custom long-horizon environments SafeAntMaze that our approach achieves comparable performance while more effectively satisfying safety constraints, while the flat safe policy fails to accomplish this task.",
    "keywords": [
      "safe reinforcement learning",
      "machine learning",
      "model based reinforcement learning",
      "hierarchical reinforcement learning"
    ],
    "venue": "ICLR",
    "year": 2025,
    "pdf_url": "https://openreview.net/pdf?id=TdIx7u2ECv",
    "forum_url": "https://openreview.net/forum?id=TdIx7u2ECv",
    "reviews": [
      {
        "rating": "5",
        "confidence": "3",
        "summary": "This paper proposes a Safe RL algorithm that learns the model of the environment as well as a hierarchical approach to policy learning. In particular, it learns a high-level policy that creates sub-goals and a low-level policy that tries to achieve/reach the sub-goals. The authors claim improved results compared with Safe RL approaches that are based on primal-dual/Lagrangian relaxation.",
        "strengths": "- well-written and clear\n- problem and approach is well-motivated",
        "weaknesses": "- There are not too many benchmarks on which this algorithm has been tested (only three)\n- There are very few Safe RL baselines used for comparison. TD3Lag is the only primal-dual baseline, and it performs decently well but was used only in SafeAntMaze. Consider comparing with more primal-dual/Lagrangian relaxation approaches. \n- It is not clear if any model-based safe RL algorithms were used as baselines, especially when the proposed approach is model-based. How does the proposed approach compare empirically with Jayant & Bhatnagar, 2022?\n- It would be nice to have a pseudocode of the algorithm in one place.\n- It would also be nice to have the training parameters used for the algorithm.\n\nMinor errors:\n- Section 2.1 title typo \"constrained\""
      },
      {
        "rating": "5",
        "confidence": "3",
        "summary": "This paper addresses the challenge of safe exploration in reinforcement learning. To balance performance with constraint satisfaction, the authors use a hierarchical architecture in which the high-level policy outputs safe subgoals and the low-level policy learns to reach these subgoals. Leveraging a learnable world model, the agent is able to fully consider safety before taking actions. The authors test the proposed ITES algorithm in the SafetyGym simulation environment, demonstrating its effectiveness in balancing safety and performance across both short-horizon and long-horizon tasks.",
        "strengths": "- Using the world model to imagine safety before executing actions is an interesting idea.\n- The paper is well-organized, and the hierarchical structure is explained clearly.\n- The experimental results demonstrate ITES’s effectiveness in balancing safety with performance across both short- and long-horizon tasks.",
        "weaknesses": "- The authors state, \"ITES is the only one that combines model-based and hierarchy approach.\" However, the necessity of combining these two approaches is not demonstrated (for instance, if the model-based approach alone sufficiently improves safety, then a hierarchical structure may not be needed). Is this combination simply an “A+B” type of innovation?\n- The experiments are limited to simple navigation tasks, raising questions about the method’s effectiveness in more complex, real-world tasks beyond navigation.\n- The implementation codes are not provided."
      },
      {
        "rating": "6",
        "confidence": "3",
        "summary": "The paper proposes ITES (Imagine To Ensure Safety), a hierarchical reinforcement learning (HRL) method that incorporates a world model and dual-level safety policy to address the safe exploration problem. By generating safe subgoals with a high-level policy and optimizing short-horizon safety at the low level, ITES aims to balance performance and safety effectively. The world model enables ITES to \"imagine\" potential actions, verifying their safety before executing them in the real environment. Experiments on SafetyGym tasks and a more complex SafeAntMaze environment suggest that ITES achieves a safety advantage in long-horizon tasks while maintaining competitive performance in simpler settings.",
        "strengths": "ITES’s use of dual-level safety with high-level safe subgoal generation and low-level safety checks is a well-conceived approach to enhancing reinforcement learning safety. The method of verifying actions in imagination through a world model adds an innovative layer that may reduce real-world safety violations.\n\nThe results show that ITES achieves a reasonable balance between safety and performance, particularly in SafeAntMaze. This structure helps demonstrate ITES’s suitability for scenarios where long-horizon safety is critical, even if it compromises some performance in short-horizon tasks.\n\nITES introduces a practical approach for managing safety constraints in HRL by embedding safety checks at both the planning and execution levels, which may inspire further hierarchical developments in safe reinforcement learning.",
        "weaknesses": "Although ITES demonstrates safety advantages in the complex SafeAntMaze environment, it does not consistently provide a safer solution than CUP in simpler SafetyGym tasks. For example, in the PointGoal1 task, ITES sacrifices some safety in favor of performance, resulting in a higher reward but slightly increased safety violations compared to CUP. This suggests that ITES may not consistently prioritize safety over performance across different task types, which could limit its applicability in certain safety-critical environments.\n\nSafeAntMaze is the only complex, long-horizon task tested in the paper, which restricts the evidence supporting ITES’s generalizability to other challenging environments. Without more complex benchmarks, it’s difficult to conclude that ITES is superior to other approaches in handling diverse safety-intensive scenarios.\n\nIn the short-horizon SafetyGym tasks, ITES shows a performance advantage over CUP in the CarGoal1 task but lacks consistent improvements in safety. This performance-safety trade-off indicates that ITES may be best suited to tasks where performance can be favored without compromising critical safety constraints, making it less optimal for environments that strictly require safety prioritization.\n\nThe hierarchical structure in ITES introduces added complexity, but the benefits of this structure are not consistently clear across all tasks. While ITES demonstrates advantages in SafeAntMaze, the mixed results in SafetyGym suggest that simpler, single-policy methods may sometimes offer comparable or superior performance and safety. A broader range of tests could provide a clearer justification for the added complexity of ITES’s hierarchical approach."
      },
      {
        "rating": "5",
        "confidence": "5",
        "summary": "The core innovation of this paper is the proposed method called ITES (Imagine To Ensure Safety in Hierarchical Reinforcement Learning). This method combines model-driven reinforcement learning and hierarchical reinforcement learning to ensure safety. It introduces a high-level policy and a low-level policy to generate safe intermediate subgoals and guide the agent toward the final goal. Through trajectory imagination, the low-level policy learns to reach these subgoals safely. \nKey contributions include:\nUsing hierarchical reinforcement learning for enhanced safety and performance.\nEmploying a world model to verify safety in imagination and a cost model for generating safe subgoals.\nDemonstrating superior performance on SafetyGym and SafeAntMaze benchmarks compared to state-of-the-art methods, especially in satisfying safety constraints.",
        "strengths": "Compared to existing methods, ITES (Imagine To Ensure Safety in Hierarchical Reinforcement Learning) achieves better performance quality while maintaining comparable safety violations. Additionally, the paper explores an alternative implementation of safety in hierarchical reinforcement learning using Lagrange multipliers and demonstrates that ITES provides better safety while maintaining comparable performance to traditional safe policies in a custom long-horizon environment called SafeAntMaze.",
        "weaknesses": "1.The paper claims novelty in integrating safety with hierarchical reinforcement learning (HRL) and a model-based approach, but similar methods have been explored previously. For instance, Safe HIRO [1]  and IAHRL [2] also focuses on hierarchical approaches for safe exploration.  Provide a clearer distinction between ITES and existing approaches. Explicitly state the unique aspects of ITES, such as how the world model or subgoal generation differs from previous methods.\n[1] Roza F S, Roscher K, Günnemann S. Safe and efficient operation with constrained hierarchical reinforcement learning[C]//Sixteenth European Workshop on Reinforcement Learning, 2023.\n[2] Lee S H, Jung Y, Seo S W. Imagination-augmented hierarchical reinforcement learning for safe and interactive autonomous driving in urban environments[J]. IEEE Transactions on Intelligent Transportation Systems, 2024.\n2.The use of a world model for safety verification in imagination depends on the accuracy of the learned model. If the model is imperfect, it may not accurately detect safety violations, potentially leading to unsafe behavior in the real environment. This paper does not address the limitations of model inaccuracies or present any strategies to handle model uncertainty."
      }
    ],
    "rating_avg": 5.25,
    "confidence_avg": 3.5,
    "decision": "Reject",
    "meta_review": "This paper proposes a model-based hierarchical RL algorithm for safe RL. The claim is that the method demonstrates superior performance on the benchmark while maintaining comparable safety violations.\n\n### Strengths\nReviewers commented that the paper was well-written and clear,  the problem and approach is well-motivated, the idea was interesting, the paper is well-organized, the experimental results demonstrate the effectiveness in performance across both short- and long-horizon tasks, and the approach is practical. \n\n### Weaknesses\nReviewers commented that the benchmark evaluation is limited, very few Safe RL baselines are included, that the method is an \"A+B\" type of innovation, the experiments are limited to simple navigation tasks, that the method is outperformed in simpler Safety Gym tasks, that the method only used one complex long-horizon task which restricts the evidence supporting ITES's generalizability to other challenging environments, that the evidence suggests it is less optimal for environments that strictly require safety prioritization, that the benefits of the added complexity are not consistently clear across all tasks, that the method is very similar, and that the paper does not address the limitations of model inaccuracies or present strategies to handle model uncertainty \n\nThe authors responded to the reviews, and then almost all of the reviewers engaged with the authors. The reviewers generally had reservations about the contribution of the method due to limited performance gains. This paper is borderline: while there is some evidence to support the claims, the results are somewhat mixed. One takeaway from the reviews is that this paper would be substantially improved with more comprehensive experiments. I recommend rejecting this paper in its current form.",
    "author_remarks": "",
    "decision_comment": ""
  },
  {
    "id": "Nfd7z9d6Bb",
    "title": "Probabilistic Conformal Prediction with Approximate Conditional Validity",
    "authors": [
      "Vincent Plassier",
      "Alexander Fishkov",
      "Mohsen Guizani",
      "Maxim Panov",
      "Eric Moulines"
    ],
    "abstract": "We develop a new method for generating prediction sets that combines the flexibility of conformal methods with an estimate of the conditional distribution $\\textup{P}_{Y \\mid X}$. Existing methods, such as conformalized quantile regression and probabilistic conformal prediction, usually provide only a marginal coverage guarantee. In contrast, our approach extends these frameworks to achieve approximately conditional coverage, which is crucial for many practical applications. Our prediction sets adapt to the behavior of the predictive distribution, making them effective even under high heteroscedasticity. While exact conditional guarantees are infeasible without assumptions on the underlying data distribution, we derive non-asymptotic bounds that depend on the total variation distance of the conditional distribution and its estimate. Using extensive simulations, we show that our method consistently outperforms existing approaches in terms of conditional coverage, leading to more reliable statistical inference in a variety of applications.",
    "keywords": [
      "Conformal Prediction",
      "Conditional coverage",
      "Probabilistic method",
      "Uncertainty Quantification"
    ],
    "venue": "ICLR",
    "year": 2025,
    "pdf_url": "https://openreview.net/pdf?id=Nfd7z9d6Bb",
    "forum_url": "https://openreview.net/forum?id=Nfd7z9d6Bb",
    "reviews": [
      {
        "rating": "6",
        "confidence": "4",
        "summary": "This paper looks at the central issue of covariate-conditional validity of conformal prediction methods. They propose a systematic and novel procedure of turning a black box estimation of conditional distributions (Y|X) into a valid conformity score which then can be used to construct prediction sets. They carefully design the procedure to make their prediction sets adaptive to the behavior of the conditional distribution. Their method effectively generalizes the previous literature on using conditional distribution estimation by 1) providing algorithmic and theoretical results targeting conditional coverage and 2) going beyond one-dimensional regression setting.",
        "strengths": "- The issue of conditional coverage of conformal prediction methods is of particular interest in CP community. They expand the ideas of using an estimation of conditional coverage to enhance the covariate-conditional performance of CP to the more general setting of multi-dimensional prediction tasks.\n- They also provide theoretical guarantees on the relation between the quality of the conditional distribution estimation and the improvements in the conditional coverage property of CP, which was a missing flavor for most of the previous works in this line of thinking.",
        "weaknesses": "- In general, the whole line of work based on estimations of conditional density suffers from the curse of dimensionality (covariate dimension). Therefore, it is important to see some empirical evaluations of the proposed method on high dimensional tasks (in particular image classification), even if it doesn't work very well, it helps the follow-up works with having a more accurate understanding of your method. Another interesting experiment to see is a synthetic regression task that you can directly plot the (conditional) coverage properties vs. dimension of the input and showcase the degree of tolerance of your proposed method. \n- Focusing on the lower dimensional tasks, where conditional density estimation is more feasible, It is good to see the performance of your proposed method in comparison with recent methods like the one proposed by https://arxiv.org/abs/2305.12616. You can for instance set their function class to be a linear map form the data itself to a scalar threshold, or train a neural network regression model in the training time and then set the function class to be a linear head from the last layer of the trained neural network to a scalar threshold. In general, it is important to see whether using the conditional density estimation (when feasible) can actually beat the methods that does not rely on conditional density estimation.\n- Taking a step back, intuitively, it is obvious that the usage of an estimate of the conditional density estimation should improve the conditional coverage behavior of CP. However, it is not entirely obvious whether all the information in the density function is needed to construct perfect prediction sets. In other words, the key question is what parts of the information in the conditional density function are actually needed for constructing prediction sets. This question is very important to look at as the answer to it might reveal a way to beat the curse of dimensionality, as then you can only try to learn the useful information instead of the whole conditional density function. To this end, 1) it might be good (as a suggestion) to discuss this point of view (maybe as a future work) in your paper. In particular, how fundamental conditional density estimation is for your pipeline. 2) It is good to discuss the methods that are based on the described idea in your paper, for instance https://arxiv.org/abs/2404.17487, as that helps the reader to have a better understanding of the whole methodology."
      },
      {
        "rating": "6",
        "confidence": "4",
        "summary": "This paper achieves powerful conditional coverage via a technique that relies on sampling from an empirical estimate of the underlying conditional data distribution. Their method achieves impressive empirical benefits alongside powerful provable guarantees. \n\nOverall this paper has clear contributions and is very sound. I vote to accept this paper.",
        "strengths": "1. the underlying approach of estimating the conditional distribution via sampling and proposing the conformal set using these samples (to my knowledge) is unique to this paper\n2. This paper has very nice asymptotic guarantees of performance under different underly data distributions\n3. The approach is very simple and applicable, making it generally useful in many fields. \n4. The empirical validation is very impressive",
        "weaknesses": "1. Some of the figures are not accessible. It is difficult to see for someone who is red-green colorblind. This includes Figure 1. \n2. Some of the presentation of the theoretical ideas, especially on page 6, is difficult to parse. Better formatting would increase readability."
      },
      {
        "rating": "6",
        "confidence": "3",
        "summary": "The authors propose a $\\text{CP}^2$ framework for conformal prediction that aims to achieve approximately conditional coverage. The key difference from classical split CP is the introduction of a parameter, $\\tau$, defined through either the estimation of the conditional distribution $P_{Y|X}$ or the use of a conditional generative model, allowing for adaptive threshold adjustments. Theoretically, they provide a finite-sample marginal coverage guarantee as well as an asymptotic guarantee through a upper bound on conditional coverage. The framework's efficiency is demonstrated through experiments on both synthetic and real-world data.",
        "strengths": "This paper provides a specific approach to leverage information from the conditional distribution to improve conditional coverage. Besides estimating conditional distributions directly, the authors also consider alternatives using a conditional generative model when identifying HPDs is challenging.",
        "weaknesses": "1. The paper's writing could be improved, particularly in terms of clarity and presentation. For example, the literature review lacks clarity, and could benefit from a more comprehensive and topic-oriented discussion of related work.\n\n2. Regarding the experimental section, it is noted that several key baselines from existing literature have been overlooked. Additionally, it seems that the superiority of CP² in terms of worst-slab coverage is not particularly evident comparing with CQR/CQR2 in Figure 3."
      },
      {
        "rating": "6",
        "confidence": "4",
        "summary": "The paper offers a new score function for constructing conformal prediction sets to improve adaptivity and approximated conditional coverage.\n\nInstead of explicitly relying on a score function, they use a confidence set function---an idea that is known in the literature. The proposed construction of the prediction set suggests scaling the conformal scores \\lambda_k by \\tau_k, extracting the 1-alpha quantile Q, and then applying the \"inverse scaling\" of Q by using f_{\\tau}.  \n\nSince their method requires estimating Y|X which is generally hard---especially when Y is high dim.---they offer an approach to using a sampling generative model for constructing the prediction sets (Algorithm 1); inspired by Wang et al.\n\nThe authors provide a marginal guarantee, approximated conditional coverage (depending on the quality of the estimator), and an asymptotic conditional coverage guarantee.",
        "strengths": "1. A conformal framework to construct conformal prediction sets with improved adaptivity.\n\n2. Thorough theoretical study (marginal, conditional, asymptotic analysis for the coverage).\n\n3. Thorough experiments, comparing CP^2 to leading methods except the multi-dim. case; see comment below.",
        "weaknesses": "1. While the paper offers a general construction for prediction sets, it shares ideas with existing methods such as (1) local conformal---the scaling part; (2) HPD split or distributional conformal prediction by Chernozhukov et al.---both using the conditional distribution estimator; and (3) sampling using generative models, inspired by Wang et al. Of course, the paper nicely combines these ideas into one framework, which is great, but I am not sure it brings a novel concept. I would be happy to get the author's feedback here: what is the concrete edge of the proposed method compared to prior work that also builds on conditional distribution estimation to promote adaptive/conditional coverage?\n\n2. I suggest better explaining the role of Z. It was not clear to me what the variable Z is until reaching line 252. For example, in line 152, it is not clear at all what you mean by \"sampled according to a kernel Z|X\". Consider improving the exposition in line 152, e.g., by providing a concrete example.\n\n3. Section 4.1: how does the CP^2-HPD perform compared to HPD-split by Izbicki et al. (2022)? Such a comparison is missing, and it is important to include it to understand the advantages of the proposed method. Please clarify why you expect the proposed method to improve performance.\n\n4. The experiments with multi-dimensional response lack stronger baseline methods, such as the one by Feldman et al (reference below) and/or related techniques. If a full experimental comparison is not feasible, it is crucial to discuss the conceptual differences between the methods.\n\nS. Feldman, S. Bates, and Y. Romano, \"Calibrated Multiple-Output Quantile Regression with Representation Learning,\" JMLR, 2022."
      },
      {
        "rating": "6",
        "confidence": "4",
        "summary": "This paper proposes a conformal prediction method to enhance conditional coverage while still ensuring a finite-sample marginal coverage guarantee. The authors consider estimating the conditional distribution of $Y|X$ on the training data and use this estimator to define a localization parameter $\\tau$ for each calibration and test sample. These parameters are then used to adjust non-conformity score values. The authors prove the marginal validity of their method and give an inflation bound for the conditional coverage. They also prove the asymptotic conditional validity of their proposed interval in the oracle sense. Experimental results show slight superiority of the proposed method compared with other conditional conformal prediction methods.",
        "strengths": "The nonconformity score function proposed is similar to dividing the residual score by a conditional standard deviation estimator, which is replaced by a factor relating the conditional distribution of Y|X by the authors. In my opinion, the proposed method is especially suitable for multi-modal settings, in which directly characterizing the overall upper and lower prediction bound is not effective.",
        "weaknesses": "Despite reasonable, the proposed method only shows slight empirical improvement compared with existing methods. The theoretical results are also achievable by methods like the LCP (Guan, 2023). There is a lack of theoretical results regarding properties like optimality or superiority, etc."
      }
    ],
    "rating_avg": 6.0,
    "confidence_avg": 3.8,
    "decision": "Accept (Poster)",
    "meta_review": "The authors leverage an estimated conditional distribution $P_{Y|X}$ to construct prediction sets that adapt to the local structure of the data, achieving approximate conditional validity. They define confidence sets $R_z(x; t)$, calibrated using a parameter $\\tau_{x,z}$ derived from $P_{Y|X}$, and use conformity scores $\\lambda_{x,y,z}$ to ensure these sets dynamically adjust to heteroscedasticity and multimodality. For complex distributions, the method supports unions of high-density regions, enabling effective prediction even in multimodal cases. The framework guarantees approximate conditional coverage, with errors bounded by the total variation distance between the true and estimated conditional distributions, making it robust and adaptable to various machine learning tasks.\n\nAs a core technical novelty, the conformity score $\\lambda_{x,y,z}$ is defined as the minimum \"effort\" i.e. size $t$ of the confidence set $R_z(x; t)$ needed to include the observed $y$. Intuitively, This score captures the relationship between the observation $y$ and the local structure of $P_{Y|X}$, allowing the prediction sets to adapt not only to the estimated distribution but also to the specific data point being predicted. \n\nThe method is innovative but heavily dependent on high-quality conditional distribution estimators. In a strict sense, the proposed method does not provide fundamentally stronger conditional guarantees than existing methods. Asymptotically, conditional coverage has been established in numerous previous conformal prediction paper as well as consistency analysis for estimation of conditional distribution. So it is pretty difficult to grasp what new problem is being solved in this paper and what new it brings to the current literature. \n\nThe paper suffers from significant clarity issues, primarily due to its dense and cluttered presentation. It overloads the reader with mathematical rigor, complex notations, and auxiliary variables without first providing an intuitive understanding of the method, making it difficult to grasp the core ideas. And at the end, we can hardly extract a significant novelty. This is really concerning and I encourage the authors to not obfuscate the readers. All the marginal coverage established in this paper hold directly from well known coverage results in conformal prediction but are presented as a *\"new result\"*.\n\n---\n*While I acknowledge that the paper would benefit greatly from simplifying the exposition and presenting the contributions in a more transparent way, the reviewers' post-rebuttal feedback indicates that the contributions are sound and sufficient for acceptance. The program chairs can weigh these merits alongside the remaining concerns to make the final decision.*",
    "author_remarks": "",
    "decision_comment": ""
  },
  {
    "id": "7jDv1RrNQX",
    "title": "Path Selection Makes BERT-family Good Generators",
    "authors": [
      "Yisheng Xiao",
      "xiaobo liang",
      "Juntao Li",
      "Zechen Sun",
      "Pei Guo",
      "Wenpeng Hu",
      "Min Zhang"
    ],
    "abstract": "The Mask-Predict decoding algorithm has been widely used to enhance the generation capacity of traditional non-autoregressive (NAR) models and provide a good recipe for adapting the pre-trained BERT-like masked language models (MLMs) to NAR generation scenarios.\nHowever, these models, which we denote as NAR-MLMs, are still regarded as inferior to competitive autoregressive (AR) models in terms of performance.\nIn this paper, we further explore the core problems leading to the performance gap of NAR-MLMs and delve into effective solutions for technological innovation.\nSpecifically, most related works neglect the impact of the training sequence decomposition format, i.e., \nUnlike the AR models which can naturally decompose the text sequence in a left-to-right manner for training and inference, NAR-MLMs are trained with a random decomposition but aim to find a determined optimal composition (denoted as decoding paths) during inference.\nTo alleviate this mismatching, we propose decoding path selection to increase the search space for finding a better \ncomposition, and path optimization methods to enable the model decoding path preference during the training process. \nResults on various zero-shot common sense reasoning and reading comprehension tasks and several task-specific generation tasks demonstrate that our NAR-MLM achieves significant performance improvements on common benchmarks with the methods mentioned above, reaching performance levels comparable to even outperforming AR pre-trained models. Our model and code will be available at Github.",
    "keywords": [
      "BERT-family",
      "path selection",
      "natural language generation"
    ],
    "venue": "ICLR",
    "year": 2025,
    "pdf_url": "https://openreview.net/pdf?id=7jDv1RrNQX",
    "forum_url": "https://openreview.net/forum?id=7jDv1RrNQX",
    "reviews": [
      {
        "rating": "3",
        "confidence": "4",
        "summary": "This paper investigates the application of BERT-style models as generators. It introduces two path selection strategies and trains a BERT-style model with instruction-following capabilities. The study demonstrates zero-shot performance in common sense question answering and reading comprehension, and achieves comparable autoregressive generation capabilities on the XSUM summary dataset.",
        "strengths": "-\tIn the context of the rising popularity of decoder-only architecture in large language models, this paper revisits the encoder-only architectures. This perspective may encourage the academic community to view generative models differently and inspire new thinking about model architecture.\n\n-\tThe method proposed by the author endows BERT-style models with zero-shot capabilities in common sense question answering tasks, while also offering a speed advantage over autoregressive models.",
        "weaknesses": "-\tWhile I believe research on encoder-only models remains valuable, the motivation behind this paper is unclear to me. Given that autoregressive models have demonstrated excellent generative capabilities across various tasks, why do the authors choose to focus on BERT-style models instead of enhancing autoregressive models? I look forward to discussing this with the authors.\n\n-\tIf the authors aim to explore whether BERT-style models can achieve generative capabilities comparable to those of autoregressive models, then a broader range of generative tasks should be included in their experiments. The datasets used in the paper, such as ARC, primarily consist of multiple-choice questions and do not leverage generative capabilities.\n\n-\tIf the authors intend to demonstrate that BERT-style models can achieve faster generation speeds, they should compare their speeds with a broader range of non-autoregressive models. However, it is unclear why the authors only use the encoder-decoder model BART as the baseline for this speed comparison in Table 2.\n\n-\tThe experimental comparison does not seem to be fair. The author's pre-trained GeBERT uses advanced RoPE position encoding and sets the maximum length to 2048, but the maximum length of BART is 1024. More advanced generative models are recommended for comparison.\n\n-\tThe writing needs improvement. The path selection algorithm is not clearly articulated, and there are also several typos present as follows:\na)\tSection 3.1 discusses the path selection algorithm; however, the phrase “As shown on the left in Figure 2” in line 157 refers to the path selection-star illustrated in Figure 2.\nb)\tLine 372, “BART-largeGeBERT 124M” -> “BART-large”\nc)\tLine 535, “fron scratch” -> “from scratch”"
      },
      {
        "rating": "6",
        "confidence": "3",
        "summary": "This work introduces GeBERT, a variant of BERT specifically pre-trained to leverage path selection, calming that it performs competitively, often on par with or surpassing traditional autoregressive models on various zero-shot and task-specific generation tasks.",
        "strengths": "1. With the rise of autoregressive models, research on BERT-family models for generative tasks has decreased, and few studies have explored their generative capabilities. This study takes a fresh approach to directly compare BERT models with AR models.\n\n2. Introduces a method to expand the search space during inference, allowing BERT models to select the optimal path for improved generation quality. and also incorporates path selection into the training process, enabling BERT models to learn and prefer certain paths over others, further enhancing output quality.\n\n3. Experimental results show substantial improvements in both zero-shot and fine-tuned settings, demonstrating that, with these modifications, BERT-family models can effectively compete with AR models.",
        "weaknesses": "1. While this research is innovative and valuable, a fundamental question remains—why use BERT for generation tasks? Given scaling laws, AR models generally improve significantly with larger model sizes, while BERT-family models struggle to achieve similar gains. Moreover, as shown in Table 1, the performance improvements for GeBERT are limited compared to AR models.\n\n2. The path selection techniques introduce additional complexity, particularly in tuning hyperparameters for path selection*. This added complexity could hinder the practical application and usability of these methods.\n\n3. The experimental models are relatively small in scale. Larger models might address or clarify the first weakness I raise, providing a stronger case for BERT's use in generation tasks."
      },
      {
        "rating": "3",
        "confidence": "3",
        "summary": "The paper proposes a method to select the decoding paths of BERT-family to conduct generation tasks. They also propose a DPO method to optimize the preferences of the model over difference paths. Experimental results show that the decoding method and preference optimization method can effectively improve the generation quality of BERT-family on zero-shot commonsense reasoning, reading comprehension, summarization and question generation tasks.",
        "strengths": "1. The proposed method select the positions to decode dynamically, which is suitable for BERT-like models. BERT-like models trained with masked language modeling objective can predict any positions in the target part, while autoregressive language models can only follow the left-to-right order.\n2. Experimental results show that the proposed method can effectively improve the generation quality of BERT-like models on various tasks.",
        "weaknesses": "1. On Line 146 the authors aim to identify an optimal decoding path. In other parts the authors also state that previous methods cannot find the optimal paths. But the proposed method cannot guarantee to find the optimal decoding path. It is a form of beam search over the mask-predict algorithm, and beam search cannot guarantee to find the optimal solution.\n2. The description of the path selection algorithm in Section 3.1 is unclear. The example in Figure 2 is not enough since it didn't describe how the lowest-k total prediction probabilities are selected. The authors should give a pseudocode to describe the algorithm.\n3. In Section 5.1 the authors find that BERT-like models can achieve competitive performance with AR models when the model predicts one token in each decoding step. In that case it requires the same number of decoding steps as AR models, and the compute of each decoding step is much larger than that of AR models since BERT-like models cannot reuse kv cache during inference. There is not efficiency advantage compared with AR models. Therefore I challenge the motivation to apply BERT-like models to generation tasks.\n4. On Line 87 the authors claim that path selection* incorporates path selection into the training process. In fact neither the sampling methods to generate the pairs nor the computation of the probability considers the path selection method."
      },
      {
        "rating": "3",
        "confidence": "4",
        "summary": "This paper examines BERT-family models' generation capabilities. It proposes path selection to expand inference search space and path selection*, which is an application of DPO, to train the model for better path selection. The methods improve BERT's performance across multiple zero-shot tasks to match or exceed autoregressive models.",
        "strengths": "This paper proposes innovative solutions - path selection to expand inference search space and path selection* to integrate path selection into training, which demonstrably elevate BERT's performance across multiple zero-shot tasks to match or exceed autoregressive models.",
        "weaknesses": "The generation capabilities of BERT are investigated in previous paper, e.g. [1]. This paper aims to improve the performance of BERT by using path selection, a non-autoregressive variation for inference. However, the paper lacks details on path selection, especially about how to choose the position to predict if beam size > 2. There are other potential issues should be considered for Mask-Predict methods, e.g. the potential mode collapse with many iterations. More ablation studies about the designs and clear pseudo-codes are needed.\n\nPath selection* is an application of DPO, but the `Score' function is not defined in the paper, which diminishes the contribution of the paper.\n\n[1] Patel, Ajay, et al. \"Bidirectional Language Models Are Also Few-shot Learners.\" The Eleventh International Conference on Learning Representations."
      }
    ],
    "rating_avg": 3.75,
    "confidence_avg": 3.5,
    "decision": "Reject",
    "meta_review": "The paper argues that the way existing methods use BERT-like models for generation (what they are calling NAR-MLMs) is suboptimal. They claim that the random decomposition of the text sequence during training doesn't match the need to find a specific order during generation. The paper tackles a relatively under-explored area – using encoder-only models like BERT for generation. The experiments are criticized for their limited scope (lack of diversity in generative tasks, comparing against one AR model, lack of different sized models). The comparison to AR models isn't considered fair by some reviewers because of the experimental setup differences. The path selection algorithm isn't clearly explained, making it hard for reviewers to assess soundness. The reviewers ask for more analysis to better understand the role of the proposed methods and other possible issues in the algorithm.  Addressing the weaknesses, particularly improving clarity and providing more robust experiments, would be crucial for future submission consideration.",
    "author_remarks": "",
    "decision_comment": ""
  },
  {
    "id": "6w9qffvXkq",
    "title": "Improving CNN training by Riemannian optimization on the generalized Stiefel manifold combined with a gradient-based manifold search",
    "authors": [
      "Alexander Studt",
      "Till Riedel",
      "Michael Beigl"
    ],
    "abstract": "Enforcing orthonormality constraints in deep learning has been shown to provide significant benefits. Although hard restrictions can be applied by constraining parameter matrices to the Stiefel manifold, this approach limits the solution space to that specific manifold. We show that a generalized Stiefel constraint $X^TSX=\\mathbb{I}$ for Riemannian optimization can lead to even faster convergence than in previous work on CNNs, which enforced orthonormality. The gained flexibility comes from a larger search space. In this paper, we therefore propose a novel approach that retains the advantages of compact restrictions while using a gradient-based formulation to adapt the solution space defined by $S$. This approach results in overall faster convergence rates and improved test performance across CIFAR10, CIFAR100, SVHN, and Tiny ImageNet32 datasets on GPU hardware.",
    "keywords": [
      "Riemannian optimization",
      "Convolutional neural networks",
      "gradient-based optimization",
      "deep neural networks",
      "generalized Stiefel manifold"
    ],
    "venue": "ICLR",
    "year": 2025,
    "pdf_url": "https://openreview.net/pdf?id=6w9qffvXkq",
    "forum_url": "https://openreview.net/forum?id=6w9qffvXkq",
    "reviews": [
      {
        "rating": "3",
        "confidence": "3",
        "summary": "The paper \"Improving CNN training by Riemannian optimization on the generalized Stiefel manifold combined with a gradient-based manifold search\" describes an optimization method on the  generalized steifel manifold using a gradient based method",
        "strengths": "Instead of using strict orthonormal constraints (Stiefel manifold), they propose a generalized version with a learnable \"overlap matrix S\" that:\nexpands the solution space beyond traditional orthonormal matrices\nwhile maintaining the beneficial properties of orthonormal approaches\nand can be optimized using gradient-based methods during training.",
        "weaknesses": "This paper is delta increment of the Li(2020 iclr) paper which proposed the cayley transformation update on the Steifel manifold, this just extends it to the generalized steifel manifold with an overlap parameter S. Once can do a exact extension of the Key steps in Li to this paper by adding extra terms related to the S matrix. This make the theoretrical contribution weak.\n\nThe experiments seem a bit forced. Why is an orthogonality regularizer needed at all? Does this make the model work better for other deep network models on these well known datasets. Limited comparsion with other approaches dont support that argument"
      },
      {
        "rating": "1",
        "confidence": "5",
        "summary": "This paper proposes an approach to improve CNN training by applying Riemannian optimization on a generalized Stiefel manifold, aiming to enhance convergence rates and performance through a dynamic adjustment of the overlap matrix SSS. While the idea of optimizing over a generalized Stiefel manifold could be useful, the paper falls short in several critical areas, both theoretically and empirically.",
        "strengths": "The paper explores a novel approach by generalizing the Stiefel manifold constraint.",
        "weaknesses": "The theoretical novelty is very limited:\n\n1. Riemannian optimization usually retraction and vector transport, instead of an exponential map or parallel transport (L 135). It is not clear why you compare exp and pt with the Cayley map. Until the next section, it comes to me that Cayley is the retraction. until I read the original paper, i realized the Cayley is one of the retractions. All of the above should be clarified and acknowledged in the paper.\n2. Eq. (4) is theoretically questionable:\n   - Why should S lie in SPD? This will limit the generality. \n   - Although $R$ in Eq. (4) lies in $R^{n \\times n}$, it is not a Euclidean parameters. How do u respect the non-Euclidean space\n   - More importantly, as $R$ changes, the latent space is changing. It is quit weird for the current method to omit this fact. For example, how do you transform the momentum between different manifolds?\n\n3. A very counterintuitive issue is that the authors used momentum but didn’t involve vector transport. through all the algorithms, it's like a straightforward variant of Trivializations [1].\n\nEmpirical validation is very unconvincing:\n  - The experimental validation is insufficient. The authors only evaluate the method on small datasets (e.g., CIFAR10, CIFAR100, SVHN, Tiny ImageNet32) and use very limited backbones. \n  - The comparison method is very limited and far from enough. For instance, as this is a direct variant of trivializations, why the authors miss trivializations is not clear. and Also the comparison with Riemannian Gen-st optimization is missing. I believe they are more, apart from the most natural competitor I mentioned.\n\n\n[1] Trivializations for Gradient-Based Optimization on Manifolds"
      },
      {
        "rating": "3",
        "confidence": "4",
        "summary": "The paper discusses the growing interest in incorporating orthonormality constraints in deep learning, particularly through the use of Riemannian optimization techniques on the Stiefel manifold, which ensures orthonormal parameter matrices in CNNs. While previous studies have shown that orthogonality regularization can improve accuracy and convergence rates, strict enforcement of orthonormality can limit the solution space and hinder performance. To address this, the authors propose a novel approach that generalizes the Stiefel manifold by introducing a flexible overlap matrix, thereby expanding the solution space during training. Their method dynamically optimizes this overlap matrix using gradient-based techniques, promising improved convergence rates and overall accuracy without excessive restrictions on optimization. The introduction situates this work within existing literature and identifies a gap regarding the implementation of generalized Stiefel manifold optimization in deep learning.",
        "strengths": "1. It seems the approach addresses the limitations of strict orthonormality constraints, which have been shown to be disadvantageous in some scenarios.\n\n2. The paper builds upon established Riemannian optimization techniques, presenting a well-structured way for optimizing the overlap matrix. \n\n3.  By addressing the challenges associated with parameter matrix optimization in CNNs, this work has the potential in improving empirical convergence rates and higher test accuracies with advancements in deep learning applications.",
        "weaknesses": "1. While the introduction provides a solid overview, some sections of the paper could benefit from clearer explanations of the mathematical concepts, particularly regarding the generalized Stiefel manifold and the optimization procedures. See questions below\n\n2. The proposed optimization method may introduce additional computational complexity. A more thorough analysis of the computational requirements and efficiency, especially in comparison to existing methods, would be beneficial. \n\n3. Unfortunately large body of the paper is in parallel with the work from paper  Li et al. (2020). The generalized Stiefel manifold and optimization algorithms on it have been well researched.  I see no very significant contribution except for making adaptive generalized Stiefel manifold for network parameters. The paper may not be suitable for ICLR.\n\n4. The implementation details should be released."
      },
      {
        "rating": "3",
        "confidence": "5",
        "summary": "This paper studies training deep neural networks with the generalized Stiefel constraint, and conduct empirical study on small datasets including CIFAR10, CIFAR100, SVHN, and Tiny ImageNet32.",
        "strengths": "Training DNNs with orthonormality constraints was explored in the literature before, and this paper extends such idea to generalized Stiefel constraint and conducted empirical study.",
        "weaknesses": "There are several major concerns.\n\n(1) The technical novelty is rather minimal. This paper considers the generalized Stiefel constraint, $X^{\\top} S X = I$, which is an incremental change compared to the regular orthonormality constraint $X^{\\top} S X = I$ on the usual Stiefel manifold. Furthermore, there are no theoretical guarantee or analysis on the claims about overall faster convergence rates and/or improved test performance.\n\n(2) The empirical study is only performed on outdated neural network architectures, such as WRN and VGG, and small datasets (CIFAR10, CIFAR100, SVHN, and Tiny ImageNet32). Much more extensive results on modern neural networks, such as vision transformers (ViT, Swin, etc.), on larger benchmarks (at least ImageNet-10k) are expected to justify the empirical claims of this paper."
      },
      {
        "rating": "3",
        "confidence": "5",
        "summary": "This paper proposes a novel approach for training convolutional neural networks (CNNs) using Riemannian optimization on the generalized Stiefel manifold, which introduces a symmetric overlap matrix \\( S \\) as a hyperparameter. The authors argue that generalizing from the standard Stiefel manifold constraint \\( X^T X = I \\) to \\( X^T S X = I \\) allows more flexibility and a larger solution space. The approach employs gradient-based optimization for \\( S \\) in combination with Riemannian optimization for the CNN parameters and evaluates this method using generalized Cayley SGD and Cayley ADAM optimizers on various datasets. The experimental results show improvements in convergence rates and classification accuracy over traditional Stiefel manifold constraints.",
        "strengths": "1.\tThe paper introduces the generalized Stiefel manifold as an alternative to traditional orthonormal constraints in CNNs, which has not been widely applied in this context. By treating \\( S \\) as a tunable hyperparameter, the approach explores a new angle in Riemannian optimization for CNNs.\n\n2.\tThe experiments present a thorough comparison across datasets, including CIFAR-10, CIFAR-100, SVHN, and Tiny ImageNet32, demonstrating that the proposed manifold constraint leads to faster convergence rates and improved test accuracy in most cases",
        "weaknesses": "1.\tWhile the paper empirically demonstrates the generalized Stiefel manifold's benefits, it lacks a theoretical explanation or proof of why the generalized constraint \\( X^T S X = I \\) should offer significant advantages over traditional orthonormal constraints in CNN applications. The claim that the generalized manifold “leads to more possible solutions” is not supported by rigorous theoretical arguments. Including a deeper exploration of how this generalization impacts learning dynamics or theoretical properties (e.g., stability or expressivity) would strengthen the work.\n\n2.\tThe evaluation primarily compares the generalized Stiefel manifold against baseline methods in the paper without broader comparisons with other established regularization techniques such as weight normalization, spectral normalization, or orthogonality regularizations (e.g., Bansal et al., 2018). Such comparisons would provide a more comprehensive assessment of the proposed method's relative performance in CNN optimization.\n\n3.\tWhile the paper uses Bayesian optimization to determine \\( S \\), it lacks visualization or interpretative analysis showing how different configurations of \\( S \\) affect convergence behavior. The overlap matrix \\( S \\) is central to the proposed approach, and further insights into its learned values across datasets or their influence on the optimization path could provide interpretative depth and help readers assess the flexibility and robustness of this method.\n\n4.\tThe additional complexity introduced by the generalized Stiefel manifold’s optimization process, particularly the inversion of \\( S \\), doubles the time for training epochs compared to Riemannian optimization without \\( S \\). While faster convergence is reported, the paper does not address the trade-offs adequately. This additional cost should be discussed in terms of computational efficiency, especially for large-scale datasets."
      }
    ],
    "rating_avg": 2.6,
    "confidence_avg": 4.4,
    "decision": "Reject",
    "meta_review": "This paper mainly focuses on improving CNN training by Riemannian optimization on the generalized Stiefel manifold. It achieves faster convergence rates and performance on several commonly adopted datasets. It receives all five negative ratings, including one strong reject and four reject. Reviewers are concerned about the limited novelty, incremental contribution, insufficient analysis, etc. Specifically, based on the method of  Li(ICLR2020), this paper mainly extends it to the generalized Stiefel manifold with an overlap parameter S, where the contribution is somewhat limited and incremental. The concerns still exist since the authors also do not present a response during the rebuttal phrase. I think the current manuscript does not meet the requirements of this top conference. I suggest the authors carefully revise the paper and submit it to another relevant venue.",
    "author_remarks": "",
    "decision_comment": ""
  },
  {
    "id": "GF1sRSBiwY",
    "title": "Physics-Informed Neural Networks with Message-Passing Weights",
    "authors": [
      "Hyunwoo Cho",
      "Hwijae Son",
      "Hyung Ju Hwang"
    ],
    "abstract": "Adaptive loss balancing algorithms play a crucial role in improving the performance of Physics-Informed Neural Networks (PINNs) by effectively managing the weights assigned to different loss components. Most notably,  Wang et al. (2022) introduced Causal Physics-Informed Neural Networks (Causal PINNs), which achieve superior performance by simply reformulating the loss function based on the causal structure that emerges from time dependency. However, despite their empirical success, a solid theoretical analysis for the effectiveness of Causal PINNs has not received adequate attention. This paper addresses this gap by providing a theoretical rationale for Causal PINNs through the Belief Propagation (BP) algorithm, which is commonly used for causal inference. In addition, motivated by this analysis, we propose a Message Passing PINNs (MP-PINNs), a novel adaptive weighting algorithm. Through extensive numerical experiments, we demonstrate that the proposed MP-PINNs significantly outperform existing adaptive weighting methods, exhibiting superior performance in solving complex PDEs. Our findings highlight the potential of MP-PINNs as a powerful tool to enhance both the accuracy \nand efficiency of PINNs.",
    "keywords": [
      "Physics-informed Neural Networks",
      "Adaptive Loss-Balancing Algorithms",
      "causal PINN",
      "Belief Propagation"
    ],
    "venue": "ICLR",
    "year": 2025,
    "pdf_url": "https://openreview.net/pdf?id=GF1sRSBiwY",
    "forum_url": "https://openreview.net/forum?id=GF1sRSBiwY",
    "reviews": [
      {
        "rating": "5",
        "confidence": "3",
        "summary": "- Provides a theoretical understanding for Causal PINNs through the Belief Propagation algorithm. \n- Proposes a novel adaptive weighting algorithm termed Message Passing PINNs (MP-PINNs)\n- Empirically demonstrate that the proposed approach MP-PINNs outperform existing adaptive weighting methods for solving complex PDEs",
        "strengths": "- Empirically demonstrates the proposed approach MP-PINNs outperform existing adaptive weighting methods for solving complex PDEs\n- Provides a novel theoretical understanding of Causal PINNs",
        "weaknesses": "- The authors note that further theoretical analysis is required for the hyper parameter D (number of message-passing iterations). A proper ablation study to empirically understand performance w.r.t. this hyper parameter would be useful."
      },
      {
        "rating": "3",
        "confidence": "4",
        "summary": "The paper attempts to provide a theoretical analysis of the effectiveness of Causal PINNs with the Belief Propagation algorithm and proposes a new algorithm called Message Passing PINNs. It demonstrates the effectiveness of this approach in solving various PDEs.",
        "strengths": "The empirical performance looks promising.",
        "weaknesses": "The paper does not seem ready for publication; the clarity is lacking, and parts of the related work and formal justification for the theoretical analysis are missing.\n\n1. **Missing related work**: In line 80, “Despite the applicability of PINNs for solving various PDEs, there are still various problems to solve.” However, the paper does not cite any work here and later cites only one paper afterward. In line 90, “to address the failure mode of PINNs.” The paper does not describe what the failure mode of this algorithm is.\n\n2. **Insufficient background**: The paper has not defined the main goal or the notation used in section 2, which may make it difficult to read.\n\n3. **Theoretical analysis organization**: The paper does not present the results as theorems and proofs but rather writes the results in paragraph form, making it less formal.\n\nWhile the empirical performance looks good, I think the current version of this paper is not yet ready for ICLR."
      },
      {
        "rating": "3",
        "confidence": "2",
        "summary": "This paper presents a message-passing algorithm for solving partial differential equations (PDEs). The main idea seems to be to discretize the input space and use the loss function of Physics-Informed Neural Networks (PINNs) for an exponential error propagation across time and space. Results for four different kind of PDEs are presented and show good results using the message passing scheme.",
        "strengths": "The paper presents an alternative (iterative) algorithm for solving PDEs where the initial- and boundary-conditions serve as training points.",
        "weaknesses": "I am not an expert in PDEs and found Section 2.1 incomprehensible: For example, isn't $\\partial_t u$ already a linear differential operator (first derivative). What is the role of $\\mathcal{R}$? Also, I was not able to follow the presentation of the main idea in Section 3; how does $v_i$ and resolve to $x$ and $t$ in Section 2? The experimental results seem convincing but I am not remotely able to understand the algorithmic idea that the authors are using. I would urge the authors to significantly improve the accessibility of their idea and algorithm."
      },
      {
        "rating": "6",
        "confidence": "2",
        "summary": "This paper analyzes the setting of Causal PINNs, which reformulates the standard PINN loss function to incorporate information about time dependencies into weights. The authors provide theoretical justification for Causal PINNs by analyzing the belief propagation algorithm. Specifically, they find that running BP over a Markov random field yields the weighting used in Causal PINNs. Next, the authors propose a message passing-based alternative form of PINNs that outperforms adaptive weighting methods for PDEs. Empirically, they demonstrate that these perform better than alternative PINN approaches on a variety of time-dependent PDEs.",
        "strengths": "1. The paper provides a new theoretical understanding of Causal PINNs.\n2. Experiments show that MP-PINNs outperform existing algorithms in handling time-dependent PDEs, especially with respect to spatial causality.",
        "weaknesses": "1. The authors mention that a limitation of their paper is the lack of theoretical analysis on the hyperparameter D (the number of iterations of message passing). While I believe that theoretical analysis may not be necessary, I think that ablation studies could be run to empirically understand the impact of this hyperparameter on performance."
      }
    ],
    "rating_avg": 4.25,
    "confidence_avg": 2.75,
    "decision": "N/A",
    "meta_review": "",
    "author_remarks": "",
    "decision_comment": ""
  },
  {
    "id": "bzB7OIbITu",
    "title": "Prompt-Independent Safe Decoding to Restrain Unsafe Image Generation for Text-to-Image Models against White-Box Adversary",
    "authors": [
      "Shengyuan Pang",
      "Jiangyi Deng",
      "Jialin Wu",
      "Yanjiao Chen",
      "Huanlong Zhong",
      "Xinfeng Li",
      "Jie Zhang",
      "Wenyuan Xu"
    ],
    "abstract": "Text-to-image (T2I) models, developed through extensive training, are capable of generating realistic images from textual inputs, profoundly influencing various facets of our lives. Nevertheless, they can be exploited by adversaries who input malicious prompts, leading to the creation of unsafe content and posing serious ethical concerns. Current defense mechanisms primarily rely on external moderation or model modification, but they are inherently fragile against white-box adversaries who have access to the model's weights and can adjust them accordingly. \n\nTo address this issue, we propose \\sys, a novel defense framework that governs both the diffusion and the decoder module of the text-to-image pipeline, enabling them to reject generating unsafe content and resist malicious fine-tuning attempts. Concretely, we first fine-tune the diffusion and the decoder module with the denial-of-service samples: 1) for the diffusion module, the inputs are unsafe image-caption pairs, the ground truth is zero predicted noise, and 2) for the decoder module, the inputs are unsafe generations from the diffusion, the ground truth is zero decoding. Then, we employ adversarial training to ensure this denial-of-service behavior for unsafe queries remains effective even after the adversary's fine-tuning with unsafe data. Specifically, we continuously simulate potential fine-tuning processes that the adversary might adopt and expose them to the model, enabling it to learn how to resist.\n\nExtensive experiments validate that \\sys effectively prevents the generation of unsafe content without compromising the model’s normal performance. Furthermore, our method demonstrates robust resistance to malicious fine-tuning by white-box adversaries, rendering it resource-intensive to corrupt our protected model, thus significantly deterring the misuse of our model for nefarious purposes.",
    "keywords": [
      "Text-to-image generation",
      "AI security",
      "Model compliance"
    ],
    "venue": "ICLR",
    "year": 2025,
    "pdf_url": "https://openreview.net/pdf?id=bzB7OIbITu",
    "forum_url": "https://openreview.net/forum?id=bzB7OIbITu",
    "reviews": [
      {
        "rating": "3",
        "confidence": "4",
        "summary": "This paper introduces a novel defensive solution called Patronus, designed to prevent T2Is from generating unsafe content. Patronus integrates an output moderator directly within the T2I's decoder. It guides the image decoder to perform conditional decoding based on safety features, transforming unsafe input features into zero vectors.",
        "strengths": "1. This paper addresses a crucial safety issue: defending T2I models against white-box adversaries. As T2I models become more popular and widely deployed, this topic is increasingly important.\n\n2. The paper presents a novel and intriguing idea.\n\n3. The content is well-structured and easy to follow.",
        "weaknesses": "While the paper introduces 'Patronus' as a novel defensive mechanism, the evaluation section of this paper is too weak, making the effectiveness of the proposed method unclear, which is essential for achieving a higher-scoring paper. \n\n1. Lacking Evaluation Results on SOTA adversarial attack for T2I. The authors should assess the proposed defense against leading Text-to-Image adversarial attacks, such as MMA-Diffusion [c0]. This attack has been reported to outperform I2P, posing a significant threat to T2I models. Evaluating the defense's effectiveness by reporting the Attack Success Rate after implementing Patronus would demonstrate its generalizability and robustness.\n\n[c0] https://arxiv.org/abs/2311.17516\n\n2. The related work section overlooks a key contribution, [c1], which fine-tunes a text decoder to defend against adversarial prompts. In contrast to this approach, the present work focuses on fine-tuning the image decoder. A discussion of [c1] should be included in the related work, highlighting this crucial difference in methodology and its potential implications. This comparison will provide a more complete context for the current work and clarify its unique contribution.\n \n[c1] https://arxiv.org/pdf/2403.01446\n\n3. Lacking comparison with close-related baselines.  The authors assert that existing content moderators \"can be easily removed by white-box adversaries\" and have other drawbacks (lines 037-041). However, it's unclear how effectively the proposed \"Patronus\" addresses these issues. To demonstrate its superiority, it is recommended that the authors compare their method with existing content moderation solutions such as LlamaGuard [c2] and OpenAI-Moderation [c3]. This comparison would highlight the effectiveness of Patronus in overcoming these challenges.\n\n[c2] https://arxiv.org/abs/2312.06674\n\n[c3] https://arxiv.org/pdf/2208.03274\n\n4. Limited Evaluation Metrics: Relying solely on \"CLIPScore\" offers an incomplete view of the proposed solution's performance. The error bar in Figure 3 nearly obscures the performance gain. A more comprehensive evaluation should include metrics such as Attack Success Rate (ASR), Area Under the Receiver Operating Characteristic Curve (AUROC), and False Positive Rate (FPR), as recommended in [c1], [c2], and [c3]. These metrics provide a clearer understanding of the solution's impact on both normal and unsafe use cases.\n\n5. Absence of Adaptive Attack Evaluation: The evaluation doesn't consider the critical scenario of adaptive attacks, where the attacker possesses full knowledge of both the T2I model and the implemented safeguards. Evaluating the defense's resilience against adaptive attacks is crucial for understanding its real-world effectiveness. The authors can follow the adaptive attack design principles suggested in [c4] to conduct experiments.\n\n[c4] Tramer, F., Carlini, N., Brendel, W., & Madry, A. (2020). On adaptive attacks to adversarial example defenses. Advances in neural information processing systems, 33, 1633-1645."
      },
      {
        "rating": "3",
        "confidence": "4",
        "summary": "This paper tries to propose a method to align text-to-image model to prevent unsafe image generation. The idea is to fine-tune the decoder and diffusion model (U-Net). Key challenge for alignment is that if the model is open-source, an attacker may fine-tune the model to remove the alignment. This paper aims to solve this challenge via aligning the model in a specific way. The alignment itself is a fine-tuning process. Evaluation is performed on several datasets and some malicious fine-tuning.",
        "strengths": "This paper aims to solve a challenging problem. For an open-source model, malicious fine-tuning to remove the safety alignment is a key challenge. \n\nThe paper follows a good formulation.\n\nEvaluation is conducted on multiple datasets, and multiple baseline alignment methods are compared.",
        "weaknesses": "The most important weakness is that the reviewer is not convinced the proposed method solves the challenge. It is not clear why the proposed alignment method can survive malicious fine-tuning. It's not clear to why the proposed method is different from baselines in terms of resistance against malicious fine-tuning. \n\nEvaluation metrics are too simple. Mainly CLIP is used to assess both attack effectiveness and performance preservation. More metrics are expected, e.g., the number of nudity parts in a generated image. FID scores or LPIPS scores to measure performance preservation for benign prompts. \n\nAdaptive attacks are shown in Appendix. I would say these are the most important results for such a defense work. I suggest to focus on these adaptive attacks, and show detailed results in main body using more fine-grained metrics for both attack effectiveness and performance preservation. \n\nEventually, a strong attacker can remove any safety alignment with enough fine-tuning data. An extreme case is that the strong attacker re-trains a model without safety alignment given enough tuning data and computation resources. So, a right question to ask is how much more resources (data and computation) an attacker needs in order to remove the safety alignment. The paper can benefit from showing such experimental results. \n\nIt's also helpful to show images generated for unsafe prompts (adaptive attacks) and safe prompts, for different methods."
      },
      {
        "rating": "6",
        "confidence": "3",
        "summary": "The paper proposes PATRONUS, a new defense framework that protects text-to-image models from white-box adversarial attacks. With a special emphasis on the threats resulting from model fine-tuning, PATRONUS represents an internal moderator and a mechanism of non fine-tunable learning rather than traditional defenses such as content moderation or alignment, which could be manipulated by attackers even at the parameter level. The internal moderator transforms unsafe input features into zero vectors, ensuring that benign features are decoded correctly while rejecting unsafe prompts. In this regard, the authors prove the efficacy of PATRONUS against different adversarial attacks with much stronger robustness compared to the state-of-the-art methods by retaining low CLIP scores on unsafe inputs while keeping performance on benign inputs.",
        "strengths": "The paper's main strengths lie in its method of applying the concepts of non-fine-tunable learning and inseparable content moderation to white-box adversaries in T2I models. it demonstrates a clear understanding of model architecture, with the authors skillfully leveraging each component to optimize the defense mechanism effectively.",
        "weaknesses": "One limitation to the method could be expensive computational resources. Using 4 A100-80GB GPUs might not be ideal for all the users who wish to use this defense method."
      },
      {
        "rating": "8",
        "confidence": "5",
        "summary": "This paper presents a framework to protect text-to-image models from generating unsafe content. The framework focuses on three key goals: (1) blocking unsafe content by embedding a safety filter in the decoder, and adjusting the diffusion process to ensure unsafe outputs result in black images, (2) resisting malicious finetuning through adversarial training that simulates such funtuning, and (3) maintaining the quality of benign content by adding a term that preserves it during generation. The design clearly outlines each goal and demonstrates effectiveness through experiments.",
        "strengths": "1. The paper addresses a timely issue—preventing unsafe content generation—and shows effectiveness both in mitigating unsafe outputs and preserving benign ones. It also introduces a defensive measure against adversaries attempting to fintune the model toward unsafe outputs by using an adversarial training scheme.\n2. The system is well-designed, with clearly defined objectives, and each loss term is crafted to meet a specific goal, making the approach easy to follow.\n3. I appreciate the novel ideas, such as fine-tuning the safety filter within the decoder to act as a conditional decoder and the effective strategy of transforming the min-max optimization into min-min in Equation 23. Both are technically sound and effective solutions.",
        "weaknesses": "1. The non-fine-tunable learning scheme seems largely based on Deng et al. (2024), so I question its contribution as a major novel element. However, I acknowledge that the loss function has been modified for the text-to-image task, providing some level of novelty.\n\n2. The evaluation metrics for defending against unsafe generation only use the CLIP score, but this may not sufficiently distinguish your method from others, given the relatively small range of differences (e.g., values of 17-28 in Figure 3 for seven methods against I2P and 16-23 in Figure 4 for Sneakyprompt). Additional metrics are suggested, like NRR from SafeGen. Also, calculating the similarity between your generated images and a black image (your intended output for unsafe prompts) might provide a more direct assessment.\n\n3. Some strategies lack clear explanations of their benefits and would benefit from experimental support. For example, Section 4.2.2 on Feature Space Calibration and the use of VGG for smoothing could be better justified. Please see detailed questions in the specific sections.\n\nMinor issues:\n1. There are inconsistencies between some figures and the descriptions, e.g., L_bd/L_fc in Figure 2 vs L_cd//Lfsc in EQ 11.\n2. Some notation in the equations is hard to follow; it would help to provide explanations for each symbol directly near the equation.\n\nI may consider raising my score if my concerns and questions are adequately addressed in the rebuttal."
      }
    ],
    "rating_avg": 5.0,
    "confidence_avg": 4.0,
    "decision": "Reject",
    "meta_review": "This paper proposes Patronus, a defense framework for text-to-image (T2I) models designed to prevent unsafe content generation. The proposed solution embeds a safety filter directly within the decoder and employs a non-fine-tunable learning scheme, making it resistant to malicious fine-tuning. The authors validate their framework on several datasets, comparing it to baseline methods, and highlight its effectiveness in mitigating unsafe content generation while maintaining performance on benign prompts.\n\nOverall, the paper studies a timely and significant topic of mitigating unsafe content generation in T2I models. It proposes a novel solution to the problem. Experiments include multiple datasets and adversarial attacks, demonstrating the effectiveness of the method. However, this paper has weaknesses in the lack of clarity in the experimental settings and use of the CLIP score to measure the defense capability. Those concerns have not been fully addressed after author responses.\n\nAlthough the paper shows promise and addresses an important research gap, further improvement and more comprehensive evaluations are needed to strengthen its contributions and make it suitable for publication. Therefore, the AC would recommend rejection.",
    "author_remarks": "",
    "decision_comment": ""
  },
  {
    "id": "GM7cmQfk2F",
    "title": "Rethinking Neural Multi-Objective Combinatorial Optimization via Neat Weight Embedding",
    "authors": [
      "Jinbiao Chen",
      "Zhiguang Cao",
      "Jiahai Wang",
      "Yaoxin Wu",
      "Hanzhang Qin",
      "Zizhen Zhang",
      "Yue-Jiao Gong"
    ],
    "abstract": "Recent decomposition-based neural multi-objective combinatorial optimization (MOCO) methods struggle to achieve desirable performance. Even equipped with complex learning techniques, they often suffer from significant optimality gaps in weight-specific subproblems. To address this challenge, we propose a neat weight embedding method to learn weight-specific representations, which captures weight-instance interaction for the subproblems and was overlooked by most current methods. We demonstrate the potentials of our method in two instantiations. First, we introduce a succinct addition model to learn weight-specific node embeddings, which surpassed most existing neural methods. Second, we design an enhanced conditional attention model to simultaneously learn the weight embedding and node embeddings, which yielded new state-of-the-art performance. Experimental results on classic MOCO problems verified the superiority of our method. Remarkably, our method also exhibits favorable generalization performance across problem sizes, even outperforming the neural method specialized for boosting size generalization.",
    "keywords": [
      "Neural Multi-Objective Combinatorial Optimization",
      "Weight Embedding",
      "Conditional Attention"
    ],
    "venue": "ICLR",
    "year": 2025,
    "pdf_url": "https://openreview.net/pdf?id=GM7cmQfk2F",
    "forum_url": "https://openreview.net/forum?id=GM7cmQfk2F",
    "reviews": [
      {
        "rating": "8",
        "confidence": "3",
        "summary": "The paper introduces a novel but simple neural multi-objective combinatorial optimization (MOCO) method. Specifically, the paper proposes a single-model method which can effectively solve MOCO problems (such as the multi-objective variants of the Traveling Salesman Problem or Capacitated Vehicle Routing Problem). This model is capable of learning the interaction of the problem instances with the weight vectors that are provided to decompose the problem into smaller, scalarized subproblems. At inference time, this allows the user to specify N weight vectors along with the problem instance, thereby producing a Pareto front of solutions. The authors introduce two variations of their method. In the first approach, named WE-Add, the interaction of the weight vectors and the node features is captured by simply adding their linear projections to get the node embeddings in the encoder of the model. In the second approach, WE-CA, the authors leverage a conditional attention model to capture the interaction of the instance and the weight vector. First, node embeddings conditioned on the weight vectors are derived through feature-wise affine transformations of the linear projections of the node features and weight vectors. Then, these embeddings are passed through standard transformer encoder layers, with multi-headed attention, instance normalization and feed forward networks. The authors demonstrate that this model not only reduces the optimality gaps of the subproblems but can also generalize well to problems of different sizes.",
        "strengths": "### Originality\nThe method of deploying \"conditional attention\" as proposed in the paper is simple and novel.\n\n### Quality\nWith the exception of the points discussed in the Weaknesses Section, the paper is of good quality.\n1. The paper features a comprehensive list of experiments. It discusses variations of several important problems, such as 20, 50, and 100 node variants of the bi- and tri-objective Traveling Salesman Problem (Bi-TSP and Tri-TSP), bi-objective Capacitated Vehicular Routing Problem (Bi-CVRP), and bi-objective Knapsack Problem (Bi-KP). The paper also demonstrates the out-of-distribution generalization for 150 and 200 node variants of Bi-TSP.\n2. The authors justify their method which uses *conditional attention* by running ablation studies for its important components, such as *conditional embeddings* and *attention*. The experiments show that the combination of both these ideas work better than either one in isolation.\n\n\n### Clarity\n\nThe paper is well-written. The ideas are communicated clearly. For example, Section 4.1 explains the base model that is used, and then builds on it in Section 4.2 to explain the model with conditional attention, making it easy to follow.\n\n### Significance\nThe contributions of the paper are significant:\n1. The simplicity of the method is commendable.\n2. The proposed method shows strong performance compared to the baselines, showing smaller optimality gaps for the subproblems and higher hypervolumes, with comparable or faster solving times.\n3. Also interesting is the finding that a unified model trained this way generally performs better than models trained for problems of specific sizes.",
        "weaknesses": "The choice of reference points for evaluating the authors' methods and the baselines raises a concern. In the paper, it is mentioned that CNH [1] bears some similarities to the authors' approach. The CNH paper also evaluates the bi- and tri-objective Traveling Salesman Problem as well as the bi-objective Capacitated Vehicle Routing Problem. Additionally, six out of the twelve baseline methods listed in Table 2 of this paper are also present in Table II of the CNH paper: MOED/D, NSGA-II, MOGLS, DRL-MOA, PMOCO, and PMOCO-Aug. However, the reference points for calculating hypervolume (HV) in this paper differ from those in the CNH paper, making direct comparisons with their results impossible. For reference, please see the table below.\n\n| Problem   | Size | Reference Point (this paper)          \t| Reference Point (CNH paper)  \t|\n|-----------|------|----------------|----------------------|\n| Bi-TSP\t| 20   | (20, 20)   \t| (15, 15)        \t|\n|       \t| 50   | (35, 35)   \t| (30, 30)        \t|\n|       \t| 100  | (65, 65)   \t| (60, 60)        \t|\n|       \t| 150  | (85, 85)   \t| (90, 90)                \t|\n|       \t| 200  | (115, 115) \t| (120, 120)                \t|\n|       \t|  \t|            \t|                  \t|\n| Bi-CVRP   | 20   | (30, 4)    \t| (15, 3)         \t|\n|       \t| 50   | (45, 4)    \t| (40, 3)         \t|\n|       \t| 100  | (80, 4)    \t| (60, 3)         \t|\n|       \t|  \t|            \t|                  \t|\n| Tri-TSP   | 20   | (20, 20, 20)   | (15, 15, 15)    \t|\n|       \t| 50   | (35, 35, 35)   | (30, 30, 30)    \t|\n|       \t| 100  | (65, 65, 65)   | (60, 60, 60)    \t|\n\nEmploying the same reference points as the CNH paper would enable a direct comparison and lend additional credence to the findings if they align with the established results.  Without this alignment, and in the absence of publicly available code, it is difficult to verify the results. Addressing this issue would greatly enhance the rigor and transparency of the paper.\n\nI would be glad to reconsider my review if the authors could either provide results using the same reference points as the CNH paper or offer a clear justification for the reference points chosen in this study. This is the concern that has informed my rating for Soundness.\n\n[1] Mingfeng Fan, Yaoxin Wu, Zhiguang Cao, Wen Song, Guillaume Sartoretti, Huan Liu, and Guohua Wu. Conditional neural heuristic for multiobjective vehicle routing problems. IEEE Transactions on Neural Networks and Learning Systems, 2024.\n\nOther concerns about the paper are thus:\n1. Figure 2 is intended to show the Pareto fronts, but it doesn’t. For instance, in the figure for KroAB200 (right), the results for CNH-Aug, represented by green circles, show that the left-most point appears to Pareto dominate all other CNH-Aug points. There are more examples across the three figures.\n2. Section 3.1 and parts of 3.2 bear significant resemblance to the Section 3.1 and 3.2 of the paper on PMOCO [2]. However, I have overlooked this as they simply discuss the problem formulation.\n3. The authors' use of subjective language, such as \"the weight embedding are ingeniously incorporated into node embeddings\" and referring to alternative approaches as \"clumsy multi-model methods\" detracts from the objectivity of the paper. A more impartial tone that directly outlines the methods would enhance the clarity and professionalism of the writing.\n\n[2] Xi Lin, Zhiyuan Yang, and Qingfu Zhang. Pareto set learning for neural multi-objective combinatorial optimization. In International Conference on Learning Representations, 2022a.\n\nA few other suggestions to improve the clarity and ease of reading the paper:\n1. It would benefit the reader if it is explained that the solution, represented as a sequence $\\( \\pi = \\{ \\pi_1, \\dots, \\pi_T \\} \\)$, is simply a permutation of the nodes for the Traveling Salesman Problem.\n2. $P(\\pi | \\lambda, s)$ is introduced in Section 3.2, but $s$ is only described in 4.1.\n3. “IN” (instance normalization) used in Eq (2) is never explicitly stated anywhere.\n4. Discussing the venue of publication in Table 1 is not necessary, in my opinion. Neither is the description of baseline methods as \"complex\" and the authors' method as \"neat\". Parameters is misspelled in the column header."
      },
      {
        "rating": "6",
        "confidence": "3",
        "summary": "This paper introduced a new way for directly learning weight-specific representations, thereby improving the handling of decomposed subproblems. The authors designed two models for weight embedding: one is an additive embedding model, which performs embedding through simple addition operations; the other is a conditional attention model, which more accurately captures the interaction between weights and instance information through a conditional attention mechanism.",
        "strengths": "The weight embedding method proposed in this paper directly learns weight-specific representations, avoiding tedious adjustments and high computational costs, while improving performance without increasing model complexity.\n\nThe weight embedding method not only performs well across various problem scales but also shows strong generalization across different scales (such as varying numbers of nodes or task complexity). This capability allows the model to maintain good optimization performance when encountering problems of different scales or new challenges, demonstrating high adaptability. The additive weight embedding and conditional attention weight embedding models designed in the paper are not only straightforward but also adaptable to various MOCO tasks.\n\nThe authors also provides a lot of experiments for validation, showing the superority for their performance.",
        "weaknesses": "I think it would be beneficial to include more theoretical discussions. For example, the paper mentions that the weighted approach can improve generalization; adding a proof for the generalization bound would make the results more convincing. Additionally, when the number of classes approaches infinity, will this weighting approach converge to the average weight?"
      },
      {
        "rating": "6",
        "confidence": "2",
        "summary": "The paper presents a method for solving Neural Multi-Objective Combinatorial Optimization (MOCO) using a \"neat\" weight embedding approach. The authors argue that existing MOCO models are limited in their ability to effectively optimize weight-specific subproblems due to complex learning techniques and significant optimality gaps. Their proposed method learns weight-specific representations through a simpler weight embedding technique, capturing weight-instance interactions. Two models instantiate this approach: one with addition-based weight embedding and another with conditional attention. Experimental results demonstrate the method’s performance on benchmark MOCO problems, showing significant improvements in generalization across different problem sizes.",
        "strengths": "This work has extensive experiments that show the effectiveness of the proposed method and show strong cross-size generalization capabilities.",
        "weaknesses": "1. The authors could a clear definition of what they mean by \"neat\" in the context of their work, and highlight specific sections where they could elaborate on how their method contrasts with the complexity of existing approaches.\n2. In the Methods section, while the structure of the proposed architecture is described, I would like to see a more detailed explanation of why each component is expected to improve performance. Specifically, theoretical justifications for key components such as the addition-based weight embedding and the conditional attention mechanism would be helpful. Some discussion of how the proposed components address specific limitations of previous approaches would also strengthen the work.\n3. It would be valuable to see more ablation studies that isolate the contributions of each architectural component. For example, a fair experiment design that solely isolates the effect of the addition-based weight embedding."
      },
      {
        "rating": "8",
        "confidence": "4",
        "summary": "The paper presents a novel weight embedding approach for neural multi-objective combinatorial optimization (MOCO) to address the optimality challenges observed in current decomposition-based methods. It focuses on capturing weight-instance interaction through a weight-specific representation learned directly within the neural model. Two model variations—Weight Embedding with Addition (WE-Add) and Weight Embedding with Conditional Attention (WE-CA)—are introduced. These models simplify MOCO by avoiding complex auxiliary techniques and showcase state-of-the-art performance across several MOCO problems, specifically the multi-objective traveling salesman, capacitated vehicle routing, and knapsack problems.",
        "strengths": "- Direct weight embedding is a fresh perspective in MOCO, addressing a gap in existing neural approaches that often require complex multi-model techniques.\n- The paper provides thorough experimental results, comparing its models with state-of-the-art baselines (including multi-model, single-model, and heuristic-based methods) on three classic MOCO problems across different scales.\n- The proposed WE-CA model achieves superior performance in terms of hypervolume (HV) and execution time, particularly highlighting its generalization capabilities across problem sizes.\n- The models eliminate the need for size-aware embedding mechanisms, thus simplifying the optimization process.",
        "weaknesses": "- Real-world applications with complex constraints are acknowledged as challenging for this approach. Further exploration into handling such constraints would enhance the paper's practical relevance.\n\n- The paper’s unified training model, WE-CA-U, provides promising generalization across problem sizes, but more discussion on its failure cases (where applicable) would improve understanding of its limitations."
      }
    ],
    "rating_avg": 7.0,
    "confidence_avg": 3.0,
    "decision": "Accept (Poster)",
    "meta_review": "The paper proposes a novel weight embedding method for neural multi-objective combinatorial optimization. It addresses the suboptimal performance of existing decomposition-based methods in weight-specific subproblems. By introducing two models, WE-Add and WE-CA, the authors effectively capture weight-instance interactions. Experimental results on multiple MOCO problems show that their approach achieves better generalization and performance compared to state-of-the-art baselines.\n\nStrengths of the paper include its originality in the weight embedding concept, comprehensive experimental validation, and clear communication of ideas. However, it has some areas for improvement. Theoretical justifications could be enhanced, and certain terms and design choices need more detailed explanations. Overall, the paper's contributions outweigh its weaknesses, and with the authors' satisfactory responses to reviewer concerns, it is worthy of acceptance.",
    "author_remarks": "",
    "decision_comment": ""
  },
  {
    "id": "09LEjbLcZW",
    "title": "AutoKaggle: A Multi-Agent Framework for Autonomous Data Science Competitions",
    "authors": [
      "Ziming Li",
      "Qianbo Zang",
      "David Ma",
      "Jiawei Guo",
      "Tianyu Zheng",
      "minghao liu",
      "Xinyao Niu",
      "Xiang Yue",
      "Yue Wang",
      "Jian Yang",
      "Jiaheng Liu",
      "Wanjun Zhong",
      "Wangchunshu Zhou",
      "Wenhao Huang",
      "Ge Zhang"
    ],
    "abstract": "Data science competitions on Kaggle, which represent real-world programming challenges, require sophisticated problem-solving approaches. While LLM-based agents demonstrate potential in various fields, their application to data science tasks often falls short due to difficulties in adapting to data changes in multi-stage reasoning and the need for precise reasoning. To address this, we propose AutoKaggle, a robust and user-centric framework that solves Kaggle problems through a collaborative multi-agent cooperative system. AutoKaggle implements an iterative development process that combines code interpretation, debugging, and comprehensive unit testing covering over 30 tests, ensuring code correctness and quality through LLM-based evaluation. It prioritizes user experience by generating detailed reports that elucidate feature engineering processes, data transformations, model selection criteria, and the reasoning behind each decision. It offers customizable workflows, allowing users to intervene and modify each stage of the process, thus combining the advantages of automated intelligence with human expertise. Additionally, we build a universal data science tool library, including carefully verified functions for data cleaning, feature engineering, and modeling, which form the foundation of this solution. We evaluate the framework on 8 carefully selected Kaggle competitions, achieve 83.8\\% in average completion rate and 42.8\\% average rank in Kaggle.",
    "keywords": [
      "large language models",
      "language agents",
      "multi-agent"
    ],
    "venue": "ICLR",
    "year": 2025,
    "pdf_url": "https://openreview.net/pdf?id=09LEjbLcZW",
    "forum_url": "https://openreview.net/forum?id=09LEjbLcZW",
    "reviews": [
      {
        "rating": "5",
        "confidence": "3",
        "summary": "This paper introduces AutoKaggle, a pipeline to automatically solve Kaggle Competitions. The authors use 5 subparts in a row: a reader, a planner, a developer, a reviewer, and a summarizer. They use LLMs with RAG to develop code-based solutions, with code running, units tests. They evaluate their method on 5 Kaggle competition benchmarks.",
        "strengths": "**Interesting problem.** With the LLMs (+RAG) becoming mature, the open source study of their integration into broader tools that can directly be applied to data science tasks, is the natural next step.\n\n**Overall good presentation.** Even if some details are lacking to grasp the authors' exact contribution (notably in the figures), the overall presentation clearly demonstrates the problem and the approach set up to tackle it. \n\n**Interesting metrics and ablation studies.**",
        "weaknesses": "**Lacking evaluation.** The evaluation is lacking comparison to existing AutoML baselines (*e.g. [1]) or explanations on why the authors are not comparing their method to any existing solution. If running such comparison is not possible at all, then the authors should provide explanations on why this is not feasible. \nWhile detailed reports are provided on their methods and the different components, as this works apply existing techniques, its evaluation is its core contribution. \nThe authors should report (at least) the standard deviation, but e.g. violin plots to compare AutoKaggle's results of other kaggle competitors could help clearly situate where this automatic pipeline stands.\n\n**Evaluation on a (previously) unknown dataset.** It seems that AutoKaggle has been designed to solve these datasets, so one cannot evaluate how much this method would transfer to another, previously unknown dataset.\nIt would be nice to provide the reader with how much out of the box your method is, maybe with a user study. It seems like its your core contribution, so having independent people trying AutoKaggle and commenting on how easy the setup and interaction is on a left out dataset would help people looking for such solutions.\n\n**Figure 2 could be improved.** The figure could be split to separate the overall pipeline from details on some of its components. Most importantly, what part is using an LLM, what part is using a human expert ? This figure represents 70% of what the reader is looking for, it should provide first the overall intuition, and then enough details on specific core components that you want to highlight.\n\n**You related work section is actually a background section.**\nYour current related work covers some domains that are integrated within AutoKaggle. It thus feels more like a related work of your background section (what AutoKaggle builds upon). Is there any *e.g.* AutoML method that you can compare to ? Any method that addresses the same issue ?\n\n\n[1] https://github.com/automl/CAAFE"
      },
      {
        "rating": "5",
        "confidence": "4",
        "summary": "This paper presents AutoKaggle, a multi-agent framework specifically designed to handle the complexities of Kaggle data science competitions.  The framework organizes the competition workflow into six distinct phases—background understanding, exploratory data analysis, data cleaning, in-depth exploratory analysis, feature engineering, and model development and validation—allowing agents to work systematically through each stage. Key agents, including Reader, Planner, Developer, Reviewer, and Summarizer, collaborate within this structure, with iterative debugging and unit testing to ensure robustness and accuracy in code generation. AutoKaggle integrates a machine learning tools library to streamline tasks, enhance code reliability, and provide users with educational insights through comprehensive reports at each phase. Evaluated across multiple Kaggle competitions, the framework achieved an average completion rate of 83.8% and ranked in the top 42.8% in Kaggle.",
        "strengths": "- AutoKaggle introduces a tailored phase-based workflow with multi-agent collaboration specifically designed for data science competitions. The system’s demonstrated high average completion rate and competitive ranking in Kaggle highlight its effectiveness, particularly in tabular classification and regression tasks, showing its strength in handling structured data challenges.\n\n- AutoKaggle empowers the Developer agent to perform iterative debugging and unit testing, bolstering the robustness of code generation. Additionally, the integration of a comprehensive machine learning tools library improves the system's efficiency and accuracy, making it better suited for tackling complex Kaggle competitions",
        "weaknesses": "- Limited novelty.  While the paper addresses data science problem-solving using LLM-based agents, it lacks a clear description of the specific challenges it intends to solve that existing methods have struggled with. Extending from a single-agent to a multi-agent system is insufficiently justified in this field, as the necessity and performance gains of such an approach are not clearly demonstrated. Existing works, as mentioned in the introduction, have also tackled similar problems with LLM-based agents, questioning the incremental contribution of AutoKaggle.\n\n- Multi-agent system design. The multi-agent system, including agents like Reader, Planner, Developer, Reviewer, and Summarizer, is insufficiently explained in terms of its collaborative structure. It is unclear whether these agents operate in an assembly-line fashion or if they engage collectively in each phase under the \"Cooperative Engagement\" label in Figure 1. Further clarification on their integration and interdependence within each workflow phase is needed.\n\n- Role clarity of Planner and Summarizer. Given AutoKaggle’s sequential, phase-based workflow, the necessity of a Planner agent is ambiguous. Can you quantify the contribution (such as on completion rates or error reduction) of this Planner agent in your system? Similarly, the Summarizer’s role in contributing to critical performance metrics such as completion rate or Best Normalized Performance Score, is not explicitly justified, leaving its impact on performance uncertain.\n\n- Unit Test and Debugging. Dose the Developer agent generate dataset-specific unit tests that align with each unique code snippet or not? How the Developer agent adjusts unit tests based on code variations to ensure logical consistency and accuracy across different tasks? \n\n- Lines 275-276 mention the importance of detecting logical errors in code, yet the method for achieving this is underexplored. Can you explain more details about detecting the logical error? More detail is needed on how logical errors are detected and avoided, as conducting exploratory data analysis or statistical checks after data cleaning or feature engineering alone may be insufficient. \n\n- Table 2 illustrates the system's performance across different debugging attempts (DT), showing how increased debugging impacts metrics like Completion Rate (CR) and Comprehensive Score (CS). The data indicate that both CR and CS improve as DT rises, reflecting enhanced task completion and accuracy with more debugging opportunities. What the 'performance plateaus' mean  in line 524-525?\n\n- The paper does not provide information on the cost of running AutoKaggle, which is essential for evaluating its performance and practical applicability. It's benifit to provide cost and total runtime to understand the performance. \n\n- The chosen baselines are not entirely convincing. Recent similar works, AIDE[1] and MLE-Agent[2] have shown remarkable capability in Kaggle competition settings. A comparative analysis with these recent works, particularly focusing on AutoKaggle’s unique advantages in effectiveness, efficiency, or other performance metrics, would highlight its distinct contributions to the field.\n\n- A broader evaluation across various task types such as time series prediction, image classification, and text classification, are necessary, as these are critical and challenging categories in Kaggle competitions. The current experiments focus primarily on tabular datasets, leaving it unclear whether AutoKaggle is capable of handling more complex, domain-specific tasks. Can AutoKaggle complete such tasks? \n\n- What is the requirement of the LLM? Can AutoKaggle works well with gpt-3.5 or other open-sourced models?\n\n\n[1] AIDE: the Machine Learning Engineer Agent(https://github.com/WecoAI/aideml)\n\n[2] MLE-Agent: Your intelligent companion for seamless AI engineering and research (https://github.com/MLSysOps/MLE-agent)"
      },
      {
        "rating": "5",
        "confidence": "4",
        "summary": "This paper presents a scaffolding framework which uses LLMs to create a multi-agent system, used to attempt Kaggle problems. They use a \"phase-based\" multi-agent approach, together with a library of hand-crafted ML tools, and extensive hand-crafted unit-tests tailored to the Kaggle problems.\n\nApplying this framework to 8 Kaggle problems (4 pre-GPT-4 training cut-off, 4 afterwards), they achieve a significant solve rate, and an average of 42% on the Kaggle leaderboard.\n\nThe paper also explores ablation of various modules (various tools, and the unit-testing module).",
        "strengths": "A system which can score 43% on Kaggle leaderboards is a significant milestone on the path to automated coding and datascience. Additionally, since many challenges which such a system would face would also arise in more general task-completion (e.g. long-term planning, establishing coherency, managing context, preventing execution from looping) and so would transfer to improve AI agents in general.\n\nGreat collection of Classic and Recent challenges, and baselines seem reasonable (though see my Q about the Strong Baseline).\n\nIt's helpful to have this variety of scores (though see my Q about CS).\n\nArchitecture is clearly laid out, and the paper is overall very easy to read.\n\nClear exploration and explanation of the underlyring readon why the feature-engineering tools reduce the framework's score (many features, leading to more complexity than the agents can handle).",
        "weaknesses": "Whenever CoT is used as an interpretability tool, I think it's always wise to mention unfaithfulness e.g. https://arxiv.org/abs/2305.04388\n\nThere are two places where a long list is hard to read:\n#1 ~L78: AutoKaggle integrates a comprehensive machine learning tools library, covering three core toolsets: data cleaning, feature engineering, and model building, validation, and prediction.\n\n#2 ~L186: The data science process is divided into six key stages: understanding the\nbackground, preliminary exploratory data analysis, data cleaning, in-depth exploratory data anal-\nysis, feature engineering, and model building, validation, and prediction\n\nPerhaps \"model-building, -validation, and -prediction\" would be easier to read.\n\n~L146: I'm surprised not to see mentioned what seems to me to be the main thing underlying the motivation of multi-agent systems: finite context length, requiring summarisation and specialisation.\n\nIt's not clear how much of the headline 43% on the leaderboard is down to the skill of the human-in-the-loop, which severely undermines the claim. Without a comparison to how well the human takes unassisted (in terms of success rate or time taken), or to how well AutoKaggle performs without HITL, it's impossible to reliably state how effective the framework is.\n\nUnspecified HITL also undermines the various claims of a \"fully automated framework\" (e.g. L175)\n\nNot much detail on these unit tests. Who writes them? What's the coverage like? Are there any guarantees? If (as I suspect) the \"meticulously designed\" unit tests are written by humans, then we have a similar situation as with the unspecified human-in-the-loop: the framework is not \"fully automated\", and it's impossible to rigorously determine how much effect the human hand-holding has on the framework's suggess. This should, at minimum, be clearly, explicitly and boldly acknowledged.\n\nAdditionally, it is unclear to me how much of the ML-tools library was developed alongside particular Kaggle Competition attempts. If the tools were developed on a case-by-case basis, to address hurdles found in the challenge, then there is significant data leakage from the evaluation dataset to the framework, leading to overfitting to the competitions chosen during development, and much of the headline 43% comes from tools handcrafted by human developers on a case-by-case basis. For a fair validation of how well this framework performs in \"fully automated\" mode, the library would need to be \"frozen\" while the framework was tested on a held-out set of Kaggle Competitions.\n\nVery minor point: ~L350, I agree that there is a risk of data leakage for competitions from before Oct '23, however to say that GPT-4o's training data includes Classic Kaggle is an assumption: better to say simply that there is a risk of data leakage.\n\nIf you're considering data leakage, it would be worth flagging that the 42% includes Classic problems: using only the newer problems, performance is slightly below human average."
      }
    ],
    "rating_avg": 5.0,
    "confidence_avg": 3.6666666666666665,
    "decision": "Reject",
    "meta_review": "The paper presents AutoKaggle, an LLM creating a multi-agent system together with a library of hand-crafted ML tools in order to solve Kaggle problems. In my opinion, the reviewers did a very thorough job and have presented salient arguments about the suitability of this paper for IJCAI in its current form. While it is interesting to see that an agentic LLM can help with Kaggle competitions, one reviewer points out that a comparison to existing AutoML approaches is missing. Indeed, the authors added a comparison to AIDE. However, AutoML is not only \"an LLM agent that generates solutions for machine learning tasks\" (as written on the AIDE github page) but also portfolio and other approaches to automatize (parts of) ML. So, a larger discussion (and comparison) is in place. As it turn out Kaggle is partnering with the International Conference on Automated ML,see https://www.kaggle.com/automl-grand-prix. Another reviewer points out that some design choices and arguments for motivation are missing; currently, it reads more like what the authors have done, but it is not well placed into the research landscape. More importantly, an evaluation across different types of modalities (time series, text classification, image object detection, ...) is missing or argued why this is currently not so important. One reviewer also pointed out that an ablation study is missing, showing that the hand-crafted tools are not doing the job in the end. So, while the direction is super interesting, it is too early for publication, but we would like to encourage the authors to push  for one of the next venues. Please note that the overall judgment should not be taken as a statement regarding the usefulness of your research.",
    "author_remarks": "",
    "decision_comment": ""
  },
  {
    "id": "lcmd2Qdrsv",
    "title": "Mixture-of-Diffusers: Dual-Stage Diffusion Model for Improved Time Series Generation",
    "authors": [
      "Khaled Alkilane",
      "Yihang He",
      "Bai Zhang",
      "Der-Horng Lee"
    ],
    "abstract": "Synthetic Time Series Generation (TSG) is a crucial task for data augmentation and various downstream applications. While TSG has advanced, its effectiveness often relies on the availability of extensive training datasets, posing challenges in data-scarce scenarios. Generative Adversarial Networks (GANs) and Variational Autoencoders (VAEs) have shown promise, but they frequently struggle to capture the complex temporal dynamics and interdependencies inherent in time series data. To address these limitations, we propose a novel generative framework, Mixture-of-Diffusers (MoD). This approach decomposes the diffusion process into a collection of specialized diffusers, each designed to model specific patterns at distinct noise levels. Early-stage diffusers focus on capturing overarching global and coarse patterns, while late-stage diffusers specialize in capturing fine-grained details as the noise level diminishes. This hierarchical decomposition empowers MoD to learn robust representations and generate realistic time series samples. The model is trained using a combination of multi-objective loss functions, ensuring both temporal consistency and alignment with the true data distribution. Extensive experiments on a diverse range of real-world and simulated time series datasets demonstrate the superior performance of MoD compared to state-of-the-art TSG generative models. Furthermore, rigorous evaluations incorporating both qualitative and quantitative metrics, coupled with assessments of downstream task performance on long-term generation and scarce time series data (see Figure 1), collectively validate the efficacy of our proposed approach.",
    "keywords": [
      "Time Series Generation; Time Series Analysis; Diffusion Models; Mixture-of-Experts"
    ],
    "venue": "ICLR",
    "year": 2025,
    "pdf_url": "https://openreview.net/pdf?id=lcmd2Qdrsv",
    "forum_url": "https://openreview.net/forum?id=lcmd2Qdrsv",
    "reviews": [
      {
        "rating": "8",
        "confidence": "4",
        "summary": "This paper proposes a novel framework, mixture-of-diffusers (MoD), for time series generation. This framework employs dual-stage diffusion models, integrating the Transformer architecture, to explicitly model the global and local features at different noise levels within time series. Experimental results show the superiority of MoD over existing approaches.",
        "strengths": "1. The hierarchical modeling of time series features at different noise levels is innovative to the best of my knowledge.\n2. This paper is well-structured and easy to follow. The authors provide sufficient preliminaries for the readers unfamiliar with the key concepts.\n3. I appreciate Figure 2. It provides a clear overview of MoD, making the general process easier to understand.\n4. The experiments are thorough, conducting a range of datasets and evaluation metrics that underscore the effectiveness of the proposed model.",
        "weaknesses": "1. The paper lacks a detailed discussion on the time-dependent weighting scheme used to integrate the early and late-stage diffusers. A more thorough analysis, supported by theoretical or empirical evidence, is required to clarify how this scheme effectively distinguishes the granularity of features for the dual-stage diffusers, e.g., how each stage of the diffusion model contributes to processing different levels of noise.\n2. The methodology section would benefit from a stronger focus on the novel designs introduced by the MoD framework. In particular, sections 2.2 and 3.1 could be streamlined to avoid redundancy and discuss more on the novel aspects of MoD.\n3. The bullet points outlining the evaluation metrics lack a clear hierarchical structure, leading to potential confusion. A more organized presentation would enhance the readability."
      },
      {
        "rating": "3",
        "confidence": "5",
        "summary": "The paper proposes a mixture of two diffusion models to generate time series in an unconditional setting. The models are trained using the MSE and KL divergence of the posteriors. Experiments show improvements over different baselines on various metrics.",
        "strengths": "- The model explores unconditional time series generation via a mixture of two diffusion models with a modified loss function\n- Results outperform the corresponding baselines on various metrics",
        "weaknesses": "- The novelty is limited. The proposed diffusion model consists of a linear interpolation of two neural networks and uses a slightly modified loss function. \n- A \"hierarchical decomposition\" should consist of more than two models.\n- The loss function in equation 12 needs to be further explained. How is the KL divergence computed? I assume there is a typo as $q(x_{t-1}\\mid x_t)$ is, to the best of my knowledge, not tractable. It is unclear how this helps the training process, as the KL divergence should simplify to a weighted l2 loss.\n- There are several wrong equations; for example, equation 8 is incorrect. No noise should be added to the mean.\n- Related works should be discussed more thoroughly. Multiple works are ignored, including irregular and unconditional models [1,2,3,4]. \n- There are various typos in the manuscript, including in the pseudo-codes, e.g., $T$ should be $t$ in algorithm 1.\n- Labels in Figure 1 are missing. It is unclear which color represents the GT and which represents the synthetic samples.\n- Experimental details are missing: how many random seeds were used to compute standard deviations?\n\n\n**Code issues:**\n- command in readme wrong\n- conflict of PyYaml: two times a different version\n- config file is only available for ETTh1\n- details should be included in the paper. E.g., dropout and EMA are applied in the code but not mentioned in the paper\n\n\n[1]: Biloš, Marin, Kashif Rasul, Anderson Schneider, Yuriy Nevmyvaka, and Stephan Günnemann. \"Modeling temporal data as continuous functions with stochastic process diffusion.\" In International Conference on Machine Learning, pp. 2452-2470. PMLR, 2023.  \n[2]: Kollovieh, Marcel, Abdul Fatir Ansari, Michael Bohlke-Schneider, Jasper Zschiegner, Hao Wang, and Yuyang Wang. \"Predict, Refine, Synthesize: Self-Guiding Diffusion Models for Probabilistic Time Series Forecasting.\"  \n[3]: Yan, Tijin, Hengheng Gong, He YongPing, Yufeng Zhan, and Yuanqing Xia. \"Probabilistic Time Series Modeling with Decomposable Denoising Diffusion Model.\" In Forty-first International Conference on Machine Learning.  \n[4]: Chen, Yu, Wei Deng, Shikai Fang, Fengpei Li, Nicole Tianjiao Yang, Yikai Zhang, Kashif Rasul, Shandian Zhe, Anderson Schneider, and Yuriy Nevmyvaka. \"Provably convergent Schrödinger bridge with applications to probabilistic time series imputation.\" In International Conference on Machine Learning, pp. 4485-4513. PMLR, 2023."
      },
      {
        "rating": "3",
        "confidence": "4",
        "summary": "This paper proposes the mixture-of-diffusers (MoD) method, which introduces two-stage diffusion models to handle the data with different noise levels. With the design of the MoD architecture and integrating the MSE and KL loss functions, this work can achieve learning robust representations and generating realistic time series samples.",
        "strengths": "1.\tThe experimental design is rich, and a variety of indicators are introduced to evaluate the quality of the generated time series, which is quite convincing.\n2.\tThe design of using the MoE approach to combine the two-stage diffusion model is original.",
        "weaknesses": "1.\tThe selection of downstream tasks is limited. The conditional generation may be a task that better reflects the multi-scale modeling of time series.\n2.\tThe innovation of this paper seems insufficient. Can the weight of MoE be changed dynamically based on the granularity level of the sample itself? Are the number of stages (two) enough? Can more diffusers further improve performance? The paper lacks further exploration, making the innovation of the method quite limited.\n3.\tThe descriptions of some figures in the paper lack information, e.g., what data the blue and red points in Figure 1 represent, which can easily confuse the readers.\n4.\tThe experimental results of the baselines seem to be directly copied from Diffusion-TS, I suggest the authors try reproducing the results of the baselines for more fair comparison."
      },
      {
        "rating": "6",
        "confidence": "4",
        "summary": "The paper proposes using a combination of exporters for time series generation with diffusion models. It suggests that one model specializes in the initial noise reduction stages where high-level details are more dominant in time series in general, while another focuses on the final steps that involve producing fine-grained details. Additionally, the paper introduces new tasks for generating longer time series (up to 256 time steps) and for creating new data in situations with limited data availability.",
        "strengths": "- The concept of using a Mixture of Experts for different attribute generation steps is sensible in the context of time series and is straightforward to implement.  \n- In my opinion, the benchmark focused on scarce training data is important and relevant.  \n- The paper is well-written.",
        "weaknesses": "- The benchmarks lack state-of-the-art methods like [1], which show significantly better results than the other methods presented. Consequently, the claim of being state-of-the-art remains invalidated.\n- In the scarce data experiment a SOTA method is not being compared to (Diffusion-TS)\n- The method is a simple adaption of a mixture of experts, although incremental changes may be important, in this case, where the results are not substantially stronger, or nor is a specific problem is being solved where other models completely fail on it, I think its a weakness of the paper.\n\n[1] Generative Modeling of Regular and Irregular Time Series Data via Koopman VAEs"
      },
      {
        "rating": "8",
        "confidence": "5",
        "summary": "This paper presents a method for time-series generation using two diffusion models. The two models are specialized for different aspects of the generation process:\n\n1. Capturing coarse-grained patterns in high-noise regimes\n2. Capturing fine-grained patterns as the noise level decreases\n\nTo train these models, the authors employed two loss functions:\n\n1. MSE (Mean Squared Error) loss\n2. KL (Kullback-Leibler) divergence loss\n\n These loss functions were used to align noise prediction with the data distribution. The results demonstrate strong performance across various datasets, including impressive results on longer sequences.\n\nThe proposed approach effectively generates time series data by leveraging the strengths of diffusion models at different noise levels. By separating the tasks of capturing coarse-grained patterns, the method appears to achieve better overall performance in time series generation tasks.",
        "strengths": "This paper is well-written and easy to understand. The authors have conducted a fair comparison with other baseline models using a variety of datasets and evaluation metrics. Additionally, the model demonstrates good performance on datasets with long-term sequences, addressing existing generative models' limitations.\n\nIn terms of contributions, the following points stand out:\n\n1. Dual Loss Function: The use of both MSE loss and KL divergence loss is a significant contribution. This approach likely enhances the 2. model's ability to align noise prediction with the data distribution more effectively.\n2. Two-Stage Diffusion Model: The implementation of two separate diffusion models is intuitive and innovative. This design allows for:\n- Capturing coarse-grained patterns in high-noise regimes\n- Focusing on fine-grained patterns as the noise level decreases\n3. Comprehensive Evaluation: The authors have demonstrated the model's effectiveness across various datasets, including those with long sequences. This thorough evaluation strengthens the credibility of their approach.\n4, Addressing Long-Term Dependencies: By showing good performance on long-term sequences, the paper tackles a known challenge in generative models for time-series data.\n\nThe combination of these strengths suggests that the paper makes a valuable contribution to the field of time-series generation, offering both theoretical insights and practical improvements over existing methods.",
        "weaknesses": "Despite being well-written overall, this paper has a significant issue. The method proposed in the paper is described as a \"mixture-of-diffusers\" in the title, but the content related to this concept is lacking in the main text. \n\nThe paper doesn't adequately explain at which point the model switches from one diffusion model to the other. This lack of clarity makes it difficult to fully understand the proposed method's mechanics.\n\nAlso, the experiments on data scarcity seem unnecessary in the context of this paper. The results show that the performance of existing models remains unchanged as the amount of data decreases from the original dataset size. This doesn't appear to contribute meaningfully to the paper's main arguments or proposed method.\n\nThese weaknesses, particularly the lack of detailed explanation about the mixture-of-diffusers approach and the inclusion of seemingly irrelevant experiments, detract from the overall impact and clarity of the paper. More in-depth analysis and better alignment with the proposed method would significantly strengthen the paper's contributions."
      }
    ],
    "rating_avg": 5.6,
    "confidence_avg": 4.4,
    "decision": "N/A",
    "meta_review": "",
    "author_remarks": "",
    "decision_comment": ""
  },
  {
    "id": "8sglLco8Ti",
    "title": "ChunkKV: Semantic-Preserving KV Cache Compression for Efficient Long-Context LLM Inference",
    "authors": [
      "Xiang Liu",
      "Zhenheng Tang",
      "Peijie Dong",
      "Zeyu Li",
      "Bo Li",
      "Xuming Hu",
      "Xiaowen Chu"
    ],
    "abstract": "Large Language Models (LLMs) have demonstrated remarkable capabilities in processing extensive contexts, but this ability comes with significant GPU memory costs, particularly in the key-value (KV) cache. Although recent KV cache compression methods show strong performance, all use discrete tokens to maintain the KV cache, leading to a loss of chunk semantic information. We introduce ChunkKV, a novel KV cache compression method that retains the most informative semantic chunks while discarding the less important ones. ChunkKV preserves semantic information by grouping related tokens. Furthermore, ChunkKV exhibits a higher similarity in the indices of the retained KV cache across different layers, so we also propose a layer-wise index reuse technique to further reduce computational overhead. This technique not only improves compression efficiency, but also provides insight into the similarities between layers within LLMs. We evaluated ChunkKV on long-context benchmarks including LongBench and Needle-In-A-HayStack, as well as the GSM8K in-context learning benchmark. Our experiments, conducted with models LLaMA-3-8B-Instruct, Mistral-7B-Instruct, and Qwen2-7B-Instruct, demonstrate that ChunkKV outperforms other KV cache compression methods in performance, even surpassing the full KV cache under the same conditions. With a compression ratio of 10\\%, ChunkKV achieves state-of-the-art performance on various tasks, indicating its effectiveness in semantic preservation and model performance for long-context and in-context LLM inference.",
    "keywords": [
      "LLM",
      "KV cache",
      "compression",
      "long-context"
    ],
    "venue": "ICLR",
    "year": 2025,
    "pdf_url": "https://openreview.net/pdf?id=8sglLco8Ti",
    "forum_url": "https://openreview.net/forum?id=8sglLco8Ti",
    "reviews": [
      {
        "rating": "5",
        "confidence": "5",
        "summary": "This paper proposes ChunkKV, a KV Cache compression method that performs token eviction at chunk level because of the better semantics preservation compared to discrete methods. In addition, the authors find that the chunk-based method has better similarity within layers. They perform eviction step by sharing the eviction indexes across recent layers to increase the efficiency during compression.",
        "strengths": "1.\tThis paper explores the granularity of token eviction, which has some enlightening significance.\n2.\tAccording to the experiment results, the proposed method seemingly has good efficiency and accuracy.",
        "weaknesses": "1.Motivation requires more elaboration and experimental verification. The comparison between the discrete eviction method and chunk-based method in Figure 1 maybe true from a human behavior perspective, as some useful information may have been corrupted. However, in LLMs, the information of the corrupted tokens may still be retained in some other preserved tokens due to the attention mechanism. The internal information of different tokens in LLMs is difficult to explain, and the explaination of the motivation seems somewhat arbitrary. For example, detailed attention score or L1 loss between full cache and compressed cache of these two methods should be explored.\n\n2.Further explanation is needed for the experimental section (from most important to least). \n\n(1) The results of n=1 should be added to Figure 6 for observing the effectiveness of Chunks. \n\n(2) ChunkKV does not have particularly obvious advantages compared to SnapKV and Pyramid KV, and a more comprehensive comparison and fair setting are needed to demonstrate its effectiveness. Some key hyper-parameters: chunk size and reuse ratio in the main experiment, the compression ratio in NIAH. Some more detailed experimental settings: compress interval, compressing prompts or compressing the whole sequence. Higher and more diverse compression ratios are needed in main experiments. \n\n(3) Lacking throughput, latency, memory usage. The focus should be on overall throughput rather than single compression time because the compression time may not be important compared with model calculation, and we can manually control the compression frequency, which only requires sacrificing a small amount of accumulated KV space.\n\n(4) The comparison of chunk size in ablation is not combined with the compression ratio, and these two hyper-parameters are intuitively highly correlated. \n\nI am looking forward to seeing more detailed explanations and experimental results on these points, which may hugely affect my opinions."
      },
      {
        "rating": "5",
        "confidence": "5",
        "summary": "The paper looks into the problem of KV cache compression for long context LLM inference. In particular, it proposes to combine chunking-based token selection policy and cross-layer reuse to reduce KV cache size. Evaluation shows that the proposed method is able to achieve comparable accuracy on tested datasets.",
        "strengths": "- The paper tackles an important problem.\n\n- The paper combines chunking-based token selection and cross-layer similarity-based reuse, which is an interesting idea.",
        "weaknesses": "- Limited novelty. Leveraging cross-layer similarity has been studied in MiniCache https://arxiv.org/abs/2405.14366.  It would be better if the paper has a discussion and comparison with MiniCache. Chunking-based selection is also very related to clustering-based selection, as the pool1D technique used in SnapKV (see below). \n\n- Inaccurate related work.  The paper claims that prior work lacks the ability to preserve semantic information in chunks. Not true. For example, SnapKV identified that discretely selecting tokens is not sufficient and proposed to use a pooling layer to get make eviction decision at clustered-token granularity. It would be better if the paper adds a discussion and comparison between the chunking method in this paper and the pooling method in SnapKV.  \n\n- Evaluation is insufficient. The evaluation is insufficient, because it neither shows how the approach trade-offs memory vs. accuracy, nor does it provide analysis on how introduced hyperparameters affect the proposed method. \n\n- Hard to use in practice. The paper introduces many parameters, such as w, c, N_reuse, the number of reuse layers, but the paper does tell the readers how those parameters are selected. This adds significant tuning overhead and can also subject to overfitting on tested datasets."
      },
      {
        "rating": "5",
        "confidence": "4",
        "summary": "The submission introduces ChunkKV, a technique designed to manage the increased GPU memory demands associated with large-context LLM inference, which can hinder throughput significantly during inference serving. The proposed solution consists of two main components: 1. chunk based KV catch preserving techniques. 2. layer-wise index reuse technique to further reduce computational overhead. With this compression technique, ChunkKV demonstrates state-of-the-art performance across several tasks.",
        "strengths": "1. The writing is clear and easy to follow.\n\n2. The paper did a lot of experiments on different tasks and ablation studies to show the effectiveness of the proposed method.",
        "weaknesses": "1.  While the proposed approach is methodologically sound, it may be seen as incremental. The concept, though well-executed, may not represent a substantial leap in novelty within the field.\n\n2. The methodology introduces a significant inductive bias through its dependency on chunk size. This reliance makes the model's performance highly sensitive to chunk size, which in turn varies across tasks. In a closed task-specific setting, this is manageable; however, in open-ended evaluations where task specifics are not predefined, determining an optimal chunk size for every potential task becomes unfeasible. Thus, while the method may find value in specialized, known tasks, its general applicability in open settings is limited.\n\n3. The proposed layer-reuse KV-cache offers a means to reduce computational costs, which is valuable. However, the simplicity of the solution also leads to a trade-off in performance. This compromise suggests that further refinement is needed to optimize both cost-efficiency and model efficacy without incurring a performance penalty.\n\nWhile the submission has certain strengths, the limited novelty, sensitivity to chunk size, and performance-cost trade-off may limit its applicability in broader contexts. Further work addressing these areas would strengthen the contribution."
      },
      {
        "rating": "6",
        "confidence": "4",
        "summary": "This paper provides ChunkKV, a simple KV cache compression method that uses fragmentation to keep semantic information and achieves state-of-the-art performance on long-context benchmarks. It also proposes the layer-wise index reuse technique to reduce the additional computational time introduced by the KV caching method.",
        "strengths": "1) Using the fragmentation method that keeps the semantic information leads to good results in benchmarks.\n2) Further combination with layer-wise index reuse can help improve deployment efficiency.",
        "weaknesses": "1) Concerning contributions:\n- The paper highlights fragmentation in KV cache compression. However, to improve accuracy, SnapKV [1] has proposed clustering methods.\n2) Concerning Experiments:\n- The paper does not include actual memory reduction and latency statistics.\n3) Concerning performance:\n- After layer reuse, the performance drops linearly with the number of reused layers. I had hoped to see layer reuse with minimal performance loss.\n\n[1] Li Y, Huang Y, Yang B, et al. Snapkv: Llm knows what you are looking for before generation[J]. arXiv preprint arXiv:2404.14469, 2024."
      }
    ],
    "rating_avg": 5.25,
    "confidence_avg": 4.5,
    "decision": "Reject",
    "meta_review": "This paper presents ChunkKV, a novel KV cache compression method that aims to preserve semantic information through chunk-based compression while reducing computational overhead through layer-wise index reuse. The key claims include achieving comparable or better performance than full KV cache while providing 5.4x speedup. The paper's strengths include addressing an important practical problem in LLM inference efficiency, demonstrating competitive empirical results, and providing thorough analysis of information preservation through multiple metrics. Initial weaknesses included: limited novelty compared to existing methods like MiniCache and SnapKV, insufficient experimental validation of memory-accuracy tradeoffs, concerns about hyperparameter sensitivity, and lack of throughput/latency measurements. During rebuttal, the authors significantly strengthened the paper by: adding detailed quantitative analysis showing better information preservation than baselines (via KV Cache L1 Loss and Attention Cosine Similarity metrics), conducting comprehensive latency/throughput experiments, and demonstrating robustness across hyperparameters. Based on the review scores, lack of novelty concerns, and insufficient experimental validation, I vote to reject this paper.",
    "author_remarks": "",
    "decision_comment": ""
  },
  {
    "id": "yGv5GzlBwr",
    "title": "Diffusion Auto-regressive Transformer for Effective Self-supervised Time Series Forecasting",
    "authors": [
      "Daoyu Wang",
      "Mingyue Cheng",
      "Zhiding Liu",
      "Qi Liu",
      "Enhong Chen"
    ],
    "abstract": "Self-supervised learning has become an essential and popular approach for enhancing time series forecasting, enabling models to learn universal representations from unlabeled data. However, effectively capturing both the global sequence dependence and local detail features within time series data remains challenging. To address this, we propose a novel generative self-supervised method called TimeDART, denoting Diffusion Auto-regressive Transformer for Time series forecasting. In TimeDART, we treat time series patches as basic modeling units. For one thing, we employ an self-attention based Transformer encoder to model the dependencies of inter-patches. For another, we introduce diffusion and denoising mechanisms to capture the locality features of intra-patch. Notably, we design a cross-attention-based denoising decoder that allows for adjustable optimization difficulty in the self-supervised task, facilitating more effective self-supervised pre-training. Extensive experiments demonstrate that TimeDART achieves state-of-the-art fine-tuning performance compared to the most advanced competitive methods in forecasting tasks. Our code is publicly available at https://anonymous.4open.science/r/TimeDART-2024.",
    "keywords": [
      "Self-supervised Learning",
      "Diffusion Model",
      "Time Series Forecasting"
    ],
    "venue": "ICLR",
    "year": 2025,
    "pdf_url": "https://openreview.net/pdf?id=yGv5GzlBwr",
    "forum_url": "https://openreview.net/forum?id=yGv5GzlBwr",
    "reviews": [
      {
        "rating": "5",
        "confidence": "4",
        "summary": "The paper introduces TimeDART (Diffusion Auto-Regressive Transformer for Time Series Forecasting), a novel self-supervised learning framework designed to enhance time series forecasting. TimeDART addresses key challenges in the field, particularly capturing both long-term dependencies and local features within time series data.",
        "strengths": "+ Combining self-attention for inter-patch dependencies, diffusion mechanisms for intra-patch dependencies, and auto-regressive optimization is an interesting and innovative approach to time series forecasting.\n+ The diffusion-based reverse process for reconstructing the sequence is novel in the context of time series forecasting.\n+ Good writing and organization.",
        "weaknesses": "+ The combination of Transformer-based attention mechanisms with the denoising diffusion process introduces substantial computational overhead. The paper mentions running experiments on a single NVIDIA RTX 4090 GPU, but it doesn't provide detailed insights into the time and memory consumption required for training. How scalable is TimeDART for larger datasets or real-time applications? \n+ The experiments conducted on noise scheduling, the number of diffusion steps, and the number of layers in the denoising network highlight a significant degree of sensitivity to hyperparameter selection. How the model will perform well in practical settings with minimal tuning?\n+ The cross-domain evaluation shows strong results on energy datasets but weaker performance on datasets like Exchange. Is TimeDART overly sensitive to the type of data it is pre-trained on? For instance, does it struggle with financial or highly volatile datasets because of the lack of shared characteristics between domains (e.g., energy vs. finance)? Could this method benefit from domain adaptation techniques to make the cross-domain transfer more robust?\n+ The model uses a denoising diffusion loss, which may not be the most suitable for every type of forecasting task. How does TimeDART perform with other loss functions (e.g., Quantile Loss, Huber Loss) that are often used in time series forecasting tasks where the goal is to forecast confidence intervals or robustly handle outliers?"
      },
      {
        "rating": "8",
        "confidence": "3",
        "summary": "Recently, effectively capturing both the global sequence dependence and local detail features within time series data remains challenging. To address this, the authors propose a novel generative self-supervised method called TimeDART, denoting Diffusion Auto-regressive Transformer for time series forecasting.",
        "strengths": "1. We propose a novel generative self-supervised learning framework, TimeDART, which in tegrates diffusion and auto-regressive modeling to effectively learn both global sequence dependencies and local detail features from time series data, addressing the challenges of capturing comprehensive temporal characteristics.\n 2. We design a cross-attention-based denoising decoder within the diffusion mechanism, which enables adjustable optimization difficulty during the self-supervised task. This design significantly enhances the model’s ability to capture localized intra-patch features, improving the effectiveness of pre-training for time series forecasting. Diffusion models and autoregressive attention mechanisms are rare collaborations in temporal tasks, and this field brings new ideas. \n3. The experimental results show that the combination of Mamba and propagation mechanism is very effective, and it also exceeds the predictive performance of supervised learning.",
        "weaknesses": "1. The reviewer is concerned about the computational overhead associated with this approach. The reviewer's core concern stems from the introduction of diffusion mechanisms, which can lead to a substantial increase in training and inference overhead for the model as a whole. If the model is expensive, the computational conditions required to solve the real task will be severe. Therefore, the authors need to report the actual time of the training and inference phase of other baseline models in the future and report the GPU and server model.\n2. The motivation for choosing to use a causal mechanism in Transformer requires further explanation. After all, time series data is encoded with more complex patterns. In particular, there are random changes caused by extreme weather events in the meteorological data, and this causal relationship is strong. But many things cause and effect is unclear, so whether such a component is appropriate needs to be used for the specific task."
      },
      {
        "rating": "5",
        "confidence": "3",
        "summary": "To effectively capture both the global sequence dependence and local detail features within time series data, this paper proposed a novel generative self-supervised method called TimeDART, denoting Diffusion Auto-regressive Transformer for Time series forecasting. Extensive experiments demonstrate that TimeDART achieves state-of-the-art fine-tuning performance compared to the most advanced competitive methods in forecasting tasks.",
        "strengths": "1. Well-written\n2. The author provides the code\n3. The performance of the model is proved by experiments",
        "weaknesses": "1. In the original paper [1], the performance of patchTST seems to be better, and it is suggested that the author should evaluate it more fairly.\n2.  Why didn't the author consider evaluating the performance of classification tasks? Currently, aside from forecasting tasks, most self-supervised learning models [2] also focus on the performance of classification tasks. This is because the main purpose of self-supervised learning is to enhance the quality of representations generated by the model and to uncover key semantic features, which is especially important for classification tasks.\n3.  A crucial role of self-supervised learning is to improve the performance of backbone models [3], but the author only uses Transformer as the backbone. I am curious whether the proposed method would still be effective if MLP or TCN were used as the backbone.\n4. The author's core motivation remains to capture both global and local dependencies, which is similar to most existing works [1] [4]. In other words, this paper lacks a central challenging problem, making the contribution at the motivational level somewhat limited.\n5. Considering that the core motivation of this paper is to capture global and local dependencies, I suggest the author evaluate the model's performance on datasets with stable patterns, such as PEMS04. This is because datasets like ETT and Exchange have inherent issues with distributional shifts [5].\n\n[1] A time series is worth 64 words: Long-term forecasting with transformers\n\n[2] SimMTM: A Simple Pre-Training Framework for Masked Time-Series Modeling\n \n[3]  Cost: Contrastive learning of disentangled seasonal-trend representations for time series forecasting\n\n[4] Segrnn: Segment recurrent neural network for long-term time series forecasting\n\n[5] Exploring Progress in Multivariate Time Series Forecasting: Comprehensive Benchmarking and Heterogeneity Analysis"
      },
      {
        "rating": "3",
        "confidence": "5",
        "summary": "This paper proposes TimeDART, a novel self-supervised learning paradigm that hopes to learn transferable generic representations from unlabeled data through pre-training and then fine-tune them to different downstream tasks, e.g., forecasting tasks, etc. In this paper, a unified self-supervised learning framework is established by fusing the diffusion-denoising process and autoregressive modeling. By learning global sequence dependencies and local detail features in multi-domain time series data, the model's ability to capture comprehensive time series features and cross-domain generalization ability are improved. Specifically, TimeDART designs a cross-attention based denoising decoder in the diffusion mechanism, which improves the effectiveness of time series pre-training by significantly enhancing the model's capability to capture features within local blocks.",
        "strengths": "The authors outline the main approaches to self-supervised learning in the time series domain, including mask reconstruction and contrast learning, and analyses the shortcomings of the two existing self-supervised learning paradigms separately, e.g., the mask reconstruction-based approach introduces a huge gap between pre-training and fine-tuning, and the contrast-learning-based approach prioritizes the capture of discriminative features, which lead to a huge discrepancy between pre-training tasks and fine-tuning tasks.\n\nIn addition, the authors raise two issues critical to the self-training paradigm, 1) how to narrow the gap between the pre-training target and the downstream fine-tuning task, and 2) modelling both long-term dependencies and local pattern information in the self-supervised pre-training phase. However, we believe that TimeDART is not the best solution to these problems.",
        "weaknesses": "**Weakness 1:** \n\nAs a Diffusion-based model, we would like to introduce more valuable metrics to fully examine the performance of the proposed TimeDART. Specifically, in order to evaluate the prediction accuracy and generalization capability of TimeDART from both forecasting and generation perspectives, existing studies often include the following four metrics (including Context-FID, Correlational Score, Discriminative Score, and Predictive Score) for comprehensively evaluating the performance of Diffusion methods. \n\nIn addition, the proposed TimeDART is not compared with advanced Diffusion-based approaches, such as Diffusion-TS[1], mr-Diff[2], and MG-TSD[3]. We believe that the introduction of more competitive and up-to-date approaches can demonstrate the effectiveness of the proposed method more objectively.\n\n**Weakness 2:** \n\nIn the in-domain setting (Table 2), there are the following weaknesses: \n\n* The performance improvement of the proposed TimeDART over SOTA methodologies SimMTM and PatchTST is less than 5%, which indicates that the performance improvement of the model is not obvious.\n\n* In addition, we note that the performance of \"Random Init\" shown in Table 1 is slightly worse than Supervised PatchTST. Does this indicate that in the supervised setting of a single domain, the proposed model architecture exhibits worse performance compared to PatchTST? If the modeling capability of the TimeDART is poor in small datasets, the model will often show worse generalization ability in cross-domain pre-training, which leads to the rationality of the model architecture being questioned.\n\n**Weakness 3:** \n\nIn the cross-domain setting (Table 3), there are the following weaknesses that can be improved: \n\n* The model is pre-trained on only two power domain datasets (ETT and Electricity). As a result, only the single domain information is included in the model, which limits the generalization ability of the model under cross-domain challenges. Recent unified time series forecasting models include two paradigms. The first is unified models based on LLM fine-tuning, such as OneFitsAll[4] and TimeLLM[5]. This is followed by pre-training on a multi-domain hybrid Time series dataset followed by fine-tuning on specific downstream tasks, e.g., Timer[6], Moriai[7] and MOMENT[8]. In conclusion, we believe that introducing information from more domains during pretraining can improve the cross-domain generalization of the model, and TimeDART is expected to be pretrained on a wider range of datasets. \n\n* Table 3 only shows the performance comparison of TimeDART under different Settings; however, it lacks the comparison with the latest baseline. In fact, recent UniTime[9] have achieved joint pretraining across multiple domains. Therefore, we expect the authors to introduce more advanced baselines to compare with TimeDART, which will help us get a comprehensive understanding of TimeDART's performance.\n\n**Weakness 4:** \n\nIn ablation experiments (Table 4), there are the following drawbacks: \n\n* There is a lack of detailed descriptions specific to ablation experiments, such as in-domain Settings or cross-domain Settings. When we compare the results in Table 4 and Table 2, we can speculate that the ablation experiment is only carried out in the in-domain setting. However, in the cross-domain setting, the reader is eager to know whether the proposed autoregressive diffusion model is effective. \n\n* In Table 4,\" The \"W/o AR\" model obtained the improved \"W/o AR\" model after introducing the Diffusion-based decoder; However, the performance of the latter was slightly degraded on the ETTh2 and Electricity datasets. This may indicate that the predictions of the model become worse when the diffusion model is introduced. This casts doubt on the rationality of introducing a Diffusion-Denoising process in the Decoder.\n\n**Reference:** \n\n1) Yuan, Xinyu and Yan Qiao. “Diffusion-TS: Interpretable Diffusion for General Time Series Generation.” ICLR 2024.\n\n2) Shen, Lifeng et al. “Multi-Resolution Diffusion Models for Time Series Forecasting.” ICLR 2024.\n\n3) Fan, Xinyao et al. “MG-TSD: Multi-Granularity Time Series Diffusion Models with Guided Learning Process.”  ICLR 2024.\n\n4) Zhou, Tian et al. “One Fits All: Power General Time Series Analysis by Pretrained LM.” NIPS 2023.\n\n5) Jin, Ming et al. “Time-LLM: Time Series Forecasting by Reprogramming Large Language Models.” ICLR 2024.\n\n6) Liu, Yong et al. “Timer: Generative Pre-trained Transformers Are Large Time Series Models.” ICML 2024.\n\n7) Woo, Gerald et al. “Unified Training of Universal Time Series Forecasting Transformers.” ICML 2024.\n\n8) Goswami, Mononito et al. “MOMENT: A Family of Open Time-series Foundation Models.” ICML 2024.\n\n9) Liu, Xu et al. “UniTime: A Language-Empowered Unified Model for Cross-Domain Time Series Forecasting.” Proceedings of the ACM on Web Conference 2024."
      }
    ],
    "rating_avg": 5.25,
    "confidence_avg": 3.75,
    "decision": "Reject",
    "meta_review": "The paper proposes TimeDART, a novel self-supervised learning framework that integrates diffusion mechanisms and autoregressive Transformers to capture global dependencies and local detail features in time series forecasting. Strengths include its innovative combination of diffusion and autoregressive techniques, a cross-attention denoising decoder for effective self-supervised pretraining, and extensive experiments showing competitive performance in forecasting tasks. However, weaknesses include significant computational overhead due to the diffusion process, limited exploration of cross-domain generalization and inter-channel dependencies, sensitivity to hyperparameter tuning, and less-than-expected improvements over state-of-the-art methods. Additionally, the paper lacks evaluation on broader tasks like classification and more diverse baselines. These limitations suggest the contributions, while promising, may not yet be sufficient to justify acceptance, leading to a recommendation for rejection.",
    "author_remarks": "",
    "decision_comment": ""
  },
  {
    "id": "leSbzBtofH",
    "title": "AutoAdvExBench: Benchmarking Autonomous Exploitation of Adversarial Example Defenses",
    "authors": [
      "Nicholas Carlini",
      "Edoardo Debenedetti",
      "Javier Rando",
      "Milad Nasr",
      "Florian Tramèr"
    ],
    "abstract": "We introduce AutoAdvExBench, a benchmark to evaluate if large language models (LLMs)\ncan autonomously exploit defenses to adversarial examples.\nWe believe our benchmark will be valuable to several distinct audiences. \nFirst, it measures if models can match the abilities of expert adversarial machine learning researchers.\nSecond, it serves as a challenging evaluation for reasoning capabilities that\ncan measure LLMs' ability to understand and interact with sophisticated codebases. \nAnd third, \nsince many adversarial examples defenses have been broken in the past,\nthis benchmark allows for evaluating the ability of LLMs to reproduce\nprior research results automatically.\nWe then benchmark the ability of current LLMs to solve this benchmark,\nand find most are unable to succeed.\nOur strongest agent, with a human-guided prompt,\nis only able to successfully generate adversarial examples on 6 of the 51 defenses in our benchmark.\nThis benchmark is publicly accessible at redacted for review.",
    "keywords": [
      "security",
      "benchmark",
      "large language models",
      "agents",
      "adversarial examples"
    ],
    "venue": "ICLR",
    "year": 2025,
    "pdf_url": "https://openreview.net/pdf?id=leSbzBtofH",
    "forum_url": "https://openreview.net/forum?id=leSbzBtofH",
    "reviews": [
      {
        "rating": "8",
        "confidence": "3",
        "summary": "This paper proposes a new benchmark to test LLM capabilities: whether they can generate adversarial attacks to proposed adversarial defenses. The authors crawled arXiv and filtered the papers to find adversarial defense methods with easily reproducible code. Current state-of-the-art LLMs were tested on this new benchmark, and do not perform well.",
        "strengths": "The authors propose a novel benchmark to test the capabilities of LLMs. The proposed task is a real-world research/security setting, where the \"correct\" answer may not even be known, and yet there is a quantitative measurement that can be extracted to evaluate the abilities of the LLM. As a result, this provides a benchmark which may still be useful even if a model has surpassed human level performance in this domain. The authors are upfront about the many limitations of the benchmark.",
        "weaknesses": "- The benchmark is evaluated in a limited setting. Even though to be successful, the model must be proficient in several different domains, the scope of the task is fairly limited.\n- As mentioned, benchmark contamination is a potential issue, especially when considering the use of this benchmark well into the future.\n- The benchmark does not appear to provide a meaningful continuous measure for current LLMs ability to generate novel attacks. Instead, it seems limited to whether they can successfully implement a known attack, as all of their current limited success on the benchmark is due to benchmark contamination."
      },
      {
        "rating": "5",
        "confidence": "5",
        "summary": "This paper proposes a benchmark, AutoAdvExBench, to measure large language models' (LLMs) ability to exploit other AI systems. To be specific, AutoAdvExBench evaluates LLMs' ability to construct adversarial examples that bypass the corresponding defense methods. Experimental results demonstrate that AutoAdvExBench is challenging with a low attack success rate: only 6 of the 51 defenses are successfully attacked by their strongest agent.",
        "strengths": "+ Measuring AI's ability to exploit other AI systems is necessary and meaningful for preparing for future safety risks. Automatic AI exploitation becomes feasible due to the automated nature of the AI agent system and could result in catastrophic risks. This paper provides a realistic implementation for such a speculative threat model. Therefore, it will be a good proxy to monitor the progress of AI and prepare for the possible safety risks. \n\n+ The construction process of AutoAdvExBench is solid: this paper collects reproducible and diverse defense papers with manual checks to compose their benchmark, which will provide a strong basis for measuring AI exploitation ability.",
        "weaknesses": "- **The evaluation metrics lack comprehensiveness.** The paper only reports robust accuracy and the number of successful attacks as metrics, neglecting more detailed analyses of the various capabilities agents need to overcome the benchmark. Areas like code comprehension, code completion, long-context understanding, and the novelty of proposed ideas are overlooked. For example, while the paper finds that only a quarter of defenses can be made differentiable (line 480)—a necessary step before designing new attacks—it’s unclear which capabilities agents lack that lead to these limitations. Simply reporting post-attack robust accuracy does not reveal which specific capabilities are bottlenecks, nor does it offer insights into where current models fall short.\n\n- **Data contamination is a significant concern** that the authors have not adequately addressed. They do not provide empirical results to demonstrate the extent of data contamination in their benchmark. Although they state (line 262) that allowing agents access to paper data does not significantly improve success rates, this does not definitively rule out contamination. Furthermore, as the benchmark does not use the most advanced agent frameworks, it’s conceivable that more sophisticated agents could leverage memorized information to generate attack codes if contamination were present, raising questions about the benchmark’s validity and challenge level.\n\n- **The captions of each table and figure lack essential details, making them difficult to follow.** For instance, in Figure 2, it’s unclear how the caption’s statement, \"each line plots the number of defenses that reduce the robust accuracy to a given level,\" corresponds to the curves in the figure. Similarly, in Table 3, the meanings of terms such as \"forward pass,\" \"differentiable,\" and \"FGSM attack\" and the respective numbers are not fully explained. This also seems inconsistent with the analysis of FGSM in the main text (line 486), where an accuracy rate of 84% is mentioned.\n\n- **The benchmark does not leverage the latest agent frameworks, such as multi-agent systems with specialized roles, which could potentially address the challenges posed by the benchmark.** The coding capabilities of the agents used in the paper seem quite limited (see Table 3), suggesting that the benchmark may not be challenging enough for cutting-edge agent models."
      },
      {
        "rating": "8",
        "confidence": "4",
        "summary": "This paper proposes an agentic benchmark for LLMs where the task is to automatically break various adversarial robustness defenses. It includes implementations and PDFs for a large number of adversarial robustness defenses, some of which have published vulnerabilities. The goal of the LLM agent is to output 1000 perturbed images under a standard \\ell_{\\infty} bound that break the defenses.",
        "strengths": "- This is a clever idea for an agentic benchmark. The task is complex but easy to evaluate, and it provides a way to measure how useful LLM agents could be for stress-testing defenses proposed by the ML community, which I think is an interesting future use case of AI agents.\n- The work is timely. Multiple new agentic benchmarks have been proposed recently, including SWE-bench and MLE-bench. This paper continues that line of benchmarking work, but with an emphasis on automated stress-testing for adversarial training defenses.\n- The writing is clear.\n- The benchmark seems well-designed. The task is easy to understand. Useful data was curated to enable the agents to perform the task (paper code and PDFs).\n- The baseline evaluations show that the task is tractable.",
        "weaknesses": "For defenses with published vulnerabilities, it would be good to include a check for whether the model is aware of these vulnerabilities or discovers them from scratch. I realize this isn't relevant to current models, since they aren't very good yet, but it could be an interesting thing to check in future models. I see your response in lines 261-262. This is just a comment that the paper would be stronger with proactive measures to address this."
      },
      {
        "rating": "6",
        "confidence": "4",
        "summary": "This paper introduces AutoAdvExBench, a benchmark to evaluate if large language models (LLMs) can autonomously break defenses to adversarial examples, given access to defense (a) the paper describing the defense, (b) the source code of the defense, (c) a correct forward pass implementation of the defense, (d) a perturbation bound, and (e) 1,000 images that should be attacked. The authors attempt both an end-to-end approach and a four-step, human-guided approach. Based on the low success rates, the authors conclude that current language models cannot autonomously break most adversarial example defenses.",
        "strengths": "-  An interesting attempt to test LLMs on a well-established security problem, i.e., defenses against adversarial examples. The authors have provided strong motivations for proposing such a new benchmark.\n\n- The paper is written well, clearly stating the contributions beyond the literature and the significance. \n\n- The fact that current LLMs largely fail in solving such a well-defined problem is somewhat surprising and so calls for future work.",
        "weaknesses": "Presentation:\n\n1. The reviewer appreciates that the authors have put much effort into describing the limitations, even as early as in Section 3.3. However, several points in Section 3.3 Limitations and Section 3.1 Motivation are actually from the same perspective but do not well connect. Specifically, as the reviewer understands, although the benchmark is “difficult” and “security-relevant”, ”Adversarial examples attacks are not representative of common security exploits”. Although the benchmark is “Messy”, its “Research code is not representative of production code”. It may help if the authors could first present the perspectives, and then talk about the motivations/advantages and limitations of the benchmark in each perspective.\n\n2. Throughout the paper, only Figure 2 was referred to in the main text, making the more summarized information in tables/figures not helpful for understanding the paper. The authors should explicitly reference relevant tables and figures when discussing results in the main text. This would help readers connect the discussion to the supporting data more easily.\n\n3. The term “successfully attacked” is not defined before use. For example, it appears in the second to last sentence of the Abstract and the caption of Table 3. In addition, it is not clear what the numbers in Table 3 mean. \n\n\nExperiment:\n\n1. Although it is OK to show current LLMs are not good at solving the new benchmark, there is no exploration of potential ways to improve them. For example, It is interesting that current LLMs still struggle with simple operations, e.g., “models were only able to implement a differentiable forward pass in 23% of cases”. However, the authors have not attempted to solve this and have not even discussed potential solutions. They could include ideas for targeted training and improved prompting strategies.\n\n2. The authors state that “We impose no time restriction, on the number of unsuccessful attempts an adversary makes, on the runtime of the algorithm, or on the cost of the attack. However, we strongly encourage reporting these numbers so that future work will be able to draw comparisons between methods that are exceptionally expensive to run, and methods that are cheaper.” The reviewer does not get why they have not reported these numbers in this paper (which seems not to require too much additional effort)."
      },
      {
        "rating": "5",
        "confidence": "4",
        "summary": "The paper introduces AutoAdvExBench, a benchmark designed to evaluate the ability of large language models (LLMs) to attack adversarial example defenses. The benchmark includes 51 defenses from 37 papers, and the LLMs are provided with the research paper and the corresponding code for the forward pass of the defense.\nThe authors test state-of-the-art LLMs like Claude 3.5-Sonnet and GPT-4o in various scenarios, finding that current models struggle significantly. Zero-shot attempts were entirely unsuccessful, and even with iterative debugging, only a few defenses were successfully attacked. \nThe paper highlights the challenges LLMs face in automating security tasks, emphasizing their limitations in understanding and exploiting such defenses.",
        "strengths": "1. The authors invested significant effort in filtering relevant papers and collecting reproducible code, resulting in a comprehensive and valuable dataset of 51 adversarial defenses from 37 papers. This rigorous collection process enhances the benchmark's credibility and relevance to the research community.\n\n2. The benchmark setup involves working with \"messy\" research codebases, which closely reflects real-world challenges in adversarial defense scenarios. This realistic approach adds significant value, as it pushes current LLMs to handle complex, imperfect code environments typical in real applications.\n\n3. The paper employs definitive evaluation methods that do not rely on black-box metrics, such as LLM-as-a-judge approaches. Instead, it uses measurable, transparent performance metrics, ensuring that the results are both interpretable and replicable.",
        "weaknesses": "1. The paper lacks detailed examples of interactions with the LLMs, such as specific prompts used or a complete end-to-end example of at least one of the defenses and its corresponding developed attack stages. Including visual aids or detailed walk-throughs of successful or failed attacks could greatly enhance readability and engagement. The absence of such details makes the content dense leading to a less engaging reading experience.\n\n2. The current experimental settings are overly general for the LLMs, so it's unsurprising to observe such low success rates. From my experience, even for simpler coding tasks, I find that even the best LLMs require significantly more detail—such as an initial code draft, context explanations, and multiple rounds of conversation and reflection, as in a chat scenario—to achieve the desired results. For example, would a 6-turn interaction (interactive human-AI chat session) with these models (like GitHub Copilot settings) yield much better results? \n\n3. The paper could have explored more powerful methods, such as ICL few-shot examples, fine-tuning, or retrieval-augmented generation (RAG), to better evaluate LLMs' capabilities in solving the benchmark. These approaches could have provided valuable insights into the strengths and limitations of LLMs when leveraging different training and interaction methodologies. The current experimental settings are necessary but insufficient.\n\n4. This is a coding task, yet the paper's background lacks information on state-of-the-art LLMs specifically trained for coding. You've tested with GPT-4o and Claude 3.5 Sonnet, but are there other LLMs worth experimenting with? \n\n5. In Section 5.1 (End-to-End Evaluation), in the sentence \"Unsurprisingly, we find that current defenses fail completely at this task ...\" do you mean \"current models\"?"
      },
      {
        "rating": "5",
        "confidence": "3",
        "summary": "The paper presented AutoAdvExBench, which evaluated if LLM can automatically exploit defenses to adversarial examples. Contributions include:\n- evaluates if models can match the abilities of expert adversarial machine learning researchers\n- measure LLMs’ ability to understand and interact with sophisticated codebases\n- evaluates the ability of LLMs to reproduce prior research results automatically\n\nThe results show: the strongest agent, with a human-guided prompt, is only able to successfully generate adversarial examples on 6 of the 51 defenses in the benchmark.",
        "strengths": "- It's an interesting benchmark to evaluate LLMs' capacity to autonomously exploit defenses to adversarial examples.\n- The defense implementations are collected comprehensively and rigorously.\n- The limitations are fairly presented.",
        "weaknesses": "The presentation can be improved:\n- It takes me a long time to find out that adversarial examples are for image classifiers. LLMs also have so-called adversarial attacks- it would be better to make it clear of the specific task in the abstract as well as early in the introduction to make it clear.\n- The introduction didn't actually specify what it is \"autonomously generate exploits on adversarial example defenses\", before jumping into what the benchmark includes and what is its impact.\n- The abstract focuses on the potential impact of the benchmark a lot, Yet it shall better inform what is the benchmark is really about-- the first sentence didn't convey it clearly.\n\nAs a benchmark paper, more LLMs should be considered and benchmarked. However, we only see the results for Claude 3.5 and GPT-4o.\n\nIf that is because other LLMs are so weak for the task, I personally think a good benchmark for current sota LLMs should be able to distinguish their capacity. If most of them fail for the benchmark, then it may not be a good choice at this time."
      }
    ],
    "rating_avg": 6.166666666666667,
    "confidence_avg": 3.8333333333333335,
    "decision": "Reject",
    "meta_review": "This paper introduces a new benchmark whereby LLMs are evaluated on their ability to break adversarial defenses.  The reviewers are conflicted about this paper.  At a high level, I think the scope of this paper is narrow, and I think the fact that the benchmark entangles multiple factors like knowledge of existing codebases and ability to reason about what might break a particular defense is a bug and not a feature of a benchmark.  Due to the multiple negative reviews (and accounting for the fact that reviewers did interact during the rebuttal period), I recommend rejection for this paper.  Nonetheless, I encourage the authors to keep improving their work.",
    "author_remarks": "",
    "decision_comment": ""
  },
  {
    "id": "l11DZY5Nxu",
    "title": "Robust Root Cause Diagnosis using In-Distribution Interventions",
    "authors": [
      "Lokesh Nagalapatti",
      "Ashutosh Srivastava",
      "Sunita Sarawagi",
      "Amit Sharma"
    ],
    "abstract": "Diagnosing the root cause of an anomaly in a complex interconnected system is\na pressing problem in today’s cloud services and industrial operations. We propose In-Distribution Interventions (IDI), a novel algorithm that predicts root cause\nas nodes that meet two criteria: 1) Anomaly: root cause nodes should take on\nanomalous values; 2) Fix: had the root cause nodes assumed usual values, the\ntarget node would not have been anomalous. Prior methods of assessing the fix\ncondition rely on counterfactuals inferred from a Structural Causal Model (SCM)\ntrained on historical data. But since anomalies are rare and fall outside the training distribution, the fitted SCMs yield unreliable counterfactual estimates. IDI\novercomes this by relying on interventional estimates obtained by solely probing the fitted SCM at in-distribution inputs. We present a theoretical analysis\ncomparing and bounding the errors in assessing the fix condition using interventional and counterfactual estimates. We then conduct experiments by systematically varying the SCM’s complexity to demonstrate the cases where IDI’s interventional approach outperforms the counterfactual approach and vice versa.\nExperiments on both synthetic and PetShop RCD benchmark datasets demonstrate that IDI consistently identifies true root causes more accurately and robustly than nine existing state-of-the-art RCD baselines. Code will be released\nat https://github.com/nlokeshiisc/IDI_release.",
    "keywords": [
      "Root Cause Diagnosis",
      "Causal Inference",
      "Interventional RCD"
    ],
    "venue": "ICLR",
    "year": 2025,
    "pdf_url": "https://openreview.net/pdf?id=l11DZY5Nxu",
    "forum_url": "https://openreview.net/forum?id=l11DZY5Nxu",
    "reviews": [
      {
        "rating": "6",
        "confidence": "2",
        "summary": "This paper focuses on addressing the issue of performance degradation caused by OOD problems in previous methods when localizing root cause curves through causal interventions. It proposes the IDI method and demonstrates its advantages over existing SCM-based root cause localization methods through multi-level experiments.",
        "strengths": "1. The presence of hidden confounding factors makes the OOD problem both prevalent and significant.\n2. The writing of this paper is clear and easy to read.\n3. The paper provides proof that the IDI method's in-distribution sampling has a bounded error, scaling with the distance between anomalies and normality.",
        "weaknesses": "See the following questions."
      },
      {
        "rating": "6",
        "confidence": "3",
        "summary": "The paper proposes an approach: IDI that identifies root causes based on two criteria: (1) the node exhibits anomalous behavior (anomalous condition), and (2) if the node had normal values, the target node would not be anomalous (fix condition). It contrasts this approach with the pre-existing methods that use counterfactuals from Structural Causal Models (trained on historical data)—often unreliable for rare anomalies (as they are OOD). IDI relies on interventional estimates within the training distribution (in reality the validation distribution).",
        "strengths": "The three strengths of the paper are: \n1. Whatever is presented in the paper is technically sound. Although I believe some clarifications are needed and the contribution is not enough (i.e., more content can be added). \n2. **Main Strength:** The experiment section is very impressive. It is thorough and the ablation studies are performed well. \n3. The main research question addressed in this paper i.e., counterfactual estimates can push SCMs to OOD regions, and sampling from in-distribution to intervene to circumvent this issue, is an important contribution to the community. However, originality of this idea is unclear. \n4. Monitoring cloud KPIs for anomalies and root cause diagnosis in them is an important application. Showing the experiments on \"Petshop\" is impressive. In a way the paper is written to cater the root cause diagnosis needs of Petshop. However, the authors need to provide some insights on cloud KPIs either in Introduction or Preliminary to make the paper even stronger for engineers.",
        "weaknesses": "The methodological contribution of the paper is a major weakness. There are some weaknesses in the experiment section as well. \n1. Sampling the latent exogenous variable from the (validation set) distribution as opposed to inverting the function $f_i$ (abduction) is important but a minor methodological tweak that might not warrant a full research paper. It is also unclear if \"in-distribution intervention\" approach is novel or has been proposed in the literature. The authors must show an analogy of the abduction step as a probability distribution. And then they should show how sampling from that distribution is different from the proposed approach. \n\n2. Most parts of the papers are pre-existing knowledge except the two theorems. Even the difference between the two theorems is the abduction step, which is intuitive from the definitions of counterfactual vs intervention (equation 4, 5, 6). \n\n3. Section 5 is over-explained (especially for the unique root cause case). The definitions of \"anomaly condition\" and \"fix condition\" is well established before that section. The only contribution I see in section 5 (i.e., the paper's approach) is \"Assumption 1\" and \"Multiple root causes explained using Shapley values\". \n\n4. \"Low variance of exogenous variables $\\epsilon_i$ is the most important assumption of this paper. It should have been reflected in the title, and the abstract. Furthermore, the variance of $\\epsilon_i$s are not mentioned for the experiments, thus not providing transparency if the experiments satisfied this assumption. \n\n5. No experiment is done for \"high variance\" of exogenous variable. Therefore a reader cannot get insights if counterfactual method is better for such cases (as opposed to IDI). Please conduct a study to compare IDI and counterfactual methods for a range of variances (of latent exogenous variable) -- clearly showing the boundary cases where counterfactual outperforms IDI. \n\n6. In table 2 and table 4, a lot of the recall values for the proposed IDI approach seems 1.00, which raises questions on the data itself. The authors must provide insight if the data is biased towards their methodology. Just mentioning IDI outperforms the baseline is not enough, since the results are too good to be true. Please do the following -- (1) provide details on the data generation process including the randomness in the graph generation, (2) do multiple replications of the study and report the standard deviation of the recall values. If the authors have a reason to believe that the dataset might be biased for their proposed approach, they must provide reasons and mention the experimental limitations explicitly. \n\n7. The authors must provide examples or case study to show that their assumption of low variance of latent exogenous variable is true. In page 2, authors mentioned that they are \"typically small in practice\" without any references, or examples. This is not acceptable for a technical publication. The authors are required to provide specific examples and/or case studies to support their claim of low variance of exogenous variables. The authors must also show how these claims are true in the experimental dataset (both synthetic and Petshop). \n\n8. The paper is too verbose. The authors repeat the two conditions (anomaly and fix) over and over again, in multiple sections without new content. I suggest the authors to reduce the length of the current version of the paper. Add a few explanations to weakness pointed out be me and other reviewers. The authors need to understand that SCMs and causality might be jargon for a lot of readers. They need to explain everything using simpler notions of either probability or graphs like Figure 1 or Figure 2. \n\n9. The paper's formatting is not acceptable. Page 5, Page 6 mentions theorem numbers are 5 and 6 and in supplementary they are written as theorems 10, 11 respectively. Similarly Theorem 6 is referring to Theorem 10, which is not a real thing in the main text of the paper. Similarly, in page 4, under \"training setup\", the symbol $D^{trn}$ is used which is not defined at all. The paper uses a lot of abbreviations and do not expand it. Some abbreviations like IDI are used even in abstract. These are incorrect formatting. I will assume the authors can make changes in rebuttal phase to these issues. \n\n10. In section 3.3., for \"1. Anomaly Condition\", the authors write \"prior methods....\". Without references, such statements must be avoided and in my honest opinion unacceptable for a technical manuscript. \n\n11. Remark on page 6 is not comprehensive. The authors must remove the \"CIRCA\" reference and explain only their method. Otherwise, it digresses from the context. \n\n12. The authors mentioned in page 7 that their work uses \"Z-score\". Please provide some preliminary knowledge on Z-score and highlight where is it used ?"
      },
      {
        "rating": "6",
        "confidence": "2",
        "summary": "This paper proposes an algorithm for diagnosing the root causes of anomalies in cloud-based systems. It addresses limitations in traditional counterfactual-based approaches by using in-distribution interventions on structural causal models to identify root causes with enhanced robustness and accuracy. By avoiding out-of-distribution issues common in counterfactuals, it achieves better performance in terms of robustness and root cause accuracy, as validated through experiments on synthetic and benchmark datasets.",
        "strengths": "- The paper provides a solid theoretical foundation for IDI, including error bounds and conditions where IDI surpasses counterfactual methods.\n\n- Experimental results consistently show that IDI outperforms baselines, highlighting its effectiveness and robustness in root cause diagnosis.",
        "weaknesses": "- The presentation is complex and may be challenging to follow, particularly in Section 3, due to the heavy use of notation. Adding examples to clarify key concepts would improve readability.\n\n- While IDI demonstrates strong performance on synthetic and benchmark datasets, further validation in diverse, real-world industrial systems would strengthen its practical applicability.\n\n- The focus is on accuracy, but runtime and latency evaluations are limited. A discussion of computational overhead and potential optimizations for large-scale deployment would increase its relevance."
      },
      {
        "rating": "8",
        "confidence": "3",
        "summary": "This paper introduces the In-Distribution Interventions (IDI) method to address the problem of RCD. The authors highlight two critical conditions in the RCD problem: the anomaly condition and the fix condition. The authors demonstrate that intervention-based approaches outperform counterfactual reasoning when tackling RCD problems, particularly by avoiding OOD errors commonly associated with counterfactual estimation. The proposed RCD algorithm uses an intervention-based approach to handle both conditions simultaneously. The evaluation results show the effectiveness of the IDI algorithm and its robustness in handling complex anomaly environments.",
        "strengths": "Strengths:\n- This paper proposes a novel in-distribution intervention algorithm to address the RCD problem, which simultaneously considers both the fix and anomaly conditions in RCD, demonstrating strong robustness in complex failure scenarios.\n- A well-supported theoretical proof. The authors demonstrate the advantages of the intervention method over counterfactual reasoning when dealing with OOD scenarios and apply this method to the fixed condition in the IDI method.\n- Based on the evaluation results, IDI demonstrates better performance and robustness than the existing baseline algorithms across different datasets.\n- Good reproducibility. The authors have open-sourced the code, data, and detailed instructions.",
        "weaknesses": "Weaknesses:\n- The OOD problem is not clearly presented. The OOD problem in RCD is an important motivation for the paper. However, I could not find a formal definition of OOD or in-distribution in RCD in the paper. The authors should provide a formal definition of OOD in the context of RCD early in the paper, e.g., in the introduction or background. Additionally, the authors should include an illustrative diagram contrasting OOD and in-distribution scenarios to help clarify this concept for readers.\n- More details about the construction of the SCM are necessary. In the paper, the authors directly apply an Oracle SCM rather than constructing it in an automated way, which is uncommon in existing RCD algorithms. The authors should carefully explain how the Oracle SCM was obtained and discuss whether this method can be generalized.\n- The description of CIRCA may have some minor issues. In CIRCA, the authors use the Descendant Adjustment technique to handle the anomaly scores of downstream nodes in the CBN from the root cause. Therefore, Descendant Adjustment can mitigate the issue with CIRCA, as mentioned in line 276 of the paper. The authors should describe this technique in the paper.\n- The authors need to provide a more precise overview of the IDI algorithm. Currently, the proof in Section 4 takes up too much space, while the description of the IDI algorithm in Section 5 needs to be more brief and mainly presented in text. The authors should include an overview figure in Section 5 to help readers understand the overall workflow of the IDI algorithm.\n- Lack of explanation of the Petshop dataset. In Table 1, the authors evaluate the results across three categories: Low, High, and Temporal. However, the paper needs to explain why these categories are separated for comparison or what observation in each category is meant to reflect. The authors should briefly explain these categories in the Petshop dataset, including why they are relevant to RCD and what insights they provide about the performance of different methods.\n- In Section 6.3, cases of Assumption 1 violations are evaluated. However, the paper does not explain the motivation for this evaluation or whether such violations occur in real-world scenarios. The authors should explain the real-world relevance of these violations and how common they might be in practice.\n- Lack of discussion on some existing counterfactual reasoning methods. Sage [1] proposed using CVAE to generate counterfactuals for RCD. The authors should discuss and compare this method in the paper.\n- Lack of case studies on IDI with OOD data. Although the experiments show promising results, the authors should at least present a case study where IDI is applied for RCD in an OOD scenario (e.g., step-by-step results of applying IDI to the OOD cases with intermediate outputs, a comparison of how IDI performs on OOD cases v.s. other methods) to validate its effectiveness on OOD data. \n- Shapley values are used for multiple root causes, possibly introducing high time complexity. The paper does not discuss the impact of this on scalability. The authors should discuss the computational complexity of their Shapley value approach and its implications for scalability in large-scale RCD scenarios, provide empirical runtime analysis, or discuss potential optimizations for improving efficiency.\n\n[1] Gan, Yu, Mingyu Liang, Sundar Dev, David Lo, and Christina Delimitrou. \"Sage: practical and scalable ML-driven performance debugging in microservices.\" In Proceedings of the 26th ACM International Conference on Architectural Support for Programming Languages and Operating Systems, pp. 135-151. 2021."
      }
    ],
    "rating_avg": 6.5,
    "confidence_avg": 2.5,
    "decision": "Accept (Poster)",
    "meta_review": "This paper addresses the challenge of diagnosing the root causes of anomalies in complex interconnected systems, such as cloud services and industrial operations. Traditional approaches rely on counterfactual estimates derived from Structural Causal Models (SCMs) trained on historical data to identify root causes. However, these counterfactual estimates are frequently unreliable since anomalies are rare and often out-of-distribution (OOD) events.\n\nTo overcome this limitation, the paper introduces In-Distribution Interventions (IDI), a novel algorithm designed to identify root causes based on two criteria: (1) Anomalous Condition – the root cause nodes must exhibit anomalous values, and (2) Fix Condition – had these nodes assumed normal values, the target node would not have been anomalous. Unlike traditional methods, IDI relies on interventional estimates obtained from SCMs probed only within the training distribution, avoiding OOD issues.\n\nTheoretical analysis demonstrates that IDI outperforms existing counterfactual-based methods, particularly when the variance of the underlying exogenous variables is low. Experimental evaluations on synthetic and real-world benchmark datasets, including the Petshop RCD dataset, show that IDI consistently identifies true root causes with greater accuracy and robustness compared to nine state-of-the-art baseline methods.\n\nBy leveraging in-distribution interventions, IDI improves the diagnosis of anomalies' root causes. It avoids the pitfalls of unreliable counterfactuals while maintaining high performance across various scenarios. This work provides a practical and effective solution to root cause diagnosis, particularly in complex systems where anomalies are rare and traditional methods fail.\n\nOverall, most reviewers comment positively about the content and contribution of the paper. I concur with the reviewers, and recommend this paper for publication.",
    "author_remarks": "",
    "decision_comment": ""
  },
  {
    "id": "VEdeDd13gx",
    "title": "ManiBox: Enhancing Spatial Grasping Generalization via Scalable Simulation Data Generation",
    "authors": [
      "Hengkai Tan",
      "Xuezhou Xu",
      "Chengyang Ying",
      "Xinyi Mao",
      "Songming Liu",
      "Xingxing Zhang",
      "Hang Su",
      "Jun Zhu"
    ],
    "abstract": "Learning a precise robotic grasping policy is crucial for embodied agents operating in complex real-world manipulation tasks. Despite significant advancements, most models still struggle with accurate spatial positioning of objects to be grasped. We first show that this spatial generalization challenge stems primarily from the extensive data requirements for adequate spatial understanding. However, collecting such data with real robots is prohibitively expensive, and relying on simulation data often leads to visual generalization gaps upon deployment. \nTo overcome these challenges, we then focus on state-based policy generalization and present ManiBox, a novel bounding-box-guided manipulation method built on a simulation-based teacher-student framework. The teacher policy efficiently generates scalable simulation data using bounding boxes, which are proven to uniquely determine the objects' spatial positions. The student policy then utilizes these low-dimensional spatial states to enable zero-shot transfer to real robots. \nThrough comprehensive evaluations in simulated and real-world environments, ManiBox demonstrates a marked improvement in spatial grasping generalization and adaptability to diverse objects and backgrounds.\nFurther, our empirical study into scaling laws for policy performance indicates that spatial volume generalization scales positively with data volume. For a certain level of spatial volume, the success rate of grasping empirically follows Michaelis-Menten kinetics relative to data volume, showing a saturation effect as data increases. Our data and code are available in the supplementary material.",
    "keywords": [
      "Robot Learning",
      "Reinforcement Learning",
      "Sim2Real",
      "Embodied AI"
    ],
    "venue": "ICLR",
    "year": 2025,
    "pdf_url": "https://openreview.net/pdf?id=VEdeDd13gx",
    "forum_url": "https://openreview.net/forum?id=VEdeDd13gx",
    "reviews": [
      {
        "rating": "6",
        "confidence": "4",
        "summary": "The authors tackle the challenge of spatial generalization and sim-2-real transfer of vision based control policies for robotic manipulation using a teacher-student reinforcement learning framework. The teacher policy, which is trained using privileged information about object location, etc.. is used to generate large scale robot trajectory data which is then used to distill a student policy which achieves sim-2-real transfer to real-world tasks. The authors also shed some light on the amount of robot trajectory data required for a given volume of reachable space of a robot.",
        "strengths": "The paper is well written and easy to read. Aside from a few details that I mention in the questions section, In my opinion the authors provide sufficient details about the experimental set up for an interested reader. The supplementary video provided also supports the paper well.\n\nThe challenge being addressed is very relevant to robotic manipulation and the results and methodology presented in the paper are interesting and compelling enough to inspire future research along similar lines.",
        "weaknesses": "1) Pseudo algorithm - In my opinion, the readability of the paper can be improved by including a pseudo algorithm that describes how the teacher is trained --> the criteria for selecting the successful robot trajectory from teacher policy --> The distillation process that generates the student policy could be very useful for a reader. \n2) The paper lacks a section on the weaknesses of the current approach. Even in the supplementary video, I dont recall a scenario where the policy fails. I think its important to know some of the failure cases of the method as well. \n3) Although this might be common knowledge among RL researchers - more information regarding the reward design could be helpful. Im assuming it involves getting close to the object and then closing fingers, however, this clearly depends on the distance to object and how fast the robot is moving - describing the reward mathematically would be a good addition to the paper."
      },
      {
        "rating": "8",
        "confidence": "4",
        "summary": "This paper presents a method called ManiBox to train generalizable (to 3D location and object) grasping policies in simulation and successfully transfer them to the real world. The method works by:\n1. First, a teacher policy is trained in simulation to grasp objects using Reinforcement Learning\n2. A student policy is trained in simulation that uses as observation bounding boxes of the target object from multiple camera streams\n3. Bounding boxes provide a low dimensional representation that transfers reasonably well between sim and real. Sim has privileged information so it's easy to get bounding boxes. In real, the YOLO world object detection module is used.\n\nUsing this method, the authors show successful sim-to-real transfer and generalization to different objects, backgrounds & 3D locations. The authors also present a study on scaling laws of success rate vs training dataset size.",
        "strengths": "1. Improvement over baseline in the given task of object grasping\n2. Insightful study on data scaling laws for robotic object grasping",
        "weaknesses": "1. Lemma 2 is a well known result in 3D computer vision. Hartley, R. and Zisserman, A., 2003. Multiple view geometry in computer vision. Cambridge university press.\n2. Limited comparison to baseline. Baseline scores are simply 0 even though there are numerous object-grasping methods (learning & heuristic based) that can grasp objects in different 3D locations."
      },
      {
        "rating": "6",
        "confidence": "3",
        "summary": "The paper introduces ManiBox, a framework for improving the generalization of robotic grasping through bounding-box-guided manipulation. Using a teacher-student policy setup, the teacher generates data in simulation, and the student learns to transfer this knowledge to real-world scenarios. Objects are represented with bounding boxes, aiming to reduce complexity and enhance generalization. A key finding is the scaling law that shows data requirements grow non-linearly with spatial volume. While the system demonstrates strong Sim2Real performance, some design choices and experimental setups leave room for clarification.",
        "strengths": "**Effective Sim2Real Transfer:**\n\nThe random masking strategy helps the system transfer successfully from simulation to real-world environments.\n\n**Background Generalization:**\n\nThe system maintains good performance across diverse backgrounds, which adds practical robustness.\n\n**Scaling Law Insight:**\n\nThe identified relationship between data volume and spatial generalization offers valuable guidance for data-driven models.",
        "weaknesses": "**Limited Object Diversity:**\n\nThe experiments use similar and simple objects, which limits the demonstration of the full generalization potential. A wider variety of objects might better highlight the benefits of the approach.\n\n**Unclear Bounding Box Usage:**\n\nThe relationship between bounding boxes for object detection and manipulation is not clearly explained. This makes it hard to understand how they work together effectively.\n\n\n**Fixed Cubic Space Constraint:**\n\nThe use of fixed cubic spaces (b x b x b) seems arbitrary. It’s unclear if more flexible bounding volumes could improve results.\nComplex Camera Setup:\n\nThe use of three cameras raises questions, as stereo vision with two cameras is often sufficient for localization. The necessity of the third camera is unclear.\n\n**Fragmented Descriptions of Settings:**\n\nThe simulation, real-world, and policy setups are described separately, making it difficult to compare them. A more structured comparison would improve clarity.\n\n\n**Lack of Vertical Variations:**\n\nThe experiments seem limited to flat surfaces. It’s unclear if the system can handle objects with more Z-axis variation or bounding boxes placed in mid-air.\n\n**Formula 4 Confusion:**\n\n\nEquation 4 lacks clear explanations of some symbols and their meanings, making it harder to follow."
      },
      {
        "rating": "3",
        "confidence": "3",
        "summary": "This paper introduces a manipulation method called ManiBox, which operates using bounding-box inputs. The policy is trained using a student-teacher framework. Specifically, a teacher policy is trained with PPO using privileged information, such as the object's 3D position. A dataset of expert trajectories is then generated from this teacher policy, which is subsequently used to train a student policy through imitation learning. Isaac Lab is employed as the simulator to facilitate scalable data collection. The authors demonstrate that as the workspace size increases, a larger amount of expert data is required to train effective student policies. Finally, the trained student policies can be deployed on a real robot by using bounding boxes generated from an open-vocabulary object detection model.",
        "strengths": "**General Idea**\n-  Leveraging vision-foundation models to train policies that can be deployed on real robots is an interesting and relevant approach for addressing many real-world manipulation tasks.\n\n**Real-robot Deployment** \n- The proposed method is tested on a real robot, verifying that the inputs from the open-vocabulary detection model can be used to transfer the learned behaviors.\n\n**Visual Presentation**\n- The overview figures, particularly Figure 2, effectively clarify the proposed model.",
        "weaknesses": "**Low Novelty**\n- The paper does not introduce a novel method, but rather employs a specific student-teacher learning formulation, using bounding boxes in the student's input space. Additionally, the finding that the amount of expert data required to train a proficient student policy scales with the robot's workspace size is unsurprising.\n- The method trains on a single object (with randomization in its scale) using a parallel gripper in an uncluttered tabletop scenario, which is a very simple task configuration that has been addressed without the need for interactive RL policies (see e.g. https://inria.hal.science/inria-00325794/document)\n\n**Method Limitations**\n- Representing objects through 2D bounding boxes provides only a rough approximation of an object’s convex hull, which is likely insufficient for generalizing to objects with diverse shapes.\n- The method currently relies on multiple camera observations. Inferring object states from a single RGB-D camera or using the history of wrist-camera observations from different poses would make the approach easier to deploy.\n\n**Results and Research Claims**\n- The Abstract claims that the paper will demonstrate that most models’ spatial generalization challenges stem from high data requirements for spatial understanding. However, this is not substantiated, as dataset size is the only variable that is investigated in the experiments. Moreover, reformulating the problem from joint-space actions and observations to end-effector control, with object position relative to the robot's gripper, could reduce variability that is unnecessary for task completion.\n- Object generalization is evaluated by testing on items different from those encountered by the teacher policy. It is mentioned that two objects are out of distribution, yet since the teacher policy training does not cover these objects, there is no reason to expect it to generalize to this configuration. Furthermore, details on how this experiment was conducted—such as the number of trials and object positions—are missing. While it is possible to learn a grasping strategy that is sufficiently general to cover the tested items, this is not a feature of the method since the teacher policy is never incentivized to do so.\n- In the Background Generalization results section, the model's generalization ability is attributed to its integration of historical information, multi-camera data, and random masking, but none of these claims are verified."
      }
    ],
    "rating_avg": 5.75,
    "confidence_avg": 3.5,
    "decision": "Reject",
    "meta_review": "The paper presents an approach for robotic grasping through simulation to real training. This a borderline paper with diverging reviews and significant amounts of discussion through the rebuttal and post-rebuttal phase. Hence I have taken a closer look at the paper, the reviews, the author responses, and post-rebuttal discussion. To summarize, the idea of distillation-based sim2real is an interesting idea. The motivation of using such ideas instead of pure imitation learning is quite clear. On the negative side, the major concern is the limited contribution towards novelty and applicability. On the novelty side, the idea of sim2real for grasping and the use of distillation based models for locomotion are quite standard in literature (e.g. DexNet, AnyGrasp). On the applicability side, it is unclear if the produced grasping policies are general enough for diverse real world tasks. For example, recent works like OK-Robot show that grasping in itself can achieve fairly high success rates in real world environments. I hence tend to agree with reviewer rbGJ that the weaknesses of this work outweigh its strengths. Having real world experiments on complex objects in complex real-world scenes would substantially improve the impact of this work in my opinion.",
    "author_remarks": "",
    "decision_comment": ""
  },
  {
    "id": "rxUz2DaulF",
    "title": "Q* Agent: Optimizing Language Agents with Q-Guided Exploration",
    "authors": [
      "Zongyu Lin",
      "Yao Tang",
      "Da Yin",
      "Stuart X. Yao",
      "Ziniu Hu",
      "Yizhou Sun",
      "Kai-Wei Chang"
    ],
    "abstract": "Language agents have become a promising solution to complex interactive tasks. One of the key ingredients to the success of language agents is the reward model on the trajectory of the agentic workflow, which provides valuable guidance during training or inference. However, due to the lack of annotations of intermediate interactions, most existing works use an outcome reward model to optimize policies across entire trajectories. This may lead to sub-optimal policies and hinder the overall performance. To address this, we propose Q\\*Agent, leveraging an estimated Q value to generate intermediate annotations for open language agents. \nBy introducing a reasoning tree and performing process reward modeling, Q\\*Agent provides effective intermediate guidance for each step. This guidance aims to automatically annotate data in a step-wise manner.\nBesides, we propose a Q-guided generation strategy that can significantly boost model performance by providing process guidance during inference.\nNotably, even with almost half the annotated data, Q\\*Agent retains strong performance, demonstrating its efficiency in handling limited supervision. We also empirically demonstrate that Q\\*Agent can lead to more accurate decision making through qualitative analysis.",
    "keywords": [
      "agent",
      "large language model",
      "q-learning",
      "self-training"
    ],
    "venue": "ICLR",
    "year": 2025,
    "pdf_url": "https://openreview.net/pdf?id=rxUz2DaulF",
    "forum_url": "https://openreview.net/forum?id=rxUz2DaulF",
    "reviews": [
      {
        "rating": "5",
        "confidence": "2",
        "summary": "This paper proposes a method to train a language agent, enabling it to handle complex tasks. To this end, the authors initialize the language agent via performing behavioral cloning on the collection of expert trajectories. Then, the authors utilize the supervised fine-tuned agent to explore the environment and collect trajectories. Using the collected trajectories, QNet is trained via Q-learning. Finally, Q-guided exploration is used to inference, and the Q\\*Agent is trained using SFT dataset and Q-guided trajectories. Based on this training steps, Q\\*Agent achieves state-of-the-art performance.",
        "strengths": "The authors propose a method to train a language agent that achieves state-of-the-art performance.",
        "weaknesses": "I have some questions about this work, which are mentioned in the Questions section below."
      },
      {
        "rating": "5",
        "confidence": "4",
        "summary": "The paper introduces Q*Agent, a novel approach of building language agents through learning a Q function and use it to select action. Experimental results on the WebShop benchmark show that QAgent achieves strong performance and efficiency gains compared to baseline methods.",
        "strengths": "1. This paper introduced learning a Q function, which provides step-wise feedback instead of outcome-based rewards for the language agents. \n2. It proposed two ways of leveraging Q functions, one for selecting actions in inference and one for filtering data in training/finetuning.",
        "weaknesses": "1. The experimental study is limited on one domain. It is unclear how effective the proposed method on other types of agent task, or even on other types of websites. \n\n2. The experimental study lacks discussion about related work. For inference-time self-improvement, the experiment only compared the proposed method with best-of-N and ignores a large body of related work on language agent. I think the following work need to be discussed and compared with the proposed method.\n - Some fundamental work on self-improvement on language agent, for example the Reflexion and LATS methods.\n - Some work use a trained model (not per-step) to provide feedback for self-improvement at the inference time. E.g. \"Autonomous Evaluation and Refinement of Digital Agents Jiayi Pan, Yichi Zhang, Nicholas Tomlin, Yifei Zhou, Sergey Levine, Alane Suhr\"\n - Some work use per-step feedback in self-improvement, without finetuning a separate Q functions, in language agent tasks. E.g. \"Tree Search for Language Model Agents Jing Yu Koh, Stephen McAleer, Daniel Fried, Ruslan Salakhutdinov\"\n\nWhen compare with methods without finetuning a new model, the paper also needs to justify the cost of finetuning additional model.\n\n3. It seems the base approach in the experimental study include common prompting methods such as CoT, few-shot, ReAct etc. It is unclear if the benefit of the proposed method is orthogonal, or covered by these basic prompting approaches for language agent."
      },
      {
        "rating": "3",
        "confidence": "5",
        "summary": "This paper study a critical problem in agent scenarios: the absence of process rewards for each intermediate step. The authors propose an approach that involves three main steps: 1. collecting a large number of interaction trajectories by constructing a reasoning tree; 2. using Bellman's equation to estimate the expected Q of each step; and 3. training a QNet to estimate the process reward Q values for states and actions. The experiments validate the effectiveness of QNet in providing intermediate step rewards during both training and reasoning, demonstrating its ability to offer process-based guidance and improve agent performance compared to trajectory-based rewards.",
        "strengths": "This paper is well-motivated. The lack of process rewards is a significant challenge in agent tasks. The proposed method reduces the costs associated with obtaining high-quality data annotations.\n\nConsidering training step-level verifiers is demonstrated to be effective in LLM reasoning tasks, applying the approach to agent tasks is of great significance.",
        "weaknesses": "The paper is poorly written, lacking many essential explanations and details. For example, in Section 4.4, the authors state, \"we also introduce augmenting action diversity with perturbation during this stage, which is realized by prompting LLM to paraphrase the task description,\" yet they do not provide any discussion on prompt implementation or examples of action diversity. The termination condition for the tree construction process is not clarified, and several definitions, such as $C_t$ in Equation (4), are missing.\nThe experimental setup also deeds further clarification. Some critical hyper-parameters, such as the discount factor $\\gamma$ for extracting Q-values is not listed. The metrics for performance in Table 1 are not explained. The sampling number per step of Q* Agent-I is not provided. \nFor visualization, the horizontal axis in Fig. 3(a) should indicate the number of sampled actions. Additionally, Fig. 3(b) lacks a label for the ordinate. \nOverall, there are too many issues with the paper to list them all here.\n\nThe versatility of the method needs to be verified in more agent tasks.\n\nEquation (3) is not the cross-entropy loss.\n\nLine 415: Table 2 is not organized into three sections."
      },
      {
        "rating": "6",
        "confidence": "3",
        "summary": "The authors propose an LLM agent algorithm based on Q-value-guided training and inference-time decision-making to tackle complex interactive (decision-making) tasks. The primary motivation is to provide more efficient feedback to the agent through step-wise rewards. By integrating the LLM agent within an MCTS-like framework, the approach optimizes the LLM agent, addressing the issue of sparse rewards that arise from solely using trajectory rewards in existing algorithms.",
        "strengths": "The main contribution of this paper lies in its ability to construct step-wise rewards for each step using an MCTS-like approach, based solely on the final reward. These rewards are then used to train a Q-value network to support decision-making at inference time.\nIn the overall algorithm design, after conducting SFT, the authors make a few adjustments to the MCTS. They utilize a “tree pruning” approach to reduce the search space and train a Q-value network based on calculated Q-values. This allows the Q-value network to guide the agent's decision-making at inference time by selecting actions that maximize the Q-value.",
        "weaknesses": "+ **Algorithm Framework**: The core framework of this paper is derived from the MCTS, yet the authors did not evaluate or compare its relationship to MCTS.\n  + **Known Environment Assumption**: Unlike tasks such as mathematical reasoning, the interactive tasks in this paper require constructing a reasoning tree using the environment to achieve state transitions (i.e., generating the next state based on the current state and action). However, the authors did not discuss this assumption.\n  + **Tree Pruning**: The main improvement of this work over MCTS lies in tree pruning, considering the vast action space for LLM as a generative model. If a simulation fails to get a positive reward, Q* Agent discards the node that attempted to expand. This approach essentially explores a few trajectories that can reach the final goal within an enormous decision space and then performs Q-value extraction. However, for complex tasks that may require dozens of steps to reach the final goal (getting a positive final reward), the probability of finding a successful trajectory is exceedingly low, severely limiting the algorithm's applicability. The authors even restrict expansion to only the first three to five steps, making the algorithm suitable only for tasks requiring exploration at the very beginning of each episode.\n  + **Task-specific Q-value Network**: This method requires training a task-specific Q-value network for each task and using the corresponding network during decision-making, limiting the algorithm's generalization capability, which is a core advantage of LLMs (otherwise, a task-specific agent could be directly trained with RL). Using RL to train the LLM with this Q-function could mitigate this issue.\n  + **MDP Design**: The state definition includes the entire interaction history. When the interaction sequence becomes lengthy, this introduces a large number of tokens, further constraining the algorithm's performance on complex tasks.\n+ **Experimental Results**: Experimentally, the authors only compares the proposed method with some simple baselines on the WebShop benchmark. While it achieves some performance improvement, the improvement is relatively small. Other experimental results do support the effectiveness of the proposed Q-guided decision-making. However, no ablation studies were conducted on techniques like tree pruning, making the experiments insufficiently comprehensive.\n  + **Experimental Setup**: Only WebShop is selected as the experimental platform, limiting the results' credibility. The authors also do not show variance or the number of test episodes, making it difficult to assess the impact of randomness on the results, especially given the small performance improvement.\n  + **Limited Experimental Content**: It is recommended that the authors conduct ablation studies on techniques in the tree construction phase, particularly on stop expansion and the \"early stage\" length in tree pruning."
      }
    ],
    "rating_avg": 4.75,
    "confidence_avg": 3.5,
    "decision": "Reject",
    "meta_review": "This paper develops a procedure that collects trajectories from a chatbot-like agent to construct a reasoning tree, builds a value function to estimate the utility of each action in this tree, and uses this procedure for Q-function guided generation/action selection on web-navigation tasks. The discourse with the reviewers revolved around clarifying questions about the approach, relationship to recent/concurrent on these problems that is rather similar, and the effectiveness of learning a value function for web navigation tasks where the action space is very large.\n\nAlthough some of these concerns are alleviated after the author responses, the key ones are not, e.g., the incremental nature of these ideas in light of existing work on this topic (Reflexion, ETO etc.), limited improvements on benchmark problems. It would also be useful to demonstrate more thorough experimental evidence of the utility of this approach, e.g., how does this approach quantitatively address the fact that there are a lot of actions to choose from while fitting, or using the value function? For these reasons, I do not recommend that this paper is accepted.",
    "author_remarks": "",
    "decision_comment": ""
  },
  {
    "id": "BBldjKEBlJ",
    "title": "QuantFormer: Learning to quantize for neural activity forecasting in mouse visual cortex",
    "authors": [
      "Salvatore Calcagno",
      "Isaak Kavasidis",
      "Simone Palazzo",
      "Brondi Marco",
      "Luca Sità",
      "Giacomo Turri",
      "Daniela Giordano",
      "Vladimir R Kostic",
      "Tommaso Fellin",
      "Massimiliano Pontil",
      "Concetto Spampinato"
    ],
    "abstract": "Understanding complex animal behaviors hinges on deciphering the intricate neural activities within specific brain circuits. Two-photon imaging emerges as a powerful tool, offering significant insights into the dynamics of neuronal ensembles. In this context, forecasting neural activities is crucial for neuroscientists to create mathematical models of brain dynamics. Existing transformer-based methods, while effective in many domains, struggle to capture the distinctiveness of neural signals characterized by spatiotemporal sparsity and intricate dependencies.\nThis paper introduces *QuantFormer*, a novel transformer-based model designed for forecasting neural activity in two-photon calcium imaging data. Unlike traditional regression-based approaches, *QuantFormer* reframes the forecasting task as a classification problem through dynamic signal quantization, enabling better learning of sparse activity patterns. Additionally, *QuantFormer* addresses the challenge of analyzing multivariate signals with an arbitrary number of neurons by using specialized neuron prompts. \nLeveraging unsupervised quantization training  on the Allen dataset, the largest publicly available dataset of two-photon calcium imaging, *QuantFormer* establishes a new benchmark in mouse neural forecasting. It provides robustness and generalization across individuals and stimuli variations, thus defining the route towards a robust foundation model of the mouse visual cortex.",
    "keywords": [
      "Neural Circuit Dynamics",
      "Neural Activity Forecasting",
      "Vector Quantization"
    ],
    "venue": "ICLR",
    "year": 2025,
    "pdf_url": "https://openreview.net/pdf?id=BBldjKEBlJ",
    "forum_url": "https://openreview.net/forum?id=BBldjKEBlJ",
    "reviews": [
      {
        "rating": "3",
        "confidence": "3",
        "summary": "This paper introduces a large-scale model pretrained on the Allen corpus, which includes calcium imaging spiking activity from the mouse visual cortex under various stimulus conditions. It presents a transformer that uses vector quantization to create a set of neural codebooks for forecasting spiking activity. This quantization approach was shown to be effective in neural activity prediction, outperforming other baseline time series forecasting models. Additionally, the paper demonstrates positive scaling results across different stimuli and individual subjects.",
        "strengths": "This paper attempts to tackle an important problem of building \"foundation models\" for neuroscience that can predict spiking activity and classify responses to stimuli.",
        "weaknesses": "1. While vector quantization has not previously been used to build neuroscience foundation models, the author did not provide sufficient justification for choosing this specific model architecture.\n2. The paper proposes only two types of downstream tasks for evaluating the foundation model. A more comprehensive evaluation is needed to assess the model's generalizability across diverse downstream tasks.\n3. The paper lacks a scaling analysis to evaluate how effective the proposed backbone is for developing a foundation model.\n4. The foundation model backbone could benefit from more rigorous benchmarking against existing methods on self-supervised prediction of spiking activity."
      },
      {
        "rating": "3",
        "confidence": "4",
        "summary": "The paper proposes a transformer-based architecture for single-neuron response forecasting. In a first step, the authors use autoencoding to pre-train an encoder or neuronal response sequences. In a second step, they fine-tune the encoder on an activity classification and a response forecasting task. They evaluate their model using visually evoked responses in the visual cortex of mice. Compared to a few forecasting models they achieve improved activity classification and response forecasting metrics.",
        "strengths": "- Novel architecture and interesting idea in principle\n- Paper is well written and easy to follow\n- Shows some ablation experiments to tease apart which components are important",
        "weaknesses": "- Doing response forecasting on visually evoked responses seems like an odd choice\n- Unclear how strong the baselines are \n- Simple baselines like PSTH or linear encoding models are missing"
      },
      {
        "rating": "3",
        "confidence": "4",
        "summary": "This paper introduces QuantFormer, a novel transformer-based model designed to forecast neural activity in mouse visual cortex using two-photon calcium imaging data. The authors reframe neural forecasting as a classification problem through vector quantization, and employ neuron-specific tokens to identify single neurons. The approach uses a two-stage training process combining pre-training through masked auto-encoding with downstream training for neural activity classification and forecasting. The network is trained on raw fluorescence traces from the Allen dataset traces rather than spike data or deconvoled fluorescence data.",
        "strengths": "- Very paper is well written. Previous literature and related work is mostly addressed, although a few citations might be missing.\n- The main novelty seems to be the quantization stage that can predict the activity of neurons as a function of 32 codebook vectors.",
        "weaknesses": "- A closer examination of QuantFormer's architecture raises important questions about its broader applicability and evaluation methodology. The encoder-quantizer-decoder architecture, while novel, relies on a relatively small codebook of 32 entries to represent all possible neuronal activity patterns. Since the codebook and decoder remain frozen after pre-training (as far as I understand), this potentially limits the model's ability to represent novel activity patterns not seen during pre-training. This yields a model that is strictly not image computable and has therefore less abilities than a simple CNN model based on images (which could be trained to forecast as well). This is a major limitation of the model that is not properly discussed.\n- As a direct result from using a finite set of stimuli, also the training and test protocol raises questions. As far as I understand, the pre-training phase includes data from the same neurons and images that appear in the test set, which may allow the model to learn specific response patterns before the actual testing phase. Because the Allen datasets includes repetitions of stimuli, this could be a major confounder for the results as the model can simply learn the mean responses given the the stimulus. The authors describe that they do not use neuron identities for pretraining. However, I (a) find this a questionable choice because this should severely limit the prediction capabilities of the model (what’s common to all neurons in cortex?) and (b) I am still not convinced that this would avoid the problem that the model learns mean responses of neurons.\n- Because of that, I find the contributions overstated:\n    - Forecasting for optogenetic manipulations is mentioned I could not find any experiment on that.\n    - Forecasting has been addressed by other transformer architecture, for instance the “universal translator” by Zhang et al (see below), which is not cited or compared to as far as I can see.\n    - Reframing forecasting of time series as a classification problem is per-se not a contribution if it doesn’t solve problems. As argued above, it seems to create problems.\n    - Handling arbitrary neuronal populations is not new as other works (such as the POYO model) already use neuron ID tokens.\n    - Finally, I would hardly call a model that is trained to forecast neurons from a finite set of stimuli a “foundation model for visual cortex”. In particular, I would expect a foundation model to be image/video computable.\n- I find the choice of dataset not well motivated. The authors argue with real-time applicability. But then they don’t test it in those conditions. So in that sense they could apply it to a bigger dataset such as SENSORIUM 2022 (if they still want to exclude videos). My guess is that the method will not work well as it contains many unique stimuli in the training set. In particular, the choice of dataset is at odds with the motivation for the codebook (sparsity). I would expect fluorescence data to be less sparse than deconvolved data (such as Sensorium). It that sense SENSORIUM or spiking data should be even better data. Finally, I do not understand how they can get baseline activity for neurons in the Allen data. As far as I remember about the dataset, images are presented back to back. This means that neuronal firing does not return to baseline between images. I do not see how this is addressed in the paper.\n- I find the choice of models to compare to a bit weak. I would recommend to include at least an oracle estimator that uses the mean responses of the neuron to that stimulus in the training set. Additionally, my guess is that a model pretrained properly on SENSORIUM and then trained to forecast a fixed number of steps in the future, should be competitive.\n- Why is neuronal identity and the stimulus ignored during pretraining? I do not understand the rationale for it. Why is it not trained on forecasting with neuronal activities since this seems to generate problems (as discussed in 3.4.2)\n- I find motivation for the classification into active and non-active not clear. It somehow assigns a special role of 10% more activity, which seems arbitrary. It also raises a question how the baseline is computed if the images are shown back to back (see above).\n- I do not find the evaluation metrics very clear. How are correlations computed (across what and are correlations averaged over).\n- In the appendix, the authors show a table with forecasting of unnormalized responses. The scores there are much lower. I do not find the explanations of the authors very clear here. I think this raises a question whether the normalization scheme somehow favors some models. Maybe a visual comparison of of normalized vs. non-normalized responses would help. Or a more detailed motivation for why normalization by the accumulated gradient helps. Also, I do not find this very clear (What gradient? Accumulated over what? Isn’t an accumulated gradient equal to the original signal up to a constant?).\n\n**Minor weaknesses (I assume you will handle those, no need to respond to them):**\n\n- `citep` and `citet` not consistently used. Please double check to use `citet` for inline citations and `citep` else.\n- I would not call deconvolved calcium signals “spiking activity”. For instance, Turishcheva et al. does not use spikes, but deconvolved Ca++ activity.\n- Possibly additional work to cite for forecasting\n    - Zhang, Y., Wang, Y., Jimenez-Beneto, D., Wang, Z., Azabou, M., Richards, B., Winter, O., International Brain Laboratory, Dyer, E., Paninski, L., & Hurwitz, C. (2024). Towards a “universal translator” for neural dynamics at single-cell, single-spike resolution. In arXiv [q-bio.NC]. arXiv. Retrieved from http://arxiv.org/abs/2407.14668\n    - Schmidt, F., Shrinivasan, S., Turishcheva, P., & Sinz, F. H. (2024). Modeling dynamic neural activity by combining naturalistic video stimuli and stimulus-independent latent factors. In arXiv [q-bio.NC]. arXiv. Retrieved from http://arxiv.org/abs/2410.16136\n- Possibly interesting work to cite for neuronal quantization\n    - Wei, X.-X., Zhou, D., Grosmark, A., Ajabi, Z., Sparks, F., Zhou, P., Brandon, M., Losonczy, A., & Paninski, L. (2019). A zero-inflated gamma model for post-deconvolved calcium imaging traces.\n- Wrong reference for SENSORIUM. The correct ones are (alternatively use the Retrospective papers from NeurIPS 2023 or NeurIPS 2024)\n    - Turishcheva, P., Fahey, P. G., Hansel, L., Froebe, R., Ponder, K., Vystrčilová, M., Willeke, K. F., Bashiri, M., Wang, E., Ding, Z., Tolias, A. S., Sinz, F. H., & Ecker, A. S. (2023). The Dynamic Sensorium competition for predicting large-scale mouse visual cortex activity from videos. In arXiv [q-bio.NC]. arXiv. Retrieved from http://arxiv.org/abs/2305.19654\n    - Willeke, K. F., Fahey, P. G., Bashiri, M., Pede, L., Burg, M. F., Blessing, C., Cadena, S. A., Ding, Z., Lurz, K.-K., Ponder, K., Muhammad, T., Patel, S. S., Ecker, A. S., Tolias, A. S., & Sinz, F. H. (2022). The Sensorium competition on predicting large-scale mouse primary visual cortex activity. In arXiv [q-bio.NC]. arXiv. Retrieved from http://arxiv.org/abs/2206.08666"
      },
      {
        "rating": "3",
        "confidence": "4",
        "summary": "The paper suggests to use a transformer to forecast neuronal activity with a focus on mice 2 photon imaged neurons. To tackle the sparse responses, the authors suggest to add quantization and classification loss derived from the quantization. They also try to tackle generalization issue and interpret their learnt neuron tokens.",
        "strengths": "Relatively original but not very clear paper, with interesting results.\nI specifically liked\n* A novel technical approach and an interesting idea with quantization, which seems to improve the results.\n* The qualitative analysis of cross-former in comparison with Quant-Former (A6-A7)\n* The authors made the first steps towards model interpretability, mainly in appendix, which is important for biological research.\n* I appreciate attaching the code, this is a huge plus for reproducability",
        "weaknesses": "* Incomplete literature review and missing baselines\n   * The Zhang et al 2024 work is not mentioned (https://arxiv.org/pdf/2407.14668 ) This work does neuron based forecasting but on neuropixels data.\n   * The older works for neuronal forecasting, such as Zhu et al 2022 (https://www.nature.com/articles/s41593-022-01189-0) or Ye & Pandarinath 2021(https://arxiv.org/abs/2108.01210)  are not mentioned and also not used for baselines (Zhu et al 2022 is for calcium data). \n\nWhile this models do not have stimuli tokens, one of them could still be a competitive baseline. I would also be interested to see the ablation showing the importance of the stimuli tokens for QuantFormer (is it about specific stimuli or stimuli type? )\n\n* Incorrect statement about other works and incorrect citations \n   * line 185  `SENSORIUM (Wang et al., 2023))`. Wang et al., 2023 does not use data from either Sensorium 2022 or 2023 competitions. It also barely discuss the competition\n   * moreover, both SENSORIUM 2022 and 2023 provide spike traces data\n   * For example, lines 176-177 *all the encoding and decoding methods discussed above rely on spiking data*, while in the mentioned works, Wang et al., 2023 (cited incorrectly though), Sinz et al 2019, Antoniades et al 2023, Turishcheva et al 2024 a/b all use calcium traces. \n   * Same for lines 90-91, both Turishcheva et al 2024 a, and Microns (https://www.microns-explorer.org/cortical-mm3) provide open access to extensive datasets with calcium traces, not spikes.\n   * Lines 144-147 *Approaches such as Turishcheva et al. (2024a;b); Li et al. (2023); Xu et al. (2023a); Sinz et al. predict neural responses based on stimuli, but often rely on trial-averaged data and are not designed to forecast future neural activity on a single-trial basis without the use of synchronous behaviour variables, which are not accessible in online settings.* While, indeed these approaches do not do neuronal forecasting, at least three out of four mentioned papers do not rely on either repeats or behaviour for responses prediction, only on the visual stimuli. Adding behaviour indeed improves performance, while repeats are used only during evaluations. \n   * Mentioned  Antoniades et al 2023 work could be used for neuronal forecasting as well \n\n* The biological validity of the paper is not clear\n    * For table 2 it is not clear what are the upper/lower bounds for the metrics, which makes it hard to interpret how good all of the models generally are, as the correlation upper bound could not be one due to significant noise in the biological data. I would inspire the authors to use repeated stimuli within the session and follow Wang et al., 2023 to estimate at least the correlation upper bound.\n    * It is also not clear, if the model is actually able to reproduce linear-nonlinear phenomenas, which the neurons should be able to do (like here https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1009028 )\n\n* The writing clarity could be improved. \n   * For example,  in section `4.1 DATASET` it would be nice to explicitly write the amount of unique neurons. If the neurons across sessions for the same mice did not repeated, then its 11*3*250 $\\approx$ 8500. If I understood the appendix correctly, there were 250 neurons per session on average. If these were exactly same neurons across sessions, it's 11*250 $\\approx$ 3000. This makes very different impression compared to the 230 000 traces, which might be understood on neurons.\n   * Generalization experiment is not explained (see questions)"
      }
    ],
    "rating_avg": 3.0,
    "confidence_avg": 3.75,
    "decision": "N/A",
    "meta_review": "",
    "author_remarks": "",
    "decision_comment": ""
  },
  {
    "id": "dQpZolwXiH",
    "title": "Intrinsic Explainability of Multimodal Learning for Crop Yield Prediction",
    "authors": [
      "Hiba Najjar",
      "Deepak Pathak",
      "Marlon Nuske",
      "Andreas Dengel"
    ],
    "abstract": "Multimodal learning enables various machine learning tasks to benefit from diverse data sources, effectively mimicking the interplay of different factors in real life events. While the heterogeneous nature of these modalities may necessitate the design of complex architectures, their interpretability is often overlooked. In this study, we leverage the intrinsic explainability of Transformer-based models to explain multimodal learning frameworks. We utilize the self-attention mechanism alongside model-specific feature attribution techniques, comparing these against post-hoc methods. Our detailed analysis focuses on the challenging task of crop yield prediction, exploiting the characteristics of the modalities and the data to aggregate local explanations at multiple levels. Our findings indicate that Transformers significantly outperform other architectures in yield prediction, making them well-suited for further intrinsic interpretability analysis. Among the modalities, satellite data emerged as the most influential but requires deeper layers for effective feature extraction due to its complex structure. Additionally, we observed that the Attention Rollout method is more robust than Generic Attention, aligns more closely with Shapley-based attributions and shows reduced sensitivity to minor input variations.",
    "keywords": [
      "intrinsic interpretability",
      "explainable AI",
      "multimodal learning",
      "Transformers",
      "shapley values",
      "crop yield prediction",
      "remote sensing"
    ],
    "venue": "ICLR",
    "year": 2025,
    "pdf_url": "https://openreview.net/pdf?id=dQpZolwXiH",
    "forum_url": "https://openreview.net/forum?id=dQpZolwXiH",
    "reviews": [
      {
        "rating": "3",
        "confidence": "3",
        "summary": "This paper focuses on developing a model for crop yield prediction by exploring various model architectures and feature engineering to effectively create and merge feature representations from multiple modalities. The authors also experiment with different explainability techniques to analyze patterns between the model's internal representations and its predictions, specifically examining how these relate to the nature of each data modality.",
        "strengths": "The model development and analysis are thorough.",
        "weaknesses": "The paper lacks a clear novel contribution, as it primarily involves constructing a model for crop prediction and testing different model architectures and feature engineering methods. The authors identify a transformer-based architecture as the best-performing model and use various XAI methods, such as linear probes across layers and attention weights attribution, to investigate the relationship between internal representations and predictions based on data modality.\n\nThe experiments appear somewhat disjointed, with individual assumptions tested in isolation rather than in service of a coherent, high-level research question. Since the paper centres on explainability, it would be valuable to provide clear takeaways from these analyses, mainly to guide model builders, decision-makers, and practitioners in understanding the practical implications of the findings.\n\nOverall, while the paper is sound, its contribution feels limited. It may be better suited for a more specialized venue focused on applied machine learning or exploratory studies rather than the conference's main track."
      },
      {
        "rating": "3",
        "confidence": "4",
        "summary": "This research paper explores intrinsic explainability techniques for multimodal learning, specifically focusing on crop yield prediction. The authors employ Transformer-based architectures to integrate diverse data sources, including satellite imagery, weather information, soil characteristics, and terrain data. The study evaluates various neural network designs, such as 1D-CNN, LSTM, ALSTM, and Transformer models. To interpret the model's decision-making process, the authors analyze learned representations across layers using linear probes, examine attention weight distributions within fields and across layers, and compare intrinsic attribution methods like Attention Rollout and Generic Attention with post-hoc techniques such as Shapley Values. The findings reveal that Transformer-based models not only excel in performance but also offer inherent interpretability benefits without sacrificing accuracy.",
        "strengths": "* This research paper presents a comprehensive analysis of a wide range of analytical approaches through a detailed ablation studies to compare various model architectures. Further, layer-wise analysis using linear probes provides insights into the evolution of learned representations across the model's depth.  Finally, exploration of attention weight distributions and comparison across multiple attribution methods is done.\n* Evaluation on real-world data for three different crops results in direct applications in agriculture and remote sensing demonstrating that interpretability doesn't compromise performance.",
        "weaknesses": "* Choice of baseline models can be improved. For example, ConvLSTM [1], STATT [2], 3D-CNN [3] seems more suitable for satellite image time-series data.\n* The focus on a dataset from Argentina raises questions about generalizability to other regions and crop types. Including experiments on datasets from various geographic regions would strengthen the model's applicability and reliability.\n* It would be better if the interpretability results are accompanied with hypothesis/explanations derived from the domain knowledge (field/agronomic knowledge). For example, the modality impact scores does not match with agronomic significance, which makes it difficult to trust the internal mechanisms of the model.\n* The temporal layer-wise attention are hard to interpret, where there doesn’t seem to be any correspondence with growing/harvesting season of the studies crops. The authors did a commendable job of dissecting the modern deep learning architectures, however the results does not seem to provide any meaningful insights.\n\nReferences:\n\n[1] Shi, Xingjian, Zhourong Chen, Hao Wang, Dit-Yan Yeung, Wai-Kin Wong, and Wang-chun Woo. \"Convolutional LSTM network: A machine learning approach for precipitation nowcasting.\" Advances in neural information processing systems 28 (2015).\n\n[2] Ghosh, Rahul, Praveen Ravirathinam, Xiaowei Jia, Chenxi Lin, Zhenong Jin, and Vipin Kumar. \"Attention-augmented spatio-temporal segmentation for land cover mapping.\" In 2021 IEEE International Conference on Big Data (Big Data), pp. 1399-1408. IEEE, 2021.\n\n[3] Ji, Shunping, Chi Zhang, Anjian Xu, Yun Shi, and Yulin Duan. \"3D convolutional neural networks for crop classification with multi-temporal remote sensing images.\" Remote Sensing 10, no. 1 (2018): 75."
      },
      {
        "rating": "3",
        "confidence": "3",
        "summary": "This paper addressed a crop yield prediction task in a multi-modal learning setting using multiple types of data such as satellite images and weather information.\nIn some prediction models, the paper showed that a transformer-based model achieved better predictive accuracy. \nTo understand the behaviors of the transformer model, it attempted to apply various existing explanation methods to the model.",
        "strengths": "- In the literature on crop yield prediction, efforts related to the explainability of this research may be novel.\n- Comparative experiments and analyses have been conducted extensively.",
        "weaknesses": "- The importance of the crop yield prediction task is not adequately stated. Therefore, the usefulness and impact of the analysis results are not conveyed.\n- The technical contributions of this research are unclear. Although the data may be unique, the prediction model and explanation methods used are existing techniques and appear to be merely applied to crop yield prediction."
      },
      {
        "rating": "3",
        "confidence": "4",
        "summary": "The paper introduces a framework based on Transformer models for crop yield prediction, emphasizing multimodal learning by integrating diverse data sources (e.g., satellite imagery, weather, and soil data) to improve prediction accuracy. A central contribution is the use of self-attention mechanisms within Transformers to achieve intrinsic interpretability, setting it apart from traditional post-hoc methods. The study finds that Transformer models not only enhance interpretability but also outperform other architectures in prediction accuracy.",
        "strengths": "- The paper introduces an original approach to crop yield prediction using Transformer-based models, a relatively novel application in this field. Its emphasis on intrinsic interpretability in multimodal learning stands out, offering a fresh alternative to the commonly used post-hoc methods in agricultural and environmental modeling.\n\n- The methodology is robust, featuring extensive experimentation across multiple neural network architectures (e.g., LSTM, CNN, and Transformer) to identify the most effective model. Additionally, the study's comparative analysis of interpretability techniques—such as Attention Rollout, Generic Attention, and Shapley values—adds considerable depth, enhancing the understanding of the model’s interpretability from multiple perspectives.\n\n- The paper is well-organized, with clear, accessible explanations of complex methodologies, complemented by visual aids that clarify the technical content and make intricate processes more intuitive for readers.\n\n- The model’s capability to provide accurate, interpretable predictions at the sub-field level holds significant implications for agriculture, where trust in predictive models is crucial for effective decision-making.",
        "weaknesses": "- Although the study compares Transformer models with LSTM, ALSTM, and CNN architectures, including more contemporary multimodal learning approaches could further enhance the analysis. For instance, comparisons with models such as Multimodal Variational Autoencoders or Multimodal Contrastive Learning frameworks would provide a more comprehensive evaluation of the Transformer's effectiveness relative to recent innovations in multimodal integration.\n\n- The Transformer model, with its 109,345 parameters, demonstrates an improvement in R² from 0.41 (ALSTM’s performance) to 0.46 and a reduction in MAE from 2.00 to 1.90. However, this comes with a significant increase in model complexity compared to ALSTM’s 38,017 parameters. A discussion on the computational costs, including inference time and resource requirements, would offer a balanced view of the model’s practicality, especially in resource-constrained settings.\n\n- While the authors focus on a qualitative evaluation of interpretability, the assessment could be strengthened by incorporating functionally-grounded evaluation metrics. Adding objective measures such as fidelity and sparsity would provide a more comprehensive and robust assessment of the model's interpretability.\n\n- Testing the model's adaptability across various crops and regions would help demonstrate its robustness. Expanding the dataset to incorporate diverse agricultural contexts or conducting transferability experiments across different geographic regions would offer insights into the model's broader applicability and generalization capacity."
      },
      {
        "rating": "6",
        "confidence": "3",
        "summary": "This paper assesses how varied interpretability and explainability techniques can be combined in a comprehensive approach to understand model-wise / layer-wise / time-wise / modality-wise behaviour of the learned model. In particular, it evaluates both representations and attention scores at the level of layers, compared to Attention Rollout and Generic Attention on each modality.",
        "strengths": "- This paper is well structured and understandable.\n- It has thoroughly referred to related paper, both in establishing existing approaches and problem significance, and to corroborate the results of the study.\n- Each of the interpretability evaluation provides visualisations, which can be leveraged to suggest either particularities of the model architecture or qualities of the data that might influence the model.\n- The dataset used is very large, and authors make sure that the analysis benefit from geographical units within the dataset (fields, farm, subfields).\n- A systematic analysis uses multiple techniques to analyze each model component individually or globally.",
        "weaknesses": "- Only one dataset is used, with no variation on modalities or indicators within each modalities. Even within the dataset, the authors do not truly enter a discussion on concept drift between the different fields, despite observing variability. Time-wise drift is not evaluated, despite years going from 2017 to 2023. How generalizable the approach is to other regions and future years is unknown.\n- Expert understanding is missing from the evaluation, hence several of the explanations that the authors provide about data influence on the model cannot be verified. Sections after lines 371, 416, 460, and 501 lack this expert confirmation on data behaviour. Additionally, assertion line 419 could have been verified experimentally by computing attention distributions on 5 days averages, or 5 days min and max, instead of daily series. This would require fitting a new model on the modified data.\n- No statistical significance, despite seemingly a lot of samples. If not samples (pixels), subfields could have been used to conduct statistical tests over distribution means.\n- Despite actionability being mentionned in introduction, no such claims were produced in experiments.\n- I could not find the corresponding code. Hence, this work cannot be considered as demonstration for comprehensive codebase on interpreting multimodal networks with transformer architecture.\n\n----- About the decision:\n\nWhile the presented work is solid in its evaluation, it lacks either a empirical perspective on how generalizable the approach is to spacial or temporal concept changes, or a demonstration of the actionability of explanations, or a confirmation of the new data understanding provided, or an easy-to-apply codebase. Therefore, I estimate that the actual paper impact would be unsufficient, any of the previous being sufficient in my opinion for paper acceptation.\n\n----- Points that I would like to see addressed but that did not impact the decision:\n\n- Fig 1 and 11: Relative error color maps should be identically scaled to allow for model comparison.\n- Weak representation due to point overlap in Fig 3 and 4 with lots of overlap. Providing a numerical aggregate (graphically or not) for the relation between |y1-y2| and cosine similarity would help, as visual inspection is not enough. For instance, spearman correlation.\n- 330: AR being preferable due to low variability is a bit of a shortcut. It has been demonstrated in Fig 3 that the functional sensitivity of deeper layers is high, hence it it believable that a fidel explanation would also have high sensitivity. Provided reference Yeh and al do demonstrate that smoothed explanations for lower sensitivity reduce infidelity, but whether AR is a smoothed version of GA is not straighforward. Their general claim \"if the explanation sensitivity is much larger than the function sensitivity around some input x, the infidelity measure in turn will necessarily be large for some point around x\", does imply that explanation sensitivity much larger that model sensitivity impacts fidelity, but GA seems in line with the composition of layer 3 and 4 variability. To me, the conclusion I see is that GA tend to focus more on the more variable layers of the Transformer, while AR incorporate better stable layers."
      },
      {
        "rating": "5",
        "confidence": "3",
        "summary": "The paper examines the intrinsic explainability of Transformer-based models for multimodal crop yield prediction, using satellite, weather, soil, and digital elevation map data. By focusing on explainability, the study addresses the challenge of understanding model decisions in agriculture. It uses self-attention layers to make predictions more interpretable and explores both intrinsic and post-hoc methods like Attention Rollout and Shapley values for feature attribution. The paper suggests that transformer models outperform alternatives like LSTM and CNN in yield prediction accuracy and interpretability, especially for satellite data, which was identified as the most influential modality.",
        "strengths": "The paper is well-written. The clarity in structure and flow makes complex concepts, such as the attention mechanism and the distinctions between interpretability methods, accessible.\n\nThe results indicate practical utility, with a focus on regions like Argentina and crops such as corn and soybean, making the findings potentially valuable for real-world applications in crop yield forecasting.",
        "weaknesses": "w1: The paper highlights discrepancies between the weighted modality activations and Shapley values for feature importance. For instance, soil features receive the highest weight with the regression head method (37.8%) but are less prominent in Shapley-based scores, which prioritize satellite data at 72.3% for corn yield predictions. This inconsistency can lead to ambiguity for practitioners who rely on model interpretation, as it’s unclear which modality consistently influences predictions .\n\n\nw2: The proposed model shows variability in capturing yield variance between different fields. In Field-B, where the Transformer model struggled, it still outperformed other architectures, yet error maps reveal inconsistencies in how yield variance is captured compared to Field-A. This suggests the model may not generalize well across varying field conditions, especially in geographically diverse regions"
      }
    ],
    "rating_avg": 3.8333333333333335,
    "confidence_avg": 3.3333333333333335,
    "decision": "N/A",
    "meta_review": "",
    "author_remarks": "",
    "decision_comment": ""
  },
  {
    "id": "TbTJJNjumY",
    "title": "Boosting Neural Combinatorial Optimization for Large-Scale Vehicle Routing Problems",
    "authors": [
      "Fu Luo",
      "Xi Lin",
      "Yaoxin Wu",
      "Zhenkun Wang",
      "Tong Xialiang",
      "Mingxuan Yuan",
      "Qingfu Zhang"
    ],
    "abstract": "Neural Combinatorial Optimization (NCO) methods have exhibited promising performance in solving Vehicle Routing Problems (VRPs). However, most NCO methods rely on the conventional self-attention mechanism that induces excessive computational complexity, thereby struggling to contend with large-scale VRPs and hindering their practical applicability. In this paper, we propose a lightweight cross-attention mechanism with linear complexity, by which a Transformer network is developed to learn efficient and favorable solutions for large-scale VRPs. We also propose a Self-Improved Training (SIT) algorithm that enables direct model training on large-scale VRP instances, bypassing extensive computational overhead for attaining labels. By iterating solution reconstruction, the Transformer network itself can generate improved partial solutions as pseudo-labels to guide the model training. Experimental results on the Travelling Salesman Problem (TSP) and the Capacitated Vehicle Routing Problem (CVRP) with up to 100K nodes indicate that our method consistently achieves superior performance for synthetic and real-world benchmarks, significantly boosting the scalability of NCO methods.",
    "keywords": [
      "Neural Combinatorial Optimization",
      "Large-Scale Vehicle Routing Problem"
    ],
    "venue": "ICLR",
    "year": 2025,
    "pdf_url": "https://openreview.net/pdf?id=TbTJJNjumY",
    "forum_url": "https://openreview.net/forum?id=TbTJJNjumY",
    "reviews": [
      {
        "rating": "5",
        "confidence": "3",
        "summary": "This paper presents a lightweight cross-attention mechanism with linear complexity to improve the efficiency of the NCO model in solving large-scale VRPs. By propagating node embeddings through representative nodes, the cross-attention mechanism maintains effective interactions between nodes while achieveing low complexity. The experimental results on TSP and CVRP with scaling up to 100K show that the proposed method is effective",
        "strengths": "The complexity of the proposed method is lower than the traditional methods.",
        "weaknesses": "The complexity analysis seems to be unfair to compare with the traditional method in that the proposed method should consider not only the computational complexity in single round, but also accumulate all computation in iterative reconstruction."
      },
      {
        "rating": "8",
        "confidence": "4",
        "summary": "In their paper, the authors present a deep learning-based, lightweight model and training scheme for solving VRPs. Specifically, the propose replacing the expensive self-attention mechanism in transformer-based solvers with cross-attention based on the first and last node of the currently constructed route. Additionally, they rely on Self-improved training (SIT) as a training mechanism instead of reinforcement or supervised learning. SIT decomposes the total solution into multiple partial solutions and resolves them to find the optimal subsolution.",
        "strengths": "The paper presents a novel learning method for deep-learning-based approaches in VRPs. SIT seems to improve performance significantly with the cross-attention making previously prohibitive problem sizes now possible. The performance of the model also seems to be very good, consistently beating the baselines.",
        "weaknesses": "I have some concerns about the evaluation procedure. Specifically, current transformer-based methods such as POMO are trained on small-scale problems (around 100 nodes) and are known to generalize poorly to bigger problems. Comparing to pre-trained models on the larger problems is a bit misleading as in this scenario the authors' method is trained and tested on the same size problem while the other baselines are forced to generalize. \n\nMoreover, and especially considering the SIT training scheme, it might have been good to see a replacement where these deep learning methods are applied on the partial problems with a size of 100 etc. that is closer to their training setting. This would help both see the effectiveness of SIT in other models and better compare with the introduced cross-attention. Alternatively, a direct comparison on smaller problems (of the same training size as the baselines) would have been useful. \n\n Finally, an important baseline would have been NeuroLKH [1] which combines deep learning methods with the LKH algorithm. It was shown to consistently beat LKH with much smaller runtimes which would be interesting to see since, in some cases, the margin between LKH and the authors' methods is not so large.\n\n[1] Xin, Liang, et al. \"Neurolkh: Combining deep learning model with lin-kernighan-helsgaun heuristic for solving the traveling salesman problem.\" Advances in Neural Information Processing Systems 34 (2021): 7472-7483."
      },
      {
        "rating": "6",
        "confidence": "4",
        "summary": "The paper proposes an efficient cross attention mechanism and a self-improved training (SIT) procedure for scaling up NCO solvers. The paper introduces representative embeddings that serve as an information bottleneck to reduce the complexity of attention. SIT algorithm iteratively improves the solution by using parallel local reconstructions. The resulting model achieves low complexity and is scalable to large VRP instances.",
        "strengths": "- The efficient cross attention mechanism is a novel way to reduce the complexity of transformer based NCO solvers. While the idea is simple, the experiments show that cross attention is really effective for large scale VRP. \n- The SIT algorithm is simple yet effective although local self improvement is not exactly a novel thing.\n- The paper is well written.",
        "weaknesses": "- The Related work section is pushed to the appendix. I know there is a lot to say about the proposed method, but the related work should be in the main text. The related work is not very well written. To improve readability, please divide the text into subsections, each discussing a different approach to the problem.\n- The paper did not compare with strong baselines such as ELG (Gao et al., 2024), GLOP (more revisions) (Ye et al., 2024) although the authors mentioned them in the related work section.\n- The paper lacks a comparison with other self improvement methods. Some examples of self improvement approach to NCO are [1]\n- The paper did not compare the sizes of the models. More parameters often lead to better results. To ensure a fair comparison, the experiment should be conducted on models of the same size.\n\n[1] Self-Improvement for Neural Combinatorial Optimization: Sample without Replacement, but Improvement. Jonathan Pirnay, Dominik G. Grimm"
      },
      {
        "rating": "6",
        "confidence": "2",
        "summary": "The paper addresses the challenge of solving large-scale vehicle routing problems (VRPs) using neural combinatorial optimization (NCO). The authors propose a novel approach that combines a lightweight cross-attention mechanism with a self-improved training (SIT) algorithm. The method is evaluated on multiple benchmark datasets, demonstrating significant improvements over existing methods in terms of solution quality and computational efficiency.",
        "strengths": "1) The paper introduces a lightweight cross-attention mechanism that significantly reduces the computational complexity of NCO models, addressing a key limitation in handling large-scale VRPs.\n\n2) The experimental setup is robust, using a variety of benchmark datasets and comparing against multiple state-of-the-art methods.\n\n3) The paper is well-structured and clearly written, making it easy to follow the methodology and understand the contributions.",
        "weaknesses": "1) Although the paper compares against several state-of-the-art methods, a more detailed comparison with recent advancements in reinforcement learning-based approaches for VRPs could provide a more comprehensive evaluation.\n\n2) An exploration of the limitations of the cross-attention mechanism and potential areas for improvement would enhance the paper's depth."
      }
    ],
    "rating_avg": 6.25,
    "confidence_avg": 3.25,
    "decision": "Accept (Poster)",
    "meta_review": "The paper presents a novel learning method for deep-learning-based approaches in VRPs. By propagating node embeddings through representative nodes, the proposed cross-attention mechanism maintains effective interactions between nodes while achieveing low complexity, which improves performance significantly with the cross-attention making previously prohibitive problem sizes now possible.  The experimental setup is robust, using a variety of benchmark datasets and comparing against multiple state-of-the-art methods. And the proposed method consistently beats the baselines. The paper is well-structured and clearly written, making it easy to follow the methodology and understand the contributions.",
    "author_remarks": "",
    "decision_comment": ""
  },
  {
    "id": "xcHIiZr3DT",
    "title": "Vision-Based Pseudo-Tactile Information Extraction and Localization for Dexterous Grasping",
    "authors": [
      "Teng Yan",
      "Cai Yaobang",
      "Tian Xia",
      "Jianhao",
      "Wenxian Li"
    ],
    "abstract": "This study addresses the challenges of tactile perception in robotic dexterous hand grasping by focusing on two main tasks: 1) Acquiring tactile information from everyday objects using vision, termed \"pseudo-tactile\" information, and 2) Building a Dexterous Hand (RH8D) model in Isaac Sim for real-time fingertip contact localization. Utilizing Isaac Sim enables safe, cost-effective experimentation and high-precision simulations that facilitate data collection for model validation. The research establishes a scientific connection between simulated 3D coordinates, actual 3D coordinates, and pseudo-tactile information derived from point clouds, quantified through normal vectors and grayscale variance analysis. Results demonstrate the ability to extract clear object surface textures, accurately locate fingertip contact points in real-time (with precision up to $0.001 m$), and provide tactile information at contact points. This framework enhances robotic grasping capabilities and offers low-cost sensory data. The source code and dataset are publicly available now.",
    "keywords": [
      "Pseudo-Tactile Information",
      "Dexterous Grasping",
      "Vision-Based Perception",
      "Robotic Localization"
    ],
    "venue": "ICLR",
    "year": 2025,
    "pdf_url": "https://openreview.net/pdf?id=xcHIiZr3DT",
    "forum_url": "https://openreview.net/forum?id=xcHIiZr3DT",
    "reviews": [
      {
        "rating": "3",
        "confidence": "4",
        "summary": "This paper presents a framework to acquire point cloud representations of objects and simulate the contact locations when using a dexterous robotic hand for grasping tasks. The point cloud data are first processed to filter the background and texture feature points are determined afterwards. The real grasping data are derived from the hardware and can be reproduced in a simulation environment with the corresponding contact locations and texture features.",
        "strengths": "This work introduces an approach to extract pseudo-tactile information from vision and contact locations for robotic grasping tasks. The topic is interesting, the pipeline is presented with details, and the experiment results show the effectiveness of the approach with high accuracy.",
        "weaknesses": "The overall contribution is marginal. The vision-based \"pseudo tactile\" features are derived using some common tools for point cloud data processing. The simulation for finger tip localization is from replicating and transforming the real motion data into the simulated environment. It is also claimed that the combination of this vision-based information and the fingertip contact points can enhance tactile feedback reliability in robotic grasping. However, this is not clear. The experiment does not show how the robotic grasping is improved."
      },
      {
        "rating": "1",
        "confidence": "4",
        "summary": "This paper presents a dataset of point cloud images of a wide variety of everyday objects. A dexterous hand model is built in an Isaac Sim simulator for real-time contact localization by replicating the real-life set up in simulation and using measured joint angles.",
        "strengths": "Open-sourced dataset of point cloud images is made available.",
        "weaknesses": "Details are so unclear it is difficult to fully understand the paper. For instance, \n- Paper repeatedly talks about the \"Y component of the normal vector\" without clearly defining a coordinate frame. Authors mention employing \"policy fine-tuning techniques\" on page 7 without ever mentioning a policy up until this point.\n- The role of simulation in the paper is not clear. The paper mentions \"This real-time linkage of each joint’s degrees of freedom with actual dexterous hand movements and the simulation platform allowed us to record the spatial coordinates of each grasping contact point in the simulation accurately.\" This sounds like a simple forward kinematics problem that would only require a mathematical model of the robot – not a full-fledged simulation.\n- Paper claims that intel realsense has “sub-mm accuracy”. This is not supported by documentation from the manufacturer: https://dev.intelrealsense.com/docs/tuning-depth-cameras-for-best-performance?_ga=2.110331777.520332705.1730517789-101245430.1730517789#section-verify-performance-regularly-on-a-flat-wall-or-target\n- Section 4.2 claims to assess localization precision. It is unclear what the ground truth is, how this is being measured and what measurement is being compared against this ground truth. Referenced Table 4 is difficult to understand, has no mention of errors or comparative ground truth. \n- An RMSE error is reported with no clarity on what quantities are being compared.\n- It is also unclear how related work Section 2.3 is connected to this work. Pseudo-haptics is associated with giving humans touch sensory feedback, whereas “pseudo-tactile” in this paper is related to analyzing the surface tactile properties of objects.\n\nMinor comment:\nPaper is very poorly formatted. Main result tables are placed in the appendix and are difficult to understand. Results in Tables 4,5 and 6 have poor choice of units (meters when dealing with textures that are likely sub-cm scale), and numbers are represented with arbitrary precision with no regard for the precision and error rates of the depth measurement device, ie. Intel Realsense cameras. Bullet points in the results section seem to have headers that have the exact font formatting as the rest of the text."
      },
      {
        "rating": "3",
        "confidence": "3",
        "summary": "This work presented an approach to acquire object surface information including textures and geometries, and proposed a simulation-involved approach to locate fingertips of robotic hand for grasping. The results demonstrated the object grasping with different number of fingers and object surface feature extraction.",
        "strengths": "The work has clear writing and good structure which makes it easy to follow and understand. Figures are well-made and informative. It is well-motivated to address the hard-to-acquire tactile perception by using vision for dexterous robotic hands.",
        "weaknesses": "I do not think this work has solid contribution or concrete experimental results. The proposed method simply combining existing techniques such as extracting point cloud from RGBD camera, and using simulator to simulate grasping. Instead of quasi-static grasping, I would encourage authors to extend it to more dynamic manipulation tasks and explore whether the extracted object features can be leveraged for these complicated tasks."
      },
      {
        "rating": "3",
        "confidence": "3",
        "summary": "This paper investigates the challenges of acquiring haptic perception during grasping by a mechanical dexterous hand and proposes solutions. The main tasks of the research include the acquisition of “pseudo-tactile” information about everyday objects through vision and the construction of a dexterous hand (RH8D) model in Isaac Sim for real-time fingertip contact localization. The study establishes a scientific link between simulated 3D coordinates, actual 3D coordinates, and pseudo-tactile information derived from the point cloud, which is quantified by normal vector and grayscale ANOVA. Experimental results show that the method is able to clearly extract the surface texture of an object, accurately locate the fingertip contact point in real time, and provide haptic information at the contact point.",
        "strengths": "This paper addresses the problem of obtaining tactile information during grasping based on only vision perception, and provides a clear method for object surface texture extraction with 3D point cloud input. The strengths are listed below.\n1. The authors provide abundunt and clear explanation for method presentation, and present a simple yet effective approach for point cloud preprocessing and feature extraction.\n2. The authors give a thorough representation on the expermental setup, and conduct real-world experiments on a dexterous hand for validation.\n3. The result of the experiments seems very ideal, indicating the effectiveness of the proposed method.",
        "weaknesses": "While I recognize some of the article's contributions, I still have the following concerns.\n1. From my point of view, this paper is a bit lack of novelty, because some parts of the method chapter are biased towards engineering practice rather than innovation, such as point cloud preprocessing, camera coordinate system transformations, and other types of work are actually common in robotics work, and cannot be listed as points of innovation. Meanwhile, the texture extraction method in the section overlaps most with [1].\n2. While generating pseudo-haptic sensing is one of the important contributions of the article, I didn't see that the authors had measured how good the quality of the generated haptic signals were, both quantitatively and qualitatively.\n3. The article's experiments still seem inadequate to me and lack comparison with previous work. For the contact position localization part, are there any previous baselines that can realiza this? For example, 3D point cloud keypoint prediction baselines, etc. Meanwhile, the authors didn't conduct the ablation studies on the proposed method, such as the different effectiveness on selections of KDTree radius, normal threshold, etc.\n\n[1] Budiyanta, N. E., Yuniarno, E. M., & Purnomo, M. H. (2021, December). Human point cloud data segmentation based on normal vector estimation using pca-svd approaches for elderly activity daily living detection. In TENCON 2021-2021 IEEE Region 10 Conference (TENCON) (pp. 632-636). IEEE."
      }
    ],
    "rating_avg": 2.5,
    "confidence_avg": 3.5,
    "decision": "Reject",
    "meta_review": "This paper introduces an approach for extracting pseudo-tactile information for robotic grasping and integrating a simulated dexterous hand model. The work was evaluated by the reviewers as lacking in novelty and depth, as it primarily combines existing techniques without significant innovation. The experimental validation was limited, with unclear metrics, insufficient baselines, and unexplored claims regarding the effectiveness of the proposed method. Additionally, the  reviewers have pointed that the presentation required significant improvement, as there were a lot of ambiguities in used terms, inconsistent reporting of results, and unsupported hardware experimentation claims.",
    "author_remarks": "",
    "decision_comment": ""
  },
  {
    "id": "srOVvTzgPo",
    "title": "Toward a Sheaf-Theoretic Understanding of Compositionality in Large Language Models",
    "authors": [
      "Ruchira Dhar",
      "Antonia Karamolegkou",
      "Anders Søgaard"
    ],
    "abstract": "Compositionality has long been considered a fundamental aspect of human cognition -  enabling the learning, manipulation, and generation of natural language. Understanding how this concept applies to Large Language Models (LLMs) and how it can be effectively evaluated remains a key challenge. In this work, we explore the potential of formalizing cognitive notions from theory, such as compositionality, to develop more nuanced evaluation frameworks for LLMs. Using a sheaf-theoretic approach, we define compositionality through four distinct conditions that capture its multifaceted nature. This formalization offers a structured perspective on evaluating LLMs, moving beyond surface-level assessments to uncover deeper insights into their behavior. Our findings suggest that theoretical frameworks like this one can play a crucial role in advancing the understanding and evaluation of LLMs, providing a foundation for more comprehensive and precise performance analyses.",
    "keywords": [
      "cognition",
      "compositionality",
      "sheaf-theory",
      "language model evaluation"
    ],
    "venue": "ICLR",
    "year": 2025,
    "pdf_url": "https://openreview.net/pdf?id=srOVvTzgPo",
    "forum_url": "https://openreview.net/forum?id=srOVvTzgPo",
    "reviews": [
      {
        "rating": "3",
        "confidence": "4",
        "summary": "The paper introduces a mathematical framework for compositionality in LLMs based on sheaf topology, defining four basic conditions: restriction maps, gluing conditions, locality conditions, and natural transformations. The authors tested each condition with a specific dataset and found that instruction-tuned models have inconsistent performance across different aspects of compositionality.",
        "strengths": "- The paper presents a nice initial effort in defining compositionality with a mathematical framework rigorously\n- The paper is well-structured and well-written",
        "weaknesses": "- (Major) Limited novelty and applicability of the findings:\n\t- The formalization of compositionality via the sheaf-theoric framework is novel, but it is not clear its purpose, how it can be used in practice in the real world and whether it's correct or not (due to a weak experimental part).\n\t- There is no novelty in the evaluation part since it uses known datasets and results for the literature, except for the introduction of the COMPCOMB dataset.\n\t- In general, there are very few contributions that justify this paper.\n- (Critical) The experimental part is extremely weak and not convincing:\n\t- In Table 1 there is a significant drop between base models and instruction-tuned models like a huge ~40% (0.82 vs 0.42) on SCAN. The authors provide an explanation that  L402 \"instruction tuning likely leads to a loss in the development of restriction maps, which could be explained by the fact that while the model retains its most important generalizations, it loses some local information to accommodate instruction tuning, leading to loss of restriction mapping\". This is in contrast with results in the literature where instruction-tuned models perform generally better. I believe there is not enough empirical evidence to sustain this statement and the huge performance drop might be due to issues in the evaluation setup. The authors mention the use of \"computing the model’s log probabilities for two possible completions\" but this has been shown to be problematic, especially in instruction-tuned models that might lose the calibration in their logits after RLHF (https://arxiv.org/abs/2402.14499 , https://arxiv.org/abs/2303.08774). I suggest using a different eval strategy (e.g., comparison with the ground truth and exact match metric) and distinguishing results between instruction-tuning and models tuned via RLHF.\n\t- In general, I don't think the experiments are thorough enough to convince me without any doubt that an increase/decrease of the score on a specific dataset (e.g., SCAN) means an increase/decrease of a compositional condition defined in the framework (e.g., Restriction Condition). There are several other factors involved in the evaluation that might lead to spurious correlations and an increase/decrease in the score. I think the author should definitively pay more attention to the evaluation of the components defined in the framework.\n- (Minor) The presentation of the results is not optimal:\n\t- The results proposed (Figures and Tables) are never referenced from the text. This creates ambiguity in the text because it's not clear what results you are commenting on. \n\t- The proposed plots lack clarity. The rationale for using a radar plot to compare accuracies in Figure 1 is unclear, and both the scale and raw values in the plot are difficult to interpret.\n- (Minor) There is a minimal discussion of related works. Missing related papers (e.g., [A Complexity-Based Theory of Compositionality](https://arxiv.org/abs/2410.14817))"
      },
      {
        "rating": "5",
        "confidence": "2",
        "summary": "Compositionality is a topic on human cognition. \nLLMs appear to show their superior language processing capability and thus evaluating the compositionality become a portal to gain insights into these models.\nThis paper introduced a sheaf-theoretic framework with 4 different datasets to assess LLMs performance on compositionality.\nKey findings include 1) larger models tend to be more performant. 2) instruction finetuned models may behave inconsistently in different tasks.",
        "strengths": "- Paper investigated both query (aka, prompt output) and internal representation in different tasks.\n- To reviewer's knowledge, this paper is clear and original in proposing the sheaf-theoretic framework for LLMs compositionality assessment.\n- Two orders of relationship are investigated, entity level and relation level.\n- Proposed 4 datasets, namely SCAN, ANTAILS, COMPCOMB, PLANE, aim to unveil insights in restriction maps, gluing condition, locality condition, and natural transformation. \n- Appendix provided abundant information about generation process of each dataset.",
        "weaknesses": "- A related work section would help readers to better understand the background and prepare readers well to follow the sheaf-theoretic framework.\n- While 4 tasks cover distinct aspects, the size of these dataset could be limited to capture the compositionality of LLMs.\n- Compositionality is an important in human cognition and investigating it in LLMs is also exciting. The paper would be more complete if authors include the importance of LLMs compositionality in applications. What are the aspects or benefits if LLMs gains better compositionality performance.\n- There is limited description of the experiment setup. It would be preferable if there are more justifications for the methodology and choice of prompting.\n- (line 908) There is a table or figure missing about the SCAN setup, showing **??**\n- Appendix also shows the template used but it would be better to include additional examples in each dataset to help readers gain insights.\n- There are many extremely long sentences, which requires a second pass and thus affect the readability of the paper."
      },
      {
        "rating": "5",
        "confidence": "3",
        "summary": "1. This work proposes a novel way to use sheaf theory for compositionality for Large Language Models (LLMs). Compositionality is a central concept of human cognition that understands complex things through simpler components. This new definition of compositionally contains four distinct conditions: restriction maps, gluing conditions, locality conditions, and natural transformations.\n\n2. The experiments conducted across multiple LLMs (such as Llama2, CodeLlama, and Mistral) show that larger models tend to exhibit better compositional abilities overall. However, instruction-tuned models experience a significant decline in performance, particularly in tasks related to the restriction condition and natural transformations. This suggests that while instruction tuning may enhance generalization, it can degrade the model's ability to handle compositional information.",
        "strengths": "1. The paper introduces a completely new, higher-level definition of compositionality using sheaf theory, which provides a fresh perspective on evaluating the compositional abilities of LLMs. This novel approach broadens the understanding of how complex linguistic expressions are structured and processed by LLMs. Provide a more comprehensive way to measure LLMs' ability.\n\n2. The authors evaluate various LLMs (such as Llama2, CodeLlama, and Mistral) across four different angles, providing a detailed comparison of their compositional performance. This analysis helps identify which models excel in certain tasks and where they fall short, offering useful insights for improving future models.",
        "weaknesses": "1. The paper does not include a dedicated Related Work section, which is critical for situating the proposed framework within the existing literature. This omission makes it difficult to understand how the new approach builds upon it.\n\n2. The paper falls short of the 10-page limit. This space can be used to conduct analysis deeper.\n\n3. While the proposed sheaf-theoretic framework is innovative and offers a high-level definition of compositionality, its real-world applicability remains uncertain. The framework may be too abstract or theoretical for immediate use in practical model development or evaluation, raising questions about its tangible impact.\n\n4. The paper does not provide a better solution for improving compositionality in LLMs."
      }
    ],
    "rating_avg": 4.333333333333333,
    "confidence_avg": 3.0,
    "decision": "Reject",
    "meta_review": "This paper proposes a new sheaf theoretic framework for reasoning about compositional generalization. They use this framework to define a taxonomy of different facets of compositionality.\n\nThe presentation is clear and well structured; the authors have made further presentation improvements during the discussion phase. Reviewers praised the originality of the chief theoretic framework for compositionality.\n\nHowever, reviewers remained unconvinced about the advantages of this theoretical framework over alternative ways of thinking about compositionality. They were unconvinced by both the correctness and by the possibility of new applications of this theory. The paper would be improved by showing how sheaf theory can be used to make novel predictions or explain phenomena around compositionality better than alternative theoretical models like Bayesian reasoning about possible automata, or better than alternative taxonomies of compositionality such as Hupkes et al. 2020.",
    "author_remarks": "",
    "decision_comment": ""
  },
  {
    "id": "h0vC0fm1q7",
    "title": "Sensitivity Verification for Additive Decision Tree Ensembles",
    "authors": [
      "Arhaan Ahmad",
      "Tanay Vineet Tayal",
      "Ashutosh Gupta",
      "S. Akshay"
    ],
    "abstract": "Tree ensemble models, such as Gradient Boosted Decision Trees (GBDTs) and random forests, are widely popular models for a variety of machine learning tasks. The power of these models comes from the ensemble of decision trees, which makes analysis of such models significantly harder than for single trees. As a result, recent work has focused on developing exact and approximate techniques for questions such as robustness verification, fairness and explainability for such models of tree ensembles.\n\nIn this paper, we focus on a specific problem of feature sensitivity for additive decision tree ensembles and build a formal verification framework for a parametrized variant of it, where we also take into account the confidence of the tree ensemble in its output. We start by showing theoretical (NP-)hardness of the problem and explain how it relates to other verification problems. Next, we provide a novel encoding of the problem using pseudo-Boolean constraints. Based on this encoding, we develop a tunable algorithm to perform sensitivity analysis, which can trade off precision for running time. We implement our algorithm and study its performance on a suite of GBDT benchmarks from the literature. Our experiments show the practical utility of our approach and its improved performance compared to existing approaches.",
    "keywords": [
      "Robustness verification",
      "Sensitivity analysis",
      "SAT solvers",
      "efficient encodings",
      "NP-hardness",
      "fairness",
      "confidence"
    ],
    "venue": "ICLR",
    "year": 2025,
    "pdf_url": "https://openreview.net/pdf?id=h0vC0fm1q7",
    "forum_url": "https://openreview.net/forum?id=h0vC0fm1q7",
    "reviews": [
      {
        "rating": "6",
        "confidence": "3",
        "summary": "This paper addresses the feature sensitivity problem for ensembles of decision trees, with a focus on Gradient Boosted Decision Trees (GBDT). The authors demonstrate that this problem is NP-complete through a reduction from the SAT problem. They then propose an algorithm to solve the p-sensitivity problem by encoding it as pseudo-Boolean constraints. Finally, experimental results are provided, comparing the proposed approach to some existing methods.",
        "strengths": "The paper is well-written, with a clear structure that makes it easy to follow. This clarity enhances the readability and understanding of the material.\n\nThe problem is well motivated.\n\nThe theoretical contributions are interesting and their proofs appear to be correct.",
        "weaknesses": "The initial result on NP-hardness of sensitivity problem for all features seems redundant after establishing NP-completeness for a single feature. \n\nMy main issue with this paper is with the experiments. The comparison with VERITAS seems a bit unfair. By limiting VERITAS to the same runtime as SENSPB, the comparison may not reflect its full potential. Allowing VERITAS more runtime might yield better results, or it could have already produced sufficiently good results within its runtime. A separate table detailing the number of instances each method solved and the time taken would provide additional insights.\n\n**Minor Comments/Typos**\n- Line 068: \"just on\" → \"just one\"\n- Line 079: Rewrite this sentence for clarity: “Can we use other forms of powerful reasoning, Pseudo-Boolean solvers, that have shown to be effective in other problems (Mexi et al., 2023), for the sensitivity problem?”\n- Line 162: \"given set of sensitive features F\" → \"given set of features F\"\n- Caption of Table 1: \"results than mine\" → \"results than our method\""
      },
      {
        "rating": "8",
        "confidence": "3",
        "summary": "This submission considers the problem of sensitivity for tree ensemble classifiers, i.e. the question of determining if, for a selection \\\\(F\\\\) of features, there exists a pair of inputs that agree on all the features outside of \\\\(F\\\\) but get classified differently by the tree ensemble. This work also develops a quantitative version of sensitivity (Def 3.2), parametrised by a number \\\\(p\\in[0,\\frac{1}{2}]\\\\), that additionally lower-bounds the \"distance\" between the two classifications. \n\nThe main theoretical contributions consist in proving that \n- the (non-quantitative) sensitivity problem is NP-hard (Thm 1)\n- the sensitivity problem restricted to singleton feature sets F={f} is also NP-hard (Thm 2)\n\nThe main practical contribution is to show that the problem of establishing \\\\(p\\\\)-sensitivity can be encoded as the satisfiability of a system of pseudo-boolean constraints (Thm 3). Experimental evidence shows that this approach scales much better than SOTA methods.",
        "strengths": "The paper is very well-written, with a good overview of the literature and easy-to-follow examples, proofs and discussions. In particular the proofs are easily understandable even by someone with very limited knowledge of computational complexity theory such as myself.\n\nThe main practical novelty of this paper -- using a pseudo-boolean satisfiability encoding -- is credibly shown to be superior to the SOTA methods in a short but convincing experimental section.",
        "weaknesses": "Theorems 1 and 2 correspond to two extremes of the sensitivity problem: the first considers sensitivity w.r.t. the full set of features, the second considers only singleton subsets of features. It feels like the full story would be a result showing that sensitivity w.r.t. subsets of features of size \\\\(N\\\\) is NP-hard, for all \\\\\\(N\\\\). Similarly, the story is slightly incomplete as in does not cover trees of depth 2 or 3 (as mentioned by the author(s)). The paper would be nicer (and stronger) if these questions were solved. too \n\nHere are some minor comments/corrections\n* l69: when THE number\n* l83: whether...whether\n* l104: some OF these\n* l117: of A \\\\(d\\\\)-dimensional\n* l157: When \\\\(F=\\\\{f\\\\}\\\\)\n* l168: two-tree\n* l194: Def 3.2 is not really a special case of Def 3.1 in the sense that Def 3.1 does not correspond to a particular choice of \\\\(p\\\\). As it stands, Def 3.1 is equivalent to \\\\(\\exists p.\\\\)Def 3.2 holds. To make Def 3.1 a special case of Def 3.2 I would change it to have \\\\(p\\geq 0\\\\) and \\\\(\\sigma(c(x_1))\\geq 0.5+p, \\sigma(c(x_2))< 0.5+p\\\\) (or the other way round). Then Def 3.1 would correspond to the case \\\\(p=0\\\\).\n* In the proofs of thm 1 and thm 2, why not simply take \\\\(X_{k+1}=\\\\{-1,1\\\\}\\\\) and \\\\(X_0=\\\\{-1,1\\\\}\\\\)?\n* l275: \\\\(F\\cup\\\\{f\\\\}\\\\) (not \\bigcup and singleton)\n* l289: I don't understand the first sentence here. Which problem requires three variables \\\\(x_1,x_2,x\\\\)?\n* l307 and l313: use \\setminus for the set difference \\\\(\\mathcal{F}\\setminus F\\\\). Also, if you'd used \\\\(x,x'\\\\) or \\\\(x,y\\\\) instead of \\\\(x_1,x_2\\\\), you wouldn't have problems with double subscripts.\n* l310: \\log instead of log\n* eq (2): shouldn't \\\\(j+1\\\\) in the RHS simply be \\\\(j\\\\)?\n* l327-328: Incomplete sentence\n* l328: Since THE root\n* Thm 3: use \\eqref in the conjunction, in order to get \\\\((1)\\wedge\\ldots\\wedge(6)\\\\). Parentheses = equations. Conversely don't use (1) and (2) to refer to the two parts of the theorem, instead use 1. and 2., or better (i) and (ii).\n* l394: mine -> us\n* l420: p-sensitive -> \\\\(p\\\\)-sensitive"
      },
      {
        "rating": "6",
        "confidence": "3",
        "summary": "The paper puts forward an approach for formal verification of feature sensitivity. Feature sensitivity is a characteristic of a model whereby the model changes its output depending on values of such features. In domains such as fairness checking for feature sensitivity is one of the ways in which fairness checks are meaningfully encoded.\n\nThe paper answers some complexity problems on answering features sensitivity, leaves some open. Crucially it provides a novel and efficient way based on pseudo-Boolean encodings to solve the verification problem. Some experimental results showing SoA performance are provided.\n\nOverall this is a solid paper, arguably with some weaknesses, that advances the SoA of the area.\n\nPost-rebuttal note: The authors answered by questions and provided additional material (developed post-submission) to solve some of the questions left unanswered in the paper. On the other hand I also noticed some presentation issues that I think can be fixed. I think the final answer on scalability on the point are raised remains unresolved; so it is still not 100% clear to me the extent to which the novel encoding is responsible for the gain. I do accept the authors point in as far as the comparison against SMT goes. \nOverall I am still mildly positive on the paper.",
        "strengths": "The paper is very well presented (some very minor typos that can be fixed). I cannot judge the soundness of the encoding but it seems reasonable. I read the complexity proofs and appear correct (even if not surprising). In terms of advancement on SoA I judge this to be in line with the standards expected at ICLR, even if perhaps not as a top paper (see weaknesses below).\n\nMost importantly solving model valuation for ensembles remains a key question in a variety of domains and this paper presents a principled and noteworthy contribution to the challenge. While the NP-hardness results may not be surprising they fill a gap in the knowledge in the area and the encoding presented achieves SoA performance.",
        "weaknesses": "While the NP hardness won't be a surprise to most, not all the theoretical questions are answered in the paper with the obvious gap being trees of depth 2 and 3. I feel this has a considerable implication even in terms of architectural suggestions from this study. Has this question been answered by the authors in the meantime? To me these corner cases are actually the most interesting ones. Finding the the case for 3 is polynomial would be a very interesting result\n\nThe reasons as to whether the approach appears to scale considerably better than present SoA were not clear to me in the paper. Do the authors have an explanation? If so, could they provide it? The reason for asking is that in principle it could even be that their implementation is just more efficient and it does not have so much to do with the encoding."
      },
      {
        "rating": "6",
        "confidence": "4",
        "summary": "The paper addresses the sensitivity verification problem of GBDTs by formalizing a pseudo-Boolean encoding. The authors claim their approach can achieve significant performance gains over existing sensitivity verification tools, specifically for GBDTs. However, the paper lacks a comprehensive presentation, robust mathematical formulation, and systematic experiments. As such, it would need major revisions to be accepted.\n\n# Discussion phase\nAfter a deep discussion phase during which the authors addressed all my weaknesses and improved their work, including a better result, I increased my overall score to 6/10. Specifically, I've changed only the scores while leaving the original review; I could also change the review if that's mandatory.",
        "strengths": "- **S1:** The paper addresses an important issue aimed at verifying the sensitive features of GBDTs.\n- **S2:** Mathematical proofs, which I would have expected to have a better presentation, but I appreciate the effort.\n- **S3:** The authors present an approach using pseudo-Boolean encoding, arguing that it is more suitable than other methods.",
        "weaknesses": "- **W1:** The notation is inconsistent and confuses readers, especially those who are unfamiliar with the topic. For example, input examples are denoted by $x$ and $x'$ in Def. 3.1, but then they are $x_1$ and $x_2$ in Def. 3.2; furthermore, in the proof of Th. 2 instances are symbolized $a$ and $b$ (a very unhappy notation). Similarly, trees are defined as $T$ in Section 2 but then symbolized with $D$ in the proof of Th. 1.\n- **W2:** Certain mathematical expressions and definitions are unclear or incorrect. For example, $F = f$ instead of $F = \\\\{f\\\\}$ detracts from the overall comprehensibility. As another example, the set minus ($\\setminus$) operation is properly used in Def. 3.1 but then in Section 4 is not used; that is, the authors use minus ($-$). A further example is when the authors use $\\mathcal F = F \\bigcup f$, which, again, is not a proper mathematical definition; it should perhaps be $\\mathcal F = F \\cup \\\\{ f \\\\}$.\n- **W3:** The proofs suffer from inconsistent symbols, poor spacing, and cluttered notation, making the logical progression of arguments hard to follow. For example, while reading the proof of Th. 1, I had to stop and skip such proof because the notations became heavy, and my overall cognitive overload intensified. To give a precise idea of how it felt: in $c'(x) = -n$, $n$ is the same $n$ as the number of decision trees in the ensemble (line 205)? What is the $\\Longrightarrow$ in the notation? What is $\\wedge$? Etc. As you can see, there are too many doubts that the reader has at this point. I assumed the proof was correct, even though I hadn't thoroughly reviewed it. The problem with this way of writing the proof is that the authors mixed textual explanations with mathematical ones in an unpleased way. This point is very critical.\n- **W4:** The experimental results lack clarity; terms like \"maximum, minimum, and average\" time are used ambiguously without explaining what they represent or if multiple runs were performed.\n- **W5:** Despite the general title, the paper focuses solely on GBDTs, excluding other ensemble methods like random forests without justification. If that's not the case, I expected to see experiments with random forests as well.\n- **W6:** The paper contains grammatical errors, inconsistent abbreviations (e.g., \"wrt\" vs. \"w.r.t.\"), and informal language, which detracts from the overall presentation."
      },
      {
        "rating": "6",
        "confidence": "4",
        "summary": "In the context of interpretable machine learning, this paper investigates the problem of \"feature sensitivity\" in tree ensembles. Specifically, given a classifier $ c $ and a set of features $ F $, the goal is to determine whether there exists an instance $ x $ such that the classification of $x$ by $c$ changes when only the values of the features in $ F $ are modified. The paper establishes that this problem is NP-complete for gradient-boosted trees, even when $ F $ consists of a single feature. The authors also explore an extension of this problem that considers the confidence associated with class changes, which is also shown to be NP-complete. To deal with this source of complexity, the authors propose a Pseudo-Boolean encoding for the feature sensitivity task, which they empirically validate on several benchmarks.",
        "strengths": "**Novelty:**\nArguably, the main strength of this paper lies the novelty of the complexity results for deciding feature sensitivity when the predictive model is a binary-class gradient boosted tree. Notably, the fact that the problem remains NP-hard even in the case where the sensitivity analysis is reduced to a single feature is intriguing.",
        "weaknesses": "**Clarity:** \nThe scope of the paper is quite challenging to define. As indicated in the title, summary, and introduction, it seems that the authors aim to examine feature sensitivity for “tree ensembles,” which is a broad category that includes several model classes, such as gradient-boosted trees (GBTs) and random forests (RFs). This is further illustrated in Section 2, where the authors attempt to provide a general definition of tree ensembles (Lines 130-136). However, upon reviewing the technical sections of the study (Sections 3-5), it becomes clear that the results are exclusively related to GBTs. This focus is reiterated toward the end of the introduction (starting at Line 65), where the authors clarify their exclusive emphasis on GBTs.\n\nTherefore, it is essential for the authors to establish a clear consensus on the scope of the paper in the revised version. If they intend to concentrate solely on GBTs, this specificity should be highlighted throughout the paper, beginning with the title and summary. The definition of tree ensembles in Section 2 should also be replaced with a definition of GBTs. Conversely, if the authors believe that their theoretical results could be easily extended to other tree ensemble classes (e.g., random forests), then the proofs in Section 4 should be modified accordingly (see Question 2).\n\nAt present, the definition of tree ensembles in Section 2 is somewhat unclear. If we denote by $c(x)$ the sum of the decisions $T_i(x)$ made by each of the $m$ decision trees $T_i$, then what class in $\\mathcal{F}$ is predicted by $c$ on $x$? This is evident for GBTs when $\\mathcal{F} = \\\\{-1,+1\\\\}$, using the sigmoid function $\\sigma$, but it remains ambiguous for other classes of tree ensembles. If the authors’ goal is to address various classes of ensemble models, it is important to provide a comprehensive definition of “tree ensemble” that can be instantiated for both GBTs and random forests.\n\n**Significance:**\nThe main theoretical contribution of this paper lies in Theorem 2, which establishes that single feature sensitivity is NP-hard for GBTs. Other NP-hardness results presented in this study stem from this case. While this finding is commendable, I remain unsure if it is sufficient for ICRL. To enhance the theoretical significance of this study, it would be beneficial to investigate whether this problem and its variants are W[1]-hard or if some of them are fixed-parameter tractable (FPT), with the parameter of interest being the maximum depth of the trees (See Question 1). Establishing hardness results for W[1] would indeed bolster the justification for the constraint programming approach discussed in Section 4."
      }
    ],
    "rating_avg": 6.4,
    "confidence_avg": 3.4,
    "decision": "Accept (Poster)",
    "meta_review": "This paper considers the feature sensitivity problem for ensembles of decision trees in a verification context. \n\nThe reviewers generally agree that there is sufficient novelty in using a pseudo-boolean satisfiability encoding. The experiments indicate that this method is often superior to the state-of-the-art. \n\nMoreover, several weaknesses regarding presentation and clarity have been mitigated in the rebuttal phase. In particular, the experiments were improved, and hence, we recommend acceptance of the paper.",
    "author_remarks": "",
    "decision_comment": ""
  },
  {
    "id": "r1KcapkzCt",
    "title": "Monte Carlo Planning with Large Language Model for Text-Based Game Agents",
    "authors": [
      "Zijing Shi",
      "Meng Fang",
      "Ling Chen"
    ],
    "abstract": "Text-based games provide valuable environments for language-based autonomous agents. However, planning-then-learning paradigms, such as those combining Monte Carlo Tree Search (MCTS) and reinforcement learning (RL), are notably time-consuming due to extensive iterations. Additionally, these algorithms perform uncertainty-driven exploration but lack language understanding and reasoning abilities.\nIn this paper, we introduce the Monte Carlo planning with Dynamic Memory-guided Large language model (MC-DML) algorithm. MC-DML leverages the language understanding and reasoning capabilities of Large Language Models (LLMs) alongside the exploratory advantages of tree search algorithms. Specifically, we enhance LLMs with in-trial and cross-trial memory mechanisms, enabling them to learn from past experiences and dynamically adjust action evaluations during planning. We conduct experiments on a series of text-based games from the Jericho benchmark. Our results demonstrate that the MC-DML algorithm significantly enhances performance across various games at the initial planning phase, outperforming strong contemporary methods that require multiple iterations. This demonstrates the effectiveness of our algorithm, paving the way for more efficient language-grounded planning in complex environments.",
    "keywords": [
      "Large language model",
      "Monte Carlo tree search",
      "Text-based games"
    ],
    "venue": "ICLR",
    "year": 2025,
    "pdf_url": "https://openreview.net/pdf?id=r1KcapkzCt",
    "forum_url": "https://openreview.net/forum?id=r1KcapkzCt",
    "reviews": [
      {
        "rating": "5",
        "confidence": "4",
        "summary": "This paper introduces Monte Carlo planning with Dynamic Memory-guided Large language model (MC-DML) algorithm, which targets at bringing the language model understanding and reasoning capabilities into Monte Carlo Tree Search and RL. Specifically, the authors propose to add in-trial (which includes exploration and results in the current game), and cross-trial memory (which is reflections from previous experiences) into predictor UCT. Experimenting on 9 text-based games in Jericho benchmark, results show that the proposed MC-DML approach improve the performance over other RL-based, LLM-based, and MCTS-based approaches.",
        "strengths": "1. This paper shows that adding LLM reasoning and planning capabilities, especially when augmenting with cross-trial reflections, can improve exploration performance in MCTS. This can be an interesting direction to study and may suggest good research results to people interested in how to make use of LLMs in RL exploration.\n2. This paper compares to previous RL-based, LLM-based, and MCTS-based methods, and shows that when combining LLM with MCTS RL methods, we would benefit from stronger reasoning and planning capabilities.",
        "weaknesses": "1. The main contribution in the proposed algorithm actually lies in introducing cross-trial reflection, as LLMs have been studies in the MCTS setup which is also mentioned by the authors. However, although the paper compares to LLM-based and MCTS-based baselines, there is no comparison to LLM + MCTS baselines, which seems to be the most relevant. \n2. Given that combining LLMs and MCTS has been well studies in both text-based games and other RL setups, the contribution of this paper might be relatively limited."
      },
      {
        "rating": "8",
        "confidence": "5",
        "summary": "This is a neat paper combining well known MCTS with LLM memory. More specifically, MCTS will be guided by past failure trajectories as learned by the LLM. The idea is demonstrated in a number of text games.",
        "strengths": "This is a neat and effective idea. It may also apply to other domains such as robot planning or math problem solving. It is still not clear how the formalism is incorporated into POMDP.",
        "weaknesses": "The method requires the LLM to remember these failure trajectories. Long term memory can be one limitation, or for complex tasks it may be needed to do some sort of RAG to retrieve the relevant memory, and this can introduce noise."
      },
      {
        "rating": "8",
        "confidence": "4",
        "summary": "This paper introduces a new planning and learning algorithm called Monte Carlo with Dynamic Memory-guided Large language model (MC-DML). This method leverages the language understanding capabilities of LLMs and the exploratory advantages of tree search algorithms. The approach is similar to Predictor UCT: actions are selected based on the Q-value function plus a probability distribution over valid actions p(a|s). In this work, p(a|s) is not trained but produced by a prompted LLM. Applied to Jericho text-based games, GPT3.5 is used to generate p(a|s) at each game state based on both an in-trial memory (M_i = sequence of past observations & actions), and a cross-trial memory (M_c = a collection of LLM generated reflections based on previous failures). In addition, the Monte Carlo search used in this work applies dynamic pruning to save search time and favor exploration.\nExperimental results on 9 Jericho games show that MC-DML yields better performance when compared to RL-based, LLM-based, and other MCTS-based methods. Ablation studies show the importance of the cross-trial memory M_c.",
        "strengths": "This paper proposes a novel method to combine the advantages of LLMs and tree-search algorithms. The idea of including both in-trial and cross-trial elements inside the decision-making process of choosing the next action is an interesting and effective technique that can inspire future work.\nThe paper is well written, the experiments correspond to the research questions, and are well motivated.",
        "weaknesses": "**W1.** Some technical aspects are not always clear, see below and the list of questions for things to clarify.\n\nThe paper could benefit from a more detailed explanation of the way each LLM prompt is constructed. In particular what is inside the {TRAJECTORY}, {IN-TRIAL MEMORY}, and {CROSS-TRIAL MEMORY} variables. An example in the appendix could help the reader understand what information the LLM has access to when making its decision.\nA discussion about how the lengthy game trajectories are handled could also clarify some technical aspects.\n\n**W2.** The Jericho benchmark has been used in many previous works, additional baselines could be included in the experimental results to make them more significant.\nIn particular MPRC-DQN & RC-DQN from Guo et al. [1], Bike+CBR from Atzeni et al. [2], and LDTs from Gontier et al. [3]\n\n[1] Guo, X., Yu, M., Gao, Y., Gan, C., Campbell, M., & Chang, S. (2020). Interactive fiction game playing as multi-paragraph reading comprehension with reinforcement learning. arXiv preprint arXiv:2010.02386\n\n[2] Atzeni, M., Dhuliawala, S., Murugesan, K., & Sachan, M. (2021). Case-based reasoning for better generalization in textual reinforcement learning. arXiv preprint arXiv:2110.08470.\n\n[3] Gontier, N., Rodriguez, P., Laradji, I., Vazquez, D., & Pal, C. (2023). Language Decision Transformers with Exponential Tilt for Interactive Text Environments. arXiv preprint arXiv:2302.05507."
      }
    ],
    "rating_avg": 7.0,
    "confidence_avg": 4.333333333333333,
    "decision": "Accept (Poster)",
    "meta_review": "The paper presents a more efficient way to do Monte Carlo planning in text games. It is well situated with respect to the literature on text game playing agents, especially those that already attempt to solve them via a mix of Deep RL and search+backtracking methods. The addition of LLMs has always been bottlenecked by the compute costs but the MC-DML could be a good answer to that. The results are also well presented and show a solid improvement over existing methods. Some of the exact implementation details are unclear from the paper itself and I'd encourage the authors to make the code for this work available if they can as that will allow for other papers to build on it - implementation details are critical for such methods especially.",
    "author_remarks": "",
    "decision_comment": ""
  },
  {
    "id": "tlH4vDii0E",
    "title": "Fine-Tuning Pre-trained Language Models for Robust Causal Representation Learning",
    "authors": [
      "Jialin Yu",
      "Yuxiang Zhou",
      "Yulan He",
      "Nevin L. Zhang",
      "Ricardo Silva"
    ],
    "abstract": "The fine-tuning of pre-trained language models (PLMs) has been shown to be effective across various domains. By using domain-specific supervised data, the general-purpose representation derived from PLMs can be transformed into a domain-specific representation. However, these methods often fail to generalize to out-of-domain (OOD) data due to their reliance on $\\textit{non-causal}$ representations, often described as spurious features. Existing methods either make use of adjustments with strong assumptions about lack of hidden common causes, or mitigate the effect of spurious features using multi-domain data. In this work, we investigate how fine-tuned pre-trained language models aid generalizability from single-domain scenarios under mild assumptions, targeting more general and practical real-world scenarios. We show that a robust representation can be derived through a so-called causal front-door adjustment, based on a $\\textit{decomposition}$ assumption, using fine-tuned representations as a source of data augmentation. Comprehensive experiments in both synthetic and real-world settings demonstrate the superior generalizability of the proposed method compared to existing approaches. Our work thus sheds light on the domain generalization problem by introducing links between fine-tuning and causal mechanisms into representation learning.",
    "keywords": [
      "representation learning",
      "causal inference",
      "robust machine learning"
    ],
    "venue": "ICLR",
    "year": 2025,
    "pdf_url": "https://openreview.net/pdf?id=tlH4vDii0E",
    "forum_url": "https://openreview.net/forum?id=tlH4vDii0E",
    "reviews": [
      {
        "rating": "6",
        "confidence": "3",
        "summary": "The authors focused on causal representation learning in NLP applications for robust generalization on OOD data. The conventional method for OOD generation is leveraging data from multiple domains as a feature augmentation, which has limitations in the natural language domain in that multi-domain data is often not readily available nor straightforwardly applicable. The authors proposed leveraging PLMs as an additional source of domain data for efficient data augmentation based on the causal front door adjustment to reduce spurious correlation in data. By evaluating text classification tasks, from single-domain scenarios under mild assumption to targeted more general real-world scenarios, the authors demonstrated the generalizability of LLM improved.",
        "strengths": "- The paper is well written, with a kind introduction of causality to NLP application (text classification)\n- The authors provide the proper theoretical formulation to apply causality for future NLP application research. The problem formulation to address robust generalization to OOD is a more principled way to tackle OOD generalization than domain adaptation based or attention based method; Estimate prediction on shifted test data $P*(y|do(x))$ by prediction on in-domain training data $P*(y|do(x))$, with assumptions in Sec 4.1.",
        "weaknesses": "- In Sec 4.2 theorem 1, the authors assume that the causal latent variable C between two environments (pre-trained and fine-tuned models) stays the same. However, this assumption seems a kind of logical leap, as there is no supporting experimental analysis or general consensus, and at the same time, practically not trivial. In other words, this assumption needs that practical solution (good fine-tuned model) is already fulfilled; if there exists a causally robust language model on each downstream task, why do we need OOD generalization of the pre-trained model?\n- Experiments are monotonic, so it is hard to comprehensively evaluate whether the suggested method increases OOD generalization.\n    - The available experimental results in the main body seem to repeat the same experimental design over just two datasets (though there are plenty of available classification benchmarks), which is insufficient for holistic understanding. Could you provide additional experiments on other dataset in diverse domain?\n    - There is no experimental analysis other than performance, so it is hard to understand how the designed algorithm actually works regarding causality. Could you provide more in-depth analysis not only performance?"
      },
      {
        "rating": "6",
        "confidence": "3",
        "summary": "The paper introduces a causal model to combat spurious correlations in NLU tasks and provides an algorithm to learn its causal features. Experimental results are provided at various strengths of spurious correlations, demonstrating their algorithm's generalization capability on OOD test sets where the traditional i.i.d. assumption is violated.",
        "strengths": "- The use of the front-door adjustment at the embedding level for LLMs appears to be novel. Recent work (e.g., https://arxiv.org/abs/2403.02738) applied it at the prompt level. \n- Assumptions are clearly stated and experimental results are provided across different instantiations of authors' method.\n- Methodology built on established self-supervised causal representation work in https://arxiv.org/pdf/2106.04619.",
        "weaknesses": "- The semi-synthetic and real-world experiments appear very similar. Both appear to be based on Amazon and Yelp review datasets, but the injected text of the real-world experiments are based on data source. Exploring datasets suggested in https://arxiv.org/pdf/2311.08648 may strengthen the experiments section.\n- More details on the connection to Theorem 4.4 in https://arxiv.org/pdf/2106.04619 would be appreciated."
      },
      {
        "rating": "5",
        "confidence": "2",
        "summary": "This paper proposes to solve OOD problems for LLM prediction tasks through causal invariance learning. It seeks to learn the causal feature through paired representations of the same input but under different models (pre-trained vs SFT). Then it produces p(y|do(x)) with the causal features.",
        "strengths": "The paper studies an important question: how to mitigate OOD in LLM prediction.",
        "weaknesses": "* I find the paper difficult to follow\n* The developed method is overly complicated, and there might be simpler ways to do it\n* The assumptions are very strong, but meanwhile I don't see the clear motivation of some design choices\n* There are many typos, sometimes in importance places (e.g. Step 4 in Algo 1)\nI will elaborate in questions part. I can adjust the points if my questions are addressed."
      },
      {
        "rating": "5",
        "confidence": "2",
        "summary": "This paper focuses on the out-of-distribution (OOD) generalization of language models (LMs). The authors hypothesize that the poor OOD generalization of LMs stems from their reliance on non-causal representations. To address this issue, the authors propose a causal front-door adjustment to augment the training data. Empirical evaluations on small-scale LMs demonstrate the effectiveness of the proposed method.",
        "strengths": "The motivation behind this paper and the proposed method is reasonable and well-justified.",
        "weaknesses": "**Unclear Method Description.** The authors use extensive mathematical derivations to analyze and explain the OOD generalization of LMs from a causal inference perspective. Although I appreciate the authors' efforts, I find it unclear how the method is actually implemented, particularly in Section 5. I would appreciate it if the authors could detail the implementation process without relying on math, specifically how a local value is constructed (Section 5.3) and how the model is trained and used for inference (Section 5.4).\n\n**(Possibly) Insufficient Evaluation.** While the proposed method shows effectiveness in the experiments, the choice of datasets appears relatively simple, and the LM backbone is somewhat limited. The authors use two sentiment classification datasets for evaluation, with `bert-base-uncased` as the LM backbone.\n\n- Regarding the model, given the significant advancements in existing large language models (e.g., LLaMA3-8b), I am concerned that the proposed method may not remain effective, as such models can easily handle a simple task like sentiment classification and achieve near-perfect performance. It would be helpful if the authors could demonstrate the method's effectiveness on stronger models.\n- Regarding the task, I also recommend that the authors evaluate their method on more challenging and commonly-used datasets, such as instruction-following and safety alignment. For example, some large language models like LLaMA-2-7B-chat are known to be over-conservative. During training (RLHF), they are fine-tuned to reject answering user questions that may lead to unsafe outputs. However, this often results in over-conservatism, causing the model to reject many safe requests. Could this be a sign of poor OOD generalization (in terms of safety) in these models? Is it possible to apply the proposed method to these tasks?\n\nI acknowledge that the second suggestion may be challenging to implement, but I encourage the authors to consider tasks beyond simple sentiment classification.\n\n**Writing Issues:** There are several writing issues in the paper:\n\n- What do $R_1$ and $R_0$ mean? When the authors introduced them in Line 243, they refer to \"variations of its (text's) representations,\" but in Line 261, they claim \"r getting its sentence summary $R_1$ and $R_0$.\"\n- Potential typos: Line 336: \"obtrain\" should be \"obtain.\"\n- Possible errors in Table 2: SWA outperforms the proposed method in the 2nd and 3rd columns.\n- Some full names and abbreviations are redundant, such as \"pretrained language models (PLMs)\" in the conclusion section. Since PLM was already defined earlier, it is unnecessary to restate the full term. If this section was revised by ChatGPT or another LLM (which often introduces abbreviations in its revisions as it does not have the full context of previous sections), I recommend that the authors review and remove these repetitions.\n\nHowever, since I am not an expert in causal inference, I acknowledge that my assessment may be limited. I will adjust my review based on other reviewers' feedback."
      },
      {
        "rating": "6",
        "confidence": "3",
        "summary": "The paper proposes to combine a pre-trained language model and a second fine-tuned model to learn two representations of a same input X and use the difference between the two representations to identify the causal factors that remain invariant to the distribution shift induced by fine-tuning. The resulting model is used to compute interventional queries, robust to further distribution shifts. The model is tested on semi-synthetic and real-world sentiment analysis benchmarks in i.i.d and o.o.d settings and outperforms self-supervised baselines.",
        "strengths": "The idea is novel and interesting and tackles the challenging problem of domain generalization. I find the combination between PLMs and causal inference particularly promising. The experiments are convincing as the proposed model performs significantly better in the o.o.d settings.",
        "weaknesses": "Although the idea is interesting, the main issue of the paper is that the theoretical basis is not explained in a clear and sound way. Many typographical errors and undefined terms greatly hinder the comprehension of the paper:\n\n1. The transportability concept, mentioned on line 187, is not properly defined and no references to prior work (e.g. [1,2]) are provided\n2. Theorem 2 identifies an interventional query $P(Y|do(X)$ based on the causal graph in Figure 1(c), but the variable X is not in that graph\n3. In Equation 3, $r_0$ and $r_1$ are not defined\n4. There is an inconsistent use of bold and calligraph fonts, for instance: are $\\mathbf{X}$ (appears in Assumption 1), $X$ (appears in Figure 1) and $\\mathcal{X}$ (appears in the \"Motivations and Intuition\" paragraph) the same quantities?\n5. In Algorithm 1, line 8, the term $\\bar{r_i}$ is used, I assume it should be $\\bar{x_i}$\n6. Again, in Algorithm 1, line 10, $f_\\phi$ is used without being defined\n7. I have also found many writing errors (e.g. missing words in sentences or wrongly spelled)\n\n\n[1] \"A General Algorithm for Deciding Transportability of Experimental Results\" [Bareinboim and Pearl, 2013]\n\n[2] \"Transportable Representations for Domain Generalization\" [Jalaldoust and Bareinboim, 2024]"
      }
    ],
    "rating_avg": 5.6,
    "confidence_avg": 2.6,
    "decision": "Reject",
    "meta_review": "This paper studies domain generalization behavior in supervised learning in the setting where the predictor is a pre-trained language model. Nominally, the goal is to learn the distribution P(Y | do(x)), on the basis that this will have some robustness to spurious correlations.\n\nThis paper generated considerable disagreement among the reviewers, so I read it myself. Ultimately, I agree with the reviewer criticisms that found the paper unclear in its exposition and assumptions (and thus also in its applicability). In particular, I found the explanation of the methodology difficult to follow, and had an even harder time understanding the connection between the theory and the method. These confusions seem to be common among the reviewers, though they vary in how much they are troubled by this. It is certainly possible that this is a good piece of work, but it is also clear that there at least needs to be a significant reworking for clarity before it can have real impact. As such, my view is that it is not yet ready for publication.\n\nBeyond the issues of clarity, I have to confess that I'm a bit worried about whether domain shifts in supervised prediction from text is still a real problem. Particularly, the dominant approach has shifted away from ERM to instead simply framing the prediction task in natural language (possibly with few shot examples) and using an LLM to complete it. It would be good to have at least one example of a problem where this more modern approach doesn't simply solve the language prediction problem (thus wholly circumventing the question of domain shifts)",
    "author_remarks": "",
    "decision_comment": ""
  },
  {
    "id": "mMXCMoU95Y",
    "title": "CAuSE: Post-hoc Natural Language Explanation of Multimodal Classifiers through Causal Abstraction",
    "authors": [
      "Dibyanayan Bandyopadhyay",
      "Soham Bhattacharjee",
      "Asif Ekbal"
    ],
    "abstract": "The increasing integration of AI models in critical areas, such as healthcare, finance, and security has raised concerns about their black-box nature, limiting trust and accountability. To ensure robust and trustworthy AI, interpretability is essential. In this paper, we propose CAuSE (Causal Abstraction under Simulated Explanation), a novel framework for post-hoc explanation of multimodal classifiers. Unlike existing interpretability methods, such as Amnesic Probing and Integrated Gradients, CAuSE generates causally faithful natural language explanations of fine-tuned multimodal classifiers' decisions. CAuSE integrates Interchange Intervention Training (IIT) within a Language Model (LM) based module to simulate the causal reasoning behind a classifier's outputs. We introduce a novel metric Counterfactual F1 score to measure causal faithfulness and demonstrate that CAuSE achieves state-of-the-art performance on this metric. We also provide a rigorous theoretical underpinning for causal abstraction between two neural networks and implement this within our CAuSE framework. This ensures that CAuSE’s natural language explanations are not only simulations of the classifier’s behavior but also reflect its underlying causal processes. Our method is task-agnostic and achieves state-of-the-art results on benchmark multimodal classification datasets, such as e-SNLI-VE and Facebook Hateful Memes, offering a scalable, faithful solution for interpretability in multimodal classifiers.",
    "keywords": [
      "Interpretability",
      "Causal Abstraction",
      "Multimodality",
      "Classification"
    ],
    "venue": "ICLR",
    "year": 2025,
    "pdf_url": "https://openreview.net/pdf?id=mMXCMoU95Y",
    "forum_url": "https://openreview.net/forum?id=mMXCMoU95Y",
    "reviews": [
      {
        "rating": "5",
        "confidence": "3",
        "summary": "The paper presents a novel framework to produce explanations for multimodal classifiers. The framework addresses several shortcomings of existing methods, aiming to produce natural language, causally faithful, and task-agnostic explanations. The authors provide theoretical guarantees on causal abstraction of their framework under specific assumptions. The authors introduce the Counterfactual F1 score as a proxy for causal faithfulness in multimodal classifier's explanations. The paper includes empirical comparisons to VLM-based baseline methods and justification for different components in their novel loss function, using well-established datasets e-SNLI and Facebook Hateful Memes.",
        "strengths": "+ The paper introduces a novel loss function to jointly train for generating natural language explanations and classifying with causal guarantees.\n+ The authors provide theoretical results under specific assumptions that guarantee causal abstraction between the classifier we want to explain and the machinery used to generate faithful natural language explanation.\n+ The authors provide reasonable baseline comparisons to VLM-based methods.\n+ The paper includes empirical validation for the need for multiple components in the loss function to generate coherent and faithful natural language explanations.\n+ The authors include case studies for both when the framework succeeds and fails to provide coherent and faithful explanations, giving some insights into the capabilities and drawbacks of the CAuSE framework.\n+ The architecture diagrams provide helpful intuition on how the CAuSE framework works.",
        "weaknesses": "+ The assumptions for Theorem 1 and 2 are restrictive and specifically require that the classifiers $\\mathcal{C}_1$ and $\\mathcal{C}_2$ share identical weights.\n+ The Counterfactual F1 score only accounts for the classifier $\\mathcal{C}_2$, without assessing the causal faithfulness of the LLM machinery $\\phi_2$ used to generate explanations. As a result, the conclusion drawn from the Counterfactual F1 score between the CAuSE framework and VLM-based baselines is unclear, making it difficult to determine if CAuSE achieves state-of-the-art results in causal faithfulness.\n+ Some architecture designs and choices for loss function components are insufficiently justified. (See Questions for questions about the motivation of specific choices)\n+ The authors identify scaleability as a challenge in prior methods (e.g., Amnesic Probing), but do not discuss scalability for the CAuSE framework.\n+ The paper’s structure hinders linear reading, with multiple references to sections and tables that appear much later. Additionally, the distance between when a choice is introduced and when it is justified makes it challenging to follow.\n+ Figures 1 and 2 would benefit from larger font sizes and detailed captions to enhance readability and comprehension of the CAuSE framework."
      },
      {
        "rating": "3",
        "confidence": "4",
        "summary": "The paper introduces the CAuSE framework for generating post-hoc natural language explanations for multimodal classifiers by leveraging causal abstraction. The proposed method aims to provide causally faithful explanations, evaluated using the proposed Counterfactual F1 score. Experiments are conducted on two visual-textual classification tasks:e-SNLI-VE and Facebook Hateful Memes.",
        "strengths": "- The paper investigates an important area of generating faithful natural language explanations for visual language models.\n- The paper proposes a causality-based approach for improving the faithfulness of explanations.",
        "weaknesses": "- The paper does not adequately validate the faithfulness of the generated explanations. More thorough investigation is needed to support the claims.\n- The evaluation metric is not sufficient to validate the faithfulness of explanations.\n- The paper lacks motivation for design choices in several components of the proposed method.\n- The paper suffers from unclear explanations of key components, making it difficult to follow some methodological details."
      },
      {
        "rating": "3",
        "confidence": "3",
        "summary": "This paper proposes a new framework for natural language explanations (NLEs) of Vision Language Models (VLMs). It introduces a new metric, counterfactual F1 score with which to self-assess its method.",
        "strengths": "- The paper makes strides on a relevant topic (NLEs for VLMs). Much work appears to have gone into architectural/training design.\n- The subject area is one of importance. Many results are amassed.",
        "weaknesses": "- While the paper seems to make good theoretical strides, it is nearly impossible to evaluate the given method against relevant baselines. The paper does verify that this is the first method of its type to compute NLEs directly from a classifier's hidden state. However, it does lack comparison against any other methods (black box or not) that would help significantly.\n- Readability is a major problem in the paper. Definitions and diagrams are piled somewhat haphazardly atop one another. Occasionally, vague justifications are used i.e. *Recent studies (Madsen et al., 2024) have highlighted these faithfulness issues, revealing inconsistencies when models are further probed* (not enough room is given for exposition).\n- The claims are elaborate in the paper (such as state-of-the-art performance on the justification that no other methods exist, as above), but the experimental evaluation is too small to justify such claims. I would recommend toning these down to some degree: *this ensures that CAuSE’s natural language explanations are not only simulations of the classifier’s behavior but also reflect its underlying causal processes*- How is it ensured? The paper later shows failure cases, which makes this statement confusing and the claim to be slightly too strong.\n- Typo: L49 *Visual Language Models*"
      }
    ],
    "rating_avg": 3.6666666666666665,
    "confidence_avg": 3.3333333333333335,
    "decision": "Reject",
    "meta_review": "This paper seeks to develop a posthoc explanation of multimodal classifiers based on causality and faithfulness. The reviewers raised several concerns including the strength of the conditions needed for the theorems, the complexity of the approach, a lack of justification of several design choices to name a few. The reviewers were through and followed up after the author response, which did not change their opinion.",
    "author_remarks": "",
    "decision_comment": ""
  },
  {
    "id": "GpUO6qYNQG",
    "title": "SpeechFake: A Large-Scale Multilingual Speech Deepfake Dataset Toward Cutting-Edge Speech Generation Methods",
    "authors": [
      "Wen Huang",
      "Yanmei Gu",
      "Zhiming Wang",
      "Huijia Zhu",
      "Yanmin Qian"
    ],
    "abstract": "As speech generation technology continues to evolve, the risk of misuse through deepfake audio has become a pressing concern, which underscores the critical need for robust detection methods.  However, many existing speech deepfake datasets fall short in terms of size, diversity, and linguistic coverage, limiting the ability of models to generalize effectively to unseen deepfakes. To address these limitations, we present SpeechFake, a large-scale dataset specifically designed for speech deepfake detection. With over 3 million deepfakes totaling more than 3,000 hours of audio, SpeechFake was generated using 40 different speech generation tools, including cutting-edge techniques, and spans 46 languages. This paper provides a detailed overview of the dataset’s composition and statistics, emphasizing its scale and diversity. Additionally, we establish baseline results for SpeechFake and explore how factors such as generation methods, language diversity, and speaker variation influence detection performance. We believe SpeechFake will be a valuable resource for advancing speech deepfake detection research, offering opportunities to explore new detection strategies and improve model robustness across diverse and evolving generation techniques. The dataset will be publicly available soon.",
    "keywords": [
      "dataset",
      "deepfake detection",
      "anti-spoofing",
      "speech generation"
    ],
    "venue": "ICLR",
    "year": 2025,
    "pdf_url": "https://openreview.net/pdf?id=GpUO6qYNQG",
    "forum_url": "https://openreview.net/forum?id=GpUO6qYNQG",
    "reviews": [
      {
        "rating": "6",
        "confidence": "4",
        "summary": "The paper introduces a novel database for speech deepfake detection, comprising a large-scale collection of samples generated by 40 different speech synthesis tools across 46 languages. Benchmark results accompany the dataset, with detailed analyses provided on performance across various subsets, each with a specific focus.",
        "strengths": "The proposed database stands out for its extensive coverage of languages and speech generation tools, providing a robust foundation for deepfake detection research. Additionally, the dataset includes rich metadata, which is invaluable for in-depth analysis of anti-spoofing performance or targeted optimizations. The exploration of generator types and the effects of language and speaker variability is particularly engaging and relevant to recent advances in the field.",
        "weaknesses": "While the dataset is comprehensive, the overall scope is closely aligned with previous work in the field, as acknowledged in Table 1. Although the paper offers a solid contribution, it represents an incremental rather than groundbreaking addition to the anti-spoofing community. The reviewer appreciates the authors' efforts but suggests that more extensive analyses or use cases could further strengthen the contribution. Potential extensions might include exploring additional anti-spoofing model variants, conducting detailed error analyses, or leveraging the dataset for novel applications using pre-trained anti-spoofing models."
      },
      {
        "rating": "6",
        "confidence": "3",
        "summary": "The paper introduces SpeechFake, a large-scale multilingual dataset designed explicitly for speech deepfake detection. It offers a vast collection of over 3 million samples (amounting to 3,000 hours of audio) generated using 40 advanced speech synthesis tools across 46 languages. The paper provides a comprehensive baseline evaluation for SpeechFake, analyzing factors like generation methods, language diversity, and speaker variation.",
        "strengths": "- SpeechFake Dataset: A large-scale and diverse dataset for speech deepfake detection, encompassing a wide range of speech generation methods. The dataset consists of 3 million utterances, totalling 3,000 hours. It would be beneficial if the authors open-source the entire dataset (including hidden), rather than just a subset.",
        "weaknesses": "- Multilingual Focus: While the work prioritizes multilingualism, it primarily focuses on English and Chinese. Training datasets are lacking for 37 out of the 46 languages, with only a set of 5,000 utterances released for testing purposes for each of these 37 languages.\n- Coverage of Speech Generation Tools: Although the dataset includes 40 different speech generation tools, it does not encompass all current techniques, nor does it provide a way to account for future techniques that may emerge. This limitation suggests that the dataset may not remain fully relevant over time and could require updates or recreation as the field advances."
      },
      {
        "rating": "5",
        "confidence": "4",
        "summary": "The paper introduces a new dataset, SpeechFake, for training and evaluating speech deepfake detectors.  The dataset is larger than previous such datasets, and includes deepfakes generated by a larger number (40) of speech generation systems, including text-to-speech (TTS), voice conversion (VC), and neural vocoders (NV).  The paper also provides baseline results using existing deepfake detection models, demonstrating that training the detectors on SpeechFake is more effective across multiple evaluation sets than training on a previous such dataset, ASV19, and measuring the detection performance across speakers, languages, and deepfake generation methods.",
        "strengths": "+ The paper addresses an important problem.\n\n+ The study of performance across multiple dimensions (languages, speakers, seen/unseen generation methods) is valuable.\n\n+ The dataset will probably be useful for research beyond deepfake detection, like data augmentaiton.",
        "weaknesses": "- The paper doesn't include enough empirical comparisons to make a convincing case for the value added of the new dataset.  It includes a comparison of training on the new dataset vs. on ASV19, but not vs. other existing datasets, or vs. combinations of existing datasets, which might provide a similar generalization benefit.\n\n- The contribution is a bit narrow for ICLR.  A dataset + baseline paper like this would be a better fit in a speech conference or related workshop.\n\n- The description of dataset construction needs more detail, e.g. how multiple speaker IDs were sampled and generated with each model.  Ideally the paper would include an \"algorithm\" for sampling examples using each method."
      }
    ],
    "rating_avg": 5.666666666666667,
    "confidence_avg": 3.6666666666666665,
    "decision": "Reject",
    "meta_review": "The paper introduces a large synthetic speech data set, with a particular focus on a wide range of synthesis models and languages.\n\nI recommend a rejection because of a lack of clear demonstrated value, as pointed out by all reviewers.\n\nNovelty of a data set paper should be demonstrated differently compared to a paper that proposes an approach to solving a problem. This paper did well demonstrating the wide variety of synthesis models and languages, but fails to show the value (i.e., challenge) that the data set brings. The problem is a combination of model choice and writing. The paper should really stress test the best models out there to demonstrate a clear challenge. Reviewers have given valuable suggestions, and the authors are encouraged to improve the paper based on the feedback.\n\nThe authors are also encouraged to improve the reproducibility of the data set so that others are able to automate/reproduce the process in future settings.",
    "author_remarks": "",
    "decision_comment": ""
  },
  {
    "id": "QIApiYYgLG",
    "title": "Discovering Clues of Spoofed LM Watermarks",
    "authors": [
      "Thibaud Gloaguen",
      "Nikola Jovanović",
      "Robin Staab",
      "Martin Vechev"
    ],
    "abstract": "LLM watermarks stand out as a promising way to attribute ownership of LLM-generated text. One threat to watermark credibility comes from spoofing attacks, where an unauthorized third party forges the watermark, enabling it to falsely attribute arbitrary texts to a particular LLM. While recent works have demonstrated that state-of-the-art schemes are in fact vulnerable to spoofing, they lack deeper qualitative analysis of the texts produced by spoofing methods. In this work, we for the first time reveal that there are observable differences between genuine and spoofed watermark texts. Namely, we show that regardless of their underlying approach, all current learning-based spoofing methods consistently leave observable artifacts in spoofed texts, indicative of watermark forgery. We build upon these findings to propose rigorous statistical tests that reliably reveal the presence of such artifacts, effectively discovering that a watermark was spoofed. Our experimental evaluation shows high test power across all current learning-based spoofing methods, providing insights into their fundamental limitations, and suggesting a way to mitigate this threat.",
    "keywords": [
      "llm",
      "watermarks",
      "spoofing"
    ],
    "venue": "ICLR",
    "year": 2025,
    "pdf_url": "https://openreview.net/pdf?id=QIApiYYgLG",
    "forum_url": "https://openreview.net/forum?id=QIApiYYgLG",
    "reviews": [
      {
        "rating": "5",
        "confidence": "3",
        "summary": "This paper explores forgery attacks on LLM watermarks, utilizing traces in forged texts that reflect the forger's partial knowledge, revealing observable differences between genuine watermarked texts and forged watermarked texts. The authors propose a statistical testing method, experimentally verifying that these traces can be detected to identify whether a watermark has been forged.",
        "strengths": "This paper investigates the forgery traces of attacks on LLM watermarks. \nIt provides definitions through formal descriptions and formula derivations, and designs a statistical testing method. The effectiveness of the testing hypothesis is validated through experiments. \nThe presentation of figures and tables is relatively clear.",
        "weaknesses": "1.There are various methods for adding watermarks to LLMs, and there may also be multiple ways to forge them. This paper only discusses the red-green watermarking scheme for LLMs and the forgery method of constructing datasets by querying a watermarked model, which is highly restrictive.\n2.The rationale for the assumptions in this paper is insufficient. The paper assumes that forgers, when constructing datasets by querying a watermarked model, will leave traces of forgery due to incomplete knowledge in the dataset. However, if the attacker queries the watermarked model again to supplement the missing knowledge in the forged dataset, they can bypass the limitations of this assumption. In this case, the premise does not hold, making the motivation of the paper weak."
      },
      {
        "rating": "6",
        "confidence": "3",
        "summary": "This paper investigates the vulnerabilities in watermarking LLMs due to spoofing attacks. While watermarks aim to identify AI-generated text, attackers can replicate them, falsely attributing unauthorized content to specific models. By analyzing \"artifacts\" left by spoofing techniques, the authors develop statistical tests to differentiate between authentic and spoofed watermarked text. Experiments show these tests are effective across various spoofing methods.",
        "strengths": "1. The paper provides a detailed analysis of the specific, observable artifacts left in spoofed texts, an underexplored area in watermark spoofing research.\n\n2. The authors conduct extensive experiments, testing their hypotheses across multiple models, parameter settings, and spoofing techniques, lending empirical robustness to their conclusions.",
        "weaknesses": "1. The paper focuses primarily on a specific watermarking scheme -- the KGW watermark. While this is an important and well-studied case, there are several newer watermarking designs that make spoofing attacks virtually impossible. These alternative methods could be used without the concerns associated with spoofing attacks. As such, the scope of the paper feels limited, as it does not consider the broader landscape of watermarking schemes. Furthermore, the paper mainly studies specific spoofing techniques, such as Stealing and Distillation, which may not fully reflect the evolving and diverse strategies available to attackers.\n\n2.  Some assumptions in the analysis are restrictive, particularly regarding the KGW watermark’s context size, often set at h=1. With this small context, green tokens are more likely to appear in the spoofer's training data, simplifying the spoofing process. For example, the assertion that \"If the context is not in D, the spoofer is forced to select the next token independently of its color\" mainly applies when h is larger, limiting its relevance to cases with small context sizes.\n\n3. The paper would benefit from a deeper exploration of how the context length h influences the statistical tests’ performance. Additionally, discussing broader applications and limitations for various watermark types could enhance the study’s relevance. For instance, cryptographic watermark designs, such as those based on pseudorandom error-correcting codes, may not face spoofing issues, and a comparison with these designs could provide more context on the strengths and weaknesses of KGW-style watermarks."
      },
      {
        "rating": "6",
        "confidence": "4",
        "summary": "This work proposes statistical tests that can differentiate spoofed texts from genuine watermarked texts, based on the intuition that spoofed text contains artifacts due to spoofers' limited knowledge.",
        "strengths": "1. This work investigates an interesting problem of whether the spoofed texts can be differentiated even if they trick the detector.\n\n2. It provides a theoretical demonstration regarding the proposed tests.\n\n3. The experiments are extensive, testing different language models and diverse settings.",
        "weaknesses": "1. The conclusion is overclaimed. This paper only examined learning-based spoofing attacks but claims that all state-of-the-art spoofing attacks leave artifacts in spoofed texts (in the abstract and introduction). What about spoofing attacks that exploit watermark robustness, e.g., Peng et al. [1] and Zhou et al. [2] in your references?\n\n2. The proposed tests are not practically useful, considering the performance is only good in some cases. In particular, from Table 1, the tests yield high TPR when $ T > 1000 $ and $ h = 3 $ or $ h = 1 $. However, spoofed texts from two learning-based attacks could achieve spoofing attacks when $ T < 1000 $. If their generated text has $ T = 500 $, the corresponding test performance at best is 0.62 (TPR@1%). Does this suggest that the model owner should deploy watermarking with $ h = 3 $?\n\n3. There is no explanation of the important variables or unclear definitions, impeding understanding (see question 1).\n\n\n4. Limited discussions. Intuition suggests that the reason for artifacts is that the spoofer only has partial knowledge due to their limited training data. How will the size of $ D $ affect the artifacts and the statistical test results? Would stronger attackers leave fewer artifacts by increase the size of $D$ or improving the sampling strategy by introducing some independence?\n\n\n\n\n\n\n----\n[1] Qi Pang, Shengyuan Hu, Wenting Zheng, and Virginia Smith. Attacking LLM watermarks by exploiting their strengths. arXiv, 2024.\n\n[2] Tong Zhou, Xuandong Zhao, Xiaolin Xu, and Shaolei Ren. Bileve: Securing text provenance in large language models against spoofing with bi-level signature. arXiv, 2024."
      },
      {
        "rating": "5",
        "confidence": "4",
        "summary": "This paper presents the first in-depth study of statistical artifacts in LLM watermark spoofing attacks. The authors demonstrate that current watermark spoofing methods leave detectable statistical patterns and propose a statistical testing framework to distinguish genuine watermarked text from spoofed ones.",
        "strengths": "1. First systematic investigation of quality characteristics in watermark spoofing, beyond mere success rates\n2. Strong theoretical foundation with rigorous statistical testing framework\n3.  Practical approach for detecting watermark spoofing, enhancing watermark reliability",
        "weaknesses": "1. The study's scope is primarily confined to the KGW watermark algorithm, leaving significant gaps in the evaluation of other important watermarking approaches. The effectiveness of the proposed method remains untested on unigram watermarking schemes  (zhao et al. 2023) that employ global green/red lists, as well as the KTH  (Kuditipudi et al. 2023)  method utilizing fixed watermark key lists. This limited coverage raises questions about the method's generalizability to alternative watermarking techniques widely used in practice.\n2.  The proposed approach imposes dual requirements of maintaining both significant green/red word ratios and cross-context consistency, which may compromise its robustness. While these requirements enhance the detection accuracy of spoofed watermark text, they could make the system overly sensitive to legitimate text modifications. Because text modification will also cause not consistent context watermark. The paper does not adequately address the critical trade-off between detection accuracy and robustness against common text editing operations. Further investigation is needed to determine whether the method can maintain its effectiveness while accommodating natural text modifications.\n3. The method's requirement for approximately 1000 tokens to achieve reliable detection presents significant practical limitations. This substantial text length requirement restricts the method's applicability in real-world scenarios, particularly for short-form content analysis."
      },
      {
        "rating": "6",
        "confidence": "3",
        "summary": "This paper proposes a hypothesis-test-based method to detect whether a watermarked text generated by an LLM is spoofed.",
        "strengths": "1. The proposed method can detect spoofed texts when the length of the text is large enough.\n2. Detailed theoretical analysis.",
        "weaknesses": "1. The insight of this paper depends on that 'if the prior contexts are not in the adversary's extracted dataset, the adversary will predict the next token randomly'. If so, utilizing a long context as the seed to determine the green-red split may easily defend the spoofing attack. The original watermark verification method (used in the watermarking scheme) may also be able to distinguish the true watermarked texts from the spoofed watermark texts. Further clarifying the challenges of detecting spoofed texts may help the readers better understand the technical contribution of this paper.\n2. Another concern is that this paper does not include any baseline method in the experiments. I think comparing with some baseline methods (e.g., the original watermark verification method) can help demonstrate the effectiveness of the proposed method.\n3. Section 5.1 presents the histograms of the distributions. However, a quantitative analysis (e.g., a hypothesis test to verify whether the distribution follows a normal distribution) can better help the readers understand the results.\n4. This paper may not be easy to read for readers who are not familiar with the statistics. I strongly suggest that the authors explain some uncommon symbols and operators. For example, the symbol in Eqs. (3a) and (3b) and the $\\xrightarrow{d}$ in Lemma 4.1."
      }
    ],
    "rating_avg": 5.6,
    "confidence_avg": 3.4,
    "decision": "Reject",
    "meta_review": "This submission proposes a forensic investigation of spoofing attacks against text watermarks for language models, which are attacks that spoof the watermark signature, injecting it into text not generated by the watermarked model. The submission shows that interestingly, for a relevant watermarking scheme spoofing attack, these attacks can in turn be detected.\n\nThis idea is interesting and the investigation by the authors has merit, but, as the topic of this discussion becomes a bit niche, it would have been good to see a broader discussion and formalization of the security problem of counter-spoofing across watermarking methods (i.e. to my understanding, current theory, such as in Section 4.1 is applicable only to the KGW watermark). The current submission reports interesting findings that could be extended into such a, more general, investigation, elevating it from its current current status that is a bit too close to an instance report to several reviewers.\n\nDue to this concern, and based on only muted support by reviewers, I do not recommend acceptance of this submission for now. I hope the authors are going to re-submit their extended analysis.",
    "author_remarks": "",
    "decision_comment": ""
  },
  {
    "id": "gTwD366p5I",
    "title": "VisualCoder: Guiding Vision Language Models in Code Execution with Fine-grained Chain-of-Thought Reasoning",
    "authors": [
      "Cuong Le Chi",
      "Chau Truong Vinh Hoang",
      "Phan Nhật Huy",
      "Dung D. Le",
      "Tien N Nguyen",
      "Nghi D. Q. Bui"
    ],
    "abstract": "Predicting program behavior and reasoning about code execution remain significant challenges in software engineering, particularly for large language models (LLMs) designed for code analysis. While these models excel at understanding static syntax, they often struggle with dynamic reasoning tasks. We introduce VisualCoder, a novel approach that enhances code reasoning by integrating multimodal Chain-of-Thought (CoT) reasoning with visual Control Flow Graphs (CFGs). By aligning code snippets with their corresponding CFGs, VisualCoder provides deeper insights into execution flow, enabling more accurate predictions of code behavior. Our experiments demonstrate that augmenting LLMs with visual CFGs significantly outperforms text-based CFG descriptions in code reasoning tasks. We address challenges in multimodal CoT integration through a reference mechanism, ensuring consistency between code and its execution path, thereby improving performance in program behavior prediction, error detection, and output generation.",
    "keywords": [
      "Multimodal Large Language Models",
      "Control Flow Graphs",
      "Visualized Code Representation",
      "Code Execution Reasoning",
      "Fault Localization",
      "Program Repair"
    ],
    "venue": "ICLR",
    "year": 2025,
    "pdf_url": "https://openreview.net/pdf?id=gTwD366p5I",
    "forum_url": "https://openreview.net/forum?id=gTwD366p5I",
    "reviews": [],
    "rating_avg": null,
    "confidence_avg": null,
    "decision": "N/A",
    "meta_review": "",
    "author_remarks": "",
    "decision_comment": ""
  },
  {
    "id": "NPDnRLFhc0",
    "title": "EvidenceBench: A Benchmark for Extracting Evidence from Biomedical Papers",
    "authors": [
      "Jianyou Wang",
      "Weili Cao",
      "Kaicheng Wang",
      "Xiaoyue Wang",
      "Ashish Dalvi",
      "Gino Prasad",
      "Qishan Liang",
      "Hsuan-lin Her",
      "Mingwang",
      "Qin Yang",
      "Gene W. Yeo",
      "David E Neal",
      "Maxim Khan",
      "Christopher D. Rosin",
      "Ramamohan Paturi",
      "Leon Bergen"
    ],
    "abstract": "We study the task of automatically finding evidence relevant to hypotheses in biomedical papers. Finding relevant evidence is an important stage when humans write systematic reviews about certain scientific hypotheses. We introduce EvidenceBench to measure models performance on this task, which is created by a novel pipeline that consists of hypothesis generation and sentence-by-sentence annotation of biomedical papers for relevant evidence, completely guided by and faithfully following existing human experts judgment. Our pipeline's value and accuracy is validated by teams of human experts. We evaluate a diverse set of language models and retrieval systems on the benchmark and find the performance of the best models still falls significantly short of expert-level on this task. To show the scalability of our proposed pipeline, we create a larger EvidenceBench-100k with 107,461 fully annotated papers with hypotheses to faciliate model training and development. Both datasets are available at https://github.com/EvidenceBench/EvidenceBench",
    "keywords": [
      "Biomedical Benchmark",
      "Scientific Information Retrieval",
      "Scientific Information Extraction",
      "Large Language Models",
      "BioNLP"
    ],
    "venue": "ICLR",
    "year": 2025,
    "pdf_url": "https://openreview.net/pdf?id=NPDnRLFhc0",
    "forum_url": "https://openreview.net/forum?id=NPDnRLFhc0",
    "reviews": [
      {
        "rating": "5",
        "confidence": "3",
        "summary": "This paper presents EvidenceBench, which is a benchmark for finding arguments supporting or against a hypothesis. They find hypotheses inside survey, and find supporting arguments from the same survey, and the original paper. \nThis paper also proposes metrics for the task and compares many LLMs' performance on the task. In addition, this paper also provides the fine-tuning results on the benchmark.",
        "strengths": "1. Identifying arguments supporting or against an argument is an important task.\n2. This paper proposes an annotation pipeline, which might be helpful for future tasks.",
        "weaknesses": "1. The paper spends too much effort on constructing the benchmark, but not many insights are provided through the experiment section.\n2. The writing can be largely improved. There's many places in the writing that are vague and not clear. \nFor example, the second paragraph in the introduction section: \n\"We consider the goal of understanding what is known in the literature about a scientific hypothesis.\nThis can be broken into several stages: searching for relevant papers; extracting information from\nthese papers; and aggregating this information. Our work focuses on the second stage.\"\nMy questions are:\na). what is precisely the research goal in terms of \"understanding what is known in the literature about a scientific hypothesis\"?\nb). why it can be broken into these three stages?\n\nIn line 047~048: \"These annotations are judgments which are ordinarily made by domain experts, and the benchmark should be faithful to these judgments\": what does it mean by \"the benchmark should be faithful to these judgements\"?\n\nIn line 048~050: \"Third, despite the complexity of annotation, the benchmark construction process should be scalable, providing a sufficient number of examples to accurately measure system performance\": what does it mean by \"should be scalable\"? what does it mean by \"providing a sufficient number of examples to accurately measure system performance\"? what is the relation between these two arguments?\n\nI found it very hard to read through the paper. I would suggest the authors for a major revision at least in terms of the writing."
      },
      {
        "rating": "6",
        "confidence": "3",
        "summary": "This paper studies the task of finding evidence for a hypothesis. The authors develop a pipeline for annotating biomedical papers for this task. Using the annotation pipeline, the authors build a benchmark of more than 400 papers. Additionally, the authors create a larger dataset containing 100K papers.\nThe authors also run experiments to evaluate the effectiveness of different approaches to the proposed task.",
        "strengths": "* The authors propose a practical task and evaluate the effectiveness of existing approaches to the task\n* A useful resource for benchmarking LLMs on the proposed task\n* The paper is well-structured and easy to follow, although some presentations can be further improved",
        "weaknesses": "There is no strong reason to reject the paper, although some issues related to clarity and presentation need to be improved.\n\n* The concept of `study aspect` is confusing, and I am unsure how the evaluation procedure considers it. For example, if a sentence is retrieved for the wrong aspect or multiple aspects.\n* Based on the task definition, the hypothesis is given. However, this may not be the case in the real world. It would be nice to see these tested models' sensitivity to the modified (paraphrasing) hypothesis.\n* The difference between `EvidenceBench` and `EvidenceBench-100k` is unclear (seems with or without human validation?)\n* The authors exclude figure and table, which might be very relevant and important for the proposed task."
      },
      {
        "rating": "6",
        "confidence": "4",
        "summary": "This paper introduces EvidenceBench, a scalable annotation pipeline designed for extracting and aligning evidence with specific hypotheses in biomedical literature. Study aspects and hypotheses are initially extracted from systematic reviews. A specialized alignment annotator then performs sentence-level annotations to link each piece of evidence directly to the corresponding hypothesis. To validate this approach, the authors use the pipeline to generate the expansive EvidenceBench-100k benchmark. Fine-tuned on this benchmark dataset, embedding models showed improved performance in the 'Result ER@Optimal' task, showing this standardized benchmark and evaluation framework will support the development of tools for automate evidence synthesis and hypothesis testing.",
        "strengths": "o\tThe original EvidenceBench evaluated the performance of selected LLMs and embedding models on evidence retrieval tasks and compared different prompting strategies, which revealed that GPT-4o is the SOTA LLM, and that embedding models underperform due to a lack of context awareness.\n\no\tThe EvidenceBench-100k fine-tuned E5-v2 model and Llama3-8B significantly improved on the result evidence retrieval task but trailed behind larger models, validating the effectiveness of the benchmark dataset.\n\no\tThe author presented the topic and their framework well, with detailed descriptions and clear figures illustrating the overall problem and their area.\n\no\tThis paper innovatively developed the pipeline for evidence retrieval for a given hypothesis and further annotated biomedical papers at the sentence level for better meta-analysis.\n\no\tThe authors conducted comprehensive experiments with both open-sourced and closed-sourced LLMs, and a small language model. Human experts were involved to validate study aspects generation and automate sentence annotation to enhance trustworthiness.",
        "weaknesses": "o\tThe authors claimed that their method using the SOTA LLMs reduces construction time from over 3,000 human hours for EvidenceBench to 3 hours. However, there is no evidence provided regarding how the 3 hours were concluded. Additionally, GPT4-0125, GPT4-o-mini, and Claude3-Opus are used during data generation without explanations of when to choose which.\n\no\tNo ablation study regarding how topics can influence the study aspect and hypothesis extraction is provided. The subsets used for experiments are randomly selected without considering the distribution of topics.\n\no\tThe experiments are conducted on a subset of the test dataset. Although EventBench-100K is comprehensive and large, only 300 data points are used to evaluate LLMs, which is a very small portion."
      },
      {
        "rating": "5",
        "confidence": "3",
        "summary": "This paper proposes a new task of finding evidence for a hypothesis. The authors built a large-scale dataset with reasonable costs using existing survey monographs and LLMs.",
        "strengths": "- The large-scale datasets are constructed using LLMs with fewer budgets.\n- Several evaluations of existing and fine-tuned models are provided and compared, showing the usefulness of the benchmark dataset for evaluating current LLMs' abilities.",
        "weaknesses": "- It needs to be clarified how the hypotheses from survey monographs are generally helpful.\n- The authors expect to provide immediate value to scientists as the first desiderate of the benchmark (lines 44-45), and the dataset creation involves several experts. Still, no manual analyses are provided for the results, so whether the results benefit scientists is unclear. \n- The proposed task focuses on the limited part of the practical problem; the task expects the candidate pool and needs to consider cases with evidence and with (the retrieval results of) the considerable paper pool (e.g., the entire PubMed database).\n\nTypo:\n- Line 509, Figure 3 should be Table 6."
      }
    ],
    "rating_avg": 5.5,
    "confidence_avg": 3.25,
    "decision": "Reject",
    "meta_review": "This paper introduces \"EvidenceBench\", a benchmark for extracting \"scientific evidence\" from biomedical papers. There was consensus that this effort addresses an important topic, and that the resultant resource may be useful. \n\nHowever, there are some basic conceptual issues here, which lessens the potential impact of the work. For example, as highlighted by reviewer D5dw, it is not really clear what constitutes a \"study aspect\" in general. The clarification offered in revision does not fully demystify this. Relatedly, the task presented is fundamentally sentence classification; the authors present this as \"evidence extraction\" intended to aid systematic reviews (per the opening paragraph of the Introduction), but it is not clear to me how extracting sentences from articles will speed up the systematic review process. For this one would need more precise data extraction targets aligned with reviewer needs. The authors might make an explicit argument for how retrieving evidence (i.e., sentences) for hypotheses is likely to help rigorous systematic review. (In rebuttal the authors claim this is a \"a concrete need in systematic review creation\" but fail to provide any evidence for this or explain how sentence retrieval would help.)\n\nAside from conceptual issues with the benchmark, the evaluation is also quite limited (see comments from FodM, D5dw).",
    "author_remarks": "",
    "decision_comment": ""
  },
  {
    "id": "Za3M6OZuCU",
    "title": "Actions Speak Louder Than Words: Rate-Reward Trade-off in Markov Decision Processes",
    "authors": [
      "Haotian Wu",
      "Gongpu Chen",
      "Deniz Gunduz"
    ],
    "abstract": "The impact of communication on decision-making systems has been extensively studied under the assumption of dedicated communication channels. We instead consider communicating through actions, where the message is embedded into the actions of an agent which interacts with the environment in a Markov decision process (MDP) framework. We conceptualize the MDP environment as a finite-state channel (FSC), where the actions of the agent serve as the channel input, while the states of the MDP observed by another agent (i.e., receiver) serve as the channel output. Here, we treat the environment as a communication channel over which the agent communicates through its actions, while at the same time, trying to maximize its reward. We first characterize the optimal information theoretic trade-off between the average reward and the rate of reliable communication in the infinite-horizon regime. Then, we propose a novel framework to design a joint control/coding policy, termed Act2Comm, which seamlessly embeds messages into actions. From a communication perspective, Act2Comm functions as a learning-based channel coding scheme for non-differentiable FSCs under input-output constraints. From a control standpoint, Act2Comm learns an MDP policy that incorporates communication capabilities, though at the cost of some control performance. Overall, Act2Comm effectively balances the dual objectives of control and communication in this environment. Experimental results validate Act2Comm's capability to enable reliable communication while maintaining a certain level of control performance.",
    "keywords": [
      "Markov Decision Process",
      "Channel coding",
      "Rate-Reward Trade-off",
      "Finite state channel"
    ],
    "venue": "ICLR",
    "year": 2025,
    "pdf_url": "https://openreview.net/pdf?id=Za3M6OZuCU",
    "forum_url": "https://openreview.net/forum?id=Za3M6OZuCU",
    "reviews": [
      {
        "rating": "8",
        "confidence": "2",
        "summary": "The paper presents an analysis and method to allow RL agents to transmit messages through control actions as sequences of visited states, trading off average reward for information rate of the transmitted message. They provide theoretical results on the maximum information theoretic capacity such transmissions have, and propose a model and algorithm to do this efficiently.",
        "strengths": "The main strengths of the paper are:\n- The problem and issues addressed are well stated and clear.\n- The theoretical results presented are interesting.\n- To the best of my knowledge, encoding messages in state-action sequences of RL agents is a novel idea.",
        "weaknesses": "The main weaknesses are:\n- I am not convinced of the significance of the work. Although the problem is relatively interesting, the theoretical results seem to fall a bit short, and the experiments are not very illustrative either (see questions below).\n- The notation is a bit cluttered and makes some technical statements hard to follow. I understand that authors make use simultaneously of RL notation and FSC notation, but as is, it is confusing. Eg: $x$ is used for actions, but in line 170 there is $a_t$ which seems to be used for actions too. $\\Epsilon$ and $\\pi$ seem to be used for policies, sometimes in the same statement. In line 449 there is a $\\mathcal{L}_{cn}$ which is not defined. In Appendix 1, the proof for the main theorem in Section 4 is presented, but immediately after the authors state that this section makes use of results in section 5 for the proof. $s^+$, $s_{t+1}$ and $s^{t+1}$ seem to be used for the same variable.\n- It is not obvious to distinguish whether the experiment environments are a common benchmark in other information theoretic RL work, or they have been specifically selected for this particular application. I understand that the method is novel, and therefore there may not be other benchmarks to compare to, but some justification for the particular choice of the experimental tasks would be beneficial."
      },
      {
        "rating": "5",
        "confidence": "4",
        "summary": "This paper considers the problem of communication in decision-making problems, they consider communicating through actions, where the message is embedded into the actions of the agents for interacting with environments. The authors model the MDP environment as a finite-state channel (FSC), with actions as the input and the states of the receiver as the output. They propose a way to balance the long-term reward and the communication compacity and show that they could achieve both optimal policies for return and minimize the communication cost at the same time.",
        "strengths": "1. This paper is well-written and well-organized.\n2. The proposed Act2Comm effectively balances the dual objectives of control for total return and communication cost.",
        "weaknesses": "1. Act2Comm assumes a pre-determined control policy $\\pi$, which means it also needs to optimize the gap between this target policy and the Act2Comm learned policies. Could add a return gap part to further stabilize this procedure. Refer to this paper here 'Chen, J., Lan, T., & Joe-Wong, C. (2024). RGMComm: Return Gap Minimization via Discrete Communications in Multi-Agent Reinforcement Learning. Proceedings of the AAAI Conference on Artificial Intelligence, 38(16), 17327-17336. https://doi.org/10.1609/aaai.v38i16.29680'.\n2. I suggest the authors add a pseudo code in the appendix to further assist the readers to know the whole training process. Right now the order of training the control policies and the communication messages is unclear. \n3. The testing environments are too simple for testing MARL-Comm methods, which only consist of 3 states or 27 states, and 2 or 3 discrete actions. The methods should be tested in continuous control environments.\n4. There are no baselines for comparing the Act2Comm algorithms for the empirical evaluation. This may affect the theoretical results' soundness.\n5. I did not find the submitted codebase in this paper's submission files. The reproducibility might be a problem."
      },
      {
        "rating": "6",
        "confidence": "3",
        "summary": "The proposed Act2Comm algorithm presents a multi-objective optimization for communication via the MDP state. This can be beneficial e.g. for multi agent scenarios in hostile environments where no dedicated communication infrastructure is available. In this case, the policy acts both as a message encoder as well as a controller. This requires integrating communication (such that a certain code rate and error probability is achieved) and control (such that a minimum return is achieved). Act2Com presents a transformer-based approach to this challenge.",
        "strengths": "S1: The idea appears to be novel and has not yet been addressed before.\n\nS2: The paper is mostly written well.",
        "weaknesses": "W1: The paper requires further clarification and explanation of several critical aspects as lined out in the questions. \n\nW2: The setting relies on finite state and action spaces and does not yet address multi-agent scenarios. \n\nW3: No code base provided.\n\nW4: The structure is not ideal in that Theorem 1 is introduced in Section 4, but the proof of Theorem 1 requires results from Section 5.\n\nFurther (minor) weaknesses:\n* Figure 1 is pretty crowded and does not look nice\n* Typo l. 131 „Blackwell Blackwell“\n* Typo l. 229 „use“s"
      },
      {
        "rating": "8",
        "confidence": "3",
        "summary": "This paper studies the fundamental tradeoff between the information content of an agent’s actions and the long-term performance of the agent in an MDP. This tradeoff is formalized as a convex optimization problem in the context of discrete state and action spaces. A transformer-based approach is then presented to approximate policies which solve a variant of the aforementioned problem, and results are presented in two small toy examples.",
        "strengths": "* The connection between information content and policy performance is of great theoretical and practical interest; this paper appears to provide a clean characterization of the tradeoff in finite state/action MDPs.\n* The paper also proposes a deep learning-based scheme for generating policies which balance transmission rate and policy performance that—due to its use of neural networks—could (optimistically?) scale to larger problems.",
        "weaknesses": "* I was surprised not to see papers like “Least inferable policies for Markov decision processes” referenced in the related work discussion. There are other papers from some of these authors which, if memory serves, essentially try to find policies which balance entropy of the state distribution with expected future reward. I believe the main difference is that they were trying to maximize entropy of the state distribution, which amounts to making the capacity of your action-state channel very small. But I imagine it’s just a sign flip to get the other direction. I would appreciate some discussion here.\n* Nitpick: line 131 should use \\citep for the Blackwell reference. What does “indecomposable” mean?\n* In the MDP preliminaries, don’t we need r() to be bounded in order to ensure that (1) is well-posed?\n* nitpick: it would be helpful to define “unichain” for unfamiliar readers\n* From only reading the main text, I would assume that Theorem 1 is surely known in the literature, and is a direct corollary of Shannon’s classic 1948 result, but adapted to the EAS channel. However, appendix A.1 presents a fairly involved proof. Please adjust the main text to explain what is new about this result from existing literature.\n    * There should be some statement of proof for every theorem/lemma, or at least a clear statement that proofs can be found in a specific appendix. I did not see such a statement (apologies if I missed it).\n* nitpick: it should be “ascent” not “decent” in line 306. Also some mention should be made of the inequality constraint here.\n* I suggest that the authors have a bit more of a discussion around lemma 1 to explain how the concavity wrt V will be used later. Currently, lemma 1 interrupts the flow a little.\n* nitpick: is the * in (12) multiplication? If so, I suggest using \\cdot. Similar suggestion on line 418.\n* The authors should clarify the discussion of non-differentiability of f_U in line 414 and below. \n* “critic network with 3 linear layers” (line 431) -> does this imply that there are no nonlinearities? Perhaps: “fully-connected layers” is what is meant here?\n* I am having a lot of difficulty following the logic of section 5 and would appreciate it if the authors could revise the presentation to more clearly articulate the key ideas, how they relate to the problem in Theorem 2, why each idea is necessary, etc.\n    * For example, I do not understand what the role of the critic is, i.e. what its inputs and outputs are and how they relate to the problem at hand. \n    * To be blunt, the first part of this paper (through section 4) is lovely, but section 5 is so confusing that it makes me seriously question my understanding of the problem from section 4. If this can be adequately addressed, I am very happy to raise my score. Specifically, I suggest that the authors:\n       1. Provide a high-level overview of how the approach in Section 5 relates to and differs from the problem formulation in Theorem 2.\n       2. Clearly explain the role of each component (e.g., the critic network) in the proposed approach, including its inputs, outputs, and how it contributes to solving the problem.\n       3. Include a diagram or flowchart illustrating the relationships between different components of the proposed method.\n       4. Consider reorganizing the section to first present the overall approach, then dive into the details of each component."
      }
    ],
    "rating_avg": 6.75,
    "confidence_avg": 3.0,
    "decision": "Accept (Poster)",
    "meta_review": "This paper introduces an analysis and method enabling reinforcement learning (RL) agents to transmit messages through control actions, represented as sequences of visited states. The approach balances the trade-off between average reward and the information rate of the transmitted message. The authors derive theoretical bounds on the maximum information-theoretic capacity of such transmissions and propose an efficient model and algorithm to achieve this. While there were concerns raised by the reviewers, the rebuttal has helped address the key issues.",
    "author_remarks": "",
    "decision_comment": ""
  },
  {
    "id": "L6gyOOJYt2",
    "title": "Sampling Process Brings Additional Bias for Debiased Recommendation",
    "authors": [
      "Chunyuan Zheng",
      "Haoxuan Li",
      "Hao Wang",
      "Chuan Zhou",
      "Xu Chen",
      "Mingming Gong"
    ],
    "abstract": "In recommender systems, selection bias arises from the users' selective interactions with items, which poses a widely-recognized challenge for unbiased evaluation and learning for recommendation models. Recently, doubly robust and its variants have been widely studied to achieve debiased learning of prediction models. However, if the users and items in the training set are not exactly the same as those in the test set, even if the imputed errors and learned propensities are accurate, all previous doubly robust based debiasing methods are biased. To tackle this problem, in this paper, we first derive the bias of doubly robust learning methods and provide alternative unbiasedness conditions when users and items are sampled from a superpopulation. Then we propose a novel superpopulation doubly robust target learning approach (SuperDR), which is unbiased when either the imputation model or propensity model is correctly specified. We further derive the generalization error bound of the proposed method under superpopulation, and show that it can be effectively controlled by the proposed target learning approach. We conduct extensive experiments on three real-world datasets, including a large-scale industrial dataset, to demonstrate the effectiveness of our method.",
    "keywords": [
      "Superpopulation",
      "Selection Bias",
      "Recommender System"
    ],
    "venue": "ICLR",
    "year": 2025,
    "pdf_url": "https://openreview.net/pdf?id=L6gyOOJYt2",
    "forum_url": "https://openreview.net/forum?id=L6gyOOJYt2",
    "reviews": [
      {
        "rating": "3",
        "confidence": "3",
        "summary": "The authors first derive the bias of existing DR methods under a \"superpopulation\" scenario, where users and items differ between training and test sets.",
        "strengths": "1.\tThe paper is well written and easy to follow.\n2.\tThe paper provides theoretical proof and experimental results of the SuperDR, demonstrating its robustness and effectiveness across different datasets.",
        "weaknesses": "1.\tThe most critical issue is that this paper assumes the users or items in the training set and test set are different. I don’t quite understand the rationale behind this assumption. Why does selection bias exist for newly added users/items that have not yet been interacted with?\n2.\tThe appearance of new users/items in the test set is essentially a cold-start problem. Could the authors compare their results with existing cold-start methods? Alternatively, could this approach also be plugged into cold-start methods?\n3.\tWhy is the dataset size so small? Why not use a larger dataset, such as the Amazon dataset or others?\n4.\tIn the experiment, when the sampling rate is not equal to 1, how are the embeddings for user/item that have not appeared in the training set handled? Are they initialized completely randomly?"
      },
      {
        "rating": "3",
        "confidence": "4",
        "summary": "This paper points out that existing debiased recommendation methods usually assume that training and testing sets contain the same set of users and items, which may have limitations. It proposes a novel superpopulation doubly robust target learning method (SuperDR). Its core idea is to develop an additional pre-optimization process to control the covariance based on the bias terms of the doubly robust estimator derived under the superpopulation. The effectiveness of SuperDR is verified on three public datasets.",
        "strengths": "S1: Further improving the performance of debiased recommendations is valuable to enhance the trustworthiness of current recommender systems.\n\nS2: Some theoretical insights into this research question are provided.\n\nS3: Experimental results in various aspects are provided on multiple public datasets (including a dataset for industrial scenarios).",
        "weaknesses": "W1: The writing of the paper seems somewhat hasty, with some key details missing and some descriptions challenging to understand. Here are some examples:\n* In Section 1, critical undescribed content is why existing debiased recommendation methods must be unbiased in a train-test setting with the same set of users and items. Based on the current description, it is not intuitive.\n\n* For Section 4.1, why, in a general scenario, does the learned imputed error or propensity estimate become the expectation? It is also not intuitive. In Section 2, the authors also mentioned that this work extends the previous methods for deterministic error imputation and propensity models to probabilistic ones. This is hard to understand.\n\n* In Section 4.2, the imputation balance correction calculation process is unclear. For example, what does $m$ mean? Is $\\epsilon$ a value? What are the meanings of the two terms of this imputation balance correction? Why does it achieve the desired control process?\n\n* What is the meaning of the superscript Bal used in many losses?\n\n* No description is provided for the division of the data set in the experiment.\n\n* In Section 5.1, MF generates embeddings for each user and item, which are then used as their features in MLP. The rationality of this process is questioned.\n\nW2: The motivation proposed may not be convincing enough. In real-world scenarios, it is rare to directly use a model trained on user (or item) set A to predict user (or item) set B. This is inherently risky because the embeddings of external users (or items) are completely random and unlearned. In fact, if SuperDR does not use a pre-trained recommendation model (such as MF) to obtain a set of well-trained user and item embeddings in the experiment, I think it will also encounter this problem.\n\nW3: The core contribution of the proposed solution compared to existing work is introducing an optimization process that controls covariance. However, there is a lack of more in-depth analysis, and the overall contribution is not significant enough.\n* In Section 4.1, the bias term consists of two parts. Although the first part (i.e., covariance) is repeatedly emphasized, it is unclear how the second part is optimized in SuperDR.\n\n* From an intuitive point of view, why does controlling for covariance help correct estimates of external populations? What is the connection between them?\n\n* Based on Algorithm 1, SuperDR does not make many major changes to the DR architecture. This makes people worry that it may not have much gain compared to DR in some cases. In fact, based on the results in Table 1, we can find that its gain is indeed marginal, especially on some larger datasets. In addition, the pre-optimization process for covariance seems difficult, which may cause unstable training in some scenarios.\n\nW4: The current experiments are not sufficiently powerful and have many limitations.\n* As described in the previous concern, the process of generating features for users and items is somewhat unusual.\n\n* In real scenarios, there is much feature information besides user and item IDs. It is unknown how they can be applied to SuperDR.\n\n* Considering that current recommendation systems contain many representative architectures, using only a simple MLP as a skeleton model is flawed and lacks applicability.\n\n* Debiased recommendation is a hot research topic with many recent works. Some newer methods (e.g. published in 2024) should be included as baselines."
      },
      {
        "rating": "8",
        "confidence": "4",
        "summary": "This paper introduces Superpopulation Doubly Robust Target Learning (SuperDR), a method designed to address selection bias in recommendation systems when training and test data are sampled from a larger superpopulation with limited overlap. SuperDR extends traditional Doubly Robust (DR) methods by incorporating probabilistic imputation and propensity models to better handle uncertainty and variability across superpopulation samples. A key innovation in this approach is the inclusion of a covariance control mechanism within the loss function, which aims to reduce bias by minimizing the empirical covariance between imputation and propensity errors. Theoretical analysis suggests that controlling this covariance can help mitigate bias under superpopulation conditions, and the authors provide a generalization error bound to support this approach. Experiments on several recommendation datasets demonstrate that SuperDR outperforms traditional DR methods and other baselines, particularly in settings where train and test sets have limited overlap in user-item pairs.",
        "strengths": "__Innovative perspective for the source of bias in DR estimation__:\nThis paper pioneers the extension of Doubly Robust (DR) estimation to settings where training and test data are sampled from a superpopulation, meaning that there may be limited or no overlap in user-item pairs across the datasets. SuperDR specifically addresses scenarios where the training and test sets differ, which is common in real-world recommendation systems as user bases and item inventories evolve. \n\n__Covariance Control to Address Bias from Imputation and Propensity Correlations__:\nA major technical contribution is the introduction of a covariance control term within the loss function, which is designed to minimize empirical covariance between errors in propensity score estimation and imputed errors. In superpopulation contexts, these two types of errors can correlate, introducing additional bias in the DR estimator. By actively controlling this covariance, SuperDR reduces the bias resulting from these correlations, making the estimator more robust in settings with non-overlapping samples. \n\n__Solid theoretical and Empirical Support for the Proposed Adjustments__:\nThe paper offers strong theoretical validation by deriving a generalization error bound using concentration inequalities. This bound supports SuperDR’s robustness claims under superpopulation sampling. Empirically, SuperDR is tested across several recommendation datasets and demonstrates improvements over traditional DR methods and other baselines. The ablation studies prove the effectiveness of the variance reduction techniques proposed.",
        "weaknesses": "__Some claims in the paper needs more clarifications__:\nThe paper claims \" if the users and items in the training set are not exactly the same as those in the test set, all previous doubly robust based debiasing methods are biased\". The paper’s statement oversimplifies the requirements for unbiasedness in DR estimation. In fact, DR methods do not require an _exact_ match between the users and items in the training and test sets. It might ask for positivity and overlap of supports [1] although an exact match surely satisfy this requirement. \n\nThe paper claims the added correction has no harm, while it is theoretically correct in the case of the empirically covariance drops to zero. However, in practical scenarios, where exact zero empirical covariance is challenging to achieve due to model imperfections, 𝜖 may not fully converge to zero and could introduce slight adjustments, potentially affecting the \"no harm\" property.\n\n__The presentation of this paper can be improved__:\nThe lack of indexing in key formulas, especially when dealing with complex constructs like superpopulation, covariance terms, and probabilistic models, makes the paper harder to follow.\n\nThe paper has solid theoretical foundations, but it could benefit from more intuition and clearer explanations on why certain choices (like probabilistic models and covariance control) are necessary. The presentation would be stronger if it provided a more intuitive context for readers to understand how the superpopulation setting is motivated.\n\n\n\n\n[1] Off-policy Bandits with Deficient Support, Noveen Sachdeva, Yi Su, Thorsten Joachims, KDD 20"
      },
      {
        "rating": "3",
        "confidence": "3",
        "summary": "The paper addresses the issue of selection bias in recommender systems. The authors present a new approach to tackle biases caused by the sampling process, particularly in situations where users and items in training data do not match exactly with those in test data. This misalignment introduces additional biases in traditional doubly robust (DR) models. The authors propose a superpopulation-based DR model, which introduces mechanisms to control the biases introduced by sampling by modifying the imputation model to reduce generalization error. Extensive experiments on multiple real-world datasets demonstrate that SuperDR achieves more accurate and unbiased recommendations than existing DR approaches.",
        "strengths": "1. The paper presents a novel theoretical extension of the DR estimator, introducing a covariance control mechanism that provides unbiased recommendations even in scenarios with sampling-induced biases. This significantly advances the field of unbiased learning in recommendation systems, e.g., cold start users, cold start items.\n\n2. The authors conduct thorough evaluations using three real-world datasets, including large-scale industrial data, which effectively show SuperDR’s advantage over conventional DR and other baselines.",
        "weaknesses": "1. In theorem 3, the SuperDR approach’s generalization upper bound is kind of loose. What is the $K_{\\phi}$? It's better to clarify the definition and interpretation of $K_{\\phi}$.\n\n2. What is the Rademacher complexity for this model. Provide a more detailed analysis of the Rademacher complexity for this specific model. What is the insight from this bound? Without a tight bound, practitioners may not be able to fully trust the model’s debiasing performance across various scenarios, limiting the method’s utility for diverse recommendation tasks where model generalization is critical.\nDiscuss the practical implications of this bound for different recommendation scenarios. Compare this bound to bounds for other debiasing methods\n\n3. Although large-scale datasets are used, the paper lacks a detailed discussion on the computational overhead and scalability of the proposed model in comparison to traditional DR models, which could impact its adoption.  Authors can provide the runtime comparisons between SuperDR and traditional DR models on datasets of varying sizes or memory usage analysis or discuss of how the method scales with increasing numbers of users/items"
      },
      {
        "rating": "5",
        "confidence": "3",
        "summary": "This paper introduces a new doubly robust estimator to tackle the challenges when the users and the items are sampled from superpopulation. The designed imputation is weighted by the propensity score. Extensive experiments have been conducted in three datasets with various evaluation metrics.",
        "strengths": "1. The paper's presentation is well-structured and clear, making it easy for readers to follow the logical flow.\n2. The authors provide a comprehensive theoretical analysis, rigorously demonstrating the advantages of their proposed methods over DR. The mathematical foundations are thoroughly explained and validated.\n3. The experimental evaluation is robust, featuring diverse state-of-the-art baselines. The proposed approach achieves superior performance compared to existing methods, establishing new benchmarks in the field.",
        "weaknesses": "1. The distribution problem of the sampling lacks practical significance. Because the debiasing methods also trained on the full dataset, $D$, rather than only training on observed data.\n2. The improvement of some metrics is quite low and is not statistically significant.\n3. Some definitions of symbols are missed, for example, $m$ used in line 210."
      }
    ],
    "rating_avg": 4.4,
    "confidence_avg": 3.4,
    "decision": "Reject",
    "meta_review": "The submission initially received negative feedback from reviewers, and the authors did not engage in the discussion of the rebuttal phase. The current version can't be accepted as an ICLR paper.\n\nI have summarized the primary issues that need to be addressed:\n\n1. **Validation of Assumptions**: The authors make several assumptions regarding the training and testing data that require validation. \n\n2. **Writing and Clarity**: The manuscript needs significant improvement in clarity and coherence. Key technical details and contributions should be clearly articulated to enhance the reader's understanding.\n\n3. **Rademacher Complexity**: The paper presents a loose bound, and the upper bound for Rademacher complexity is absent. \n\n4. **Experimental Significance**: The significance of the experiments conducted is relatively low, primarily due to the use of somewhat small datasets. Expanding the dataset or enhancing the experimental design could provide more robust findings.\n\nBased on these concerns, I recommend rejecting the submission. However, I encourage the authors to consider the reviewers' suggestions, as they provide valuable insights to refine and strengthen their work for future submissions.",
    "author_remarks": "",
    "decision_comment": ""
  },
  {
    "id": "DYXl6P70aH",
    "title": "Benchmarking Robustness of Foundation Models for Remote Sensing",
    "authors": [
      "Hakob Tamazyan",
      "Ani Vanyan",
      "Tigran Galstyan",
      "Alvard Barseghyan",
      "Anna Khosrovyan",
      "Vahan Huroyan",
      "Hrant Khachatrian"
    ],
    "abstract": "Foundation models have significantly advanced machine learning applications across various modalities, including images. Recently numerous attempts have been made on developing foundation models specifically tailored for remote sensing applications, predominantly through masked image modeling techniques. This work explores the essential characteristics and performance expectations for a foundation model in aerial imagery. We introduce a benchmark designed to evaluate the model's performance as well as robustness to changes in scale and spectral bands of the input. Our benchmarks encompass tasks unique to aerial imagery, such as change detection and scene classification, and utilize publicly available datasets RESISC45, BigEarthNet, LEVIR-CD and OSCD. We evaluate recently proposed foundation models on the benchmark. Furthermore, we explore the impact of various design choices in pretraining and fine-tuning on the performance of the models on our benchmark. Specifically, we pretrain several variations of a self-distillation based self-supervised model on aerial imagery datasets, including one without scale-augmentations and another one with a pretrained mask decoder module.",
    "keywords": [
      "aerial imagery",
      "foundation models",
      "self-supervised learning",
      "benchmark"
    ],
    "venue": "ICLR",
    "year": 2025,
    "pdf_url": "https://openreview.net/pdf?id=DYXl6P70aH",
    "forum_url": "https://openreview.net/forum?id=DYXl6P70aH",
    "reviews": [
      {
        "rating": "3",
        "confidence": "5",
        "summary": "This paper examines the key characteristics and performance benchmarks for foundation models applied to remote sensing data. The authors present a comprehensive benchmark framework to assess the performance and robustness of these models across diverse scales and spectral bands. This benchmark includes tasks such as change detection and scene classification, leveraging publicly available datasets like RESISC45, BigEarthNet, LEVIR-CD, and OSCD. The topic is highly relevant, as establishing benchmarks for remote sensing (RS) foundation models is essential for advancing this field.",
        "strengths": "1) The topic of this paper is valuable, as benchmarking remote sensing (RS) foundation models is crucial for the future development of this field.\n2) The experiments on spectral bands and the idea of a pretrained mask decoder are interesting, and I encourage the authors to expand and reorganize these sections. However, in its current form, I believe the paper still falls short of the standards required for ICLR.",
        "weaknesses": "1) I am concerned about the label quality of the datasets used. For example, BigEarthNet V2 [8] provides a significant improvement over BigEarthNet. While I understand that it might not be feasible to use BENv2 given its release date, the authors should consider data and label quality when selecting datasets for benchmarking. The authors shall discuss how they assessed the quality of the datasets used and what impact potential label quality issues might have on their results. \n\n2) How do the authors define the generalizability of foundation models? Given that different foundation models are trained on different datasets or combinations, comparisons may be problematic. For instance, DinoV2 uses data augmentation techniques like random cropping and scaling, which enrich the spatial resolution of the training data. However, not all foundation models use such augmentations, potentially making direct comparisons unfair. The authors should address these inconsistencies and avoid drawing broad conclusions about generalizability without accounting for differences in training data and augmentations. The authors are suggested to provide a clear definition of generalizability in the context of their study and include a detailed analysis of the training data and augmentation techniques used by each evaluated model, and discuss how these differences might impact the comparisons and conclusions drawn from the benchmark results\n\n3) It would be beneficial to also compare the foundation models with smaller models like ResNet50. This comparison could illustrate the advantages and trade-offs of using larger foundation models versus smaller ones.\n\n4) The paper claims that the performance gap between frozen models and full fine-tuning is relatively large for models such as ChannelViT-S, Prithvi, and Clay v1. However, I am concerned about how the learning rate was selected. Using the same learning rate across different models may not be optimal. Moreover, different learning rates for the backbone and the task-specific heads (e.g., classification, segmentation, change detection) should be considered. Without optimizing these hyperparameters for each model, the conclusions drawn regarding their performance are not convincing.\n\n5) The authors conclude that all tested models struggle with generalizability across scales and spectral bands. While foundation models are expected to generalize well to different data sources, this relies on training with large, diverse datasets. It is therefore expected that models trained on aerial images may perform poorly on satellite images due to the inherent differences between these data sources. I recommend that the authors further investigate the relationship between pre-training datasets, data augmentations, and model generalizability."
      },
      {
        "rating": "1",
        "confidence": "4",
        "summary": "This paper introduces a benchmark aimed at evaluating the robustness and generalization capabilities of foundation models specifically designed for remote sensing applications. The authors assess performance across various image resolutions and spectral bands, focusing on tasks like change detection and scene classification. Using aerial imagery datasets such as RESISC45, BigEarthNet, LEVIR-CD, and OSCD, the paper benchmarks several models and explores the influence of pretraining and fine-tuning strategies on model robustness.",
        "strengths": "1. The paper's attempt to establish a generalization benchmark tailored to remote sensing fills an essential gap, addressing unique requirements in aerial imaging, like resilience to scale and spectral variations.\n2. By focusing on change detection and scene classification, the paper makes an effort to connect benchmark results with real-world implications, enhancing the relevance of the benchmark.",
        "weaknesses": "1. Although the paper aims to establish a benchmark for evaluating foundation models in remote sensing, the scope of experimentation is limited. The study only explores a small subset of possible variations and factors within the remote sensing domain, which weakens its potential to serve as a comprehensive benchmark for ICLR readers. For instance, the study could have broadened its scope by including more downstream tasks, such as object detection and segmentation. Additionally, it fails to address important variables such as geographical location, times of the day, or seasonal variations, all of which could significantly impact the models' performance in real-world applications. By focusing on just a few experimental parameters, the study provides only a partial view of the potential applications and robustness of these foundation models in remote sensing.\n2. Remote sensing data includes numerous factors that could influence model performance, such as resolution, spectral band variability, and environmental conditions. However, the current study only examines resolution and spectral bands, omitting several critical factors that users in the field of remote sensing would consider valuable. For instance, controlling for environmental factors (e.g., time of year, weather conditions) or ablation studies on model and dataset size could provide more meaningful insights. Additionally, benchmarks could have varied the type of pretraining datasets used, comparing options like FAIR1M and MillionAID, which cater specifically to different data characteristics. This limited approach leaves significant gaps in understanding the models' broader adaptability and robustness.\n3. One of the most significant weaknesses of the paper is its lack of coverage of remote-sensing-specific foundation models, particularly those developed with unique properties for remote sensing challenges. Models such as Scale-MAE and SatMAE are designed to address the exact generalization challenges discussed in the paper, such as resilience to spatial, temporal, and spectral variability. Scale-MAE, for instance, is specifically designed to handle resolution variations, a critical factor in satellite imagery, while SatMAE incorporates temporal and locational encoding, making it suitable for applications that require adaptability across time and space. By not including these specialized models, the paper misses a critical opportunity to benchmark the very architectures that are purpose-built to handle the complexities of remote sensing, thus limiting the practical relevance and depth of the benchmark.\n4. While the paper discusses self-distillation-based models, it does not sufficiently evaluate how different pretraining methods, such as DINOv2 and EVA, might impact model robustness and generalization capabilities. Advanced pretraining techniques are known to affect the performance of foundation models differently, especially when fine-tuning for specific tasks like those in remote sensing. Including a comparative analysis of these methods could offer insights into how various approaches to pretraining influence downstream task performance and generalization in remote sensing contexts. This omission reduces the value of the benchmark, as it does not provide a complete picture of how alternative pretraining methods might improve or hinder model performance in real-world scenarios.\n\n### References\n- [SatMAE] Cong, Yezhen, et al. \"Satmae: Pre-training transformers for temporal and multi-spectral satellite imagery.\" Advances in Neural Information Processing Systems 35 (2022): 197-211.\n- [Scale-MAE] Reed, Colorado J., et al. \"Scale-mae: A scale-aware masked autoencoder for multiscale geospatial representation learning.\" Proceedings of the IEEE/CVF International Conference on Computer Vision. 2023.\n- [EVA] Fang, Yuxin, et al. \"Eva: Exploring the limits of masked visual representation learning at scale.\" Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2023.\n- [DINOv2] Oquab, Maxime, et al. \"Dinov2: Learning robust visual features without supervision.\" TMLR. 2024."
      },
      {
        "rating": "5",
        "confidence": "5",
        "summary": "The authors conduct benchmarking for remote sensing foundation models around different characteristics including changes to different resolutions and new bands.  The authors train several iBOT models on the MIllionAID dataset with different augmentations and evaluate it on change detection and scene classification.",
        "strengths": "This is an interesting and important line of investigation as the ability to produce high-quality remote sensing foundation models has dramatically lagged behind other domains.\n\nOverall the text is clear and well wrtiten.\n\nSignificant benchmarks are run with multiple trials to generate error bars.  \n\nDesign choices are all reasonable.",
        "weaknesses": "Only scene classification and change detection are explored.  There are many other tasks within remote sensing which are highly relevant and may have dramatically different feature relevancy (i.e. more spectrally dominant vs. structurally).  \n\nI disagree with the authors' stance that images at inference time are more likely to be lower-resolution.  Very often the opposite is true- there are huge amounts of publicly available low resolution imagery.  However, with the introduction of private satellite, planes, and drones, into the remote sensing space, people are trying to use these high-resolution sources for a very specific task while leveraging the decades of low resolution data that exists.  Similarly, satellite imagery is only going to get better over time so being able to adapt the low resolution data to a new high resolution task is paramount.  \n\nFor tasks like change detection and scene classification in general, there is substantial labeled data out there- foundation models would hopefully boost performance, but they're still usable.  In contrast, there are many novel remote sensing tasks (especially in ecology/climate and agriculture) which are blocked by a lack of good labels and desperately need improved foundation models.  I think exploring some of these would dramatically improve the impact of the work.  \n\nAdditional analysis and discussion is warranted around why contradictory results are seen for different tasks/datasets.  This type of result has been a key challenge (particularly in remote sensing), so I think it warrants more discussion."
      },
      {
        "rating": "3",
        "confidence": "4",
        "summary": "The paper introduces a benchmark pipeline that measures the generalization ability and performances on downstream tasks. It first outlines the motivation for application of self-supervised foundation models to remotes sensing tasks and the needs to test these foundation models with different experimental settings. The paper points out a few significant axes of generalization and highlights why resolution and bands are of key interest. It explains the benchmarking methods and evaluation metrics of scale augmentation for resolution study and different spectral bands combination study. The authors select iBOT, a cutting-edge vision transformer variation, as backbone and tested the impact of introduction of scale augmentation at different training stages, they also develop a joint training strategy for mask decoder. The authors point out that fine-tuning has negative impact on the generalization performance, where frozen backbone can become handy. For the results, they list the metric scores for different models on different remote sensing tasks and demonstrate that most foundation models perform not very well on generalization to lower resolutions and different spectral bands, they also point out that froze backbone preserves general representations better than fine-tuned ones.",
        "strengths": "This paper gives out a comprehensive benchmarking for foundation models in aerial imagery processing. It addresses two practical challenges: resolution and spectral bands variation. It also evaluated different techniques which could cause positive/negative impact for generalization. It reveals the limitations of current models. This paper has a easy-to-understand writing style.",
        "weaknesses": "1. Lack of novelty: From what I received in this paper, this paper lacks new algorithm/architecture/methodology with fundamental contribution. All works are limited to testing and applying of architectures or metrics from previous works. Correct me if I am wrong.\n2. New loss? New architecture?: This paper did a good job in demonstrating current models are not competitive in generalization to different resolutions and band combinations, but gives out no new solutions or possible proposals. For example, will it be helpful to develop a new loss mechanism or a new architecture? Or re-design current models to adapt to your generalization needs?\n3. Multi/hyper-spectral data: Recent studies more focus on how to retrieve spectral representations across all bands instead of transferring the knowledge from, say RGB, to NIR. Correct me if I am wrong.\n4. Pre-training, Fine-tuning: These are not new concepts at all and have been studied extensively, the conclusion of fine-tuned backbone impact generalization and frozen backbone preserves generalization ability is intuitive and familiar to most researchers and has been widely accepted as a fact, repeatedly conduct these trainings seems redundant."
      }
    ],
    "rating_avg": 3.0,
    "confidence_avg": 4.5,
    "decision": "N/A",
    "meta_review": "",
    "author_remarks": "",
    "decision_comment": ""
  },
  {
    "id": "IANtNtNpYd",
    "title": "Enhancing Trust-Region Bayesian Optimization via Derivatives of Gaussian Processes",
    "authors": [
      "Quanlin Chen",
      "Yiyu Chen",
      "Jing Huo",
      "Tianyu Ding",
      "Yang Gao",
      "Yuetong Chen"
    ],
    "abstract": "Bayesian Optimization (BO) has been widely applied to optimize expensive black-box functions while retaining sample efﬁciency. However, scaling BO to high-dimensional spaces remains challenging. Existing literature proposes performing standard BO in several local trust regions (TuRBO) for heterogeneous modeling of the objective function and avoiding over-exploration. Despite its advantages, using local Gaussian Processes (GPs) reduces sampling efﬁciency compared to a global GP. To enhance sampling efﬁciency while preserving heterogeneous modeling, we propose to construct several local quadratic models using gradients and Hessians from a global GP, and select new sample points by solving the bound-constrained quadratic program. We provide a convergence analysis and demonstrate through experimental results that our method enhances the efﬁcacy of TuRBO and outperforms a wide range of high-dimensional BO techniques on synthetic functions and real-world applications.",
    "keywords": [
      "Bayesian optimization",
      "High-dimensional Bayesian optimization",
      "Trust-Region methods"
    ],
    "venue": "ICLR",
    "year": 2025,
    "pdf_url": "https://openreview.net/pdf?id=IANtNtNpYd",
    "forum_url": "https://openreview.net/forum?id=IANtNtNpYd",
    "reviews": [
      {
        "rating": "6",
        "confidence": "3",
        "summary": "This paper proposes the TuRBO-D method for optimizing expensive blackbox functions, which improve on the previous work of TuRBO (trust region Bayesian optimization) by using local quadratic models within each trust region and enable applications to mid/high-dimensional settings. Theoretical results are provided to justify the convergence of this method to a stationary point of the true underlying blackbox functions. Simulations and some real world applications are provided.",
        "strengths": "1. The paper is overall clear and well-written.\n2. The proposed method, originating from TuRBO, has a good and clear motivation.\n3. Necessary background materials are provided.\n4. Theoretical analysis of convergence to a stationary point are helpful.\n5. The performance of the proposed method are justified through a few real world applications.",
        "weaknesses": "To me, it seems that more background and discussions on the original TuRBO method (Eriksson et al., 2019) could be provided. For instance, TuRBO method and the newly proposed TuRBO-D method has the following differences, which would be helpful to discuss the motivations and reasons:\n1. TuRBO uses local GP within each trust region to deal with large number of observations, whereas TuRBO-D does local quadratic approximation to a glocal GP instead of local GPs\n2. TuRBO choose samples across trust regions through Thompson sampling, whereas TuRBO-D traverse through all trust regions recursively, each time choosing a sample from a trust region.\n\nThere are many real world applications in the TuRBO paper (Eriksson et al., 2019). While the current applications do provide certain convincing justifications, it would be helpful to also see how TuRBO-D performs in applications of the TuRBO paper."
      },
      {
        "rating": "5",
        "confidence": "3",
        "summary": "This paper proposes an approach for high dimensional Bayesian optimization, which the authors call TuRBO-D, that takes the posterior mean and variance of the fitted Gaussian process (GP) to form local quadratic functions as a proxy for acquisition. Instead of doing local GP  fit as in TuRBO which suffers from a reduction of sampling efficiency, TuRBO-D utilizes statistical information from a global GP fit to invoke a trust region mechanism to handle high dimensionality. The authors provide a theoretical convergence result and conduct a range of experiments to support their approach.",
        "strengths": "- While there have been work in injecting derivative information from the (expensive) objective function into posterior GP fitting, the approach carried out by the authors, namely extracting posterior GP to inform the derivatives in constructing local quadratic approximation, appears novel and has computational benefits.\n\n- The improvements over benchmarks like TuRBO are demonstrated in the range of experiments.",
        "weaknesses": "1. From my understanding and as the authors also describe in their paper, a main strength and motivation of TuRBO is to allow for the heterogeneous modeling of the objective function which is especially important in high dimension. This is done by local GP fits. On the other hand, the authors' approach globally fits the GP which seems to basically forgo this important strength of TuRBO. In other words, if the global GP fit is bad, then the extracted derivatives are also badly informed, and thus the method would work poorly in high dimension. The authors claim that their approach gains sampling efficiency, but how important is this compared to the heterogeneity in modeling the objective? It seems that heterogeneity is more important, as the GP fit typically depends negligibly on points that are far away but a poor modeling of the objective function is more impactful (please correct me if I'm wrong).\n\n3. The main theoretical result (Theorem 4) is weak in the following sense: It says, with high probability, the inf of gradient over the solution sequence is close to 0. However, this inf only means that there exists a subsequence whose gradients are close to 0. If we stop the algorithm at some large iteration step, there is no guarantee that the gradient is small since that step may not be in that subsequence. That is, even putting aside the lack of convergence rate etc. (which I understand can be difficult to obtain in general for BO algorithms) and viewing at a basic level, the theoretical result does not seem meaningful. \n\nThe above are my main concerns. Additionally,\n\n1. The authors propose to use a subset of dimensions instead of full dimension to form the quadratic approximation, but the theoretical analyses do not take this into account.\n\n2. A possible strength of TuRBO is that the local fit uses less computation due to the smaller matrix inversion. However, by global fitting, the authors' approach faces a computation load as high as standard BO (as least for this posterior update step). This might need some discussions.\n\n3. The implementation of the main benchmark TuRBO has no details, and it's unclear if the comparison is fair. E.g., how do you set the hyperparameters for TuRBO and TuRBO-D?"
      },
      {
        "rating": "5",
        "confidence": "3",
        "summary": "The paper introduces an advanced approach for high-dimensional Bayesian Optimization (BO) using derivatives to improve sampling efficiency in trust-region-based BO frameworks. The method constructs local quadratic models using gradients and Hessians derived from a global Gaussian Process (GP), facilitating efficient optimization across trust regions and achieving better sampling efficiency without relying solely on local GPs.",
        "strengths": "1. The paper offers convergence proofs enhancing the method’s robustness.\n2. The proposed method addresses the dimensionality issue in BO.\n3 The experimental evaluation shows that TuRBO-D outperforms existing BO methods on tasks with up to 300 dimensions.",
        "weaknesses": "1. The complexity experiments are not included in the paper\n2. The code has not been found in the paper"
      },
      {
        "rating": "3",
        "confidence": "4",
        "summary": "This paper proposes TuRBO-D, a trust region-based Bayesian optimization (BO) method for high-dimensional black-box optimization problems. Based on a global Gaussian process (GP) model, TuRBO-D constructs multiple trust regions, and approximate the local function landscape using the quadratic model from GP gradients and Hessians. The points for next round sampling are optimized from the quadratic approximation. The authors provide convergence analysis of the proposed method. The experimental results on both synthetic functions and real-world problems demonstrate that TuRBO-D has better optimization performance than other local BO baselines when the sample budget is less than 300.",
        "strengths": "1. The paper is clear and well-written, and the theoretical part is detailed.\n\n2. The proposed method demonstrate better sample efficiency when the sample budget is small.",
        "weaknesses": "1. I think an important related work [1] is missed by the authors, where the convergence analysis is conducted on a local BO method using GP gradients. The current work seems extend the convergence analysis to the multiple trust region setting.\n\n2. The current experiment results only optimize the problem with a few hundred evaluations, which is far from convergence. I think more evaluations (e.g. a few thousand in original TuRBO paper) can better access the algorithm performance along with the convergence analysis.\n\n\n\n[1] Wu, Kaiwen, et al. \"The behavior and convergence of local bayesian optimization.\" Advances in neural information processing systems 36 (2024).\n\n[2] Eriksson, David, et al. \"Scalable global optimization via local Bayesian optimization.\" Advances in neural information processing systems 32 (2019)."
      },
      {
        "rating": "1",
        "confidence": "4",
        "summary": "The paper proposes TuRBO-D, an improvement over previous Trust-Region Bayesian Optimization (TRBO) work. The proposed approach claims to enhance the sampling efficiency of high-dimensional BO tasks over previous TRBO work. The authors present a convergence analysis, showing that their algorithm converges to a stationary point. The authors also conduct experiments comparing their algorithm against previous methods. \n\nThe key insight of the algorithm is by leveraging gradients and Hessians of the GP; the underlying objective function can be modeled more accurately, thus leading to sample efficiency compared to TRBO.",
        "strengths": "1. The authors recognize the sample inefficiency of current high-dimensional Bayesian optimization algorithms and propose a more sample-efficient alternative. \n\n2. The authors try to prove the convergence of their proposed algorithm. \n\n3. There is a decent amount of experimental results to demonstrate the validity of the proposed algorithm.",
        "weaknesses": "1. The methods seem to have merit but are hard to validate due to the paper's lack of rigor and presentation clarity.\n\n2. The authors claim their method is more sample-efficient than TRBO. Experimental results show that their method, TRBO-B, is sample efficient and obtains better final values than TRBO (as shown in the bottom row of Fig 1 and Fig 2). Why is that the case? It invalidates all the claims for me. Maybe I am wrong. \n\n3. The paper suffers from issues in presentation, with insufficient explanations of key concepts, unclear notation, and missing justifications for several methodological choices. The cumulative effect of these issues reduces the paper's accessibility and perceived rigor. Here are the main points which make it hard to follow:\n  a. The authors claim TRBO suffers from sample inefficiency. Nowhere in the paper is it explained or shown why that is the case.\n  b. Why does using gradients and Hessians lead to better sample inefficiency? Why did the authors make this decision?\n  c. The algorithm is stated without any explanation. How do the authors choose the final point? It seems like Algorithm 1 returns a point for each trust region. \n  d. Baselines and experimental settings are not explained. What is ALEBO? Why did you compare against it? What is Griewank's function, or what is Ackley's?\n \n4. The theoretical results and the actual proofs are stated in the middle of the paper without any supporting text. It is hard to infer what the authors are trying to show and validate its correctness.  \n\nSuggestions: \n1. Please improve the presentation rigor. Each technical claim and design decision needs to be motivated. \n2. The theoretical results need supporting text to explain the math and claims clearly.\n3. Experimental settings and results need to be clearly explained."
      },
      {
        "rating": "5",
        "confidence": "3",
        "summary": "The authors propose an approach to address Bayesian optimisation in high-dimensional spaces. Their method utilises local quadratic models that leverage gradients and Hessians from a global GP and selects new sample points by solving a bound-constrained quadratic program.",
        "strengths": "The paper addresses a relevant problem—high-dimensional Bayesian optimisation—and demonstrates strong performance against various baselines in multiple experiments. Overall, the paper is well written, with a clear discussion of related work and a well-stated contribution. However, the theory section is somewhat disorganised.",
        "weaknesses": "Overall, I find the paper lacks clarity, particularly in the theory section. Each theorem or lemma is presented without any motivation or discussion, making them feel disconnected from the rest of the paper. Additionally, the presentation of the method itself sometimes lacks clarity; for example, the trust region update strategy is barely discussed, including how the trust regions are initialised."
      },
      {
        "rating": "3",
        "confidence": "3",
        "summary": "This paper considers the high-dimensional Bayesian optimization problem. \nThe proposed algorithm, TuRBO-D, extends the existing TuRBO algorithm by incorporating a quadratic model into the local optimization routine of TuRBO. \nBy combining the existing convergence analysis of trust-region derivative-free optimization methods \nwith the probabilistic error bounds of GP sample paths, the authors show high-probability convergence \nto the stationary point of the proposed local optimization routine. \nThe empirical performance of the proposed algorithm is confirmed with 2 synthetic and 3 real-world-based problems.",
        "strengths": "- Originality: Although the basic algorithm construction relies on the existing TuRBO algorithm, incorporating global GP modeling information into the local quadratic optimization routine is novel to me.  \n- Quality: The theoretical analysis and proofs support the effectiveness of the proposed method; however, I believe that more discussion about the assumptions of this paper is essential.",
        "weaknesses": "- The validity of Assumptions 2, 3, and 4 is not discussed. I believe that these assumptions are not valid under the assumption $f \\sim \\mathcal{GP}(0, k)$ (suggested in Assumption 1), even if we adopt commonly-used SE or Matérn family kernels. Some assumptions seem to be valid for these commonly-used kernels by relying on more careful probabilistic arguments; however, others are unknown to me. I summarize my current understanding below:\n    - Assumption 3: When the kernel is SE or Matérn, the boundedness of the sample path is valid with high probability if the input domain is compact (e.g., Ghosal & Roy (2006), Kandasamy et al. (2019)); however, the same result does not hold for $\\mathbb{R}^D$ (as the authors assumed).\n    - Assumption 1: When the kernel is four times continuously differentiable and stationary, the Lipschitz assumption holds with high probability for the compact input domain (e.g., Srinivas et al. (2009)).\n    - Assumptions 2 and 4: When the kernel is four times continuously differentiable and stationary, the gradient norm is bounded from above with high probability in a compact input domain (e.g., Srinivas et al. (2009)); however, I do not know of any existing results that suggest the true and approximate Hessian matrices are bounded from above.\n\nGhosal, Subhashis, and Anindya Roy. \"Posterior consistency of Gaussian process prior for nonparametric binary regression.\" (2006): 2413-2429.  \nSrinivas, Niranjan, et al. \"Gaussian process optimization in the bandit setting: No regret and experimental design.\" arXiv preprint arXiv:0912.3995 (2009).  \nKandasamy, Kirthevasan, et al. \"Multi-fidelity Gaussian process bandit optimization.\" Journal of Artificial Intelligence Research 66 (2019): 151-196.\n\n- There seem to be some gaps between the theoretically and practically verified algorithms without discussion. Discussions about the following gaps are desired:\n    - The explanations in Section 3 and the empirical evaluations in Section 6 seem to allow noisy function evaluations; however, the theory and algorithm construction rely on noise-less function evaluation (e.g., Line 8 in Algorithm 1, construction of $m_k$ in Eq.(2)).\n    - The treatment of the trust regions is different between practical (Lines 190, 191) and theoretical (Algorithm 2) usages.\n    - The random subset-selection of the dimensions (Lines 213-226) seems not to be considered in the theorems.\n- The description of the experimental section is inadequate to reproduce the results for the reader. For example, clarification of the following settings is desired:\n    - The choice of the kernel.\n    - The treatment of the hyperparameters of the kernel.\n    - The parameter settings of the local optimization routine.\n\n(Minor)\n- Last year's NeurIPS paper (Wu et al. (2023)) is closely related to this paper in the sense that the convergence of the local Bayesian optimization routine is analyzed.\n\nWu, Kaiwen, et al. \"The behavior and convergence of local Bayesian optimization.\" Advances in Neural Information Processing Systems 36 (2023)."
      }
    ],
    "rating_avg": 4.0,
    "confidence_avg": 3.2857142857142856,
    "decision": "N/A",
    "meta_review": "",
    "author_remarks": "",
    "decision_comment": ""
  },
  {
    "id": "ghk8lnOYRq",
    "title": "Solving the 2-norm k-hyperplane clustering problem via multi-norm formulations",
    "authors": [
      "Stefano Coniglio"
    ],
    "abstract": "We tackle the 2-norm (Euclidean) $k$-Hyperplane Clustering problem ($k$-HC$_2$), which asks for finding $k$ hyperplanes that minimize the sum of squared 2-norm (Euclidean) distances between each point and its closest hyperplane. We solve the problem to global optimality via spatial branch-and-bound techniques (SBB) by strengthening a mixed integer quadratically-constrained quadratic programming formulation with constraints that arise when formulating the problem in $p$-norms with $p \\neq 2$. In particular, we show that, for every (appropriately scaled) $p \\in \\mathbb{N} \\cup \\{\\infty\\}$, one obtains a variant of $k$-HC$_2$, whose optimal solutions yield lower bounds within a multiplicative approximation factor. We focus on the case of polyhedral norms where $p=1, \\infty$ (which admit a disjunctive-programming reformulation), and prove that strengthening the original formulation by including, on top of the original 2-norm constraints, the constraints of one of the polyhedral-norms leads to an SBB method where nonzero lower bounds are obtained in a linear (as opposed to exponential) number of SBB nodes. Experimentally, we show that our strengthened formulations lead to speedups from $\\frac{1}{4}$ to 1.5 orders of magnitude, drastically improving the problem's solvability to global optimality.",
    "keywords": [
      "hyperplane clustering; mathematical programming; spatial branch and bound"
    ],
    "venue": "ICLR",
    "year": 2025,
    "pdf_url": "https://openreview.net/pdf?id=ghk8lnOYRq",
    "forum_url": "https://openreview.net/forum?id=ghk8lnOYRq",
    "reviews": [
      {
        "rating": "5",
        "confidence": "2",
        "summary": "The paper tackles the k-Hyperplane Clustering Problem (k-HC2), emphasizing the use of the 2-norm (Euclidean) distance. The goal in this problem is to identify k hyperplanes that minimize the total squared Euclidean distances between each data point and its nearest hyperplane. This task is particularly challenging due to the NP-hard nature of k-HC2; the computational complexity of fitting multiple points to hyperplanes while minimizing distances grows significantly, especially in higher-dimensional spaces.",
        "strengths": "- The authors present an innovative approach to solving k-HC2 by incorporating alternative norm constraints, specifically the 1-norm and ∞-norm, to develop a multi-norm formulation.\n\n- Strengthening the k-HC2 formulation with 1-norm and ∞-norm constraints significantly accelerates the SBB algorithm, making it possible to solve instances that previously demanded extensive computation and achieving up to a 1.5 orders-of-magnitude improvement in some cases.\n\n- The paper provides a rigorous theoretical foundation, including proofs and approximation relationships, for applying multiple norm constraints to tackle complex clustering problems.",
        "weaknesses": "The experimental results are somewhat unclear:\n\n- The results appear to be based on simulations. Are there any findings from real-world datasets?\n\n- The sample size is restricted under 100. What might be the reason for this limitation?\n\n- Would it be possible to use plots for comparisons rather than tables?\n\nAdding multiple norm constraints increases the complexity of the MI-QCQP formulation, which could make practical implementation more challenging. How would you address this issue?"
      },
      {
        "rating": "5",
        "confidence": "4",
        "summary": "The paper considers the 2-norm k-hyperplane clustering problem. The problem is traditionally solved via Mixed Integer Quadratically Constrained Quadratic Programming (MI-QCQP), as reviewed in Section 4.2.\n\nThe main proposal is to strengthen this classic MI-QCQP formulation via adding extra norm constraints.",
        "strengths": "The proposed method seems to be faster than traditional approaches for certain instances, as shown in Tables 1 and 2.",
        "weaknesses": "The paper has a few major weaknesses.\n\nFirst, the presentation is suboptimal with redundancies and unclarity. For example:\n- The theorems and propositions in Section 3 appear to be natural consequences of the norm equivalence. Technically it is incremental. And it is unclear how this serves the subsequent sections (see below).\n- At the end of the day, the paper proposes adding L1 and L-infinity constraints to the formulation, which already has L2 constraints. This leads to two questions. First, why is Section 3 useful? Second, these constraints are redundant as the L2 constraint $|| w_j ||_2\\geq 1$ implies the L1 and L-infinity constraints, as the paper plots in Figures 1 and 2. While the paper means that the L1 and L-infinity constraints are useful during the execution of the SBB algorithm, this leads to great confusion. And furthermore, since the SBB algorithm is disconnected from the actual implementation (see the point below), and since there is a lack of formal descriptions of the SBB algorithm, it is hard to assess whether the proposed redundant constraints are useful for SBB.\n- The discussions on spatial branch-and-bound in Section 4 are disconnected from the actual implementations of the methods. It appears to me that the algorithms are implemented by writing down the formulation and invoking Gurobi. Note that Gurobi is a commercial, closed-source solver. Its implementation is unlikely to be pure spatial branch-and-bound; if that were the case, and as per Proposition 2, the classic MI-QCQP formulation would take exponential time at every iteration of bound calculation. Tables 1 and 2 show, instead, that the classic MI-QCQP formulation could be fast for some instances. This leads to concerns about the correctness of Proposition 2 or whether it is obtained by considering a worst case. Indeed, having a nonzero lower bound is easy: just add a constraint $d_i \\geq \\epsilon$ for a sufficiently small epsilon>0. I would guess that doing so can also speed up the algorithm. \n- The introduction of MI-QCQP and the proposed formulation is not clear. Specifically:\n   - At Line 302, why is it that *The only nonconvexity of the formulation is due to the 2-norm constraints*? Isn't that $x_{ij}$ being binary is also a non-convex constraint?\n   - Typo in Eq. (3f), and Eq. (3f) is not justified: Why do we need a binary variable $s_{jh}$ to bound the entries of $w_j$? Isn't it that we could just take $w_{jh}^+$ to be the positive entries of $w_{jh}$? This uniquely determines  $w_{jh}^+$ and  $w_{jh}^-$.\n   - Constraints in Eq. (3e) are not justified: Why do we want every entry of $w_j$ is bounded in $[-1,1]$?"
      },
      {
        "rating": "5",
        "confidence": "4",
        "summary": "This paper considers the k-hyperplane clustering problem where the goal is to find k hyperplanes to minimize the sum of squared distance from every data point to its closest hyperplane. This problem is computationally hard. The authors first show how to relax the $L_2$ constraint to $L_1$ and $L_{\\infty}$ to transform the solution space into a polyhedra then they use the spatial branch-and-bound techniques to find a solution in the relaxed solution space. The experiments show that optimizing the relaxed formulation yields a speedup of tens of times that of solving the original formulation when running in the low-dimensional data set.\n\nThe problem studied is important and very hard. I think the ideas presented are interesting and useful. My concern is the algorithm does not scale as the dimension increases (as shown in the theoretical and experimental results).",
        "strengths": "1. Simple but useful techniques to tackle a very hard problem. \n2. The experimental results show the techniques are useful in low-dimensional data sets.",
        "weaknesses": "1. The approximation ratio can be as large as $\\Omega(n)$, by corollary 2 of the paper. \n2. The experiment on the high-dimensional data set does not show a significant improvement. This phenomenon has been discussed in the paper. Proposition 3 shows that the branching nodes of the $L_1$ relaxation grow exponentially by the dimension $n$. Thus the results may not be very helpful in solving high dimensional clustering tasks."
      },
      {
        "rating": "5",
        "confidence": "4",
        "summary": "This paper studies the hyperplane clustering problem using the L2-norm. To improve computational efficiency, the authors propose solving a generalized and a strengthened formulation utilizing other Lp-norms. All formulations of the clustering problem can be solved by the spatial branch-and-bound (SBB) method proposed by Amaldi & Coniglio (2013). When applied to the formulations proposed by the authors, the optimization time can be reduced by a factor of 1.5. Bounds on the optimal objective values between the classical and generalized formulation are derived.",
        "strengths": "The significant contribution of the paper is to propose a generalized formulation of the problem that can be solved more efficiently using SBB.",
        "weaknesses": "1, Results regarding clustering accuracy are relatively weak. The SBB algorithm can only find a lower bound, which can make the clustering results hard to interpret. Bounds between strengthened formulations and the original formulation are missing, for instance,  bound between $HC_{(2,1), (\\infty, 1)}$ and $HC_{(2,1)}$ is not provided.\n\n2, Corollary 2 might be wrong. The authors said that $1/(1+ \\frac{(\\sqrt{n} - 1)^2}{n-1})$ is strictly smaller than $1/n$ for all $n$. But $1/(1+ \\frac{(\\sqrt{n} - 1)^2}{n-1})$ converges to $1/2$, while $1/n$ converges to 0.\n\n3, No applications using real datasets are provided.\n\n4, Comparisons with existing methods are NOT included in the simulations. In addition, the following paper is highly relevant but is not discussed in sufficient detail: Hyperplane Clustering Via Dual Principal Component Pursuit by Manolis C. Tsakiris and Rene Vidal (ICML 2017). The following works are also related but are not mentioned in the paper: T. Zhang, A. Szlam, and G. Lerman, Median k-flats for hybrid linear modeling with many outliers, in Workshop on Subspace Methods, pages 234–241, 2009; G. Lerman, M. B. McCoy, J. A. Tropp, and T. Zhang, Robust computation of linear models by convex relaxation, Foundations of Computational Mathematics, 15(2):363–410, 2015. Please refer to the papers cited in \"Hyperplane Clustering Via Dual Principal Component Pursuit\" for more related work."
      }
    ],
    "rating_avg": 5.0,
    "confidence_avg": 3.5,
    "decision": "Reject",
    "meta_review": "This work modifies the spatial branch-and-bound (SBB) method for the 2-norm k-hyperplane clustering problem to achieve better computational efficiency. In particular, it is shown that the p-norm variants can provide meaningful lowerbounds and greatly reduce the number of SBB nodes. Presentation of the analysis, in particular the statement of Corollary 2, were questioned by the reviewers. Numerical experiments are also considered not very practical.",
    "author_remarks": "",
    "decision_comment": ""
  },
  {
    "id": "rAoEub6Nw2",
    "title": "A Statistical Framework for Ranking LLM-based Chatbots",
    "authors": [
      "Siavash Ameli",
      "Siyuan Zhuang",
      "Ion Stoica",
      "Michael W. Mahoney"
    ],
    "abstract": "Large language models (LLMs) have transformed natural language processing, with frameworks like Chatbot Arena providing pioneering platforms for evaluating these models. By facilitating millions of pairwise comparisons based on human judgments, Chatbot Arena has become a cornerstone in LLM evaluation, offering rich datasets for ranking models in open-ended conversational tasks. Building upon this foundation, we propose a statistical framework that incorporates key advancements to address specific challenges in pairwise comparison analysis. First, we introduce a factored tie model that enhances the ability to handle ties—an integral aspect of human-judged comparisons—significantly improving the model's fit to observed data. Second, we extend the framework to model covariance between competitors, enabling deeper insights into performance relationships and facilitating intuitive groupings into performance tiers. Third, we resolve optimization challenges arising from parameter non-uniqueness by introducing novel constraints, ensuring stable and interpretable parameter estimation. Through rigorous evaluation and extensive experimentation, our framework demonstrates substantial improvements over existing methods in modeling pairwise comparison data. To support reproducibility and practical adoption, we release leaderbot, an open-source Python package implementing our models and analyses.",
    "keywords": [
      "Large Language Models (LLMs)",
      "Paired Comparison",
      "Statistical Ranking",
      "Human Preferences",
      "Chatbot Arena",
      "Logistic Regression"
    ],
    "venue": "ICLR",
    "year": 2025,
    "pdf_url": "https://openreview.net/pdf?id=rAoEub6Nw2",
    "forum_url": "https://openreview.net/forum?id=rAoEub6Nw2",
    "reviews": [
      {
        "rating": "5",
        "confidence": "3",
        "summary": "This paper presents a statistical framework for ranking LLM-based chatbots. It addresses the limitations of existing methods like the Elo rating system by incorporating ties and covariance structures. The proposed apply well-established statistical models to properly account for ties within an axiomatic framework and introducing factor analysis. Experiments on the Chatbot Arena dataset show improved accuracy and insights into chatbot rankings and relationships.",
        "strengths": "1. The proposed method can account for ties in an axiomatic framework. This improves not only tie prediction but also enhances win-loss inference.\n2. The mathematical analysis is comprehensive and thorough.\n3. This work has an open source python package which is easy to use.",
        "weaknesses": "1. For model ranking, it has no \"ground truth\". Therefore, it is hard to convince others under this method, the ranking is more accurate.\n2. The evaluation is highly dependent on the Chatbot Arena dataset which makes this work a slight improvement on chatbot arena. Therefore, the impact of this work is limited.\n3. As for chatbot arena, a simple enough ranking rule is more important if the users are common users. This work will make the rule too complicated for them to understand and then reduce the impact of chatbot arena."
      },
      {
        "rating": "6",
        "confidence": "4",
        "summary": "The authors propose an improved statistical model for ranking large language models (LLMs) on the Chatbot Arena dataset to enhance the traditional Elo rating system. Paper points out that the Elo system has limitations in handling ties and capturing relationships between models. To address these issues, paper introduces the Rao & Kupper and Davidson models, as well as a novel factor model to better capture the complexity of ties between different models, thereby improving prediction performance. Finally, they provide a Python package, “Leaderbot,” to reproduce the statistical model and support further experiments.",
        "strengths": "1. The authors identify symmetry issues in the likelihood function of traditional models, which could lead to instability in parameter estimation. To address this, they propose symmetry constraints that ensure stable parameter estimation, thereby enhancing the model’s optimization performance and interpretability;\n2. They effectively address the issue of ties, which is a limitation of the existing Elo system, and make optimizations to handle this;\n3. They provide a Python package that allows for the reproduction of the paper's results and supports further research.",
        "weaknesses": "1. The authors use multiple models to rank models, showing that high-ranking models exhibit greater consistency than lower-ranking ones. However, they do not provide further analysis, such as examining the specific characteristics of models that initially show ranking inconsistencies;\n2. The authors’ work focuses on optimizing the ranking model but lacks subsequent analysis. Additional insights, such as a more in-depth examination of correlations between LLMs or an analysis of the differences between Leaderbot rankings and Chatbot Arena Elo rankings in relation to model characteristics, would enhance this work."
      },
      {
        "rating": "6",
        "confidence": "3",
        "summary": "This paper addresses a novel problem in the evaluation of large language model (LLM)-based chatbots by proposing an advanced statistical framework that builds on existing methods used in the Chatbot Arena setting. The framework integrates well-established models, such as Rao-Kupper and Davidson, to account for ties in a rigorous axiomatic framework, and introduces Thurstonian representations to model covariance structures between competitors. These additions allow for more nuanced insights into chatbot rankings and performance consistency. A Python package, leaderbot, is also provided for reproducibility and ease of experimentation.",
        "strengths": "1. **Pioneering Approach**: This paper tackles a novel and important problem in LLM evaluation, presenting a unique perspective on using advanced statistical models to refine the ranking process in chatbot comparisons. Its approach to systematically modeling ties and latent structures sets a new precedent for evaluating LLM-based chatbots and offers fresh insights that go beyond traditional ranking methods.\n2. **Innovative Use of Thurstonian Representations**: By integrating Thurstonian models and introducing covariance structures, the paper offers a groundbreaking method for capturing relationships among LLMs. This enables a deeper analysis of model consistency and performance that extends beyond simple rankings, marking a notable advancement in chatbot evaluation techniques.",
        "weaknesses": "1. While the paper introduces an alternative framework, it does not clearly discuss why Arena’s Elo-based approach is insufficient beyond the issue of ties. Additional insight into Arena’s limitations in capturing competitive dynamics or certain statistical shortcomings would strengthen the argument for this new model.\n2. The authors mention consistency in high-ranking models and variability in lower-ranking models, but do not explore further distinctions within these groups. For example, identifying specific characteristics (e.g., model size) associated with high consistency could provide more actionable insights."
      }
    ],
    "rating_avg": 5.666666666666667,
    "confidence_avg": 3.3333333333333335,
    "decision": "Accept (Poster)",
    "meta_review": "This paper proposes an improved version of ELo rating in Chatbot Arena by considering ties and covariances by using Rao & Kupper and Davidson models. Experiments found that the proposed improvement is better at modeling empirical data.\n\nStrengths:\n1. The method improves the ELo rating by considering ties and covariances.\n2. The authors also released an open-source Python package.\n\nWeaknesses:\n1. It is not clear how much benefits we get by considering ties compared to the existing ELo ratings.\n2. As reviewers pointed out, the proposed metric is harder to be understood by normal users of Chatbot Arena.\n\nSince reviewers are overall positive about this paper, I'm recommending acceptance, but I wouldn't mind if the paper gets rejected.",
    "author_remarks": "",
    "decision_comment": ""
  },
  {
    "id": "QEHrmQPBdd",
    "title": "RM-Bench: Benchmarking Reward Models of Language Models with Subtlety and Style",
    "authors": [
      "Yantao Liu",
      "Zijun Yao",
      "Rui Min",
      "Yixin Cao",
      "Lei Hou",
      "Juanzi Li"
    ],
    "abstract": "Reward models are critical in techniques like Reinforcement Learning from Human Feedback (RLHF) and Inference Scaling Laws, where they guide language model alignment and select optimal responses. \nDespite their importance, existing reward model benchmarks often evaluate models by asking them to distinguish between responses generated by models of varying power. \nHowever, this approach fails to assess reward models on subtle but critical content changes and variations in style, resulting in a low correlation with policy model performance.\nTo this end, we introduce RM-Bench, a novel benchmark designed to evaluate reward models based on their sensitivity to subtle content differences and resistance to style biases. \nExtensive experiments demonstrate that RM-Bench strongly correlates with policy model performance, making it a reliable reference for selecting reward models to align language models effectively.\nWe evaluate nearly 40 reward models on RM-Bench. \nOur results reveal that even state-of-the-art models achieve an average performance of only 46.6%, which falls short of random-level accuracy (50%) when faced with style bias interference.\nThese findings highlight the significant room for improvement in current reward models.",
    "keywords": [
      "Reward Models",
      "Language Models",
      "Evaluation",
      "Alignment"
    ],
    "venue": "ICLR",
    "year": 2025,
    "pdf_url": "https://openreview.net/pdf?id=QEHrmQPBdd",
    "forum_url": "https://openreview.net/forum?id=QEHrmQPBdd",
    "reviews": [
      {
        "rating": "8",
        "confidence": "4",
        "summary": "In this submission, the authors have introduced RM-BENCH, a benchmark for evaluating reward models that: 1. evaluates reward models' sensitivity to subtle content differences and 2. tests resistance to style biases like length and markdown formatting.",
        "strengths": "- The paper is well-motivated and offers various prompts to explicitly control for style bias, in contrast to the RewardBench benchmark.\n- It also establishes a clear methodology for evaluating biases, which could be extended to other categories or used to add tasks focused on reasoning and safety. In short, the overall methodology appears scalable, though it may require some human-level judgment.",
        "weaknesses": "I feel that the paper in its current state has a lot of scope for improvement, and hence I am leaning towards a borderline reject. I might be willing to increase my score after the rebuttal period with the authors if they are able to improve upon the following areas:\n\n- Currently, the benchmark relies heavily on gpt4o. I am aware that the authors discussed this in the Appendix's Limitations section, but I strongly feel that, to make the benchmark ready for deployment, it should be diverse and include responses from more SOTA models like Claude, Gemini, etc.\n- The results shown in Table 4 and the correlation analysis in Section 5 and the Appendix rely on the Tulu-v2.5 model. I would like to see the same analysis on at least one more model (maybe from Qwen or LLaMA family) before drawing conclusions on correlation analysis.\n- While the authors explain that they use gpt4o to create different versions of the same content (short vs. long, with and without special formatting), they do not provide enough details about how exactly they do this or how they ensure that the different versions maintain the same meaning. These missing details about their exact process—such as the specific prompt given to gpt4o for summarizing responses or removing markdown, or how they check the quality of generated responses (after removing markdown)—should be included in the Appendix.\n- I would also like to see more details on length control in Table 2. For example, what are the target length ranges for each category when selecting normal vs. long responses, and how do you ensure that, for concise responses (both correct and rejected), the model retains the core information (fact or code snippet) even after summarization?"
      },
      {
        "rating": "8",
        "confidence": "3",
        "summary": "This paper introduces a new benchmark, called RM-Bench, to evaluate reward models. The authors state that an ideal reward model should be able to identify subtle differences in content quality (correctness) and consistently reward better responses, regardless of stylistic variations. They argue that existing benchmarks, which rely on comparing responses generated by LLMs of differing power, fail to fully capture these aspects of reward model evaluation.\n\nRM-Bench addresses this by constructing a dataset where both chosen and rejected responses are generated by the same LLM, gpt-4o (except for safety, where responses are generated using different models to ensure safety violations). They use (i) domain-specific techniques to introduce subtle errors to the rejected responses, and (ii) prompting the LLM to generate response variants with differing levels of detail and markdown formatting. Their main contribution is the introduction of the style-substance evaluation matrix and the corresponding {easy, normal, hard} accuracy metrics that allow a more granular analysis of how style influences reward model predictions.\n\nBy evaluating a wide range of reward models on RM-Bench, they demonstrate that a wide range of reward models have a style bias (a high easy accuracy but a low hard accuracy). They also empirically show that the performance of a reward model on RM-Bench (moderately) correlates with the performance of the resulting aligned policy model (under style-controlled evaluation and across downstream tasks).",
        "strengths": "The use of style-controlled generation of responses for building the evaluation dataset is a simple but structured and original idea to directly assess the style bias in reward models. It is generic in the sense that it can also be applied to existing datasets with verbose responses (or the model can be asked to alter the response such that they are more verbose and with formatting). Style-substance evaluation matrix enables to quantify the degree of the bias and its impact on reward predictions.\n\nThe experiments are comprehensive and demonstrate that it is a challenging benchmark for the current reward models, exposing their weaknesses with respect to style bias and robustness. This is a significant result (but may be of limited scope; see below). The performances of the aligned policy models, measured by their style-control scores and how well they perform in downstream tasks, correlate positively with the performance of the corresponding reward models on RM-Bench. This correlation, while not strong, is nonetheless better than that observed with RewardBench, which does not explicitly focus on style bias and relies on preference datasets with responses that are human curated or generated using a strong and a weak LLM pair. However, there may be multiple parameters in play here and a clarification may be needed.",
        "weaknesses": "In the paper, the authors construct the RM-Bench dataset in two steps: (i) generate domain specific preference pairs as described in sections 3.1-3.3, and (ii) add style-controlled variants of these pairs as described in section 3.4. Adding style-controlled variants (step (ii)) is essential to understand the style bias and the main focus of the paper, but its contribution to (average) accuracy and the correlation with the performance of the aligned policy models is unclear. In Table 3, we can see that the normal accuracy is close to the average accuracy, which may hint that accuracy based on (y_c^{L,M}, y_r^{L, M}) pairs alone could be be a good indicator. To better understand the role of the style-controlled generation, the authors should provide these numbers and compare the results in sections 4.2 (DPO) and 5 (correlation with the policy model) with RM-Bench performance based on y^{L, M} only.\n\nIn section 4.3, the correctness and verbosity scores of the examples (from Nemotron-4-340B-Reward model) are conditioned on the prompt. The scores of responses with different prompts may not be comparable. This makes it difficult to interpret the presented results. What is the behavior of the model when you use the accuracy r(y_c) > r(y_r) is used for both correctness and verbosity scores instead?"
      },
      {
        "rating": "8",
        "confidence": "4",
        "summary": "This paper introduces a benchmark for reward models that is designed to be robust to subtleties in generated text. Previous reward model benchmarks have used weaker models to generate rejected responses, and stronger models for the chosen responses. Such a benchmark could be exploited by a reward model that prefers properties of responses unrelated to what the benchmark is intended to evaluate, such as the style of text.\n\nInstead of using stronger and weaker models, RM-Bench uses one model to generate the chosen and rejected responses, where the rejected responses are flawed in some way (e.g., they were generated by a model that had previously been jailbroken). Style is also controlled via prompting, and the benchmark covers three styles (concise, detailed and markdown). The accuracy of RM-Bench is evidenced by showing correlation between reward models that score higher on RM-Bench and improved performance of policy models on evaluations such as GSM8k and HumanEval+.\n\nThe main takeaway is that even the best publicly available reward models have imperfect performance on RM-Bench, so there is plausibly room for significant improvements in reward modeling. The paper also shows that DPO models outperform some sequence classifiers on RM-Bench, and that the importance of style has likely gone underappreciated in reward model evaluation.\n\nThe Appendix gives evidence that RM-Bench is more accurate than prior work by showing the weaker correlation for benchmark performance of the policy model and performance on Reward Bench.",
        "strengths": "**Originality**: I'm not aware of prior work that benchmarks reward models while controlling for style. Similar ideas have been discussed generally in RL, but not used to design better reward model benchmarks. To the best of my knowledge the contributions are original.\n\n**Quality**: The method is sufficiently rigorous for the results to be reproduced. The way the paper evaluates the accuracy of RM-Bench is sound, and the three main takeaways from the paper are well evidenced. For example, Appendix K shows the authors covered many popular publicly available reward models, which supports the claim that progress in reward modeling is necessary.\n\n**Clarity**: The paper is clearly written and the figures are not confusing. The authors introduce the problem, background and their contributions well.\n\n**Significance**: I find the results significant. They point to what seems to be an important issue in a previous evaluation and improve upon it by mitigating that issue. They then show the improved benchmark is correlated with downstream policy model performance. The other takeaways of the paper are also significant in their own right, such as benchmarking the reward modeling of models trained with DPO, but these are of course less significant than the main contribution of the paper.",
        "weaknesses": "- As far as I could tell the exact data used in the paper is not available. It would be good to have a 'canonical' version of RM-Bench on HuggingFace or somewhere similar to make reproducing the results easier.\n- The paper does not show that the reason RM-Bench is more accurate is because you control for subtleties in the text like style. Although this seems likely, showing evidence that this isn't because of other differences between RM-Bench and Reward Bench (e.g. by ablating the control for style bias) would increase my soundness score to a 4.\n- It would be interesting to see the correlations separately for each of the benchmark types (math, code, safety)."
      }
    ],
    "rating_avg": 8.0,
    "confidence_avg": 3.6666666666666665,
    "decision": "Accept (Oral)",
    "meta_review": "This paper introduces a new benchmark for reward modeling that is designed to be robust to subtleties in generated text. In previous benchmarks, rejected answers were usually generated by weak models, which could be easily exploited.\n\nStrengths:  \nThis paper studies an important problem with novel solution ideas. The results provide valuable new observations to the community, particularly regarding DPO models as reward models.\n\nWeaknesses:  \nThe initial version of this paper relied heavily on GPT4o, and many results were conducted on only one model series. However, the authors addressed these concerns by adding additional experimental results during the rebuttal period.\n\nOverall, I think the results of this paper are interesting and significant.",
    "author_remarks": "",
    "decision_comment": ""
  },
  {
    "id": "sEv6vHIUnu",
    "title": "Structured Predictive Representations in Reinforcement Learning",
    "authors": [
      "Aditya Mohan",
      "Marius Lindauer"
    ],
    "abstract": "Reinforcement Learning (RL) remains brittle in complex environments characterized by sparse rewards, partial observability, and subtask dependencies. Predictive state abstractions capture the environment's underlying temporal structure and are crucial to overcoming these challenges. Yet, such methods often only focus on global one-step transitions and overlook local relationships between trajectories. This paper explores how capturing such relationships can enhance representation learning methods in RL. Our primary contribution is to show that incorporating a Graph-Neural Network (GNN) into the observation-predictive learning process improves sample efficiency and robustness to changes in size and distractors. Through experiments on the MiniGrid suite, we demonstrate that our GNN-based approach outperforms typical models that use Multi-layer Perceptrons (MLPs) in sparse reward and partially observable environments where task decomposition are critical. These results highlight the value of structural inductive biases for generalization and adaptability, revealing how such mechanisms can bolster performance in RL.",
    "keywords": [
      "Representation Learning; State Abstractions; Reinforcement Learning; Self-Prediction"
    ],
    "venue": "ICLR",
    "year": 2025,
    "pdf_url": "https://openreview.net/pdf?id=sEv6vHIUnu",
    "forum_url": "https://openreview.net/forum?id=sEv6vHIUnu",
    "reviews": [
      {
        "rating": "8",
        "confidence": "3",
        "summary": "This paper introduces a GNN-based approach to representation learning, specifically geared towards environments with sparse rewards and partial observability, that aims to improve sample efficiency and robustness by taking advantage of spatial and temporal structure in trajectories. Building upon past work on self-predictive methods for representation learning (Ni et al. 2024), the authors demonstrate improvements in selected MiniGrid environments. Additionally, the authors show that representations learned with the proposed method generalize better to distractors or size changes in the environment.",
        "strengths": "Originality:\n- The paper investigates a novel question, namely can graph-structures be leveraged when learning representations. A brief search shows the contributions of the paper are indeed original work (I was unable to find other GNN-based representation learning methods for RL). \n\nQuality:\n- The quality of the paper is generally quite good, with sufficient motivation and background, before introducing results for the proposed method. \n- The experiments demonstrate the authors claims, that learning from structure across a batch of latent states has improved sample efficiency and increased robustness. They demonstrate good experimental design, with the only changed factor being the GNN operating over trajectories instead of the MLP operating on a single state in the batch. \n\nClarity:\n- I think the paper is very well-written and clear in its presentation. Specifically, sections 2.1, 2.2 and 3.2 are particularly excellent. \n\nSignificance:\n- The significance of the paper is moderate. The contributions demonstrate some improvement, showing benefit over prior work, via a new proposed addition. However, there could be more experimentation to demonstrate how this method performs in different, more complex environments and gain further insight into the structures learned. \n\nOverall, the authors present a novel, yet slight, GNN-based modification to an existing self-predictive representation learning method, with the aim to improve the quality of learned representation by leveraging spatial and temporal structure across trajectories. The quality, novelty and clarity of the paper and it's contributions are solid. I would be willing to increase my score if the authors were able to demonstrate or justify why this method would perform well in environments more complex than gridworld-based environments, where the inherent structure the method claims to take advantage of would be far more complex. Additionally, I would be able to increase my score for the significance of this paper if there were more results on the insights gleaned from the structures this method learns. Lastly, I also have some questions around experimental results and baseline design, for which I would appreciate clarifying responses from the authors.",
        "weaknesses": "There's a few areas of improvements that are warranted by the paper. \n- While the overall clarity is great, it was not immediately clear in the abstract and introduction that the authors were focused on environments with partial observability (and hence the selection of MiniGrid as their testbed). It's clear that as you read the paper that their work focuses on the POMDP model (history encoder, extending the objectives to the POMDP case, etc.). Additional clarity would make this paper slightly stronger.\n    - Specifically, line 17, 53, etc. says in RL, but should be more specific.\n- The work only tests their method on a gridworld domain (MiniGrid) and it's not clear if this work can generalize to more complex environments, where perhaps the graph structure is more complicated and similarities between trajectories are less clear. \n- Further experiments to understand what the learned structure in the latent space would be very useful to provide further insight into _why_ the GNN-based method works in various settings. Work similar to Figure 1 for other environments enhance the contributions of the paper. Such results would bolster the intuition described in Section 3.1. It would also help strengthen the significance of the paper and it's contributions, because it would shed light on how such structures can apply to other \n- The baselines comparison could be substantially stronger. The authors only compare to a version their method without the GNN, but not against other variants or other methods in the literature (such as the ones compared to in Ni et al. or other cited work). Concretely, the authors say \"the MLP predicts the next observation for each latent state in a batch and does not use relational reasoning for the whole batch.\" I understand this to mean that the MLP predicts each state in the batch independently. However, an ablation study where the authors compare to a variant that is an MLP allowed to predict over the entire latent batch, like the GNN, but with fully connected layers instead of message passing, would be helpful in isolating what element of the method makes the largest contribution (or if you need both). \n    - Also, if I misunderstood the MLP baseline, and it is actually a fully connected layer that operates over the states in a batch (i.e. is provided the trajectories instead of individual states), then I would make the same argument about comparing to the single-state version. More baselines would be helpful to fully understand the nature of the improvement. \n\nNits (did not affect score but just flagging for the authors):\n- There's a grammatical error in the sentence construction on line 155.\n- There's a typo on line 291, extra observation.\n- Line 423 has a typo on `tMiniGrid`, should be `MiniGrid`. \n- Line 537 should be `incorporate more algorithms.` (`into it` is not quite grammatical)"
      },
      {
        "rating": "5",
        "confidence": "3",
        "summary": "The paper introduces Message Passing Graph Neural Networks as network architecture in self-predictive RL.",
        "strengths": "- The paper is clear and well-written\n- The paper addresses a compelling problem for the community.\n- The idea is well motivated",
        "weaknesses": "Flaws in Notation/Clarity: \n- minor notational mistakes (for instance Equations (1), (RP))\n- General typos (L189, 228, 292, 294, 330+331,…)\n- Usually, “value based methods” refer to methods, that don’t learn a policy (L.119)\n- Term “Q-Function” is not explained\n- subscript of h seems to have different meanings (L. 217 & L. 124)\n\n\nMethod:\n- Proposition 3.1 is not clear, as not all spaces and metrics are formally defined. Moreover, there appears to be no proof for this proposition. \n- It is not clear how this Theorem provides the foundation for the hypothesis “Training a model to minimize the loss L by reasoning over both these trajectories ensures that the model generalizes between these subtasks, capturing the similarities between these histories.”, especially how this generalises between subtasks.\n- It is not clear how the construction of the graphs (L 274 -279) enforces the intuition behind the example in Figure 2.\n\n\nExperiments:\n- The results on some environments look substantially worse than the results presented in the baseline paper (Comparing Figure 4 here with Figure 6 in (Ni et al., 2024)). \n- I assume that the shaded regions in figure 4 and 5 respectively are 95%-CIs. Due to (partially) high overlap, it is not so clear, that the Graph Neural Network based method outperform the MLP counterpart."
      },
      {
        "rating": "5",
        "confidence": "4",
        "summary": "The papers discusses predictive state abstractions based on local relationships between trajectories. It shows that incorporating GNNs into the learning process improves the sample efficiency and robustness. The results give further evidence to the known fact that inductive biases can improve learning, if applicable to a certain class of problems such as 2D grid worlds.",
        "strengths": "The paper is written in a reader-friendly way, and the reported results appear to be technically correct. \n\nThe main statements are sufficiently well evidenced are likely to be correct.\n\nThe theoretical contribution is interesting and important for the considered type of problems.\n\nThe paper covers a good range of related work.",
        "weaknesses": "The main problem is the efficiency of the approach compared to other model-based versions of RL: For square grids a set of multi-resolution look-up table would be similarly useful as a maps (or model) in small or medium size grid-world problems. For larger problems, it needs to be be checked whether the GNN does not introduce any errors that could actually be misleading. In other words, the relation of any training errors of the GNN (or a degree of non-stationarity of the task) and the returns would be needed to reasonably assess the benefits of this particular scheme, beyond the general insight that models are useful in well-described (and stationary) environments.\n\nA related problem is the question of applicability to continuous problems, which could have been considered at least in the theoretical part. \n\nAbbreviations (GNN, MLP) need to be be explained in the abstract, because abstracts are to be readable also by non-specialists. The “O” in POMDP  is usually “observable” (rather than “observed”).\n\nThe role of discount factor in Eq. 1 needs to be reconsidered or explained.\n\nSect. 2.2: Put a full stop before “This”.\n\nThe paper is not particularly clear about the details of the experiments, although these can be inferred from other papers. E.g.: “We periodically increase the size”: If the size is always increased, it is not strictly “periodical”. Also, it is necessary to state the size range (8x8 and above?). To what level this range is explored? Is the size change even visible in the observations? Likewise, the number of \"distractors\" is only indirectly stated and whether there are particular arrangements of distractors and how they are affecting the agents perception or action, remains open. Also, changes of topology are mentioned, but there is no further information about this."
      },
      {
        "rating": "3",
        "confidence": "4",
        "summary": "The paper introduces a graph neural network based observation-predictive model to learn the latent representation for the downstream reinforcement learning. Experiments on navigation tasks in MiniGrid validate the performance of the proposed algorithm.",
        "strengths": "1. The paper adopts a graph neural network to replace the multi-layer perception to learn the observation representation for a downstream reinforcement learning. Simulation experiments on MiniGrid are presented.  \n2. The organization is ok.",
        "weaknesses": "1. The paper is largely influenced by the reference Ni et al. (2024), from the problem formulation, method, to experiments. However, some parts inherited from the reference are not related to this paper, which seems irrelevant, as the Q-irrelevant abstractions, model-irrelevant abstraction. The idea is incremental and intuitive. And the contribution compared the reference is minimal. \n2. Although the Proposition 3.1 is mentioned in the experimental section, no specific analysis is offered for clear description. \n3. Experiments on only one benchmark of MiniGrid is not sufficient, and the performance is also not stably convinced. \n4. Beside using the graph neural network as the observation representation learner, transformer is also widely used with better performance, as M-CURL [TPAMI 2023] to learn the state representation, TACO [NeurIPS 2024] to learn the state and action representations, and so on. \n\nThere are also some minor writing problems, as \n1. “{S2, U, S4, U, S5} (shown in red)” is not consistent with Fig. 2.\n2. The same paragraph as the above, the first character of \"for instance\" should be in capital. \n3. Why and how choosing the number of neighbors as m=4?\n4. The comparison method as AIS should be clearly stated in this paper to make the paper self contained. \n\nTo sum up, the authors are suggested to investigate the literature thoroughly to focus on a more important and clearer problem."
      },
      {
        "rating": "3",
        "confidence": "4",
        "summary": "This paper presented a representation learning method in RL, which learns predictable representations by integrating GNNs into a prediction model.  The main motivation is to capture temporal and relational dependencies by constructing graph structures in the latent space. Empirical evaluations are performed on the MiniGrid benchmark. The results show that using GNNs is better than MLPs in terms of performance and robustness.",
        "strengths": "- The paper is well motivated. \n- The presentation is good. \n- The performed experiment evaluations are relevant.",
        "weaknesses": "The idea of combining GNNs with a forward prediction model for learning predictive embeddings is interesting. But its contribution is limited, as it has been well investigated to learn representations by predicting raw future observations[1] or GNNs[2] in RL. \n\n- The main baseline, min-AIS presented in (Ni et al., 2024), was evaluated in 20 tasks from the MiniGrid benchmarks and several MuJoco tasks. I don't understand why the experiments only consider 4 MiniGrid tasks. I think drawing a conclusion based on the results on the picked 4 tasks is unsuitable. \n\n- According to Figure 4, min-OP is comparable to its counterpart using GNNs on 3 of 4 task, namely DoorKey, KeyCorridorS3R2, UnlockPickup tasks. Therefore, the Graph-based representation learning methods DO NOT outperform the MLP-based methods in all the cases. Therefore the conclusion in line 413 is inaccurate. \n\n- In Figure 5, the interval of min-OP is overlapped with Graph-OP in the presence of distraction changes (a) or size changes (b). So it is wrong to say that Graph-OP outperforms min-OP in ALL scenarios. \n\n[1] Improving sample efficiency in model-free reinforcement learning from images, AAAI 2020.  \n[2] Contrastive learning of structured world models, ICLR 2020."
      }
    ],
    "rating_avg": 4.8,
    "confidence_avg": 3.6,
    "decision": "Reject",
    "meta_review": "This work studies how incorporating a graph structured prediction into an observation prediction learning process can help improve sample efficiency and robustness. The key method insight is to take a latent self predictive model and then incorporate a GNN based prediction module into this. This is shown to help in robustness and efficiency over some minigrid experiments. \n\nStrengths\nThe idea makes intuitive sense and seems useful across many domains\nThere is theoretical backing to the work\n\nWeaknesses\nThe contribution over Ni et al does seem somewhat minimal and incremental\nThe experimental results are only on a single, relatively simple domain. Given the incremental nature of the methodology, much greater empirical evidence is needed to support the claims being made in the paper. \n\nOverall I think the paper has merit, but for it to reach it's full potential needs to be tried across a variety of more complex environments, with continuous spaces and so on. This will make a resubmission much stronger!",
    "author_remarks": "",
    "decision_comment": ""
  },
  {
    "id": "nNiWRRj6r9",
    "title": "ONLINE EPSILON NET & PIERCING SET FOR GEOMETRIC CONCEPTS",
    "authors": [
      "Sujoy Bhore",
      "Devdan Dey",
      "Satyam Singh"
    ],
    "abstract": "VC-dimension (Vapnik & Chervonenkis (1971)) and $\\varepsilon$-nets  (Haussler & Welzl (1987)) are key concepts in Statistical Learning Theory. Intuitively, VC-dimension is a measure of the size of a class of sets. The famous $\\varepsilon$-net theorem, a fundamental result in Discrete Geometry, asserts that if the VC-dimension of a set system is bounded, then a small sample exists that intersects all sufficiently large sets.\n    \n    In online learning scenarios where data arrives sequentially, the VC-dimension helps to bound the complexity of the set system, and $\\varepsilon$-nets ensure the selection of a small representative set. This sampling framework is crucial in various domains, including spatial data analysis, motion planning in dynamic environments, optimization of sensor networks, and feature extraction in computer vision, among others. Motivated by these applications, we study the online $\\varepsilon$-net problem for geometric concepts with bounded VC-dimension. While the offline version of this problem has been extensively studied, surprisingly, there are no known theoretical results for the online version to date. We present the first deterministic online algorithm with an optimal competitive ratio for intervals in $\\mathbb{R}$. Next, we give a randomized online algorithm with a near-optimal competitive ratio for axis-aligned boxes in $\\mathbb{R}^d$, for $d\\le 3$. Furthermore, we introduce a novel technique to analyze similar-sized objects of constant description complexity in $\\mathbb{R}^d$, which may be of independent interest. \n    \n    Next, we focus on the continuous version of this problem (called online piercing set), where ranges of the set system are geometric concepts in $\\mathbb{R}^d$ arriving in an online manner, but the universe is the entire ambient space, and the objective is to choose a small sample that intersects all the ranges. Although online piercing set is a very well-studied problem in the literature, to our surprise, very few works have addressed generic geometric concepts without any assumption about the sizes. We advance this field by proposing asymptotically optimal competitive deterministic algorithms for boxes and ellipsoids in $\\mathbb{R}^d$, for any $d\\in\\mathbb{N}$.",
    "keywords": [
      "Theoretical machine learning",
      "VC-dimension",
      "Geometric sampling"
    ],
    "venue": "ICLR",
    "year": 2025,
    "pdf_url": "https://openreview.net/pdf?id=nNiWRRj6r9",
    "forum_url": "https://openreview.net/forum?id=nNiWRRj6r9",
    "reviews": [
      {
        "rating": "6",
        "confidence": "2",
        "summary": "This is a theoretical paper that gives algorithms to construct epsilon nets and piercing sets for geometric objects that appear in an online setting. The size of the nets and piercing sets are tight in terms of the competitive ratio i.e. the largest ratio of the size of the net returned by the algorithm to the optimal size of the net at any point in the online setting.",
        "strengths": "1) Epsilon nets are very important in the field of computational geometry and learning theory. It appears that very less work is done regarding construction of epsilon nets/piercing nets when the objects appear in an online manner. Hence the paper will be of interest to the community.\n\n2) I tried to check the proofs in the main part of the paper to the best of my ability and the paper appears to be sound.\n\n3) The techniques/insights described here might be useful to construct epsilon nets for other objects also. I appreciate the use of figures to convey certain ideas.",
        "weaknesses": "1) The writing and the presentation of the paper is very weak. Parts of the paper are very abstract. Certain words and concepts appear earlier and are explained later and that too in abstract manner. The writing is repetitive also. Here I give few specific examples:\n\ni) In the Notation and Preliminaries section there is hardly any difference in the definition of online epsilon net and online piercing set. \n\nii) Terms like ranges, range space are used in the introduction section without properly defining them.\n\niii) You can give simple examples for what can be $\\mathcal{X}, \\mathcal {R}$ etc. in the introduction itself. The final results can be abstract but at least some examples might help understand the terminology better.\n\niv) It would be better to bring the pseudo code of the algorithms in the main paper\n\nThe writing and presentation need to be improved a lot.  In the current state the paper will not be accessible to a broad audience.\n\n2) It is not clear from the paper what are the technical challenges faced to maintain an epsilon net in the online setting. Please clarify as it will help highlight the novelty as to why the techniques of constructing the epsilon net differ from the offline case. For this you can add a small paragraph has to how epsilon nets can be constructed for similar object in the offline setting and why it is difficult to modify such algorithms for the online setting."
      },
      {
        "rating": "6",
        "confidence": "2",
        "summary": "The paper tackles the problems of online $\\epsilon$-nets and online piercing sets for geometric concepts, specifically focusing on bounded VC-dimension and various types of geometric shapes such as intervals, axis-aligned boxes, and ellipsoids. The authors introduce several new algorithms that achieve optimal or near-optimal competitive ratios for these problems, marking the first known results in several of these areas.",
        "strengths": "1. This paper is one of the first to tackle online $\\epsilon$-net and piercing set problems with a formalized approach, filling a noticeable gap in the existing literature.\n2. The work provides clear proofs and establishes bounds on the competitive ratios of the proposed algorithms.",
        "weaknesses": "1. This paper mainly focuses on lower-dimensional cases (one-dimensional intervals and boxes in up to three dimensions). Many practical problems exist in higher dimensions, and the algorithms’ performance and applicability might not extend well to such cases."
      },
      {
        "rating": "6",
        "confidence": "2",
        "summary": "The paper studies the online $\\epsilon$-net problem and the online piercing set problem for geometrical objects. \n\nFor the online $\\epsilon$-net problem, the paper considers the range space of intervals in $\\mathbb{R}^1$ and axis-aligned retangles in $\\mathbb{R}^2$ and $\\mathbb{R}^3$. For intervals, the paper gives an algorithm with asymptotically tight competitive ratio $O(\\log(1/\\epsilon))$. For axis-aligned rectangles, the paper gives an algorithm with nearly asymptotically tight competitive ratios ($O(\\log(1/\\epsilon))$ in $\\mathbb{R}^2$ and $O(\\log^3(1/\\epsilon))$ in $\\mathbb{R}^3$). \n\nFor the online piercing set problem, the paper considers the range spae of axis-aligned boxes, ellipsoids, and fat objects in $\\mathbb{R}^d$ for general $d$. For axis-aligned boxes and ellipsoids, the paper gives an algorithm with an asymptotically tight competitive ratio $O(\\log(M))$, where $M$ is the length range of the geometrical objects. For $\\alpha$-fat objects, the paper gives an algorithm slightly improving the existing $ O\\left(\\left(\\frac{2}{\\alpha}+2\\right)^d \\log M\\right)$ competitive ratio to $O\\left(\\left(\\frac{2}{\\alpha}+\\frac{7}{8}\\right)^d \\log M\\right)$ for $\\alpha \\in [1/2,1]$",
        "strengths": "The paper studies fundamental problems (online eps-net and online piercing set). The problem settings considered(range spaces of intervals, rectangles, ellipsoids, and fat-objects) are interesting and natural. The paper makes good contributions on these problems. In some problems, the paper achieves asymptotically optimal competitive ratio. \n\nOverall, I believe the paper makes good contributions to a natural problem. Its contributions are worthy to publish.",
        "weaknesses": "The main weakness lies in the writing of the paper. The writing lacks rigor and causes distraction. Many concepts are not clearly defined. Some concepts are not clearly utilized. The connection between the existing results and this paper's result is not clearly stated. I have detailed these issues scifically in the Questions section below.\n\nOverall, I believe the paper has the potential to be decent-to-good, provided that its writing is polished."
      },
      {
        "rating": "5",
        "confidence": "2",
        "summary": "This paper addresses the online ε-net and online piercing set problems for geometric concepts in computational geometry.  Specifically, it proposes  randomized algorithms for axis-aligned boxes in two- and three-dimensional spaces, achieving near-optimal competitive ratios, and  online algorithms for the piercing set problem  for more complex structures like ellipsoids and axis-aligned rectangles, presenting competitive ratios.",
        "strengths": "1. Novelty in Online Setup: The transition from offline to online algorithms for ε-nets and piercing sets addresses a gap in existing research. This online focus adds significant value to applications in dynamic learning environments.\n2. Comprehensive Theoretical Analysis: Each algorithm is rigorously analyzed for its competitive ratio, demonstrating tight bounds for several common geometric configurations.",
        "weaknesses": "1. The competitive ratios for higher dimensions grow rapidly, limiting the algorithms’ effectiveness in high-dimensional applications (e.g., for dimensions $d \\ge 4$). This can restrict practical use in real-world, high-dimensional datasets.\n2. The results are mainly for regular, axis-aligned geometric objects (boxes, ellipsoids), yet real-world applications often involve irregular or rotated shapes. Without additional adaptability, the proposed algorithms would struggle in cases where piercing sets are needed for non-standard objects.\n3. In the randomized approach for axis-aligned rectangles, a binary search tree is constructed over a subset of points, dividing intervals repeatedly until only ε-heavy regions remain. While theoretically sound, constructing and updating such a binary tree might be impractical in real-time applications due to overhead. A practical complexity analysis or alternative for dynamic binary tree maintenance would make the algorithm more viable.\n4. The paper is heavily theoretical, with limited discussion of empirical validation. Experiments comparing the proposed algorithms' performance to existing methods would strengthen the practical implications.\n5. Overall, I think this is a good paper, but might not be quite suitable for ICLR. Maybe the computational geometry or theory conferences, like SoCG, are more appropriate."
      }
    ],
    "rating_avg": 5.75,
    "confidence_avg": 2.0,
    "decision": "Accept (Poster)",
    "meta_review": "This work presents new algorithms for online eps-net and piercing set of certain geometric concepts. While the concept classes studied in this paper are quite limited, the theory still advances the literature via establishing almost matching lower and upper bounds and may inspire future research. Based on the reviews and the AC's own reading, the AC believes that the results are significant enough.",
    "author_remarks": "",
    "decision_comment": ""
  },
  {
    "id": "XBF63bHDZw",
    "title": "SimulPL: Aligning Human Preferences in Simultaneous Machine Translation",
    "authors": [
      "Donglei Yu",
      "Yang Zhao",
      "Jie Zhu",
      "Yangyifan Xu",
      "Yu Zhou",
      "Chengqing Zong"
    ],
    "abstract": "Simultaneous Machine Translation (SiMT) generates translations while receiving streaming source inputs. This requires the SiMT model to learn a read/write policy, deciding when to translate and when to wait for more source input. Numerous linguistic studies indicate that audiences in SiMT scenarios have distinct preferences, such as accurate translations, simpler syntax, and no unnecessary latency. Aligning SiMT models with these human preferences is crucial to improve their performances. However, this issue still remains unexplored. Additionally, preference optimization for SiMT task is also challenging. Existing methods focus solely on optimizing the generated responses, ignoring human preferences related to latency and the optimization of read/write policy during the preference optimization phase. To address these challenges, we propose Simultaneous Preference Learning (SimulPL), a preference learning framework tailored for the SiMT task. In the SimulPL framework, we categorize SiMT human preferences into five aspects: **translation quality preference**, **monotonicity preference**, **key point preference**, **simplicity preference**, and **latency preference**. By leveraging the first four preferences, we construct human preference prompts to efficiently guide GPT-4/4o in generating preference data for the SiMT task. In the preference optimization phase, SimulPL integrates **latency preference** into the optimization objective and enables SiMT models to improve the read/write policy, thereby aligning with human preferences more effectively. Experimental results indicate that SimulPL exhibits better alignment with human preferences across all latency levels in Zh$\\rightarrow$En, De$\\rightarrow$En and En$\\rightarrow$Zh SiMT tasks.  Our data and code will be available at https://github.com/EurekaForNLP/SimulPL.",
    "keywords": [
      "simultaneous machine translation",
      "simultaneous preference optimization",
      "human preferences"
    ],
    "venue": "ICLR",
    "year": 2025,
    "pdf_url": "https://openreview.net/pdf?id=XBF63bHDZw",
    "forum_url": "https://openreview.net/forum?id=XBF63bHDZw",
    "reviews": [
      {
        "rating": "8",
        "confidence": "4",
        "summary": "This works present a preference learning framework for simultaneous tasks like SiMT. Particularly, the proposed SimulPL framework categorizes SiMT human preferences into five aspects: translation quality preference, monotonicity preference, key point preference, simplicity preference, and latency preference.",
        "strengths": "1. This is an intriguing question and a useful framework for practical SiMT scenarios. While SiMT has been extensively studied in the research community, most papers have focused on automatic metrics rather than real human preferences. This work proposed 5 human preferences that are closely related to the end-users of SiMT.\n\n2. The proposed optimization objective aligns well with the proposed human preferences. For example, the output length constraint is applied for latency preference. The derived final objective in Eq(9) is further to improve its read/write policy.",
        "weaknesses": "1. The data construction relies on GPT-4/4o. What is the cost of construction the training data? Does it mean GPT-4/4o is the upper bound of human preference alignment? Or this work is to GPT-4 preference alignment?  Figure 2 only shows the win-rate between GPT-4 translation and original one. Is there a comparison between GPT-4 and professional interpreter?\n\n2. In the experiments, you only tune the hyper-parameter $\\alpha$, and set $c_t$ as 0.5 to control the read/write. In general, tuning the thresholds of $c_t$ may introduce various read/write strategies. Did you try other threshold?"
      },
      {
        "rating": "6",
        "confidence": "4",
        "summary": "The paper introduces Simultaneous Preference Learning (SimulPL) for the task of Simultaneous Machine Translation. The approach encompasses not only data construction but also model training and inference strategies. However, the novelty of the proposed method appears to be insufficient.",
        "strengths": "The paper presents a comprehensive approach to Simultaneous Machine Translation, addressing data construction, model training, and inference.",
        "weaknesses": "1. The paper lacks a clear emphasis on the innovative aspects of the proposed method. Highlighting specific novel contributions would strengthen the paper.\n\n2. It remains unclear how the quality of the automatic labeling by GPT-4 is ensured, and the consistency rate with human labeling is not provided.\n\n3. The distinction between the uppercase X and lowercase x in equations 6 and 7 needs clarification.\n\n4. According to Figure 6, the improvement of SimulPL over only MSFT is not substantial, raising questions about the effectiveness of the proposed method."
      },
      {
        "rating": "6",
        "confidence": "4",
        "summary": "This paper studies the problem of Simultaneous Machine Translation (SiMT). To achieve preference alignment for SiMT models, this paper categorizes human preferences in SiMT scenarios and focus on five aspects: translation quality preference, monotonicity preference, key point preference, simplicity preference, and latency preference. Based on this catogorization, this pape rconstructs human preference prompts with GPT to generate preference data for SiMT. After constructing the data, this paper designs a multi-task supervised fine-tuning stage and a simultaneous direct preference optimization stage to achieve preference alignment for the SiMT model. Experiments on text-to-text SiMT tasks show the effectiveness of the proposed approach.",
        "strengths": "1. The proposed approach shows performance improvement on the machine translation datasets.\n2. The proposed five aspects for SiMT preference alignment could be useful.\n3. The presentation is clear and easy to understand.",
        "weaknesses": "1. Heavy reliance on the quality of the GPT-generated preference data, and few effort is done to verify the quality/correctness/trustworthiness of the generated data.\n2. Overall limited novelty for the whole framework, the idea of length penalty term |y| in the proposed SimulDPO loss function come from [1], and nothing much novel is added here.\n3. Scope is very limited to SiMT only, and this method does not seem applicable to more general LLM preference alignment cases.\n4. Some design is arbitrary. For example, in Confidence-Based Policy During Inference, why set the confidence c_t as exactly 0.5? What if your confidence estimation model is biased, e.g., $\\mathbb{E}(c_t)\\neq0.5$?\n5. More experiments and analysis should be done to conduct a comprehensive evaluation. In the current form, experiment analysis are limited.\n\n\nReferences:\n[1] Park, Ryan, et al. \"Disentangling length from quality in direct preference optimization.\" arXiv preprint arXiv:2403.19159 (2024)."
      },
      {
        "rating": "8",
        "confidence": "4",
        "summary": "This paper introduces a new approach to simultaneous interpretation with low latency.",
        "strengths": "The experimental results look impressive.\n\nI think there will also be interest in the experimental materials.  Your arguments about offline machine\ntranslation (OMT)  are convincing.  That said, I didn't see any discussion of sharing those materials.\n\nI like the idea of offering the user choices over preferences, but do we need to restrict ourselves to a single choice?  Could you imagine a speech-to-text scenario where you could offer multiple text windows so the user can look at one window when latency is a priority and another window when BLEU is a priority?",
        "weaknesses": "I have never been that happy with the standard discussion of latency and BLEU scores in this literature.  I have quite a bit of experience with professional interpreters as well as automatic solutions.  According to a number of standard metrics, the automatic solutions are better than professional interpreters, but I know that I am more engaged in the meeting when I have access to an interpreter.  They tell me what I need to know when I need to know it.  In addition, sometimes the speaker uses a metaphor that requires more explanation.    The professionals understand when then need to do more than just translate what the speaker said.\n\nI never liked average latency.  I can't fault you for doing what others have done, but sometimes latency matters and sometimes it doesn't.  The professionals understand this.  They speed up when necessary and slow down when latency is less of a priority.  Moreover, I probably care more about worst case latency or RMS latency than average latency.\n\nThis literature would benefit by including more input from professional interpreters that have a lot more experience in this area than we have.\n\nI would really like to see some data from schools that teach professional interpreters. We should be able to record what students say in the booth when they learn how to do this task."
      }
    ],
    "rating_avg": 7.0,
    "confidence_avg": 4.0,
    "decision": "Accept (Poster)",
    "meta_review": "The paper introduces a framework for simultaneous machine translation (SiMT) that aligns with human preferences, categorized into five aspects: translation quality, monotonicity, key points, simplicity, and latency.\n\nThe paper's strengths include its comprehensive approach to addressing human preferences in SiMT, the innovative use of GPT-4/4o for generating preference data, and the convincing experimental results demonstrating significant improvements in alignment with human preferences. The paper is well-written and easy to understand, making complex ideas accessible to the reader.\n\nThe weaknesses include the reliance on GPT-4/4o for data construction, raising questions about the cost and quality of the generated data, and the lack of detailed comparisons with professional interpreters. The presentation could be improved, particularly in sections discussing the empirical validation and the logical flow between different parts of the paper.\n\nAll the reviewers are positive about the paper. I recommend accepting it.",
    "author_remarks": "",
    "decision_comment": ""
  },
  {
    "id": "R2834dhBlo",
    "title": "Neural Interactive Proofs",
    "authors": [
      "Lewis Hammond",
      "Sam Adam-Day"
    ],
    "abstract": "We consider the problem of how a trusted, but computationally bounded agent (a 'verifier') can learn to interact with one or more powerful but untrusted agents ('provers') in order to solve a given task. More specifically, we study the case in which agents are represented using neural networks and refer to solutions of this problem as neural interactive proofs. First we introduce a unifying framework based on prover-verifier games (Anil et al., 2021), which generalises previously proposed interaction protocols. We then describe several new protocols for generating neural interactive proofs, and provide a theoretical comparison of both new and existing approaches. Finally, we support this theory with experiments in two domains: a toy graph isomorphism problem that illustrates the key ideas, and a code validation task using large language models. In so doing, we aim to create a foundation for future work on neural interactive proofs and their application in building safer AI systems.",
    "keywords": [
      "interactive proofs",
      "game theory",
      "neural networks",
      "safety",
      "multi-agent reinforcement learning"
    ],
    "venue": "ICLR",
    "year": 2025,
    "pdf_url": "https://openreview.net/pdf?id=R2834dhBlo",
    "forum_url": "https://openreview.net/forum?id=R2834dhBlo",
    "reviews": [
      {
        "rating": "5",
        "confidence": "3",
        "summary": "This paper discusses various games which could be used as multi-agent training setups. The objective of these games is to come up with ways of training models by getting models to interact with each other; this is justified by reference to the problem of training models that are untrusted, and the problem of training models that are smarter than human labelers (\"scalable oversight\").\n\nThe paper provides some formalism for a variety of games that could be used for this purpose, proving various results about them (e.g. about cases where you can bound the worst-case risk).\n\nIt introduces some new protocols, such as the neural interactive proof protocol, and some zero-knowledge protocols.\n\nIt then evaluates some of these protocols in empirical settings; an algorithmic graph isomorphism setting and an APPS code verification setting.",
        "strengths": "- I think the problem discussed by this work is important\n- I'm not aware of the NIP protocol being investigated in the past (though it is an obvious generalization of other things that have been studied). I think that the NIP protocol is plausibly better than other protocols that have been investigated, so it's a contribution to suggest it and empirically investigate it.",
        "weaknesses": "This paper has two main contributions: theory and empirical results. I'm concerned that the theoretical results aren't very important, they aren't crucially related to the empirical results, and the empirical results (while promising) aren't very detailed/strong.\n\n## The theoretical results aren't very important\n\nFirstly, I was not persuaded that a lot of the theory is very useful to understand. I assume that the results are correct, but I don't think they're very informative about how to construct better protocols or how to analyze the safety of protocols in this setting.\n\n- I'm not sure that the proofs about worst-case performance can be used in practice, because the conditions are very strong.\n- As a less important example, the paper introduces the possibility of zero-knowledge proofs, but only very briefly gestures at why it would be helpful to have a protocol be zero-knowledge in this context.\n\n## The theoretical results aren't crucially related to the empirical results\n\nI don't see a strong connection between the theoretical contributions and the empirical experiments. E.g. the zero-knowledge proof idea is proposed, very briefly justified, and then doesn't appear in the empirical results.\n\n## The empirical results aren't very detailed/strong\n\nThe results on graph isomorphism are somewhat interesting but it's hard to take much away from them except as a demonstration that the nip protocol isn't buggy somehow.\n\nThe results on APPS have the potential to be really interesting--I can totally imagine a version of this paper where, along the lines of various scalable oversight papers in the past, you implement nip in the APPS setting and demonstrate that it works better than debate etc. But I don't feel like this paper establishes this conclusively or provides substantial insight into why the technique works (e.g. section 6.2 here is much less detailed than section 3 in Khan et al, \"Debating with More Persuasive LLMs Leads to More Truthful Answers\", https://arxiv.org/pdf/2402.06782).\n\n----\n\nI'm also not persuaded that prover verifier games are a good formalism for developing oversight techniques, compared to e.g. the type of formalism in \"AI Control: Improving Safety Despite Intentional Subversion\" https://arxiv.org/abs/2312.06942."
      },
      {
        "rating": "10",
        "confidence": "2",
        "summary": "This paper introduces \"Neural Interactive Proofs\" (NIPs), a framework for enabling a computationally bounded but trusted agent (verifier) to learn to interact with more powerful but untrusted agents (provers) to solve decision problems. The work bridges concepts from interactive proofs in complexity theory with modern machine learning approaches. The paper makes four main contributions:\n\n1. A unifying game-theoretic framework based on prover-verifier games that generalizes existing neural interactive proof protocols\n2. Several new protocols, including single-prover (NIP), multi-prover (MNIP), and zero-knowledge variants, each with theoretical guarantees about their properties and computational power\n3. A theoretical and empirical comparison of both existing and new protocols\n4. Empirical validation on two domains: a graph isomorphism task, and a code validation task using large language models\n\nThe work aims to create a foundation for future research on neural interactive proofs and their application in building safer AI systems by providing ways for weaker systems to verify the outputs of more powerful ones. The authors provide theoretical results establishing correspondences between their protocols and valid proof systems, as well as empirical evidence.",
        "strengths": "This paper stands out for bridging theoretical and practical contributions while maintaining high standards of rigor throughout, as well as for the generality of the neural interactive proofs framework.\n\n1. Originality:\n    - Novel unification of interactive proofs with neural networks, bridging complexity theory and machine learning\n    - Creative adaptation of game-theoretic concepts to create learnable verification protocols, particularly use of Nash and Stackelberg equilibria and their relationship to proof validity\n    - The careful treatment of approximate equilibria to handle practical ML settings\n2. Quality:\n    - Strong theoretical foundations with rigorous proofs of protocol properties\n    - Documentation of hyperparameters, architecture choices, and training procedures\n    - Release of reproducible codebase for future research\n3. Clarity:\n    - Excellent high-level exposition of the key ideas and their implications throughout the paper.\n        - I want to call out in particular the description of practical applications of zero-knowledge proofs (L368-369: preventing model stealing via black-box access): this was enlightening.\n4. Significance:\n    - Addresses a crucial challenge in AI safety: verifying outputs of powerful AI systems when the verifier is computationally bounded but trusted, and the prover is powerful but potentially untrustworthy\n    - Provides a theoretical framework that can be extended to many verification scenarios\n    - Demonstrates the approach through experiments on both toy problems (graph isomorphism) and large language models (coding challenge)\n    - Opens new research directions in combining interactive proofs with machine learning\n    - Potential impact on development of safer AI systems",
        "weaknesses": "I believe there are two central weaknesses of this paper, beyond what is listed in section 7 (lack of use of advanced methods, evaluation only on two domains, lack of evaluation of all protocols):\n\nThe biggest weakness is that the scope, motivation, and impact of NIP are not made clear.  Perhaps this is just a lack of context on interactive proofs and game theory on my part, but I cannot tell whether the combination of game-theoretic equilibria with generalization-from-examples for specifying the verifier will be widely applicable and revolutionary, or turn out to be relatively niche in practice.\n\nSome more specific points in an attempt to drive at my confusion:\n\n- Line 107 says “Importantly, we assume that it is impractical or impossible to convert the task description into a specification amenable to standard formal verification tools.” This assumption seems wrong.  Insofar as we are capable of training a non-interactive verifier, and willing to trust that verifier, we can just use the verifier itself (however large it may be) as the formal specification.  Applying more-or-less standard formal verification techniques to theorem statements that contain a full neural net is considered, for example, in [1].  Instead, it seems the assumption to make here is that the task is complicated enough that any system which is powerful enough to (non-interactively) verify the solution is larger or more complicated than what we’d be willing to trust as part of our specification.\n- Proposition 1 (L242—245, L770) is used to motivate the insufficiency of `adp`, but the example constructed in the appendix is contrived as far as I can tell.  Sure, it is possible to gerrymander the set of possible prover protocols and verifier protocols so that Stackelberg equilibria are insufficient, but this seems to me to be severely unrealistic.  In realistic settings, we expect that computationally unbounded verifiers always have a winning strategy of “ignore the provers and solve the problem”, and so sufficiency of `adp` or `nip` must be evaluated with regard to some reasonable model of computational limitations.  I did not find any justification in the paper for believing that the game used to prove Proposition 1 is a reasonable toy model of computationally limited provers.\n- I would very much like to see an example of a problem where the interactivity permits significant compression of the specification / theorem statement (thereby making the specification easier to trust, as per the motivation of Example 1).  In the absence of this, the case for `nip` over `adp` is much weaker.  The graph isomorphism example is too weak: a verifier for graph isomorphism can be hand-coded to run in polynomial time.  In problems like graph non-isomorphism, where interactivity allows bypassing an exhaustive loop with random checking, we don’t expect significant compression in an interactivity-based theorem statement over a non-interactive theorem statement.  However, transformers cannot use loops, so this theorem statement compression is not relevant to NIP over IP.  Can NIP be fully factored into the classical compression that interactivity gives in IP (that of loops, as far as I’m aware) and the generalization-from-examples discussed on lines 266—269, or is there some interaction between the interactivity component and the neural / game-theory equilibrium component that would suggest that Example 1 is realistic rather than hyperbolic?\n\nAdditionally, perhaps relatedly, there is no exploration of how performance degrades as the complexity of verification tasks increases.\n\nA secondary weakness is that, while a valiant attempt is made to present the theory rigorously, the notation is not fully explained and the constraints in one of the central definitions (5) are contradictory.  I call this weakness secondary because it is obvious that the ideas are sound and the definitions are repairable.\n\nDefinition 3 in general is under-defined:\n\n- Line 173: ∆ is used without being defined.  What is it?\n- Line 174—175: The notation $C(i) := \\{c \\in C : i \\in N \\}$ is being used non-standardly.  Strictly interpreting set-builder notation would give $C(i) := C$ or $C(i) := \\prod_{i\\in N} C$ (depending on whether we are taking a union or a disjoint union), but this is clearly not what is mean.  Perhaps you meant to write $C(i) := \\{c \\in C : c(i) = 2 \\}$?  (Note that defining $N = \\{1, \\ldots, n\\}$ is inconsistent with taking $2 = \\{0, 1\\}$, so for consistency you have to use 1 for false and 2 for true unless you want to change the definition of $N$ or call out $2$ as a different set.)\n- Line 174: “When $\\mu(c, t)$ is deterministic” how is non-determinism defined here?  What indication was there that $\\mu$ could be non-deterministic?\n- Line 176: What does $\\sim$ in $i \\in N’ \\sim \\mu(t, c)$ mean?\n- Line 178: What is $\\rho$?\n- Line 178: Is the message chosen randomly per-channel, per-timestep, per channel per-timestep, or per-game?\n\nDefinition 5 is also confusing:\n\n- Line 223—225: What is $m^T$?  Is it the same as $m_T$ in L140?  And I presume $1_S$ is the indicator function on membership in $S$?\n- Line 223—225: The direction of the inequality seems wrong.  If we are trying to minimize loss, then we want $\\sigma$ to have lower verifier loss (be better) when the expected match with the indicator function is higher.\n- Line 228—230: Criterion 3 is inconsistent.  L219 says $\\mu(c, 0) = \\emptyset$ for all $c\\in C$, but here we say that $\\mu(0, c^\\dagger)$ (which I assume is a typo for $\\mu(c^\\dagger, 0)$, as otherwise it does not type-check) is non-empty.  L220 is also contradicted: $c^\\dagger = \\{ p \\}$ for $p \\in N^p$ but $c^\\dagger$ is assumed on L220 to equal $\\{ v \\}$ for some $v \\in N^v$, which is only possible if $N^p \\cap N^v \\neq \\emptyset$.  But even if this is the case, it would still contradict criterion 2, which asserts that no verifier can solve the problem, precluding the overlap of provers and verifiers.\n\n[1] Jason Gross, Rajashree Agrawal, Thomas Kwa, Euan Ong, Chun Hei Yip, Alex Gibson, Soufiane Noubir, and Lawrence Chan. “Compact Proofs of Model Performance via Mechanistic Interpretability.” 2024. [arXiv:2406.11779](https://arxiv.org/abs/2406.11779)."
      },
      {
        "rating": "5",
        "confidence": "4",
        "summary": "The paper considers a prover-verifier game to improve the correctness of the output of ML models. The verifier, which cannot direct prove the correctness, engages with a set of provers whose outputs are not trustable. The interaction between verifier and provers can make the final answer more trustable. It also formulates their interactions as a zero-knowledge proof. \n\nSimple experiments are conducted on two use cases: testing graph isomorphism and code validation.",
        "strengths": "The formulation of the problem into a zero-knowledge based verifier-prover interaction.",
        "weaknesses": "While I like the formulation, I have some concerns about this paper: \n\n1. It is unclear on the zero-knowledge aspect. Why do we need to have the zero-knowledge in their interactions? The argument on the potential model stealing needs to be more carefully consolidated. \n\n2. The actual technical contribution is limited. Neural interactive proof is technically explained with worst-case loss and Stackelberg game. First, I wasn't able to understand the paragraph under Proposition 2, due to the confusing and undefined notations. This seriously affects my understanding about the worst case loss. Second, the bi-level optimisation used to solve the Stackelberg game is obvious, and for a verifier-prover game, I don't think we need to go through a definition of Stackelberg game to reach the bi-level optimisation. \n\n3. Many technical developments in the paper are not actually implemented and experimented, including the zero-knowledge interactions. This, combined with many typos in the paper (e.g., \"a node a similar node the second graph\"), shows that the paper requires more developments before it becomes publishable. \n\n4. The experiments were conducted on two simple experiments. It is unclear if the method is actually better and can generalise to more complex settings. \n\nIn summary, I like the formulation of the problem as a zero-knowledge based verifier-prover game, but such reduction is not well motivated and the actual technical contribution (e.g., zero-knowledge) is not consolidated, neither theoretically nor practically."
      }
    ],
    "rating_avg": 6.666666666666667,
    "confidence_avg": 3.0,
    "decision": "Accept (Poster)",
    "meta_review": "This paper provides a framework that generalizes prover-verifier games where agents are parametrized by Neural Networks. They provide several protocols where the agents can leverage data and learn equilibria of the game to find valid proofs. \n\nThe strengths of this paper are:\n- Conceptually, it aims at tackling an important problem\n- It lays some strong theoretical foundations for prover-verifier games at the intersection between standard theoretical computer science, game theory and machine learning. \n- Even though the paper has some significant theoretical contributions, the authors also provide some experiments showing the efficiency of the proposed protocol.\n\nThe weaknesses of this paper are the experiments and the potential lack of novelty with respect to the related work on debating agents. \nAfter reading the paper and some of the related work, I believe that the conceptual (and theoretical) contributions are novel enough.\n  \n\nI suggest the authors to:\n- Make their paper more accessible to the ML community, as the language used in the paper is not the most adapted to ML researchers. In particular, it would be helpful to:\n- Be more precise regarding the usefulness of the theory and its takeaways. For instance, it could be useful to have a summary somewhere (e.g. in the contribution) of the theoretical insights (citing one of your answers here):\n  - Optimising for Nash equilibrium is not sufficient for finding a valid protocol\n  - Several subtle aspects of the interaction protocol can have a significant impact on its resulting efficacy, such as:\n     - The ability of the verifier to randomize (Proposition 1)\n     - Separate communication channels for the provers\n- How these insights are implemented in practice in your methods (while not occurring in the baselines)\n- Make a precise practical ablation regarding the importance of these theoretical insights (i.e. showing experiments that validate the theoretical claims above).",
    "author_remarks": "",
    "decision_comment": ""
  },
  {
    "id": "dML3XGvWmy",
    "title": "Gödel Agent: A Self-Referential Framework Helps for Recursively Self-Improvement",
    "authors": [
      "Xunjian Yin",
      "Xinyi Wang",
      "Liangming Pan",
      "Xiaojun Wan",
      "William Yang Wang"
    ],
    "abstract": "The rapid advancement of large language models (LLMs) has significantly enhanced the capabilities of AI-driven agents across various tasks. However, existing agentic systems, whether based on fixed pipeline algorithms or pre-defined meta-learning frameworks, cannot search the whole agent design space due to the restriction of human-designed components, and thus might miss the globally optimal agent design. In this paper, we introduce Gödel Agent, a self-evolving framework inspired by the Gödel machine, enabling agents to recursively improve themselves without relying on predefined routines or fixed optimization algorithms. Gödel Agent leverages LLMs to dynamically modify its own logic and behavior, guided solely by high-level objectives through prompting. Experimental results on mathematical reasoning and complex agent tasks demonstrate that implementation of Gödel Agent can achieve continuous self-improvement, surpassing manually crafted agents in performance, efficiency, and generalizability.",
    "keywords": [
      "Agent",
      "Large Language Model",
      "Reasoning",
      "Self-Improvement"
    ],
    "venue": "ICLR",
    "year": 2025,
    "pdf_url": "https://openreview.net/pdf?id=dML3XGvWmy",
    "forum_url": "https://openreview.net/forum?id=dML3XGvWmy",
    "reviews": [
      {
        "rating": "5",
        "confidence": "3",
        "summary": "The paper proposes a self-improving language model agent (\"Godel agent\") and evaluates it on a variety of benchmarks. The results suggest that the self-improving agent achieves better performance than hand-designed agent scaffolds or meta-learned agents, while also being cheaper to run than the latter.",
        "strengths": "* The proposed method is conceptually simple and clear and provides and intriguing possibility of building self-improving agents with current LLM technology.\n* The experiments include multiple benchmarks, a number of baselines and generally suggest strong results.\n  * The authors run ablations of different components of their agent and find all of them improve performance.\n* The qualitative analysis of the results is insightful and provides a good understanding of the strategies the self-improving agent implements.",
        "weaknesses": "**Results**\nI'm concerned about the presentation of the experiments and the **fairness of the empirical evaluation**. My key concerns are that the Godel agent uses significantly more inference compute than any of the other methods and that the description of the evaluation protocol is not sufficient to determine if the evalaution is fair.\n\nHere is my understanding of the evaluation setup (please correct me if I'm wrong):\n* The Godel agent is run for N iterations on a validation set of samples. In each iteration is produces a new policy and a new learning function.\n* After N iteration the policy is evaluated on held-out test problems and this result is reported.\n\nThis process gives the Godel agent significantly more inference compute than any of the hand-designed agent systems, which makes the comparison unfair. The only fair comparison in Table 1 is to Meta Agent Search which seems to typically be comparable in performance. Based on these results, I am not convinced the the Godel agent actually improves performance in a fair comparison.\n\nThis concern could be addressed by letting the baseline be a best-of-N method that applies N somewhat random perturbations to the policy and chooses the best of them. For example, this could be implemented by using GPT-4 to generate N different prompt variations and choose the best according to performance on the validation data.\n\nRelatedly, according to Appendix B the Godel agent uses GPT-4 for the learning algorithm but all methods only use GPT-3.5 for the policy. This makes the comparison additionally skewed in favor of the Godel agent which has access to GPT-4 in contrast to the other methods. A fair comparison would use GPT-4 for both the learning algorithm and the policy.\n\n\n**Presentation**\n\nI also have some concerns about the presentation and framing of self-improving agents in the paper. The paper often uses the term \"self-awareness\" without qualification. I'm concerned that anthropomorphization leads to a less scientific discussions and I would recommend the authors try to rewrite the paper to remove phrases like \"Our Godel Agent achieves self-awareness\".\n\nMoreover, potential risks from self-improving AI are not appropriately discussed. There is a significant literature on risks from self-improving AIs and this is a key concern in the AGI safety community. I think this literature should be acknowledged in the paper and there should be a more complete discussion of broader impacts of this technique than currently the case."
      },
      {
        "rating": "6",
        "confidence": "3",
        "summary": "* A big limitation of LLM agents is that there are handcrafted, self-improving agents are a promising direction to make this more autonomous\n* self referential framework that enables agents to recursively improve themselves without predefined routines\n* Agent can alter its own code and runtime memroy\n\nThe paper introduces Gödel Agent, a self-referential framework that enables agents to recursively improve themselves without predefined routines or fixed optimization algorithms.\nInspired by the Gödel machine, Gödel Agent allows agents to modify their own code and logic using large language models (LLMs), guided only by high-level objectives.\nThe agent uses techniques like monkey patching to read and alter its runtime memory, achieving self-awareness and self-modification.\nExperiments across coding, science, and math tasks show that Gödel Agent outperforms manually crafted agents in performance, efficiency, and generalizability.",
        "strengths": "* Seems like a promising and open-ended approach for removing humans in the loop of agent pipeline building\n* ADAS Meta Agent is a strong similar baseline and Godel outperforms it\n* Demonstrated effective self-improvement across multiple domains including reasoning",
        "weaknesses": "* Experiments seem limited in scope—mostly on controlled tasks; might not scale to complex real-world applications or embodied tasks\n* The final policies that are returned by the method don't seem very complicated or different from a basic human designed template. The agent designs discovered in the ADAS paper seem much more complex and creative. What explains this difference? \n* Given the limited evaluations, the room for self-improvement seems limited, can we really get much better than the base model for mathematical reasoning with fancy agent pipelines and prompts? A better showcase of the method would be on openended or embodied tasks vs text based reasoning\n* What’s the upper limit of self improvement, does it saturate?\n   *Whats the improvement in the 6 iterations\n* More detailed comparison to ADAS is needed in related work (Automated Design of Agentic Systems)\n   * What is Meta Agent Search and why does this Godel agent perform better?\n      * This needs to be clearer in the paper\n* The method is somewhat vague and not clear what’s going on, and what this has to do with self reference/recursion. Is this different than just tasking an LLM with modifying its own agent code?"
      },
      {
        "rating": "6",
        "confidence": "5",
        "summary": "This paper proposes a new self-evolving framework, Godel Agent, which leverages LLMs to dynamically modify self-generated logic and behavior. Empirical experiments show that this framework enables agents to recursively improve themselves without predefined routines or fixed optimization algorithms.",
        "strengths": "1. The workflow proposed in this paper is interesting; the core idea of recursive improvement is not implemented by improving the response itself step-by-step, but through updating the policy in an indirect way.\n\n2. The paper is well written, and easy to follow.\n\n3. The illustrations in figure 1 and examples given in Appendix C are clear and informative.",
        "weaknesses": "1. The motivation for adding four additional tools is not well-justified; there is no evidence supporting that these are the correct tools to add or that they comprehensively cover all needs. It's counterintuitive because if we claim the model has the ability to refine its policy and develop new policies, why do we need to provide tool guidance? Additionally, it's notable in Appendix C that although there is variability in the best policy, this policy seems can be decomposed into a combination of the listed tools, which suggests this work is not fully distinguished from meta-learning optimized agents where humans manually define the high-level strategy, and the agent learn a strategy to combine or rank the high-level strategy.\n\n2. The current framework heavily relies on the model's capability to generate and refine policies, as well as generate responses given a policy and query. However, this would not improve the model's ability to acquire new knowledge if such kind of off-line dataset available.\n\n3. The current refinement requires an oracle to progress the performance (U in line 6 from Algorithm 1). For the current Table 1, is the number of oracle utility function calls the same across all methods, and is the number of model queries the same for different settings?"
      },
      {
        "rating": "6",
        "confidence": "4",
        "summary": "The authors propose a self-evolving framework, Gödel Agent, inspired by the Gödel machine, to enable recursive self-improvements of agents, without relying on predefined routines or fixed optimization algorithms.\nThe authors conduct experiments to validate the proposed approach.",
        "strengths": "1) A framework\nThe authors propose a self-evolving framework, Gödel Agent, inspired by the Gödel machine, to enable recursive self-improvements of agents, without relying on predefined routines or fixed optimization algorithms.\n\n2) Experiments\nThe authors conduct experiments to validate the proposed approach.",
        "weaknesses": "1. Why LLM-based agent is a valid approach? No LLM is perfect. All LLMs make mistakes. What is reliable information? What is ground truth? Then why should we rely on LLMs to make decisions? For software engineering, no LLM can achieve a pass@1 of 100%. To make it worse, the popular evaluation method with several tests, is not perfect, so the evaluation results are not fully reliable.\n\n2.\nHow to make LLM-based agent a valid approach? LLMs may help generate plausible solutions. But there should be a mechanism to filter out or fix incorrect solutions.\n\nThe current submission does not provide such a mechanism.\n\nHow to improve an LLM-based agent? \nIt seems this boils down to waiting for stronger LLMs, which is likely out of the scope of the paper, though.\n\n3.\nThere are papers discussing / criticizing the reasoning / planning capacity of LLMs, which is the foundation of LLM-based agent (including those based on the Gödel machine), e.g.\n\nLLMs can’t plan, but can help planning in LLM-modulo frameworks, in ICML, 2024.\n\nGSM-Symbolic: Understanding the Limitations of Mathematical Reasoning in Large Language Models. arXiv 2024\n\nWithout sound capabilities for reasoning / planning, how to build LLM-based agents, in particular, the Gödel Agent?\n\nIt appears that empirical improvements are not enough to answer the above questions."
      },
      {
        "rating": "5",
        "confidence": "4",
        "summary": "The paper presents the Godel Agent, a prompt engineering framework inspired by the Godel machine, claiming to be a self-improvement framework. The authors evaluate Godel Agent in 4 tasks, and the game of 24.",
        "strengths": "The research topic is interesting and important. The paper provides an extensive evaluation.",
        "weaknesses": "1. There are several ambitious claims within the paper; for example, the abstract suggests that the method can explore the entire space to find the optimal solution. This is a bold statement and does not seem to be substantiated by the findings presented.\n2. The central claim about the capability to create \"different agents\" from an initial agent mostly involves modifying the conditioning of the autoregressive order through prompt engineering.\n3. Figure 1 shows some learnable components, yet the framework itself does not appear to incorporate learnable elements.\n4. Line 50 claims \"to eliminate the human design prior,\" which is challenging given that LLMs inherently contain human priors from being trained on human-generated text.\n5. Discussions on self-awareness of LLMs are speculative and might be better left out of a scholarly paper focused on introducing a new method.\n6. Section 3 is notably small and lacks clarity on the method’s implementation. It would benefit from additional details, particularly on how self-improvement is enacted within the Godel Agent and how evaluations are conducted.\n7. Lines 215-233 imply that evaluations rely on the environments provided. If this involves using the test set for evaluation, it represents a significant limitation of the method.\n8. How the solutions in Godel Agent are evaluated (referenced in line 6 of the pseudocode) needs clearer explanation.\n9. It would be beneficial to compare the cost of the Godel Agent with other methods, such as the CoT, both in terms of time and financial resources.\nThe authors might want to reevaluate their claims and revise the paper to provide a clearer presentation of the proposed method."
      }
    ],
    "rating_avg": 5.6,
    "confidence_avg": 3.8,
    "decision": "Reject",
    "meta_review": "This paper proposes an ambitious goal of creating a fully self-improving agent that can modify its own programmatic code. However, there are a few concerns that make this work not yet ready for publication. Firstly, the evaluation is not fair on a compute basis, since there is no control on the number of generation calls (mentioned by Reviewer ALKV). Secondly, the reported results for the Gödel agent are not better than ADAS, as the error bars are all overlapping, with the exception of MGSM. Deeper analysis revealing how the incremental program modifications and final programs produced by Gödel agent differ from and contribute to its success with respect to baselines like ADAS would make the contribution here much clearer.",
    "author_remarks": "",
    "decision_comment": ""
  },
  {
    "id": "1S8ndwxMts",
    "title": "Towards Robust Evaluation of Protein Generative Models: A Systematic Analysis of Metrics",
    "authors": [
      "Pavel Strashnov",
      "Andrey Shevtsov",
      "Viacheslav Meshchaninov",
      "Maria Ivanova",
      "Fedor Nikolaev",
      "Olga Kardymon",
      "Dmitry Vetrov"
    ],
    "abstract": "The rapid advancement of protein generative models necessitates robust and principled methods for their evaluation and comparison. As new models of increasing complexity continue to emerge, it is crucial to ensure that the metrics used for assessment are well-understood and reliable. In this work, we conduct a systematic investigation of commonly used metrics for evaluating sequence protein generative models, focusing on quality, diversity, and distributional similarity. We examine the behavior of these metrics under various conditions, including synthetic perturbations and real-world generative models. Our analysis explores different design choices, parameters, and underlying representation models, revealing how these factors influence metric performance. We identify several challenges in applying these metrics, such as sample size dependencies, sensitivity to data distribution shifts, and computational efficiency trade-offs. By testing metrics on both synthetic datasets with controlled properties and outputs from state-of-the-art protein generators, we provide insights into each metric's strengths, limitations, and practical applicability. Based on our findings, we offer a set of practical recommendations for researchers to consider when evaluating protein generative models, aiming to contribute to the development of more robust and meaningful evaluation practices in the field of protein design.",
    "keywords": [
      "evaluation metrics",
      "protein",
      "protein generative models"
    ],
    "venue": "ICLR",
    "year": 2025,
    "pdf_url": "https://openreview.net/pdf?id=1S8ndwxMts",
    "forum_url": "https://openreview.net/forum?id=1S8ndwxMts",
    "reviews": [
      {
        "rating": "5",
        "confidence": "4",
        "summary": "This paper studies several common evaluation metrics for protein sequence generative models covering quality, diversity and distributional similarity of samples. \nThe authors present controlled experiments and derive guidelines for a robust assessment of the performance of protein generative models.",
        "strengths": "### Importance\n\nUnifying benchmarking attempts for protein generative models is an extremely important open challenge. \nStudying various common evaluation metrics systematically and in a controlled setup is impactful because it can inform future developments of new methods and allow researchers to benchmark their models in a more convincing way.\nThe problem is motivated nicely and grounded in related works.\n\n### Breadth\n\nThe paper addresses three dimensions of generative model evaluation: **quality**, **diversity**, and **distributional similarity**.\nIt furthermore identifies at least two axes along which evaluation metrics should be assessed: **robustness vs sensitivity** and **reliability vs computational efficiency**.\nTogether these cover most practically relevant aspects of model evaluation in this space.",
        "weaknesses": "### Clarity\n\nThe presented topic is very complex and the authors' attempt to illuminate the design space for these metrics from various angles is commendable.\nHowever, the clarity of the presentation of their results can be improved. \nThe paper introduces a lot of metrics and desirable properties thereof but the arguments are sometimes difficult to follow in the current state.\nIt could be useful to restructure the experimental results section so that each subsection (quality, diversity and distribution similarity) systematically analyses different available metrics regarding their (1) robustness-sensitivity trade-off, and (2) reliability-efficiency trade-off.\nI would define a clear, quantitative criterion for each and follow an identical structure in each subsection (quality, diversity and distribution similarity).\nThe current discussion sometimes mixes empirically supported findings with intuition-derived arguments.\n\nIn the background section, it is confusing that most of the time the paper discusses three key axes of model performance: quality, diversity and distribution similarity,\nbut in Section 2.2 it talks about an alternative set of objectives: fidelity, diversity, novelty. \nSimilarly, the paper introduces \"Interpretability\" in Section 2.3 but does not discuss this aspect in the Results section.\nI would recommend to be more consistent throughout the paper (both in terms of wording and semantics).\n\nFurthermore, the paper should define the scope of the work clearly. It only covers generative models for amino acids _sequences_ as opposed to backbone _structures_.\nThe discussion about self-consistency in Section 2.1 seems unnecessarily detailed given the concept is only used once later on (scPerplexity metric). \nWhen I arrived at this point in the manuscript I was under the impression that the paper discusses both sequence and structure generative models because self-consistency is primarily used in the evaluation of _structure_ design methods (e.g. [1]).\n\n\n\n### Analysis of diversity metrics\n\nThe analysis of diversity metrics (Section 4.3) is extremely short, and it is unclear whether the presented data in Figure 3 provides information about the _sensitivity_ or _robustness_ of the Cluster Density metric.\nThe absence of a comparison with alternative approaches additionally makes it hard to interpret the results.\n\n\n### Support every claim with empirical data\n\nA systematic evaluation of metrics should always provide empirical evidence to back up the presented conclusions. \nHere, this is missing in some cases. For instance,\n- Looking at Figure 9 I would argue there are still notable differences between AlphaFold2 and ESMFold. Rather than just assessing their correlation, it would be useful to understand how sensitive and robust each method is to sample quality differences.\n- The paper states that simple diversity metrics lack discriminative power but it does not discuss any examples in the analysis in Section 4.3.\n- The paper also mentions intrinsically disordered regions as a potential stumbling block for the pLDDT metric. While this assumption is reasonable, it is still possible that pLDDT has better discriminative power than alternative metrics in those cases, but only empirical data can provide an answer to this question.\n- Finally, statements about computational efficiency are never quantified. Providing concrete run times would be an important piece of information that allows readers to get an idea about the reliability-efficiency trade-off.\n\n\n\n### References\n\n[1] Yim, Jason, et al. \"SE (3) diffusion model with application to protein backbone generation.\" arXiv preprint arXiv:2302.02277 (2023)."
      },
      {
        "rating": "3",
        "confidence": "4",
        "summary": "The paper analyses several metrics for protein generation on synthetic datasets with controlled properties in order to see their strengths, limitations, and practical applicability. The paper highlights that some metrics are dependant on sample size and that computationally efficient metrics can be just as effective.",
        "strengths": "- The paper's background section and motivation is extremely strong. The need for reliable evaluation metrics for protein generation is convincing and some of the metrics used in the literature are clearly outlined.\n\n- The controlled experiments are well thought out and provide some useful information about the quality of the metrics.\n\n- The authors perform a rigorous set of experiments and the provided practical recommendations could be useful to the community.",
        "weaknesses": "- The main weakness comes from evaluating the metrics in such a controlled and synthetic setting. The quality metrics are evaluated on proteins which the models (such as ESMFold) are trained on. In this case, introducing more noise is shown to cause the metrics to get worse. In practice though, we generate unseen proteins and it is not clear whether these metrics generalize to proteins they are not trained on. Additionally, it is not clear from the paper whether these metrics correlate with anything experimentally.  Therefore, the evaluation of these metrics in the given scenario doesn’t seem to offer much practical insight on the usefulness of these metrics. \n\n- The authors compare different metrics and explain that there should be a tradeoff with computational efficiency. However, it is not clear how the methods actually differ in this regard. You mention a few times that scPerplexity is expensive to calculate as it involves two models but there is no figure or timing comparison given. How much slower is it and is it impractical? You also say that your proposed metrics allow for rapid evaluation. Again, how long are these proposed metrics taking and what does the term “rapid” quantitatively mean? Although computational efficiency is mentioned a lot throughout the work, and seems to be important for selecting metrics, I have no indication from the paper on how these methods actually differ in this regard and why I should use a method over another practically.  To improve this, the authors could include a table or figure comparing the runtime of each metric on a standardized dataset, perhaps across different sample sizes."
      },
      {
        "rating": "1",
        "confidence": "5",
        "summary": "The present work attempts to provide insight into various metrics of generative models over protein sequences. They evaluate several metrics used in prior works such as predicted local distance difference test, perplexity, pseudo perplexity, self-consistency perplexity, cluster density, and multiple techniques for distributional similarity metrics. On a curated dataset, they measure robustness to random perturbations, sensitivity to sample size, and use of different protein language models to compute the metrics. Some recommendations are provided at the end of which models to use and sample size for robust evaluation.",
        "strengths": "* Evaluation of robustness to several protein sequence generation metrics.",
        "weaknesses": "The present work contains no technical novelty or new results. Therefore the analysis and presentation needs to be of high quality. Unfortunately the presentation quality is low and the insights are novel enough for acceptance to ICLR.\n\n* First, the work claims to evaluate protein generative models but proceeds to ignore or miss protein structure generative models such as RFdiffusion [1], Chroma [2]. The work only attempts to evaluate protein sequences without consideration for generated structures. Considering the popularity and success of [1, 2], this is a major omission.\n\n* There are **no benchmarks** of generative models in this work. The experiments are conducted on artificial perturbations of known sequences and on a curated set of sequences from 5 protein families. The insights in this work cannot be believed and are of little use unless the metrics are rigorously evaluated on state-of-the-art protein generative models.\n\n* Metrics are only useful if they correspond to success in downstream applications. The metrics used in [1, 2] are accepted because they are known to correlate (albeit weakly) with experimental success [3]. None of the metrics utilized in this work are associated with success in downstream applications. Indeed we care about how well the samples capture distributions but they are auxiliary metrics and are not the primary metrics in high impact protein generative model publications.\n\n* The noise perturbations are artificial. How do we know if randomly mutating 5-30% of the sequence is a failure mode or common occurrence in existing protein generative models?\n\n* Novelty is mentioned as a important consideration but no novelty metrics are presented or discussed.\n\n* Only using 5 protein families is far too small of an evaluation set. Line 234 states the experiments are done on \"real-world generated data\" but what is actually being generated here?\n\n* Section 4.3 on diversity metric analysis is weak. The trend in Figure 3 is the expected behavior of the 50% and 95% sequence similarity threshold. There is no new insight here.\n\n* I'm not sure what new insight is provided from the noise. Figures 2 and 3 show more noise leads to all the metrics becoming worse. This is expected but there is no indication of how this transfers to commonly used protein generative models. Do protein generative models exhibit such behavior?\n\n* Section 4.4 is also weak on insights. The graphs are expected by changing the noise and RBG kernel width. It would seem to me that different downstream applications would call for different parameters and robustness. Instead, the claims here are too general and unclear how useful they are for specific downstream applications such as binder design.\n\n* I would have liked to see a ranking of protein sequence generative models such as ESM2, ProGen, T5 with the metrics provided. \n\nOverall I do not believe this work provides a careful and rigorous study of evaluating protein generative models. I recommend the authors to rethink the experiments and hypotheses they wish to test.\n\n[1] https://www.nature.com/articles/s41586-023-06415-8\n[2] https://www.nature.com/articles/s41586-023-06728-8\n[3] https://www.nature.com/articles/s41467-023-38328-5"
      },
      {
        "rating": "3",
        "confidence": "5",
        "summary": "This work evaluates various quality, diversity and distributional similarity metrics for their ability to co-vary with random synthetic perturbations on protein amino acid sequences. The authors also evaluate differences in plddt scores for forward folded noised sequences. \nThe stated aim is to provide a systematic overview of how those metrics change with sequence randomness (noise), number of protein samples and model size to advance the evaluation of protein generative models. However, I think this works falls short of this aim. The proposed metrics are omitting the non-bijective nature of the protein structure-sequence relationship, the authors do not compare with well-established quality metrics in the field of generative protein design (e.g. self-consistency folding as a quality metric for structural fidelity, or edit-distance as a function of distributional similarity). The authors only present results on synthetically perturbed sequences, where residues are mutated with equal probability to assess perplexity and diversity. This is very different from the case of generative modeling, where diverse sequences are generated (non-randomly!) via auto-regressive sampling, any-order sampling or temperature sampling. I would recommend to generate sequences with these models, and synthetically perturbed sequences with BLOSUM or PAN transition matrices.\nI don't think that machine-learning motivated metrics, such as perplexity, or earth mover's distance are practically useful for the field of generative protein design. Useful metrics should capture if the model generates protein sequences or structures, that fold, are stable, exhibit a specific function.\nI have several concerns about the methodology, biological soundness and presentation of this work as I will outline concretely below.",
        "strengths": "Originality: A systematic analysis of metric variability with protein sequence diversity is a good idea and I would recommend the authors to build on it, but incorporate several improvements: Instead of uniform probabilities for mutations it might be more meaningful to use PAM or BLOSUM matrices. These are the transition probabilities from one amino acid residue to another one (based on similar hydrophobicity, charge, polarity, size etc.). \nSignificance: The authors correctly emphasize that there is no gold-standard in the field of generative protein models on what constitutes a \"good\" protein. The topic is worth being addressed, although I don't think that this work provides a significant contribution.",
        "weaknesses": "Background section:\n1. The motivation of diversity in the absence of training data is confusing. The authors should discuss that the structure-sequence relationship is no bijective and a one-to-many mapping problem. There are very many sequences that fold into the same or similar structures. The true diversity of this solution space is not known, given the small size of structural data in the PDB. This diversity is likely a complex function of protein size (there are very many diverse sequences that all fold into the same alpha helix peptide), packing (internal residues less diverse, versus external residues etc. \n2. The authors mention structural stability as a measure of a \"good\" protein, but do not evaluate this property in this work, this is confusing.\n3. I find the mathematical notations (especially under \"self-consistency\" overly complicated (given they are not being used) anywhere else. \nSection 3, Metrics:\n1. Fidelity metrics: The fidelity metrics are not addressing structural fidelity in terms of structural similarity (e.g. TM-score or RMSE) in the case of forward folding. Or self-consistency TM in the case of inverse folding. \n2. In general I would recommend the authors to split metrics for different generative model types and approaches, e.g. sequence-based (e.g. LLMs), inverse folding (structure-to-sequence)\n3. In section 2.3. the authors state that metrics should be interpretable. I don't find perplexity, or pseudo-perplexity very interpretable. plddt is interpretable. I would recommend adopting metrics like edit distance or structure consistency (e.g. TMscore). I think reporting perplexity in a protein LLM is still valuable, but it's not particularly novel or insightful. I am not sure if self-consistency perplexity: -logp(S|G(F(S)) makes sense given that this protein inverse folding (G) is a one-to-many problem with an unknown and variable number of diverse solutions. And as the authors state -- the folding and inverse folding model bias might further complicate this metric.\n4.  Section 3.2: The diversity defintion of cluster density at 50% and 95% is interesting, but shoudl be compared to more commonly adopted diversity metrics in the field, such as edit distance and pairwise distances. \n\nSection 4: Experiments:\n1. I like the idea of a systematic perturbation of amio acid sequences, but random noise (uniform transition probabilities) is unrealistic. I would recommend using BLOSOM or PAN matrices. Additionally to the synthetic perturbations I am missing an actual application to generative models. I would recommend using different inverse folding models, e.g. ESMIF or ProteinMPNN and generating diverse sequences with random decoding orders and temperature sampling. Currently the authors perturb the sequence in a random way which likely turns them easily into garbage (ie they would never exist in nature and fold). \n2. The random perturbations do not create meaningful biological diversity in the sequences and simply degrade their quality. As such Figures 2 and 4 are stating obvious trends: The more noise, the worse the quality/fidelity metrics. \n\nPresentation: \n1. Please review citation guidelines, current citation style is reader unfriendly.\n2. Please mark supplementary figures as such (e.g. Figure 9). \n3. Figure 8 is missing"
      }
    ],
    "rating_avg": 3.0,
    "confidence_avg": 4.5,
    "decision": "Reject",
    "meta_review": "This paper examines evaluation metrics for protein generative models, looking at quality, diversity, and distributional similarity criteria. Proteins are essential to life, and AI has shown great promise in biology with the advent of AlphaFold and other state-of-the-art protein models (both at the sequence and structure levels). Several metrics are used in the literature to evaluate these protein models. Analyzing these metrics is therefore important. While the reviewers agree on the importance of this topic, they judged the paper, in its present state, misses several key elements. Indeed, it failed to include some metrics in the evaluation set, it looked only at synthetic datasets and used perturbation schemes for protein sequences such as random noise that might be unrealistic. Reviewers were also unhappy with the lack of clarity of the presentation.",
    "author_remarks": "",
    "decision_comment": ""
  },
  {
    "id": "ZS7UEI3vG5",
    "title": "Oracle efficient truncated statistics",
    "authors": [
      "Konstantinos Karatapanis",
      "Vasilis Kontonis",
      "Christos Tzamos"
    ],
    "abstract": "We study the problem of learning from truncated samples: instead of observing\nsamples from some underlying population $p^\\ast$, we observe only the examples that fall in some survival set $S \\subset \\mathbb{R}^d$ whose probability mass (measured with respect to $p^\\ast$) is at least $\\alpha$.  Assuming membership oracle access to the truncation set $S$, prior works obtained algorithms for the case where $p^\\ast$ is Gaussian or more generally an exponential family with strongly convex likelihood --- albeit with a super-polynomial \ndependency on the (inverse) survival mass $1/\\alpha$\nboth in terms of runtime and in number of oracle calls to the set $S$.  In this work we design a new learning method with runtime and query complexity polynomial in $1/\\alpha$.  \nOur result significantly improves over the prior works \nby focusing on efficiently solving the underlying optimization problem using a general\npurpose optimization algorithm with minimal assumptions.",
    "keywords": [
      "truncated statistics",
      "exponential family",
      "statistical learning"
    ],
    "venue": "ICLR",
    "year": 2025,
    "pdf_url": "https://openreview.net/pdf?id=ZS7UEI3vG5",
    "forum_url": "https://openreview.net/forum?id=ZS7UEI3vG5",
    "reviews": [
      {
        "rating": "8",
        "confidence": "4",
        "summary": "This paper revisits the problem of learning an exponential family of distributions under truncated samples. The main focus is the dependence of the runtime and sample complexity on the mass of the truncation set. \n\nIn the truncated samples model, the samples are only observed when they fall into a subset S of the domain that has some measure $\\alpha$. Such a sampling oracle can be implemented using a membership oracle for the set S. Although for constant values of the mass $\\alpha$ the sample (and query) complexity asymptotically matches the bounds from prior work on the problem, there is an exponential improvement in the dependence on $1/\\alpha$, when $\\alpha$ gets close to $0$. Another difference from prior work is the use of weaker assumptions, which also leads to a weaker type of learner. More specifically, while prior work by Lee et’ al can estimate the parameter vector of the exponential family up to error $\\varepsilon$, in this paper, the algorithm is a proper learner that outputs an exponential family that has small KL divergence with the true distribution. \n\nFrom a technical standpoint, the novelty lies in the definition of a sequence of constrained optimization problems. Specifically, the authors use projected SGD in a region where the negative log likelihood is not allowed to exceed a certain threshold during each iteration. This prohibits the algorithm from moving to regions in the parameter space that would assign very small mass to the truncation set and seems to be crucial for achieving the exponential improvement in terms of the inverse mass $1/\\alpha$ of that set S. \n\n\n\nMinor comments:\n\n-Line 53: “resoursed”->“resourses”\n\n-Lines 109-114: The example here needs some rephrasing. I get the point you are making, but technically, when you fix a set (S=[0,1] in this case), the mass assigned to it and the variance of the distribution, there is a unique distribution (NOT multiple ones) satisfying these constraints. Maybe you could say $O(\\alpha)$ mass.\n\n-Lines 131 and 371: In the second argument of the KL distance, it should be $\\hat{\\theta}$ in the subscript.\n\n-Line 388: Usually the word “requires” is used for lower bounds. Maybe say “a good initialization can be found”\n\n-Line 399: “estimate of”->”bound on”\n\n-Line 448: Proof of Observation 3.8: The statement seems reasonable,  but I think that the proof is incomplete. You show that the exponential is at most 1, but you need something stronger since it could be that $Pr_{\\theta^\\prime}[S]>Pr_{\\theta}[S]$, right?\n\n-Line 490: “$SE(K,\\beta)$”->“$SE(K^2,\\beta)$”",
        "strengths": "The paper gives an interesting perspective to an important question in statistics involving data corruption and potentially expands the applicability of state-of-the-art techniques to settings where the corruption is much stronger.",
        "weaknesses": "I believe the authors should make the assumptions they need to use clearer from the introduction to improve the presentation quality. For example, the strong convexity and smoothness assumption is not mentioned in the statement of Theorem 1.5, which makes it seem too strong."
      },
      {
        "rating": "3",
        "confidence": "4",
        "summary": "The authors address the problem of estimating a parametric distribution from truncated samples. \nThey propose an efficient procedure for parameter estimation within an exponential family under these conditions, improving the dependence on the probability mass of the survival set from a super-polynomial to a polynomial rate.",
        "strengths": "This work fits well within the existing literature; the efficiency problem is well-motivated and clearly defined. \nThe authors present a clear improvement in terms of computational efficiency.",
        "weaknesses": "The presentation of the paper is poor:\n- The structure of the paper is unclear, the main approach is not even presented in the main body of the paper;\n- There are significant redundancies; for example, Section 2.1 is nearly identical to Section 1.1;\n- There are many typos.\n \nThe proof of the main result contains several gaps (see Questions), and I do not find it convincing at this stage.\n\nThere are no numerical experiments to illustrate their theoretical results or to compare with existing approaches."
      },
      {
        "rating": "8",
        "confidence": "3",
        "summary": "This paper studies the problem of learning a high-dimensional probability distribution from \"truncated samples\" -- that is, the goal is to learn a distribution $p$ given samples from $p$ conditioned on some event $S$, called the \"survival set\".This is not possible with reasonable (polynomial) sample complexity for an arbitrary distribution $p$, so, like prior work, the paper focuses on exponential family distributions.\n\nMore concretely, the model is that one gets:\n\n-- samples from $p$ conditioned on $S$; the set $S$ is not known to the algorithm\n-- access to an oracle which takes as input a probability distribution $q$ and returns a samples from $q$ conditioned on $S$\n\nHere $p$ and $q$ should be exponential family distributions so that they have a short description which can be handed to the oracle. There is a further constraint that the probability mass of $S$ under $p$ and $q$ is at least some parameter $\\alpha > 0$. As $\\alpha$ gets small, this problem gets harder, since we are observing only samples from some low-probability event under $p$.\n\nPrior work showed how to accomplish this task for exponential family distributions, with sample complexity and running time depending polynomially on dimension of the distribution and the inverse of the accuracy to which the distribution is learned, but super-polynomially on $1/\\alpha$. (Prior work achieved only quasipolynomial dependence.)\n\nThis dependence on survival probability is important for overall running time, because one way to implement the sampling oracle is via rejection sampling, using a membership oracle for $S$ and a sampling algorithm for $q$. But the running time of such an implementation will be about $1/\\alpha$ to get a single sample.\n\nThe main contribution of this work is to give an algorithm with running time and sample complexity having polynomial dependence on dimension, inverse of the accuracy, and $1/\\alpha$. My understanding is that this result is novel even in the special case of Gaussian distributions.\n\nThe problem is extremely well motivated -- truncation is a common situation for \"in the wild\" datasets. And the technical contribution is certainly sufficient for ICLR. I recommend acceptance.",
        "strengths": "See above",
        "weaknesses": "See above"
      },
      {
        "rating": "6",
        "confidence": "3",
        "summary": "This paper studies the problem of learning an exponential family with truncated samples. Specifically, for any distribution $p$, the truncated distribution $p^S$ corresponds to the distribution of $p$ restricted to a set $S$. The paper shows that if a distribution $p$ is selected from an exponential family, and we are able to observe samples from $p^S$ and access a membership oracle for $1\\\\{x \\in S\\\\}$, then one can find an estimator $\\hat{p}$ such that $KL(p^S ||\\hat{p}^S) \\leq \\epsilon$. The main technical contribution is to obtain bounds on the sample complexity and oracle complexity that depend poly-logarithmically on $\\alpha:=p^S[S]$, with a computationally efficient estimator $\\hat{p}$.",
        "strengths": "The main strength of this paper comes from the polylogarithmic dependency on the parameter $\\alpha$ in both the sample and oracle complexities. As far as I'm aware, this seems to be original, at least for bounding the KL-divergence of the truncated distributions themselves. The paper also introduces several new techniques, such as the minimization of the \"truncated\" negative log-likelihood (NLL) constrained by a bound on the original NLL.",
        "weaknesses": "The main weakness of the paper is its presentation; it is quite difficult to follow the proofs provided in Section 3. I have the following specific comments:\n\n1. The paper emphasizes that its primary contribution is improving the poly($1/\\alpha$) dependency from Lee et al. (2023) to poly-log($1/\\alpha$). However, a quick look at that paper reveals that Lee et al. (2023) focuses on estimating the parameter, not the truncated distribution. Therefore, I am unsure how significant this improvement is.\n\n2. Section 3 is quite dense, and the logical flow of the proof is not well explained. Overall, the section feels extremely unstructured.\n\nI suggest that the authors improve the writing in Section 3 by, for example, providing a clear roadmap of the proof at the beginning of this section and clearly explaining how each lemma contributes to the final proofs. Please also refer to the \"Questions\" section."
      }
    ],
    "rating_avg": 6.25,
    "confidence_avg": 3.5,
    "decision": "Accept (Poster)",
    "meta_review": "The paper focuses on the problem of parameter estimation from truncated samples, i.e., samples that lie inside a survival set S and moreover it is assumed that we have oracle access to this set S. The main result of this work is to design an algorithm that is polynomial in 1/\\alpha where \\alpha is the probability mass of S and improve prior works in which the running time was exponential in 1/\\alpha.\nFrom a technical standpoint, the novelty lies in the definition of a sequence of constrained optimization problems. Specifically, the authors use projected SGD in a region where the negative log likelihood is not allowed to exceed a certain threshold during each iteration. This prohibits the algorithm from moving to regions in the parameter space that would assign very small mass to the truncation set and seems to be crucial for achieving the exponential improvement in terms of 1/\\alpha. The reviewers and so does the AC believe that the paper is above the bar and has nice technical contributions, it improves the state-of-the-art for learning from truncated samples. We recommend the reviewers to read carefully 3xik comments and improve the presentation for the camera ready.",
    "author_remarks": "",
    "decision_comment": ""
  },
  {
    "id": "IULlNTZZel",
    "title": "RedHat: Towards Reducing Hallucination in Essay Critiques with Large Language Models",
    "authors": [
      "Andrew Zhuoer Feng",
      "Cunxiang Wang",
      "Bosi Wen",
      "Boqun Kou",
      "Haohan Chi",
      "Yu Luo",
      "Lin Fan",
      "Xiaotao Gu",
      "Jie Tang",
      "Hongning Wang",
      "Minlie Huang"
    ],
    "abstract": "Essay critiques refer to the textual assessment of an essay, serving as the basis for the scoring of the essay, and are crucial for the improvements of the essay. Essay critique generation has received increasing attention after the blooming of large language models (LLMs), which show promising potential in writing and critiquing essays. Automatic critique generation can streamline both instructors and reviewers as well as spur LLM advancement in long context generation characterized by essay writing. However, current LLMs suffer from hallucinations when generating essay critiques, which are still under-explored in the community. To facilitate research in reliable essay critique generation, we first define this task with a unified input-output format as well as clear judging criteria. To minimize hallucinations in critique generation, we introduce RedHat, a novel approach that embeds the key information from essays directly into the generation process through document-level question-answering, ensuring critiques stay firmly anchored to the original text. We collected a large-scale, high-quality essay critique dataset called EssayC, annotated by human experts over multiple LLM-generated critiques, from a campus undergraduate essay writing course. We experimented RedHat backboned by commercial and open-sourced LLMs. Results showed that critiques generated by RedHat are preferred by human experts over baseline in 20% of cases on EssayC in detailedness and informativeness, with a decrement around 10% on hallucinations in our judging criteria.",
    "keywords": [
      "essay critique generation",
      "large language model",
      "hallucination"
    ],
    "venue": "ICLR",
    "year": 2025,
    "pdf_url": "https://openreview.net/pdf?id=IULlNTZZel",
    "forum_url": "https://openreview.net/forum?id=IULlNTZZel",
    "reviews": [
      {
        "rating": "3",
        "confidence": "4",
        "summary": "The paper introduces a benchmark and corresponding experiments for the task of automatically providing useful free-form feedback for human-written essays. The main objective is to reduce to what the paper refers to as 'hallucinations' - i.e. in this case irrelevant feedback.\nTo achieve this, the paper introduces a resource called EssayC - essays written in Chinese by students, which are enriched by LLM-generated critiques. The main contribution of the paper seems to be the use of an automatically derived questionnaire aimed at evaluating different aspects pertaining to the quality of the essay, which - together with automatically derived answers - is used to enrich the prompt of LLMs when generating the essay feedback, an approach which the papers calls \"RedHat\".",
        "strengths": "Overall this work is intriguing and makes good use of prompt engineering in a clever way. The results seems to indicate some level of success.",
        "weaknesses": "I have a few concerns with the paper:\n\n- Firstly, the construction of the evaluation criteria seems rather ad-hoc, GPT4 is prompted for questions, which are then voted upon by human experts in form of GTAs. The results are in no way linked to or rooted in existing rich literature on evaluating essays. I think this is a missed opportuninty to investigate, how well GPT4's question lists align with existing criteria proposed in the literature. Similarly, the generated critiques are not compared to the actual human-written critiques which existed for the collected essays, in fact they were deliberatly removed and disregarded. This again presents a missed opportuninty to further understand the quality of the approach.\n\n- Secondly, for all the prompt engineering, the results are not very impressive. This is down to a few points: Firstly, only a single LLM, chatGLM-9B is evaluated. Secondly, the overall scores in Table 2, pairwise comparisons in Figure 4 and Table 4 show only a small improvement over the chatGLM baseline. In fact given the rather small dataset size, I'm not convinced they are statistically significant. Thirdly, i am not at all convinced by section 5.3 - the Table and the corresponding explaining paragraph (l 428 ff) seem at odds with each other: The paragraph claims that QA-enhanced RedHat methodology increases the overlap (which in itself doesn't mean that the questions are useful), but the table shows the opposite. Indeed the baseline without QA seems to have a higher overlap than the RedHat method.\n\n- Lastly, I am not convinced by the gravity and impact of the contribution - the task of essay feedback generation is rather niche and very application-focussed, only one language is studied and the presented approach amounts to prompt engineering. Generalising the findings would be difficult, as the human studies would need to be reproduced.\n\nMinor concerns include the wording - for example, the decision to use the word \"hallucinations\" is not very spot-on, \"hallucinations\" refer to content that is made up in summaries, i don't think what the paper describes as \"hallucinations\" meets this broad definition. Furthermore, the vocabulary used to outline the contributions is too strong given the actual results - for example l 103 claims to \"prove\" generalisability, yet I have not found a formal proof. Similarly, l 107 states that human annotators prefer automatically refined essays based on RedHat's feedback, while the majority of the annotators is indifferent to the changes (60% vote tie in Table 4).\n\n\nOverall, given the concerns outlined below, I would gravitate towards rejection.\n\nMy recommendations to improve the paper would be to (a) root the approach more firmly in existing literature e.g. by comparing the question lists with existing literature; (b) increase the scope, by e.g. comparing more models or comparing model results to human-written critiques. The collection of human ratings would also enable the creation of preference data, which could be used to more efficiently align the models (e.g. by RLHF methods) rather than just using SFT. It should also enable to learn a essay quality ranking method, e.g. by regressing the overall/hallu/detail/info scores in table 2. This should greatly increase the impact of the work, as this learned metrics could be used to predict the quality of essays _without human annotations_, thus enabling to generalise the method and reproduce the findings without reproducing the human annotations."
      },
      {
        "rating": "5",
        "confidence": "3",
        "summary": "This paper addresses the essay critique generation task using large language models (LLMs) and proposes a technique to reduce hallucination in this task. The authors propose RedHat, a technique to reduce hallucination by incorporating document-level question-answering into the critique generation process. The authors compare the proposed method with others, including post-pretraining (PT) and supervised fine-tuning (SFT), and show that their proposed method does reduce hallucination.",
        "strengths": "* The proposed method, RedHat, appears to be grounded in solid assessment practices, with critiques based on concrete practices in answering questions.\n* They are working with a non-English (Chinese) dataset and task.\n* They provide a clear, position-based analysis highlighting where improvements occurred.",
        "weaknesses": "* The proposed method, RedHat, simply adds document-level questions and answers, which may come across as an incremental, somewhat trivial improvement.\n* It’s unclear whether the issue the authors address is truly \"hallucination\" or simply improving task performance in critique generation. Are there types of essay critique generation errors that are not hallucination? A clear definition would be valuable here.\n* The paper is quite vague; while the tasks and datasets used are in Chinese, this isn’t clearly stated. Working on non-English tasks and datasets is generally beneficial for diversity in the English-dominated LLM landscape. However, the paper lacks clarity on this and, more importantly, offers very limited insights on whether the findings apply to other datasets, languages, or base LLMs (e.g., GLM). For instance, it would be useful to know if similar techniques could improve essay critique generation in English using models like ChatGPT."
      },
      {
        "rating": "8",
        "confidence": "4",
        "summary": "The background proposed in this paper is to use LLM to evaluate and criticize essay writing. It points out that the efficiency of using LLM is much higher than that of humans. However, LLM has some problems in performing this task, such as (1) Providing suggestions that do not match or are inappropriate to the essay content, and (2) Proposing logical errors that do not exist in the essay. These hallucination seriously affect the usability of LLMs in generating essay reviews.  This paper has two main contributions, a dataset and a new method to mitigate hallucinations. The results of automatic and manual evaluation demonstrate the effectiveness of the work proposed by the authors.",
        "strengths": "1. The authors list definitions of various types of hallucinations in Table 1, which is helpful for clearly defined tasks.\n2. The evaluation setting is solid which including both auto and human evaluation.",
        "weaknesses": "1. From Figure 4, it seems that the evaluation results of GPT are not reliable. This is because people trust the results of artificial experts more. Although the results of untrained human annotators are also random.\n2. Why consider ROUGE and BLUE as metrics, as they only consider word overlap. Maybe try BERTScore, BLEURT.\n3.The writing structure seems a bit confusing. Chapters 2, 3, and 4 each contain a literature review, plus the work of this paper.\n4. It is very good that the authors present a new dataset. But perhaps more annotation process and quality assessment should be provided?"
      }
    ],
    "rating_avg": 5.333333333333333,
    "confidence_avg": 3.6666666666666665,
    "decision": "Reject",
    "meta_review": "The paper proposing a prompting technique to generate grounded critiques for essays; the main goal is to mitigate \"hallucinations\" in the critiques that refer to phenomenon not seen in the essay. The approach shows some improvement over baselines like SFT, etc. based on human evaluation. Reviewers raise the issue of this human evaluation criterion not being grounded on existing literature in argumentation. The paper can be augmented with more discussion/analysis of the critiques to better outline how meaningfully different the generated critiques are (score differences of <0.5 points on a likert scale are not informative in this regard).",
    "author_remarks": "",
    "decision_comment": ""
  },
  {
    "id": "gx1wHnf5Vp",
    "title": "Drop-Upcycling: Training Sparse Mixture of Experts with Partial Re-initialization",
    "authors": [
      "Taishi Nakamura",
      "Takuya Akiba",
      "Kazuki Fujii",
      "Yusuke Oda",
      "Rio Yokota",
      "Jun Suzuki"
    ],
    "abstract": "The Mixture of Experts (MoE) architecture reduces the training and inference cost significantly compared to a dense model of equivalent capacity. Upcycling is an approach that initializes and trains an MoE model using a pre-trained dense model. While upcycling leads to initial performance gains, the training progresses slower than when trained from scratch, leading to suboptimal performance in the long term. We propose Drop-Upcycling - a method that effectively addresses this problem. Drop-Upcycling combines two seemingly contradictory approaches: utilizing the knowledge of pre-trained dense models while statistically re-initializing some parts of the weights. This approach strategically promotes expert specialization, significantly enhancing the MoE model's efficiency in knowledge acquisition. \nExtensive large-scale experiments demonstrate that Drop-Upcycling significantly outperforms previous MoE construction methods in the long term, specifically when training on hundreds of billions of tokens or more.\nAs a result, our MoE model with 5.9B active parameters achieves comparable performance to a 13B dense model in the same model family, while requiring approximately 1/4 of the training FLOPs.\nAll experimental resources, including source code, training data, model checkpoints and logs, are publicly available to promote reproducibility and future research on MoE.",
    "keywords": [
      "mixture of experts",
      "large language models",
      "continual pre-training"
    ],
    "venue": "ICLR",
    "year": 2025,
    "pdf_url": "https://openreview.net/pdf?id=gx1wHnf5Vp",
    "forum_url": "https://openreview.net/forum?id=gx1wHnf5Vp",
    "reviews": [
      {
        "rating": "5",
        "confidence": "4",
        "summary": "This paper presents Drop-Upcycling for MoE training utilizing the knowledge of pre-trained dense models while statistically re-initializing\nsome parts of the weights. The proposed method promotes expert specialization (which is often a bottleneck in traditional upcycling), significantly enhancing the MoE model’s efficiency in knowledge acquisition.",
        "strengths": "- The paper is well written and easy to follow.\n- The idea of drop-upcycling is interesting although not new (see weaknesses section).\n- Extensive experiments and release of all the relevant materials for reproducibility.",
        "weaknesses": "- How is the proposed upcycling method different from the upcycling used in Qwen2: https://arxiv.org/pdf/2407.10671? Qwen2 shuffles parameters along the intermediate dimension to promote diversity which I think is very similar to the current method. They also randomly initialize 50% of the parameters. I would suggest the authors to discuss the differences with experiments.\n- What are the benefits of upcycling over training from scratch? I think changing architectural components are often difficult as upcycling is often constrained by the dense model architecture.\n- Will the current method going to be scalable to very large MoEs, say 100B+ parameter models? What additional challenges author think to encounter in training large MoEs with upcycling? \n- Can upcycling going to help in continual learning? E.g., can we add new experts to an existing MoE using dropupcycling?"
      },
      {
        "rating": "6",
        "confidence": "4",
        "summary": "This paper proposes \"Drop-Upcycling\",  a method that enables an improved initialization scheme for expert parameters based on the weights of a pre-trained dense model. The approach addresses the lack of diversity in expert weights, a limitation of the standard Upcycling method where expert weights are simply cloned from the FFN in the dense model. \n\nDrop-Upcycling randomly samples indices from the intermediate dimension of the FFNs. The weights corresponding to these indices from $W_{up}$, $W_{gate}$, and $W_{down}$ matrices are dropped and reinitialized using the statistics of the dropped weights. The parameter $ r $ controls the proportion of indices sampled, with $ r = 1 $ representing full random initialization and $ r = 0 $ corresponding to naive upcycling.\n\nThe authors performed thorough experiments with an overall 200k plus GPU hours. A key insight is that the advantages of the approach is mainly in long-term training scenarios (>100B tokens).",
        "strengths": "- The empirical evaluation section and the number of large-scale training conducted are impressive.\n- The proposed method is very simple and the parameter $r$ intuitively controls the trade-off between knowledge retention from the dense network and incorporating diversity.\n- The authors implement their drop-upcycling on different parameter scale regimes from ~400M all the way to 18B parameters.\n- The authors provide the source code which is great for reproducibility",
        "weaknesses": "- Although the empirical evaluation is thorough and the results are promising, the paper has rather limited novelty. The paper would have become stronger if the authors could handle more challenging cases appearing in recent MoE literature such as fine-grained MoEs, or experimenting with a shared expert design. It would be beneficial to report the result of some other intuitive baselines such as adding random noise to the channels of the upcycled experts.\n\n- The way the load-balancing loss is applied seems ineffective. Could you elaborate why the loss was not applied layer-wise as that should prevent expert collapse. Even the model trained with Drop-upcycling shows half of the experts in layer 23 are not used by any of the domains.\n\n- The authors mention that the proposed method outperforms other upcycling approaches in long-term training scenarios. It seems in the very long-term training setting, training from scratch may outperform all methods and in the very short-term training (e.g. <50B tokens) the Branch-Train-Mix upcycling achieves the lowest loss. It would be best if the authors could explain this angle better and also study effect of model parameter size. For example at r=0.5, it takes around 70B Tokens to surpass Branch-Train-Mix for the $8\\times 152M$ model, while ~130B tokens are required for surpassing it for the $8\\times 1.5B$ Tokens."
      },
      {
        "rating": "8",
        "confidence": "3",
        "summary": "This paper introduces Drop-Upcycling, a novel method for initializing Mixture of Experts (MoE) models from pre-trained dense models. The key innovation is selectively re-initializing parameters of expert feedforward networks while preserving some knowledge from the pre-trained model. Through extensive experiments, the authors demonstrate that Drop-Upcycling outperforms existing initialization methods like naive Upcycling and Branch-Train-MiX, achieving better performance with reduced training costs. Their best MoE model with 5.9B active parameters matches the performance of a 13B dense model while requiring only 1/4 of the training FLOPs.",
        "strengths": "1. The paper presents a clear technical contribution with Drop-Upcycling that addresses a fundamental challenge in MoE training - balancing knowledge transfer and expert specialization. This is demonstrated through comprehensive empirical results.\n2. The experimental evaluation is thorough and well-designed, including ablation studies on re-initialization ratios, detailed analysis of expert routing patterns, and large-scale experiments across multiple model sizes (152M to 3.7B).\n3. The work demonstrates significant practical impact by achieving comparable performance to larger dense models with substantially reduced computational costs, which is particularly relevant given the increasing focus on efficient training of large language models.",
        "weaknesses": "1. While the paper shows Drop-Upcycling works well for decoder-only transformers with MoE in FFN layers, there's limited discussion or analysis of how the method might generalize to other architectures (e.g., encoder-decoder models) or different MoE configurations (e.g., attention-based MoE layers).\n2. The theoretical analysis in Section 3.2.2 is relatively brief and could benefit from a bit more substance. I understand the space constraints, but it would be great if the authors could include some formal verification or empirical validation for the approximations used in equation (5).\n3. The paper uses a fixed re-initialization ratio (r=0.5) across all layers and experts. Given that different layers in transformer models are known to learn different types of features, a more adaptive approach to setting the re-initialization ratio based on layer position or expert functionality might yield better results. The authors don't explore this possibility or justify why a uniform ratio is optimal."
      },
      {
        "rating": "6",
        "confidence": "3",
        "summary": "This paper presents Drop-upcycling, which aims to boost the effectiveness of upcycling method by selectively re-initializing parameters to achieve the trade-off between expert diversity and knowledge transfers. Besides, this work provides a detailed introduction of employing upcycling for the initialization of MoE models, with good readability. The experiments are designed using two dense models such as Llama and Mixtral, and this work includes extensive experimental evaluation across seven types of tasks from both Japanese and English.",
        "strengths": "- 1) This paper is well-written and the Method Section is well-organized, thoroughly demonstrating the authors' understanding of the upcycling methods for MoE models. After reading the Method Section, readers gain valuable insights and can quickly follow the authors' motivation.\n\n- 2) The Drop-upcycling proposed in this paper to enhance the specialization of experts in MoE models is very straightforward, and it includes a hyperparameter that can control the degree of expert specialization and knowledge transfer.\n\n- 3) The experiments in this work are comprehensive, and the Experiment Section provides relatively analyses of the observed phenomena.",
        "weaknesses": "- 1) In Table 1, the training costs of different MoE initialization methods vary. It is recommended to add a comparison of training times for different models to demonstrate the advantages of your proposed method.\n\n- 2) In line 428, the author uses Model 1, Models 2 and 3, etc., to describe the performance comparison of different baseline models. However, it is unclear which model each number represents. It is recommended to add a \"Baseline Models\" section to introduce the names and methods of different baseline models. The same issue also appears in line 411.\n\n- 3) There are many ways to enhance the specialization of each expert in MoE models. For example, the Branch-Train-MiX (BTX) [Ref A] ensures expert diversity and specialization by feeding each expert different data distributions. In contrast, this work proposes a hyperparameter $r$ to control the initialization density of the FFN layer to ensure specialization. What are the advantages of this approach compared to the BTX method? Please give a brief discussion during the rebuttal period.\n\n[Ref A] Branch-Train-MiX: Mixing Expert LLMs into a Mixture-of-Experts LLM"
      }
    ],
    "rating_avg": 6.25,
    "confidence_avg": 3.5,
    "decision": "Accept (Poster)",
    "meta_review": "This paper proposes Drop-upcycling, which selectively initializes MoE models from pre-trained dense models, and successfully balances expert diversity and knowledge transfer. The paper is well-written, with a clear and easily understandable motivation, and the experimental section provides extensive and solid evaluation. The reviewers raised concerns regarding similar work and some experimental analyses, which the authors addressed with detailed analysis and additional experiments that demonstrate the superiority of Drop-upcycling, largely alleviating the reviewers' concerns. Overall, this work is good and solid, so the AC recommends accept.",
    "author_remarks": "",
    "decision_comment": ""
  },
  {
    "id": "BPyNGmM3jy",
    "title": "DiRaGNN: Attention-Enhanced Entity Ranking for Sparse Graph Networks",
    "authors": [
      "Fiza Husain",
      "Anjaly Parayil",
      "Ayush Choure",
      "Rujia Wang",
      "Chetan Bansal"
    ],
    "abstract": "Sparsity in both the structural and engagement information presents a core challenge in entity ranking problems for graph networks. The interaction dynamics of entities are often characterized by limited structural and engagement information which results in inferior performance of the state-of-the-art approaches. In this work, we present DiRaGNN, an attention-enhanced entity ranking model designed\nto address the problem of dimension recommendation and ranking for automated watchdogs in the cloud setting. DiRaGNN is inspired by transformer architectures and utilizes a multi-head attention mechanism to focus on heterogeneous neighbors and their attributes. Additionally, our model employs multi-faceted loss functions to optimize for relevant recommendations and reduce popularity bias. To manage computational complexity, we sample a local subgraph that includes multiple hops of neighbors. Empirical evaluations demonstrate significant improvements over existing methods, with our model achieving a 39.7% increase in MRR.",
    "keywords": [
      "Heterogeneous Graphs",
      "Graph Neural Networks",
      "Recommendation System"
    ],
    "venue": "ICLR",
    "year": 2025,
    "pdf_url": "https://openreview.net/pdf?id=BPyNGmM3jy",
    "forum_url": "https://openreview.net/forum?id=BPyNGmM3jy",
    "reviews": [
      {
        "rating": "5",
        "confidence": "3",
        "summary": "The paper presents \"DiRaGNN,\" an attention-enhanced entity ranking model designed to address the challenges of sparsity in structural and engagement information for entity ranking problems within graph networks. DiRaGNN leverages a transformer-inspired multi-head attention mechanism to focus on heterogeneous neighbors and their attributes. The model employs a multi-faceted loss function that includes diversity-aware and ranking losses to improve recommendation relevance and reduce popularity bias. Experimental results show that DiRaGNN significantly improves entity ranking accuracy, achieving a 39.7% increase in mean reciprocal rank (MRR) over existing approaches.",
        "strengths": "1. The proposed model is explicitly designed to tackle the issue of sparse interactions, which is a common limitation in entity ranking tasks for practical consideration.\n2. The paper is generally written with good clarity and thus is easy to follow.",
        "weaknesses": "1. The technical contribution of this work appears limited, particularly in the design of the DiRaGNN model, which could be seen as fitting within the general framework of graph transformers. The authors are encouraged to emphasize their unique technical innovations to better distinguish their approach.\n2. Some illustrations, such as Figure 4, are difficult to interpret. The authors are advised to improve the visual clarity of these figures to enhance readability.\n3. The process of neighborhood sampling and subgraph generation lacks sufficient detail. For instance, the \"carefully designed edge splitting strategy\" should be elaborated upon. Additionally, for the multi-hop subgraph sampling method, it is unclear whether it was achieved through random walks or simple node sampling.\n4. In terms of evaluation, only one medium-sized dataset was used, which may limit the generalizability of the results. Moreover, the paper does not specify the number of repeated experiments or the number of seeds used, which is crucial for demonstrating the robustness of the performance."
      },
      {
        "rating": "5",
        "confidence": "4",
        "summary": "This paper focuses on the problem of recommending dimensions for monitor creation in the cloud setting, where an attention-enhanced entity ranking model is proposed. The authors illustrate the characteristics of the monitor entity graph, then study a set of loss functions to improve the recommendation quality, and finally empirical results show the improvements over classic baselines (e.g., SAGEConv).",
        "strengths": "This paper is easy to read and well organized. \n\nIn section 2 and 3, the authors spend 2.5 pages to formulate the research problem and illustrate the characteristics of the monitor entity graph, which might be helpful for the beginners to interpret the topics of this work.",
        "weaknesses": "1. The section of related works is missing. I highly recommend the authors to compare this work with recent advances in the filed of representation learning over heterogeneous graphs and emphasize the technique contributions.\n\n2. It seems that DIAGNN is a combination of existing works, and thus the contribution looks incremental. Meanwhile, it is not clear to me which part of the networks is proposed to solve the issue of graph sparsity and why it works.\n\n3. The training objective, including CE loss, TOP1-max Ranking loss and diversity loss, is not new. Also, the idea of subgraph sampling with negative training examples is standard in task of node classification and recommender systems. The authors are encouraged to clarify the difference to existing works."
      },
      {
        "rating": "3",
        "confidence": "4",
        "summary": "In this paper, the authors propose an attention-enhanced entity ranking model aimed at improving dimension recommendation and ranking systems. However, the technique employed is not particularly innovative, as there are several existing studies incorporating transformer architectures into heterogeneous graphs. Furthermore, the authors do not provide strong experimental results in comparison to recently proposed methods.",
        "strengths": "1. This paper introduces a diverse ranking approach for GNNs by incorporating multi-head attention to capture long-range dependencies within the graph structure.\n2. Overall, the paper is well-written.",
        "weaknesses": "1. The paper’s key novelty is unclear, given that previous work has already integrated transformer architectures into GNNs.\n2. The experimental results are limited, as the authors only include SAGEConv and TransformerConv as baselines and use a single heterogeneous graph dataset (without a publicly accessible link).\n3. The intuition behind the proposed methods, particularly concerning the monitor entity graph, is not clearly explained."
      },
      {
        "rating": "1",
        "confidence": "4",
        "summary": "Cloud service providers (e.g., Azure, AWS, GCP) aim to ensure the continuous availability of their cloud services. The cloud service monitors, also known as watchdogs, continuously monitor the status of cloud services, tracking various metrics and logs to detect anomalies. In this work, the authors represent a cloud service network as a heterogeneous monitor entity graph. In the context of this paper, the heterogeneous graph consists of three types of nodes: monitor, metric (such as device usage or latency), and dimension (like an attribute of a device). It also contains three types of edges representing the connections between these node types. The paper utilizes the heterogeneous graph to derive the embedding vectors for each node in the monitor entity graph. These embedding vectors are then used to compute a composite loss function, which combines BCE Loss, Ranking Loss, and Diversity Loss. (However, the paper does not provide detailed information on the inputs for these losses.)",
        "strengths": "- The authors proposed the DiRaGNN framework for the dimension recommendation and ranking problem in the context of cloud services.\n- The authors address the computational challenges of processing large-scale heterogeneous graphs by employing neighborhood sampling and subgraph generation.\n- The author evaluates the diversity loss and ranking loss through an ablation analysis, comparing three model variants and visualizing how the relevance of top-ranked dimensions changes across configurations using rank stability plots. However, providing additional quantitative metrics for the rank stability plots would further help reviewers understand the differences between the model variants.",
        "weaknesses": "- The paper writing is poor. Almost every part of the paper lacks critical information that would help the reviewer understand the work, making the entire paper filled with ambiguity. Moreover, the authors did not clearly introduce or define what the “dimension ranking problem” (or the “entity ranking problem in a cloud setting”) is. It was only after reading a cited paper, Intelligent Monitoring Framework for Cloud Services: A Data-Driven Approach, that I could finally understand what the authors meant by the “dimension recommendation and ranking problem.”\n- The font size in the figures is too small (Figure 1, Figure 3b, Figure 4, and Figure 5), making it very difficult to read. Additionally, the figures are poorly designed, looking almost like children’s doodles. (For example, in Figure 1a, the elements in the blocks are not properly aligned, and in Figure 1b, the word “dimension” is even tilted rather than being properly displayed in the horizontal direction.)\n- While the paper introduces the adopted DiRaGNN framework and loss functions, the authors fail to explain the source of the datasets used. Furthermore, the ground truth for the dimension ranking task for monitors is neither defined nor explained. Without these details, it becomes difficult for the reviewer to assess the capability of the proposed DiRaGNN framework, relying solely on the reported metric scores.\n- The content of subsubsection 3.2.1 (MESSAGE PASSING MECHANISM) actually describes the concept of a Heterogeneous Graph Attention Network (referenced below). However, the authors do not cite any relevant papers to support this approach.\n- In the framework overview shown in Figure 4, the DiRaGNN framework includes both a classifier and link prediction. However, the paper does not explain how the loss is calculated through these two components, making it difficult to understand the framework's workflow.\n-The authors only conduct experiments on a single dataset. Performing experiments on additional datasets would help demonstrate the generalizability of the proposed approach.\n- The paper’s presentation could be improved; figures are not vector graphics, and some tables appear poorly formatted."
      }
    ],
    "rating_avg": 3.5,
    "confidence_avg": 3.75,
    "decision": "N/A",
    "meta_review": "",
    "author_remarks": "",
    "decision_comment": ""
  },
  {
    "id": "PflweLMInP",
    "title": "Complete multi-modal metric learning for multi-modal sarcasm detection",
    "authors": [
      "Jiecheng Zhang",
      "C.L.Philip Chen",
      "Shuzhen Li",
      "Tong Zhang"
    ],
    "abstract": "Multi-modal sarcasm detection identifies sarcasm from text-image pairs, an essential technology for accurately understanding the user's real attitude.\nMost research extracted the incongruity of text-image pairs as sarcasm information. However, these methods neglected inter-modal or intra-modal incongruities in fact and sentiment perspectives, leading to incomplete sarcasm information and biased performance.\nTo address the above issues, this paper proposes a complete multi-modal metric learning network (CMML-Net) for multi-modal sarcasm detection tasks.\nSpecifically, CMML-Net utilizes a fact-sentiment multi-task representation learning module to produce refined fact and sentiment text-image representation pairs.\nIt then designs a complete multi-modal metric learning to iteratively calculate inter-modal and intra-modal incongruities in a unified space (e.g., fact and sentiment metric space), efficiently capturing complete multi-modal incongruities.\nCMML-Net performs well in explicitly capturing comprehensive sarcasm information and obtaining discriminative performance via deep metric learning.\nThe state-of-the-art performance on the widely-used dataset demonstrates CMML-Net's effectiveness in multi-modal sarcasm detection.",
    "keywords": [
      "multi-modal sarcasm detection",
      "metric learning",
      "complete multi-modal incongruities"
    ],
    "venue": "ICLR",
    "year": 2025,
    "pdf_url": "https://openreview.net/pdf?id=PflweLMInP",
    "forum_url": "https://openreview.net/forum?id=PflweLMInP",
    "reviews": [
      {
        "rating": "5",
        "confidence": "3",
        "summary": "The paper introduces a novel framework called the Complete Multi-Modal Metric Learning Network (CMML-Net) designed for multi-modal sarcasm detection, leveraging both text and image data. This task is complex due to sarcasm's reliance on implicit contrasts, often between literal meanings and actual sentiments or facts. The CMML-Net improves sarcasm detection by identifying these contrasts through inter-modal (between text and image) and intra-modal (within each modality) incongruities, enhancing sarcasm recognition accuracy. In general, the CMML-Net demonstrates a significant advancement in multi-modal sarcasm detection, providing a repeatable and well-organized structure for detecting sarcasm with high accuracy. The model’s design effectively captures multi-dimensional incongruities, though its computational demands and current scope might limit broader real-time and cross-modal applications.",
        "strengths": "1. The modular structure of CMML-Net enables clear, systematic analysis of sarcasm, making the model robust and extensible for future research. The dual-stream network is meticulously designed to assess sarcasm through both fact and sentiment incongruities, improving detection accuracy.\n\n2. By building upon existing work and leveraging well-established models, the CMML-Net is highly repeatable, with well-documented performance on benchmark datasets.",
        "weaknesses": "1. The paper lacks clarity due to some undefined symbols and terms. For instance, the architecture is based on \"units\" in section 3.2 that are repeatedly referenced as learnable, but their exact nature is not defined. It is unclear whether these units are neuron clusters, specific network layers, or memory mechanisms designed to integrate multiple modalities. Additionally, other symbols, such as the capital \"S\" and \"F,\" are not explicitly defined. While \"S\" seems to represent sentiment-related information, the meaning of \"F\" is ambiguous and should be clarified. Could you please clarify those terms where they are firstly introduced?\n\n2.  The paper’s focus on multi-modal sarcasm detection is narrow, limiting its potential impact and relevance for the broader machine learning community. Could you please give some potential broader implications or applications of their work beyond sarcasm detection. \n3.  The framework is built largely on existing approaches, enhancing its reproducibility. However, this reliance on established methodologies limits its originality, as there is a lack of significant methodological contribution. This may affect its impact within the research community, which typically values innovation in addition to reproducibility."
      },
      {
        "rating": "3",
        "confidence": "4",
        "summary": "This paper introduces a novel network, CMML-Net, designed for detecting sarcasm in text-image pairs. The network addresses the limitations of previous methods that focused solely on inter-modal incongruities, neglecting intra-modal incongruities. CMML-Net employs a fact-sentiment multi-task representation learning module to generate refined representations and a complete multi-modal metric learning approach to iteratively calculate inter-modal and intra-modal incongruities in both fact and sentiment metric spaces. The model demonstrates state-of-the-art performance on the Multimodal Sarcasm Detection (MSD) dataset, outperforming existing methods by capturing more comprehensive sarcasm information.",
        "strengths": "1.\tThis paper is well-written with a clear and concise expression.\n2.\tThe authors have conducted a thorough set of experiments, which is a significant strength of the paper.",
        "weaknesses": "1.\tThe summary of related work is incomplete.\n2.\tThe authors mention that previous work neglected the importance of intra-modal incongruity in sarcasm detection, leading to incomplete incongruities and biased performance, but do not provide reasons why intra-modal incongruity is useful for sarcasm. It is suggested to use examples in the Introduction section to intuitively demonstrate this.\n3.\tThe authors mention two innovative points in the Introduction section, but these two points essentially seem to be the same.\n4.\tThe authors explain that \"Fact incongruity means sarcasm occurs when the literal meaning and the observed facts unexpectedly contrast.\" Additionally, in the method design, both the FISN and SISN modules take the combined results of image and text as input. This indicates that the work primarily focuses on addressing inter-modal incongruities. However, the authors describe the FISN and SISN as aiming to capture both intra-modal and inter-modal incongruities (Sections 3.2.1 and 3.2.2). Where is the intra-modal incongruity reflected?\n5.\tOnly one dataset is considered in the experiments, such as MMSD2.0 and MSTI, which are not included, and the generalizability of the method cannot be demonstrated.\n6.\tThe Main Result lacks significance analysis.\n7.\tIn Section 4.6, the authors analyze the YOLO-task representation, but is it possible to replace it with other models to achieve multimodal sarcasm detection results based on different backbones?"
      },
      {
        "rating": "3",
        "confidence": "5",
        "summary": "This work focus on multimodal sarcasm detection task. As existing works neglected inter-modal or intra-modal incongruities in fact and sentiment perspectives, their performance exist a bias. To achieve this, this paper proposes a complete multi-modal metric learning network (CMML-Net) for multi-modal sarcasm detection tasks. Extensive experiments demonstrates the effectiveness and the scalability of the proposed CMML-Net.",
        "strengths": "1.\tThe proposed CMML-Net model achieves the state-of-the-art performance on different datsets.\n2.\tAblation studies validate the necessity of each component. Visualizations provide intuitive understanding.\n3.\tThe related literatures are well covered.\n4.\tThis work provides code for reproduce.",
        "weaknesses": "1.\tLack of insights in the proposed approach. Motivation of the proposed module in the overall framework is unclear in this paper.\n2.\tThe method of this paper exhibits limited novelty. In my opinion, introducing the Yolo task, the face stream aims to find the image-based incongruity. However, the image-based incongruity have been discussed in existing works. And they proposed many effectiveness approach to solve this problem.[1,2,3,4]\n3.\tThere is unclear motivation of why this paper introduces deep metric learning. And what’s it’s advantage compared to traditional deep learning in existing works?\n4.\tThis paper highlights the incongruity from two perspective: fact and sentiment. The sentiment aspect is easy to understand. However, there lacks more discussion on why the fact aspect is important for multimodal sarcasm detection in introduction section. \n\n[1] H. Liu, W. Wang, and H. Li, “Towards multi-modal sarcasm detection via hierarchical congruity modeling with knowledge enhancement,” in EMNLP, 2022, pp. 4995–5006.\n[2] B. Liang, C. Lou, X. Li, L. Gui, M. Yang, and R. Xu, “Multi-modal sarcasm detection with interactive in-modal and cross-modal graphs,” in Proceedings of the ACM International Conference on Multimedia (MM), 2021, pp. 4707–4715.\n[3] B. Liang, C. Lou, X. Li, M. Yang, L. Gui, Y. He, W. Pei, and R. Xu, “Multi-modal sarcasm detection via cross-modal graph convolutional network,” in ACL, 2022, pp. 1767–1777.\n[4] N. Xu, Z. Zeng, and W. Mao, “Reasoning with multimodal sarcastic tweets via modeling cross-modality contrast and semantic association,” in Proceedings of the Annual Meeting of the Association for Computational Linguistics (ACL), 2020, pp. 3777–3786."
      },
      {
        "rating": "10",
        "confidence": "4",
        "summary": "This paper proposes a complete multi-modal metric learning network (CMML-Net) for multi-modal sarcasm detection tasks. Specifically, CMML-Net utilizes a fact-sentiment multi-task representation learning module to produce refined fact and sentiment text-image representation pairs. It then designs a complete multi-modal metric learning to iteratively calculate inter-modal and intra-modal incongruities in fact and sentiment metric spaces, explicitly capturing complete multi-modal incongruities. CMML-Net performs well in explicitly capturing comprehensive sarcasm information and obtaining discriminative performance via deep metric learning. The state-of-the-art performance on the widely-used dataset demonstrates CMML-Net's effectiveness in multi-modal sarcasm detection.",
        "strengths": "1.The authors use the method of metric learning to study multimodal sarcasm detection, which is innovative.\n\n2.The authors provide a detailed analysis of the effectiveness of each module.\n\n3.The author makes a detailed analysis of the inconsistencies of multimodal irony in images and texts.",
        "weaknesses": "1.Metrics Learning Related Work: This paper is inspired by metrics learning, but lacks work on metrics learning.\n\n2.Typographical errors: There are errors in some of the corner marks in the text, e.g. line 140. Some punctuation errors, such as line 148. Some sentences are redundant, such as lines 165 to 167.\n\n3.Row 153: What is the size of the target range k and whether it will affect the module.\n\n4.Inadequate experimentation: It is not enough to adopt only one dataset, more datasets including MMSD2.0 [1], DMSD [2], RedEval [3] verification model need to be adopted.\n\n5.Supplemental baseline: Comparisons of relevant sarcasm detection work are missing, and it is recommended to add, e.g., G2SAM[4], DynRT-Net[5], DMSD-CL[2]. \n\n[1]. MMSD2.0: Towards a Reliable Multi-modal Sarcasm Detection System. ACL-23\n\n[2]. Debiasing Multimodal Sarcasm Detection with Contrastive Learning. AAAI-24\n\n[3]. Leveraging Generative Large Language Models with Visual Instruction and Demonstration Retrieval for Multimodal Sarcasm Detection. NAACL-24.\n\n[4]. G2SAM: Graph-Based Global Semantic Awareness Method for Multimodal Sarcasm Detection. AAAI-24.\n\n[5]. Dynamic Routing Transformer Network for Multimodal Sarcasm Detection. ACL-23."
      }
    ],
    "rating_avg": 5.25,
    "confidence_avg": 4.0,
    "decision": "Reject",
    "meta_review": "This paper proposes a metric learning framework to enhance the task of multimodal sarcasm detection. By combining two aspects, namely sentiment aspect and factual aspect, the proposed method incorporates intra- and inter-modal incongruities across two aspects to capture more nuanced samples. Experiments demonstrate the proposed method outperforms existing baselines on the MSD dataset.\n\nStrengths:\n- The joint model which aims to capture both sentiment-oriented and fact-oriented sarcasm is reasonable and interesting. Despite the fact that inter-modal and intra-modal relationships have been proposed earlier, the integration of two perspectives is novel.\n- The adoption of metric learning for this task is efficient and effective.\n- Experiments on the MSD dataset shows the proposed method gives the best performance.\n\nWeaknesses:\n- The contribution is limited. Several existing methods have incorporated both inter-modal and intra-modal relationships for sarcasm detection (e.g., Pan et al. 2020, Liang et al. 2021). It is not accurate to claim this contribution.\n- The initial experiment only considers one dataset with slight improvement. Although the authors provided more experiments with other datasets as suggested by reviewers, the result does not seem to indicate substantial gains, especially for MMSD 2.0.\n- The motivation of the model design is lacking. It is not very clear why metric learning is beneficial in this task, compared with existing deep learning methods, such as using a neural incongruity scorer.\n- Most importantly, the application domain is narrow. More diverse tasks such as fake news detection should be included to demonstrate the impact of the proposed method.",
    "author_remarks": "",
    "decision_comment": ""
  },
  {
    "id": "LsTIW9VAF7",
    "title": "Less is More: Stealthy and Adaptive Clean-Image Backdoor Attacks with Few Poisoned",
    "authors": [
      "Binyan Xu",
      "Fan YANG",
      "Di Tang",
      "Xilin Dai",
      "Kehuan Zhang"
    ],
    "abstract": "Deep neural networks are fundamental in security-critical applications such as facial recognition, autonomous driving, and medical diagnostics, yet they are vulnerable to backdoor attacks. Clean-image backdoor attack, a stealthy attack utilizing solely label manipulation to implant backdoors, renders models vulnerable to exploitation by malicious labelers. However, existing clean-image backdoor attacks likely lead to a noticeable drop in Clean Accuracy (CA), decreasing their stealthiness. In this paper, we show that clean-image backdoor attacks can achieve a negligible decrease in CA by poisoning only a few samples while still maintaining a high attack success rate. We introduce **G**enerative Adversarial **C**lean-Image **B**ackdoors (GCB), a novel attack method that minimizes the drop in CA to less than 1\\% by optimizing the trigger pattern for easier learning by the victim model. Leveraging a variant of InfoGAN, we ensure that the trigger pattern we used has already been contained in some training images and can be easily separated from those feature patterns used for benign tasks. Our experiments demonstrate that GCB can be adapted to 5 datasets—including MNIST, CIFAR-10, CIFAR-100, GTSRB, and Tiny-ImageNet—5 different architectures, and 4 tasks, including classification, multi-label classification, regression, and segmentation. Furthermore, GCB demonstrates strong resistance to backdoor defenses, successfully evading all detection methods we know. Code: *anonymous.4open.science/r/GCB*.",
    "keywords": [
      "Backdoor Attack",
      "Generative Adversarial Networks",
      "Clean-Image Backdoor Attacks",
      "Deep Neural Networks",
      "InfoGAN",
      "Poisoning Attack",
      "Model Integrity"
    ],
    "venue": "ICLR",
    "year": 2025,
    "pdf_url": "https://openreview.net/pdf?id=LsTIW9VAF7",
    "forum_url": "https://openreview.net/forum?id=LsTIW9VAF7",
    "reviews": [
      {
        "rating": "5",
        "confidence": "3",
        "summary": "This paper proposes a mutual information-constrained approach for backdoor pattern generation, to create backdoored samples with similar distribution to the target class. Therefore, the authors can enhance the stealthiness of backdoor samples. The authors demonstrate the strong correlation between the backdoor samples and the backdoor labels, showing that such samples can be easily learned by the model.",
        "strengths": "The authors propose to generate backdoor samples based on InfoGAN, enhancing stealthy of backdoor attacks. The proposed backdoor is proved to be more undetectable and easy to learn. This work is validated by theoretical analysis and supported by well-designed experiments.",
        "weaknesses": "1.To my best knowledge, other advanced clean image backdoor methods are strongly related to the proposed approach. Although they are not referred to as ‘clean image backdoors,’ they are also rather ‘invisible backdoors’. From this perspective, the innovation of the proposed approach seems limited. I suggest that the authors compare their method with these state-of-the-art techniques and clarify its advantages.\nReferences:\n[1]Li, Yuezun, et al. \"Invisible backdoor attack with sample-specific triggers.\" Proceedings of the IEEE/CVF international conference on computer vision. 2021.\n[2]S. Li, M. Xue, B. Z. H. Zhao, H. Zhu and X. Zhang, \"Invisible Backdoor Attacks on Deep Neural Networks Via Steganography and Regularization,\" in IEEE Transactions on Dependable and Secure Computing, vol. 18, no. 5, pp. 2088-2105, 1 Sept.-Oct. 2021, doi: 10.1109/TDSC.2020.3021407.\n[3]R. Ning, J. Li, C. Xin and H. Wu, \"Invisible Poison: A Blackbox Clean Label Backdoor Attack to Deep Neural Networks,\" IEEE INFOCOM 2021 - IEEE Conference on Computer Communications, Vancouver, BC, Canada, 2021, pp. 1-10, doi: 10.1109/INFOCOM42981.2021.9488902.\n2.The condition ‘irrelevance’ is only briefly explained in the ablation study, where this loss is removed to measure ASR. However, the experiments do not effectively demonstrate why the generated samples are irrelevant to the original-class samples."
      },
      {
        "rating": "5",
        "confidence": "5",
        "summary": "The paper proposes a clean-image backdoor attack that achieves low poisoning rates even in the all-to-one setting. The proposed method relies on learning an InfoGAN's generator network to generate images from real and fake classes (this is used to generate the triggered images) and a discriminator network to distinguish samples between real and fake classes (this is used as scoring function to select poisoned samples). This design of InfoGAN's networks ensures that the trigger patterns exist within the real images, while making the poisoned tuples separated from the clean tuples for easier backdoor training. The paper provides extensive empirical results to demonstrate the effectiveness of the proposed method on multiple datasets, architectures, and defenses.",
        "strengths": "The main strengths of the paper lie in its clever use of InfoGAN and the extensive empirical results (although I do have some concerns in these aspects as well)\n* The use of InfoGAN, while trivial, shows a cleverness in using it for clean-image backdoor attack. \n* The experiments include multiple benchmark datasets. The paper also evaluate against multiple networks and a large number of defenses.",
        "weaknesses": "While this paper is interesting, I also find several concerns, specifically on its rigorous analysis of why the method works so well:\n\n* The paper proposes to use Wasserstein loss, but the theoretical analysis instead shows the convergence on JS Divergence. This is a crucial mismatch. In fact, I don't even think the proof of convergence is necessary because it is quite well established for InfoGAN (and GAN in general), and the paper does not change anything in the base InfoGAN model, rather than changing the model's input. \n* I also find that the statement of converging, especially in the context of GANs, is quite strong. It's been known that GANs' theoretical convergence and what actually happens in practice are two very different things. I suggest that the paper focuses more on analyzing why the scoring function works so well instead, and provide a more rigorous analysis there. \n* In fact, I find that the design of the attack is based on several assumptions (such as convergence) that may or may not hold in practice. While the final results show favorable performance for GCB, the paper lacks rigorous connections between these assumptions and the performance, which is a bit disappointing. \n* For example, the statement that the backdoor can be learned even more easily than BadNets deserves more rigorous analysis. In general, in backdoor attacks, when the backdoor is learned really easily, it also causes several consequences; for example, ABL relies on the fact that the loss of poisoned samples drops abruptly during training, which urges the question of why GCB works so well. As there are so many backdoor attack papers in the last several years, I think that these analyses are much more important than demonstrating that the method \"just works very well\".\n* I also find that while several defenses have been tested (which is commendable), a new category of defenses (based on fine-tuning, such as FT-SAM) is not evaluated. I wonder whether the fact that the backdoor is learned very quickly could also mean that fine-tuning defenses could work very well against GCB.\n* Another weakness of the paper is that several experiments only include the evaluations on CIFAR10 and CIFAR100, which are essentially the same. I would suggest that the paper to include all datasets.\n* On line 214, the paper suddenly introduces *c*, a notation that is not explained until a bit later. I find that this part of the paper could be improved quite a lot. In addition, I struggled a bit to understand how the triggered images are created during inference. I think the paper assumes that the reader is very familiar with the backdoor domain, and I hope the paper can make this part clearer and more accessible to new readers.\n* Some minor grammatical errors/typos: - line 69: \"construct trigger\", several places the paper mention InforGAN."
      },
      {
        "rating": "8",
        "confidence": "5",
        "summary": "This paper proposes a GAN-based architecture that makes backdoor triggers easier to learn for the victim model and hence achieves high ASR and hinders non-trivial clean accuracy drop. The proposed GCB (Generative adversarial clean image backdoor) combines InfoGAN and Conditional GAN to ensure that the backdoor trigger meet requirements of existence, separability and irrelevancy. The authors perform comprehensive evaluations over various dataset across different model architectures and demonstrate that GCB achieves high ASR and CA with a low poisoning rate. They also conduct a extensive ablation study of their design choices and assess GCB against multiple existing defenses.",
        "strengths": "- This paper tackles the clean accuracy drop issue in clean-image backdoors, which further improves the effectiveness and stealthiness of such an attack.\n\n- The proposed GAN architecture is technically sounded and novel. The authors explicitly explain their motivations of using InfoGAN and conditional GAN, and the GCB design is well-aligned with the objectives of triggers properties (i.e., existence, separability and irrelevancy).\n\n- The authors also provide detailed theoretical proofs and mathematical analysis for the design.\n\n- The experiments are abundant to support the authors claims. They show that the GCB can generalize to different datasets and model architectures including TinyImageNet and ViT.  They also test it on multiple vision tasks such as image regression and segmentation. In addition, GCB is evaluated against prestigious defenses for backdoor attacks.\n\n- The paper is well-written and easy to follow.",
        "weaknesses": "- I don't see any major weaknesses/issues in this paper."
      },
      {
        "rating": "5",
        "confidence": "5",
        "summary": "This paper introduces Generative Adversarial Clean-Image Backdoors (GCB), a backdoor attack technique that minimizes detection in neural networks used for sensitive applications like facial recognition and autonomous driving. Unlike traditional backdoor attacks, GCB only uses clean images with manipulated labels, avoiding noticeable accuracy drops and making the attack stealthier. The technique employs a variant of InfoGAN, called C-InfoGAN, to embed backdoor triggers naturally by manipulating benign features in the dataset. The method maintains high attack success rates (ASR) across multiple tasks, datasets, and architectures, even with low poison rates. Extensive experiments show GCB’s resilience against numerous backdoor defenses, including Neural Cleanse and STRIP, and strong adaptability across diverse visual tasks.",
        "strengths": "(1)  GCB achieves high attack success rates (ASR) with minimal impact on clean accuracy (CA), which is critical for stealthiness in security-sensitive applications.\n\n(2) With a poison rate as low as 0.1%, GCB still maintains high ASR, showcasing efficiency in terms of resource requirements.",
        "weaknesses": "(1) This paper employs GANs to generate the trigger image. However, GANs are known for their limited ability to fit complex data distributions, such as ImageNet, raising concerns about the method's applicability to more complex datasets.\n\n(2) Since the trigger in this study is GAN-generated, there may be a significant distributional gap between the generated trigger and real image data. Consequently, it is essential to analyze the method’s resistance to defense strategies based on abnormal sample detection.\n\n(3) The theoretical justification in Section 3.2 closely aligns with prior work on InfoGAN, and this overlap should be clarified to better situate the contribution within the existing literature.\n\n(4) The paper uses InfoGAN to partition the benign training set into two subsets (A and B), selecting one (B) for poisoning. However, this approach may reduce benign accuracy on the original subset B. Additional experiments and discussion regarding the impact on benign accuracy would strengthen this section."
      },
      {
        "rating": "6",
        "confidence": "5",
        "summary": "This paper proposes Generative Adversarial Clean-Image Backdoors (GCB), a novel clean-image backdoor attack method that maintains high ASR with low poison rates and minimal drop in clean accuracy (CA). The key idea is optimizing the trigger pattern to make it easier for the victim model to learn, by using a variant of InfoGAN called C-InfoGAN. Experiments demonstrate GCB's effectiveness across 5 datasets, 5 model architectures, and 4 vision tasks. GCB also shows strong resistance to existing backdoor defenses.",
        "strengths": "- Achieves outstanding stealthiness, with high ASR (>90%), low poison rate (<=1%), and minimal CA drop (<=1%) across all tested datasets. This significantly advances clean-image backdoor attack capabilities.\n- Shows strong adaptivity to 5 datasets, 5 architectures, and 4 vision tasks beyond just classification. Indicates the attack is widely applicable.\n- Introduces a novel C-InfoGAN method to optimize triggers for easy learning without interfering with clean task accuracy. The theoretical analysis supports why this works.\n- Demonstrates robustness to a wide range of backdoor defenses, revealing gaps in existing mitigation techniques that need to be addressed.\n- Extensive experiments and ablations provide good insight into the attack's behavior and validate the approach.",
        "weaknesses": "- Scalability concerns: The paper only evaluates on relatively small datasets. The required poison rate increases as dataset complexity grows (e.g. from CIFAR-10 to Tiny ImageNet), suggesting scalability issues. It's unclear if the method would still be effective on large-scale datasets like ImageNet-1K without requiring an impractically high poison rate. Testing on a wider range of dataset sizes would help assess the scalability limits.\n- Limited evaluation against newer defenses: Many of the backdoor defenses tested are relatively dated. The attack's effectiveness against more recent state-of-the-art defenses, particularly those developed in the past 1-2 years, is not demonstrated. Additionally, for the Label Cleaning experiments, only one technique is evaluated. There are several other advanced Label Cleaning approaches that may be more effective but are not considered, such as DivideMix, MentorMix, and Robust Meta-Learning.\n- Relabeling mitigation analysis: The authors' claim that a >95% relabeling rate is needed to keep ASR below 20% seems questionable given advancements in vision-language models. With the increasing popularity and capability of models like CLIP and BLIP, it may be feasible to automatically relabel large portions of the training set accurately and efficiently. This could significantly lower the cost of relabeling and make it a more viable mitigation strategy. The paper's analysis of relabeling as a defense does not sufficiently consider this."
      }
    ],
    "rating_avg": 5.8,
    "confidence_avg": 4.6,
    "decision": "Reject",
    "meta_review": "It received ratings of 5 ,5 ,8, 5, 6. The reviewers pointed out several weaknesses including a mismatch between the proposed Wasserstein loss and the theoretical analysis based on JS Divergence, which undermines the theoretical contribution. The claim of convergence in GANs, especially in practice, is too strong and lacks necessary rigor, as the assumptions may not hold in real-world scenarios. The analysis of the attack's effectiveness is superficial, and the rapid learning of backdoors, particularly in GCB, warrants more detailed investigation. There are also concerns about the method's scalability to more complex datasets (e.g., ImageNet), its robustness against newer defenses, and the limited evaluation of recent defense strategies such as fine-tuning defenses and advanced Label Cleaning techniques. The use of InfoGAN for partitioning the training set could negatively affect benign accuracy, and there is insufficient discussion on the broader impact of this. Finally, the paper's reliance on small datasets (CIFAR-10/100) and lack of clear explanations in certain parts, such as the creation of triggered images, detracts from its accessibility and general applicability.\n\nWhile one reviewer is positive, it is relatively brief and does not list any weakness. It lists the following strengths: The paper introduces a novel GAN-based architecture to improve clean-image backdoors, enhancing attack effectiveness and stealth. It uses InfoGAN and conditional GAN with a GCB design aligned to trigger properties. Theoretical foundations are strong, and extensive experiments show GCB's effectiveness across various datasets, tasks, and against top defenses. The paper is clear and well-written.\n\nSince in the end most reviewers still have concerns about this submission, this paper will be rejected.",
    "author_remarks": "",
    "decision_comment": ""
  },
  {
    "id": "Kh5OS3oNlg",
    "title": "PARSE-Ego4D: Personal Action Recommendation Suggestions for Ego-Centric Videos",
    "authors": [
      "Steven Abreu",
      "Tiffany D Do",
      "Karan Ahuja",
      "Eric J Gonzalez",
      "Lee Payne",
      "Daniel McDuff",
      "Mar Gonzalez-Franco"
    ],
    "abstract": "Intelligent assistance involves not only understanding but also action. Existing ego-centric video datasets contain rich annotations of the videos, but not of actions that an intelligent assistant could perform in the moment. To address this gap, we release PARSE-Ego4D, a new set of personal action recommendation annotations for the Ego4D dataset. We take a multi-stage approach to generating and evaluating these annotations. First, we used a prompt-engineered large language model (LLM) to generate context-aware action suggestions and identified over 18,000 action suggestions. While these synthetic action suggestions are valuable, the inherent limitations of LLMs necessitate human evaluation. To ensure high-quality and user-centered recommendations, we conducted a large-scale human annotation study that provides grounding in human preferences for all of PARSE-Ego4D. We analyze the inter-rater agreement and evaluate subjective preferences of participants. Based on our synthetic dataset and complete human annotations, we propose several new tasks for action suggestions based on ego-centric videos. We encourage novel solutions that improve latency and energy requirements. The annotations in PARSE-Ego4D will support researchers and developers who are working on building action recommendation systems for augmented and virtual reality systems.",
    "keywords": [
      "augmented reality",
      "virtual reality",
      "human annotation",
      "recommender systems",
      "perception",
      "large language models"
    ],
    "venue": "ICLR",
    "year": 2025,
    "pdf_url": "https://openreview.net/pdf?id=Kh5OS3oNlg",
    "forum_url": "https://openreview.net/forum?id=Kh5OS3oNlg",
    "reviews": [
      {
        "rating": "5",
        "confidence": "2",
        "summary": "The paper augments Ego4D for action suggestion annotations, termed as Parse-Ego4D. The action suggestion classes include categories like search, assistant search, assistant local, language, directions, assistant guide and others. With this new proposed dataset, the paper also introduces two tasks: action recommendation systems for (1) explicit user query to action suggestion, and (2) implicit user query to action suggestions.",
        "strengths": "The motivations behind creating this augmented dataset is based on guessing future usecases in AR/VR systems. They introduce two tasks with this augmented dataset created atop ego4d.  The paper includes performance and efficiency metrics. \nThe subjective user study is valuable.",
        "weaknesses": "The action suggestion labels have been created solely based on narrations. Any limitations in the narrations do not have opportunity in recovering."
      },
      {
        "rating": "6",
        "confidence": "4",
        "summary": "The authors release pseudo-labels of action recommendations over the Ego4D dataset. They perform the generation of pseudo-labels using a multimodal LLM, and filter the results using human annotators. They perform analysis over the quality of the dataset with intra-human variance and introduce two tasks that make use of this dataset, with baselines of several SOTA models.",
        "strengths": "1) The work is well motivated for many areas in Human-Robot Interaction, Augmented Reality and Virtual Reality. Systems that can anticipate actions of the actor and act preemptively are very valuable. The paper also outlines many exciting future possibilities of extending this work.\n2) LLMs can generate problematic pseudo-labels, but the authors have made sure to introduce strong screening measures, along with some helpful quantitative analysis.\n3) The action space of the recommendations is extensive and covers use-cases of many interesting applications.",
        "weaknesses": "1) I feel the paper is missing qualitative results over the outputs of the LLM (pre and post-human analysis), along with a broader characterization of the dataset. Though to the authors credit, the quantitative analysis is extensive.\n2) The lack of video input to any of the baselines results in the trained models missing a lot of contextual information (e.g. head cues) needed to decide when/what recommendations are useful. While it is reasonable video is not ingested by the model producing the pseudo ground truth (video is observed by the human annotators instead), the baselines would be much more powerful if they had access to video.\n3) The user study is highly subjective and largely prone to speculative error - of course, the best option would be to ask the actor the survey questions, but that would require a collection of a new dataset."
      },
      {
        "rating": "6",
        "confidence": "3",
        "summary": "The paper introduces a new dataset, PARSE-Ego4D, that contains action recommendation annotations for a potential AR assistive agent. The proposed dataset is based on Ego4D, and the annotations were first collected by prompting Gemini Pro and then filtered by human raters based on sensibility, correctness, implicitness, etc. In addition to the dataset, the paper proposes two tasks for query to action prediction.",
        "strengths": "- I like the paper's research direction of studying personal action recommendations of AR assistive agents. It is new and interesting. If the dataset is released, it may attract new research in assistive AR, leveraging computer vision and LLMs. I also appreciate the author's effort in curating a large dataset and filtering the LLMs-generated results with human raters. The dataset creation is not trivial work, and the authors have put thoughts into the dataset creation, including annotating based on different metrics, e.g., sensibility, correctness, etc.",
        "weaknesses": "- First, the paper uses the NeurIPS 2024 Track on Datasets and Benchmark manuscript template instead of the ICLR 2025 template. Such carelessness raises concerns about whether the paper has incorporated review suggestions from NeurIPS or not. \n\n- Regardless of the previous point, a significant portion of the paper's content describes the creation of the dataset while leaving little space to describe the benchmark tasks, how these benchmark tasks differ from existing research, and whether they are significant enough to attract future researches to use these benchmark tasks. While the paper might be a reasonable consideration for a dataset track submission, it is too thin for a main conference paper in venues like ICLR. \n\n- The paper should seriously consider improving presentation clarity. For example, I have to read Section 4.2 multiple times, trying to understand what the authors mean by the \"implicit\" query-to-action task. It wasn't very clear. I also needed to refer back to Figure 1 and try to map that to the inline equation f: c \\to (q, a). This is just one place. Again, the paper is too focused to describe the dataset."
      },
      {
        "rating": "5",
        "confidence": "4",
        "summary": "This paper introduces a new dataset called PARSE-Ego4D, which builds on top of the existing Ego4D dataset by collecting personal action recommendation annotations. The authors adopt a two-stage annotation process: they generate context-aware action suggestions using a prompt-engineered LLM in the first stage and evaluate the automated suggestions through human study in the second stage. The authors also propose two tasks for action suggestions based on PARSE-Ego4D: explicit query-to-action and implicit query-to-action. The explicit query-to-action task predicts an action suggestion given the query. On the other hand, the model needs to predict the action suggestion without an explicit user query for the implicit query-to-action task.",
        "strengths": "- The new set of annotations introduced in the proposed dataset does look practical and timely, considering that it is specifically designed to empower proactive AI assistants. It can be used to develop intelligent systems that provide personalized action suggestions.\n- The proposed benchmark, which consists of two tasks, also looks interesting and well-defined. Especially, the implicit query-to-action task is open-ended, leaving the vision community with much room for improvement.\n- The paper reads well and is easy to follow. It looks well-organized, with the required figures and tables placed throughout.\n- It also discusses the limitations of the proposed dataset and benchmarks in many aspects.",
        "weaknesses": "- [W1] 80% of the dataset, which is held for training and validation splits, has only been annotated by a single human rater. This can cause instability in the training process of AI assistant models because the annotations collected by a single annotator might be too noisy. I believe that at least three answers should be collected and averaged (or decided by a majority vote).\n- [W2] The action suggestion annotations are highly imbalanced, which can also contribute to instability in the training/validation process. For example, the two types of “instructions” and “assistants” account for over 80% of the annotations. On the other hand, “language” and “other” types account for only 0.02%. I believe breaking down “instructions” and “assistants” types into multiple subdivisions solves this imbalance problem, which might be more practical for dataset users.\n- [W3] The explicit query-to-action task is merely a simple classification problem with only 6 classes. Even the simple baselines already achieve 87% accuracy. I highly believe that the authors should subdivide the action suggestions, especially for “instructions” and “assistants” types.\n- [W4] The number of verified and high-quality suggestions (defined by the authors in line 220) is 7770, which seems too small and only accounts for 42.43% of the annotations. I believe that the authors should collect more high-quality annotations.\n- [W5] I do not believe that the negative log-likelihood (NLL) is the best metric for the implicit query-to-action task. There are other metrics besides BLEU (e.g., ROUGE, WUP, METEOR), and I believe that the authors should propose a new accuracy metric based on these existing ones.\n- [W6] The dataset does not consider continual interactions between humans and AI assistants, although the actual users will show continual aspects."
      }
    ],
    "rating_avg": 5.5,
    "confidence_avg": 3.25,
    "decision": "Reject",
    "meta_review": "The paper proposes a dataset for action recommendation on top of the Ego4D dataset. Reviewers appreciate the problem and data, but share concerns with the method (e.g. labels created just based on narrations, not enough data annotated by multiple participants), technical contribution (e.g. focus on dataset creation), bias, and clarity. Two borderline accept and two borderline reject are not sufficient signal to justify acceptance.",
    "author_remarks": "",
    "decision_comment": ""
  },
  {
    "id": "E4LAVLXAHW",
    "title": "Black-Box Detection of Language Model Watermarks",
    "authors": [
      "Thibaud Gloaguen",
      "Nikola Jovanović",
      "Robin Staab",
      "Martin Vechev"
    ],
    "abstract": "Watermarking has emerged as a promising way to detect LLM-generated text, by augmenting LLM generations with later detectable signals. Recent work has proposed multiple families of watermarking schemes, several of which focus on preserving the LLM distribution. This distribution-preservation property is motivated by the fact that it is a tractable proxy for retaining LLM capabilities, as well as the inherently implied undetectability of the watermark by downstream users. Yet, despite much discourse around undetectability, no prior work has investigated the practical detectability of any of the current watermarking schemes in a realistic black-box setting. In this work we tackle this for the first time, developing rigorous statistical tests to detect the presence, and estimate parameters, of all three popular watermarking scheme families, using only a limited number of black-box queries. We experimentally confirm the effectiveness of our methods on a range of schemes and a diverse set of open-source models. Further, we validate the feasibility of our tests on real-world APIs. Our findings indicate that current watermarking schemes are more detectable than previously believed.",
    "keywords": [
      "llm",
      "watermarking"
    ],
    "venue": "ICLR",
    "year": 2025,
    "pdf_url": "https://openreview.net/pdf?id=E4LAVLXAHW",
    "forum_url": "https://openreview.net/forum?id=E4LAVLXAHW",
    "reviews": [
      {
        "rating": "8",
        "confidence": "3",
        "summary": "The paper shows that it is possible to detect the presence of most existing watermarks using black-box interaction with the model, without knowing the watermarking key.\nThey also demonstrate that their attack is capable of estimating the parameters used in the watermarking schemes.",
        "strengths": "A huge number of watermarking papers have come out recently.\nMany of them ask whether their watermarks harm generation quality by performing experimental evaluations, but these are inherently limited: There is no way to experimentally guarantee that the watermark will preserve the quality under *every possible* use-case of the model.\nTherefore, perhaps a more useful test of quality is to simply attempt to detect it. If attacks that are specifically designed to detect the watermark still fail to do so, then this can be seen as unusually strong evidence that it is quality-preserving.\n\nThis work shows that existing schemes typically fall short in this respect, demonstrating an important weakness.",
        "weaknesses": "It is not surprising that they were able to easily detect the schemes they attacked. Those schemes are not designed to be undetectable.\nIn the \"Limitations\" section, they justify the choice to only consider these schemes with the claim that the provably-undetectable schemes \"lack experimental validation\" and \"are not yet practical due to slow generation speed.\"\n\nHowever, I believe these claims require justification because:\n- \"Excuse me, sir? Your language model is leaking (information)\" is a practical implementation of an undetectable scheme. The author doesn't report any issues. This seems to already contradict the above claims.\n- As I understand it, the generation speed of these techniques (including the one just mentioned) is _no slower_ than it is for any other scheme. They work essentially identically to other schemes, except that they are careful not to embed bias in cases where it might be noticeable without the key.\n- I think that the reason there are relatively few practical demonstrations of undetectable schemes is just that most people doing experiments don't care about it. If you can get slightly better robustness by dropping undetectability, most experimentalists will go for that. However, since the message of the present paper depends on it _actually being difficult_ to build a practical undetectable scheme, it would be much more compelling if you at least attempt to do so.\n\nHere is a simple undetectable scheme that you could try as a benchmark: Use Aaronson's scheme exactly (implemented in many places, e.g. Piet et al.), except that if a $k$-gram has empirical entropy (as defined in Christ et al.) less than $\\lambda$, then don't use the Gumbel-max trick and instead just sample without bias according to the model. (Crucially, the first $k$ tokens in any response should be sampled exactly according to the model, without any watermark bias.) Note that this scheme is no slower than any other scheme. Detection with the key is also extremely fast.\n\nIt is easy to see that this scheme will require seeing roughly $2^{\\lambda/2}$ tokens before it becomes detectable _without_ the key; and it should be detectable _with_ the key as long as the text has (empirical) entropy at least $\\lambda$ in most sequences of $k$ consecutive tokens.\n- If you find that this scheme only becomes practically undetectable once you set $k$ or $\\lambda$ to be unreasonably large (such that detection with the key significantly suffers), then I would find the message that existing practical schemes much more compelling.\n- If you find that this scheme is in fact practically undetectable for reasonable choices of $k$ and $\\lambda$, then that would arguably be an even more compelling result (although the message would change slightly)."
      },
      {
        "rating": "6",
        "confidence": "4",
        "summary": "This paper proposes a black-box detection method for identifying whether a watermark is embedded in a Large Language Model (LLM). In this paper, the detectability of current watermarking schemes is investigated for the first time in a practical black-box environment. The researchers developed statistical test methods to detect the presence of watermarks and estimate parameters using a limited number of black-box queries for three popular families of watermarking schemes; Red-Green, Fixed-Sampling and Cache-Augmented. Experimental results show that these approaches are effective and cost-efficient across multiple open source models and different settings. The paper also discusses the ethical implications of its work, highlighting the benefits of raising awareness of the ease of detection of watermarking schemes, despite the potential risk of misuse.",
        "strengths": "1. This paper, for the first time, examines the detectability of current watermarking schemes in a practical black-box setting, which is practical in the real detection scenario.\n2. The method is well written and the method makes sense and is easily understood. Each method has a clear section structure. \n3. The experimental results in the black-box scenario verify the effectiveness of the method.",
        "weaknesses": "1. Although the authors pointed out that their motivation is to study the ability of current watermarks to resist detection, they did not highlight the significance of watermark detection in real scenarios. Providing specific application scenarios of black-box watermark detection can help readers better understand the contribution of black-box watermark detection.\n\n2. The results in Table 1 indicate the method in the paper is constrained by the need for distinct detection techniques for various watermarking methods, with poor generalization among them. As more watermarking methods are proposed, this may increase the cost of detecting watermarks.\n\n3. Minor concern: Watermark detection results in Table 2 for production-level language models accessed via API are suboptimal and you can not conclude on the presence of a watermark,  which brings some concerns to readers about real-world detection."
      },
      {
        "rating": "6",
        "confidence": "5",
        "summary": "The authors introduce statistical tests for detecting three main watermark families under blackbox setting, namely, Red-Green, Fixed-Sampling, and Cache-Augmented watermarks. They confirm the effectiveness of their methods in an extensive experimental evaluation across seven schemes and five open-source models, and execute them on three deployed models.",
        "strengths": "This paper suggests that current watermarking schemes may be susceptible to detection in the black-box setting and verify it in their experiments.",
        "weaknesses": "- This paper lacks a clear mathematical presentation of its algorithms, and the descriptions are often vague.\n\n- The detection tasks for Fixed-Sampling and Cache-Augmented watermarks are trivial, and the proposed simple algorithm can be easily defended against.\n  1. The detection algorithm based on unique outputs is not practical. In real-world applications, one can simply skip the first few tokens to ensure that generated outputs are different, which has been proposed in Algorithm 3 in Christ et al, 2024[1].\n  2. The detection algorithm focused on cache is not applicable. It could take too much time for the detection to complete in waiting for the cache to be reset in a global cache. While user cache is usually not applicable due to a potentially large number of users.\n  3. The cache mechanism is only a minor component of these watermarking schemes, and removing it often does not degrade performance, as discussed in Hu et al., 2023[2].\n\n\n- Reporting median p-values over 5 watermarking keys is impractical, as only a single watermarking key is typically used per model in real-world applications.\n\nThe median p-value is not a good metric, as it does not reflect the actual false positive rate. It is also difficult to interpret.\n\n- As shown in Figure 3, there are large deviations from the actual $\\delta$, indicating that the current results may not be suitable for downstream tasks.\n\n[1] Christ, Miranda, Sam Gunn, and Or Zamir. \"Undetectable watermarks for language models.\" The Thirty Seventh Annual Conference on Learning Theory. PMLR, 2024.\n\n[2] Hu, Zhengmian, et al. \"Unbiased watermark for large language models.\" arXiv preprint arXiv:2310.10669 (2023)."
      },
      {
        "rating": "8",
        "confidence": "4",
        "summary": "This paper presents a significant contribution to the field of LLM watermarking. From the authors' claims, they are the first to provide a comprehensive study of black-box watermark detection. Their findings demonstrate the practical detectability of prominent watermarking schemes, challenging previous assumptions about their undetectability. This paper has provided the foundation for future research on more robust watermarking techniques and advanced detection methods.",
        "strengths": "This paper is extremely well-written. Kudos to the authors for taking time to ensure that the paper is concise, clear, and enjoyable enough for anyone to read. The formulations for each statistical test for detectability are clear and well explained. Providing detailed tests for each class of watermarks further strengthened the paper. The results highlight the strength of their approach as watermarks can be detected accurately, more so at a low cost. I also appreciate the fact that they experimented to see if their tests could cross detect other watermarks.",
        "weaknesses": "- The methods, while detailed, appear to focus on a strict reverse engineering approach for detecting each specific class of watermark. Did the authors explore the possibility of a unified approach that could detect all classes of watermarks? What are the authors' thoughts on this?\n\n- The experiments were limited to just three classes of watermarks. I believe this is okay, and future work could expand the scope to include other types, but it is a weakness for this paper.\n\n- The cross-detection tests only applied to watermarks from different classes. However, there were no evaluations on whether the detection is robust to variations in the hyperparameters of the same watermark. Can the detection identify a watermark regardless of the hyperparameters used?\n\n- Additionally, the paper lacks details on the efficiency of the detection tests. For instance, how many tokens are required to reliably detect the presence of watermarks using these methods? Addressing this could further minimize costs."
      }
    ],
    "rating_avg": 7.0,
    "confidence_avg": 4.0,
    "decision": "Accept (Poster)",
    "meta_review": "Summary: This paper studies the problem of detecting LLM watermarks in a black-box way, without even knowing the watermark key. Extensive experiments across three families of LLM watermarks, Red-Green, Fixed-Sampling and Cache-Augmented, verify the effectiveness of the proposed method.\n\nStrengths:\n1. This paper is the first work that detects LLM watermarks in a black-box way. It suggests that current watermarks are susceptible to detection in the black-box setting.\n2. The paper is well-written and the experiments are rich.\n\nWeaknesses:\n1. Reviewers have concerns on the claim that the provably-undetectable schemes \"lack experimental validation\" and \"are not yet practical due to slow generation speed.\"\n2. Reviewers have concerns on the generalizability of the proposed detectors, as they are mostly based on reverse engineering. The experiments were limited to just three classes of watermarks.\n\nAll reviewers consistently vote for acceptance, two of who champion the paper with a score of 8. There is no doubt that the paper is above the acceptance bar of ICLR.",
    "author_remarks": "",
    "decision_comment": ""
  },
  {
    "id": "5VK1UulEbE",
    "title": "FredNormer: Frequency Domain Normalization for Non-stationary Time Series Forecasting",
    "authors": [
      "Xihao Piao",
      "Zheng Chen",
      "Yushun Dong",
      "Yasuko Matsubara",
      "Yasushi Sakurai"
    ],
    "abstract": "Recent normalization-based methods have shown great success in tackling the distribution shift issue, facilitating non-stationary time series forecasting.\nSince these methods operate in the time domain, they may fail to fully capture the dynamic patterns that are more apparent in the frequency domain, leading to suboptimal results.\nThis paper first theoretically analyzes how normalization methods affect frequency components.\nWe prove that the current normalization methods that operate in the time domain uniformly scale non-zero frequencies, and thus, they struggle to determine components that contribute to more robust forecasting.\nTherefore, we propose FredNormer, which observes datasets from a frequency perspective and adaptively up-weights the key frequency components.\nTo this end, FredNormer consists of two components: a statistical metric that normalizes the input samples based on their frequency stability and a learnable weighting layer that adjusts stability and introduces sample-specific variations. Notably, FredNormer is a plug-and-play module, which does not compromise the efficiency compared to existing normalization methods. \nExtensive experiments show that FredNormer improves the averaged MSE of backbone forecasting models by 33.3\\% and 55.3\\% on the ETTm2 dataset.\nCompared to the baseline normalization methods, FredNormer achieves 18 top-1 results and 6 top-2 results out of 28 settings.\nOur code is available at: https://anonymous.4open.science/r/ICLR2025-13956-8F84",
    "keywords": [
      "time series forecasting",
      "deep learning"
    ],
    "venue": "ICLR",
    "year": 2025,
    "pdf_url": "https://openreview.net/pdf?id=5VK1UulEbE",
    "forum_url": "https://openreview.net/forum?id=5VK1UulEbE",
    "reviews": [
      {
        "rating": "3",
        "confidence": "5",
        "summary": "This paper reveals that traditional time-domain normalization methods uniformly scale non-zero frequencies, which limits their ability to effectively handle distribution shifts in time series forecasting. To address this limitation, the authors propose FredNormer, a plug-and-play module that combines statistical frequency stability normalization with learnable sample-specific weighting, enabling better adaptation to key frequency components and more robust forecasting performance.",
        "strengths": "1. this paper studies an interesting problem in time series forecasting, i.e., the distribution shift problem.\n\n2. the paper is understandable and easy to follow.",
        "weaknesses": "1. this paper is not very well-motivated. The paper mentioned that \"Modeling solely in the time domain struggles to distinguish between different frequency components within superimposed time series\" as their first motivation. Does it have any difference with the distribution shift or non-stationary forecasting? Also, it mentioned that \"the z-score normalization applies uniform scaling across all frequency components, which leaves frequency-specific patterns unaltered\". I believe only RevIN uses \"learnable\" z-score normalization but other methods like SIN, SAN, FAN do not use z-score normalization. What they do cannot be equal to z-score normalization. So how can you use z-score to summarize these works?\n\n2. this paper is kind of confusing for the theoretical analysis. Based on the Theorem 1, the authors mentioned that \"the normalization operation keeps the proportion unchanged\". The proportion is unchanged does not mean it cannot normalize the time series. So the theoretical analysis cannot show the existing normalization would fail. Moreover, how can you say your defined stability is correlated with the non-sationarity? Why the frequency components are entangled and thus influence normalization? These parts don't have theoretical analysis I believe.\n\n3. the experiments are somehow lack of comparisons with state-of-the-art normalization techniques, such as SIN [1].\n\n[1] SIN: Selective and Interpretable Normalization for Long-Term Time Series Forecasting. In ICML."
      },
      {
        "rating": "5",
        "confidence": "4",
        "summary": "This paper focuses on the issue of distribution shift in the frequency domain to improve non-stationary time series forecasting. Its primary contribution lies in the theoretical analysis of how normalization methods impact frequency components and in adaptively up-weighting key frequency components. Specifically, the proposed method, FredNormer, includes a statistical metric to normalize input samples and a learnable weighting layer to adjust stability.",
        "strengths": "1. The authors provide a theoretical proof showing that time-domain normalization is not effective for frequency components.\n2. The proposed method is a simple and effective method for learning time-invariant frequency components to suppress non-stationary in the frequency domain.\n3. FredNormer is demonstrated to be effective, achieving state-of-the-art (SOTA) performance in experiments.",
        "weaknesses": "1. FAN is also a method based on adaptive normalization in the frequency domain, capable of handling both trend and seasonal non-stationary patterns in time series data. Compared with it, although this paper provides a theoretical guarantee, its contribution appears insufficient. \n\n[1] Ye W, Deng S, Zou Q, et al. Frequency Adaptive Normalization For Non-stationary Time Series Forecasting[J]. Advances in Neural Information Processing Systems, 2024.\n\n2. In Non-stationary Transformer, the authors argue that removing inherent non-stationarity from time series may reduce the model's ability to forecast real-world bursty events. Could suppressing non-stationary information in FredNormer similarly lead to over-stationarization, limiting its practical applicability? \n\n[1] Liu Y, Wu H, Wang J, et al. Non-stationary transformers: Exploring the stationarity in time series forecasting[J]. Advances in Neural Information Processing Systems, 2022, 35: 9881-9893.\n\n3. In Definition 2, you mention \"M components with higher stability S(k).\" How do you define \"higher\" stability? What is the threshold value used, and how is it selected? \n\n4. The authors only compare against with Transformer-based and MLP-based methods. Why not include comparisons with more CNN-based baselines, such as TSLANet, ModernTCN, and TimesNet, to demonstrate the robustness and generalization of FredNormer?\n\n[1] Eldele E, Ragab M, Chen Z, et al. TSLANet: Rethinking Transformers for Time Series Representation Learning[C]//Forty-first International Conference on Machine Learning, 2024.\n\n[2] Luo D, Wang X. Moderntcn: A modern pure convolution structure for general time series analysis[C]//The Twelfth International Conference on Learning Representations. 2024.\n\n[3] Wu H, Hu T, Liu Y, et al. TimesNet: Temporal 2D-Variation Modeling for General Time Series Analysis[C]//The Eleventh International Conference on Learning Representations, 2023.\n\n5. I am curious about FredNormer’s impact on frequency-domain methods like FiTS and FreTS. Have you tested its performance on these models?\n\nMinor Error:\n1. Section 4.2 mentions running time, but Figure 4 seems to be missing. \n2. In Section 4.2, you refer to a \"fourth-shaped frequency component.\" Could you clarify what you mean by this?\n3. In the notations section, the indicator function I{k=0} is said to equal 1 if k is not equal to 0. \nIn Proof 1, you state that for k≠1,I{k=0}=0. Could you clarify which case is correct?"
      },
      {
        "rating": "3",
        "confidence": "3",
        "summary": "The paper notes that normalization-based methods can only partially address the distribution shift problem in non-stationary time series forecasting, as these methods operate solely in the time domain and may overlook prominent dynamic patterns in the frequency domain. To tackle this, they propose FredNormer, a plug-and-play module that dynamically adjusts the weight of each frequency component based on a proposed measure termed Frequency Stability $\\mathrm{S}$.",
        "strengths": "* The authors define Frequency Stability $\\mathrm{S}$ across the entire dataset based on the discrete Fourier transform coefficients, and they theoretically demonstrate that time-domain normalization can only uniformly scale non-zero frequency components, leaving the proportion of the Stable Frequency Subset $\\mathcal{O}$ within the spectrum unchanged after normalization.\n\n* The authors propose to enhance stable frequency components for better generalization in TS forecasting. They introduce a learnable layer that assigns greater weights to stable frequency elements based on $\\mathrm{S}$.",
        "weaknesses": "* The contribution of the paper seems limited. According to equation (10), the core approach mainly involves applying a linear transformation to frequency components based on the matrix $\\mathrm{S}$. It is unclear how $\\mathrm{S}$ functions as a constraint to realize the key motivation of enhancing the weight of stable frequency components.\n\n* In Definition 2, the authors introduce the concept of a Stable Frequency Subset $\\mathcal{O}$ but do not provide a clear criterion for determining what qualifies as a stable frequency. Some notations, such as Stable Frequency Subset $\\mathcal{O}$, and Theorem 1 presented in Section 2 are not well linked to the design of the method proposed in Section 3.\n\n* The experimental evaluation lacks thoroughness, as it includes only three baseline models (Dlinear, PatchTST, and iTransformer). Although the authors mention other models, such as CrossFormer, they do not include it in their comparisons. Additionally, the Nonstationary Transformer [1] would also be a relevant model for further comparison.\n\n* The empirical analysis in Figure 3 is confusing to the reviewer. Could the authors provide additional clarification on how the adjustments to the amplitudes of the input series and forecasting target, based on the Frequency Stability score, affect model prediction accuracy? Additionally, could you explain why these adjustments are effective in enhancing the model's performance? Both Equations (9) and (10) have large spacing from the preceding text.\n\n[1] Liu, Yong, et al. \"Non-stationary transformers: Exploring the stationarity in time series forecasting.\" Advances in Neural Information Processing Systems 35 (2022): 9881-9893."
      },
      {
        "rating": "5",
        "confidence": "4",
        "summary": "This paper presents FredNormer, a method designed to tackle the distribution shift issue in the frequency domain. It comprises two components: a statistical metric and a learnable weighting layer. Extensive experiments demonstrate that FredNormer enhances forecasting performance.",
        "strengths": "1. This paper is well-written and easy to follow.\n\n2. Extensive experiments have demonstrated that FredNormer enhances the performance of backbone forecasting models, resulting in notable improvements.",
        "weaknesses": "My main concern is regarding the contribution of this work. What are the key differences between FredNormer and the two referenced papers [1][2]?\n\n\n\n[1] Frequency Adaptive Normalization For Non-stationary Time Series Forecasting, in NeurIPS 2024\n\n\n[2] Deep Frequency Derivative Learning for Non-stationary Time Series Forecasting, in IJCAI 2024"
      },
      {
        "rating": "5",
        "confidence": "5",
        "summary": "This research tackles a fundamental challenge in time series forecasting—the non-stationarity of real-world data—by introducing a novel perspective on normalization within the frequency domain. The authors propose a versatile plug-and-play module that analyzes datasets from a frequency standpoint and dynamically enhances the significance of key frequency components. Comprehensive experiments demonstrate that the FredNormer module enhances the average Mean Squared Error (MSE) of various underlying forecasting models.",
        "strengths": "The paper is generally well-structured, with a clear progression from introduction to conclusion. The use of technical language is appropriate for the audience, and the figures and tables are mostly supportive of the text.\n\nThe authors propose FredNormer, a frequency domain normalization method that adaptively up-weights key frequency components based on their stability. The method is model-agnostic and can be integrated into various forecasting models without compromising efficiency. \n\nThis paper tackles an important problem in time series forecasting—the non-stationarity of real-world data. The idea of approaching normalization from the frequency domain is novel and could potentially offer new insights into the field.",
        "weaknesses": "The importance of the questions posed by the paper is not in doubt, but the execution and resulting conclusions may be less reliable due to experimental concerns. The technical claims of the paper are where the most significant concerns lie. The experimental methodology appears to have several flaws, which may compromise the validity of the results. Without a solid experimental foundation, the technical claims, no matter how innovative, cannot be adequately supported. The paper would benefit from a thorough revision of the experimental design and possibly additional experiments to validate the findings.  \n\nThe initial discussion in the article pertains to the equivalence of linear combinations before and after applying the Fast Fourier Transform (FFT). However, this proof fails to address the first-order differences introduced in the practical algorithmic procedure. Specifically, Algorithm 1 computes a quantity $S$ based on the batch mean and variance of frequency domain points derived from the input sequence. Conversely, Algorithm 2 utilizes this $S$ to perform a linear transformation on the frequency domain representation of the first-order differences of the sequence. It is evident that the actual algorithmic workflow does not fully align with the theoretical proof provided.\n\nWhen evaluating the experimental runtime, it is important to note that if the speed is not measured during the stable phase of training, factors such as initial data loading during training runs may obscure the speed reduction effect attributable to the FredNormer plugin.\n\nThe potential contribution of the paper to the field is significant if the method can be validated. However, as it stands, the experimental issues limit the trust that can be placed in the results."
      }
    ],
    "rating_avg": 4.2,
    "confidence_avg": 4.2,
    "decision": "N/A",
    "meta_review": "",
    "author_remarks": "",
    "decision_comment": ""
  },
  {
    "id": "tpHqsyZ3YX",
    "title": "ProAdvPrompter: A Two-Stage Journey to Effective Adversarial Prompting for LLMs",
    "authors": [
      "Hao Di",
      "Tong He",
      "Haishan Ye",
      "Yinghui Huang",
      "Xiangyu Chang",
      "Guang Dai",
      "Ivor Tsang"
    ],
    "abstract": "As large language models (LLMs) are increasingly being integrated into various real-world applications, the identification of their vulnerabilities to jailbreaking attacks becomes an essential component of ensuring the safety and reliability of LLMs. \nPrevious studies have developed LLM assistants, known as the adversarial prompter, to automatically generate suffixes that manipulate target LLMs into generating harmful and undesirable outputs.\nHowever, these approaches often suffer from low performance or generate semantically meaningless prompts, which can be easily identified by perplexity-based defenses.\nIn this paper, we introduce a novel two-stage method, $\\texttt{ProAdvPrompter}$, that significantly improves the performance of adversarial prompters.\nIn $\\texttt{ProAdvPrompter}$, the first stage (Exploration) utilizes the loss information to guide the adversarial prompter in generating suffixes that are more likely to elicit harmful responses.\nThen the second stage (Exploitation) iteratively fine-tunes the prompter using high-quality generated adversarial suffixes to further boost performance.\nAdditionally, we incorporate the prompt template to aid in the Exploration stage and propose a filtering mechanism to accelerate the training process in the Exploitation stage.\nWe evaluate $\\texttt{ProAdvPrompter}$ against the well-aligned LLMs (i.e., Llama2-Chat-7B and Llama3-chat-8B), achieving attack success rates of 99.68% and 97.12% respectively after 10 trials on the AdvBench dataset, thereby enhancing performance by $\\sim 2$ times compared to previous works.\nMoreover, $\\texttt{ProAdvPrompter}$ reduces training time by 20% on Llama3-Instruct-8B, generates more generalized adversarial suffixes, and demonstrates resilience against the perplexity defense.\nAn ablation study further evaluates the effects of key components in $\\texttt{ProAdvPrompter}$ (the prompt template and the filtering mechanism).",
    "keywords": [
      "jailbreaking attacks; large language model"
    ],
    "venue": "ICLR",
    "year": 2025,
    "pdf_url": "https://openreview.net/pdf?id=tpHqsyZ3YX",
    "forum_url": "https://openreview.net/forum?id=tpHqsyZ3YX",
    "reviews": [
      {
        "rating": "5",
        "confidence": "4",
        "summary": "Build upon the previous work[1], proadvprompter propose a two-stage training technique with dataset filter in the second stage to obtain a generation model to produce jailbreak suffixes.",
        "strengths": "The method seems very to be effective, achieving a very high ASR.",
        "weaknesses": "1. The novelty of this work is doubtful, since the first stage Exploration pipeline is exact the same as AdvPrompter, and proposing a two-stage fine tunning workfolw with filter in the second stage seems to be lack of novelty. Moreover, there seems to be no significant technique contribution and methodology difference between two stage, as both are collecting the dataset (intact or filtered) first and then tuning the model. Maybe authors could consider the difference between various fine tune method and investigate their impact on training the jailbreak prompters to give a technique insightful conclusion. For example, is LoRA much more robust to get a better jailbreak prompter than SFT, or something like that. Furthermore, it would be better if the author could explain the intuition why involving a exploitation stage can significantly improve the ASR, and give some ablation studies to show how the proposed exploitation stage contribute to this result. \n2. It seems the ProAdvPrompter setup is different across different target model, which might imply the two-stage pipeline is not robust across different models.\n\nTypos:\nIn line 135, the hyperlink refers to Equation 2, which should be Equation 1 instead.\nThe input of Algorithm 1 contains repetitive discription of \"the initial parameter theta_0\""
      },
      {
        "rating": "3",
        "confidence": "4",
        "summary": "This study proposes ProAdvPrompter, a two-stage approach to enhance adversarial prompting effectiveness. During the Exploration stage, loss feedback directs the prompter to generate suffixes more likely to induce harmful responses. In the Exploitation stage, ProAdvPrompter undergoes iterative fine-tuning with high-quality adversarial suffixes to further improve performance.",
        "strengths": "1. This paper is well-written, with the authors providing a clear and comprehensive presentation of the algorithm process and their perspectives.\n2. The proposed method achieves state-of-the-art ASR performance compared to the selected baseline attacks.\n3. The baselines chosen by the authors are all recent, reflecting a strong selection of relevant comparisons.",
        "weaknesses": "The method proposed in this paper shows a slight lack of innovation.\nIt consists of two stages: in the first, Exploration stage, the authors adopt the search strategy of Paulus et al. (2024) along with beam search. In the second, Exploitation stage, they apply fine-tuning to produce high-quality adversarial suffixes. While the second stage displays more originality than the first, it generally divides into two sub-phases—dataset generation and training—to yield refined adversarial suffixes. Although effective, this approach remains relatively conventional."
      },
      {
        "rating": "6",
        "confidence": "3",
        "summary": "This paper introduces a novel two-stage method, which significantly enhances the performance of adversarial prompters. The Exploration stage uses loss information to guide the prompter in generating harmful suffixes, while the Exploitation stage iteratively fine-tunes the prompter to further improve performance.  The paper also demonstrates reduced training time and resilience against perplexity defense, with an ablation study further evaluating the effects of key components.",
        "strengths": "- The ProAdvPrompter method proposed in the article achieves a very high attack success rate on two well-aligned LLMs. The article validates the performance of the method on two mainstream open-source LLM models, such as llama2-chat and llama3-chat.\n\n- The article analyzed the limitations of existing state-of-the-art methods, and specifically proposed improvement strategies with clear research motivation.\n\n- The method section of the article is very detailed, clearly demonstrating the principles of the proposed method.",
        "weaknesses": "- It seems that the method in this article has not been experimented on closed LLMs (such as transfer-attacking), please refer to the [1]. We all know that in practical applications, black-box models occupy a considerable market share and pose greater security issues. Therefore, can the method proposed in the article also reveal the security issues of black-box models?\n- Although the method has achieved excellent performance, the entire pipeline appears to be quite lengthy, which may pose significant difficulties for replication.\n\n\n\n\n[1] Paulus A, Zharmagambetov A, Guo C, et al. Advprompter: Fast adaptive adversarial prompting for llms[J]. arXiv preprint arXiv:2404.16873, 2024."
      },
      {
        "rating": "6",
        "confidence": "3",
        "summary": "The paper proposes a two-stage method called ProAdvPrompter which uses adversarial prompters (LLM) to generate adversarial suffixes. ProAdvPrompter achieves high attack success rate, with good readability, adaptability and fast speed.",
        "strengths": "1. The experimental results suggest ProAdvPrompter achieves high attack success rate, with a low perplexity.\n2. The exploration and exploitation of ProAdvPrompter is an interesting and effective idea.\n3. The paper is well-written and clearly expressed.",
        "weaknesses": "1. The method needs to fine-tuning the adversarial prompter at each stage. Although once the adversarial prompter has been trained, the attack process is fast. But I still concern the training cost of adversarial prompter at training stage. \n2. The experiment results suggest ProAdvPrompter achieves high ASR. Is the reported ASR tested on safety questions in other domain? I concern the two-stage fine-tuning makes the adversarial prompter overfitted on the trained data"
      }
    ],
    "rating_avg": 5.0,
    "confidence_avg": 3.5,
    "decision": "Accept (Poster)",
    "meta_review": "This paper proposed the ProAdvPrompter to generate adversarial prompts. The strengths of this paper are (1) this method is effective with a very high ASR; (2) this paper is well-written; (3) baselines are all very recent papers;  and (4) idea is interesting. The main concerns of this paper after rebuttal are the novelty of this method.  Compared to AdvPrompter, two reviewers raised similar concerns. However, the reviewers did not provide further comments or a final score. Thus, AC read all of them. After examining all rebuttals and concerns, the AC believes that these issues have been addressed. This method is different from ensemble learning, and the paper effectively addresses the shortcomings of AdvPrompter, as demonstrated by the results. AC feels this paper still has impact to the community and recomend for acceptance.",
    "author_remarks": "",
    "decision_comment": ""
  },
  {
    "id": "LOAfGVdL2G",
    "title": "Commute Your Domains: Trajectory Optimality Criterion for Multi-Domain Learning",
    "authors": [
      "Alexey Rukhovich",
      "Alexander Podolskiy",
      "Irina Piontkovskaya"
    ],
    "abstract": "In multi-domain learning, a single model is trained on diverse data domains to leverage shared knowledge and improve generalization. The order in which the data from these domains is used for training can significantly affect the model's performance on each domain. However, this dependence is under-studied. In this paper, we investigate the influence of training order (or data mixing) in multi-domain learning using the concept of Lie bracket of gradient vector fields. By analyzing the infinitesimal effects of changing the training order, we identify regions in the parameter space where altering the order between two training domains can benefit the target loss. We validate the predictions of our theoretical framework on the influence of training order (or data mixing) both on a toy example and  bilingual LLM pre-training.",
    "keywords": [
      "Multi-domain learning",
      "Lie bracket",
      "Gradient dynamics",
      "Domain interaction"
    ],
    "venue": "ICLR",
    "year": 2025,
    "pdf_url": "https://openreview.net/pdf?id=LOAfGVdL2G",
    "forum_url": "https://openreview.net/forum?id=LOAfGVdL2G",
    "reviews": [
      {
        "rating": "5",
        "confidence": "2",
        "summary": "This paper studies the effect of domain orders in the multi-domain learning problems. With the lens of vector field, it shows that the order of domain influences training dynamics. Furthermore, it proposes scheduling for weights to sample batch of each domain, which can benefit the target loss. Finally, it validates its theory with numerical experiments.",
        "strengths": "Disclaimer: I do not have proper knowledge to evaluate its theoretical analysis. It is hard to judge the significance of the theories the paper has provided.\n\n- Provide theoretical analysis about effect of domain order. \n\n- Propose scheduling for weight to sample domain batches grounded on the theory.\n\n- Validate the theoretical analysis with the numerical experiments.",
        "weaknesses": "- Hard to tell actual benefits of the proposed weight scheduling. Based on Figure 3, the constant domain weight schedule seems to work well. Better to elaborate the practical advantage of the proposed method.\n\n- I think there are many relevant works. The final goal is to learn to minimize the total domain loss without interfering other domains, which is the goal of multi-task learning. It would be better to compare the proposed method against some well-known multi-task learning methods (such as [1,2,3,4]) and show its benefit compared to them.\n\n\n[1] Navon, Aviv, et al. \"Multi-Task Learning as a Bargaining Game.\" International Conference on Machine Learning. PMLR, 2022.\n\n[2] Lee, Seanie, et al. \"Sequential Reptile: Inter-Task Gradient Alignment for Multilingual Learning.\" International Conference on Learning Representations. 2022.\n\n[3] Yu, Tianhe, et al. \"Gradient surgery for multi-task learning.\" Advances in Neural Information Processing Systems 33 (2020): 5824-5836.\n\n[4] Wang, Zirui, et al. \"Gradient Vaccine: Investigating and Improving Multi-task Optimization in Massively Multilingual Models.\" International Conference on Learning Representations. 2021."
      },
      {
        "rating": "5",
        "confidence": "2",
        "summary": "This paper studied how the order of training on different data domains affects model performance in multi-domain setting. The authors develop a theoretical framework based on Lie bracket analysis of gradient vector fields to predict and understand the effects of changing domain training order. They introduce a trajectory optimality criterion that helps determine when to switch between domains during training. The framework is validated through experiments on both a toy quadratic optimization problem and a bilingual language model pre-training task.",
        "strengths": "1. The paper provides a theoretical foundation for analyzing domain ordering effects in multi-domain learning, an important but under-studied problem. \n2. The use of Lie bracket analysis is interesting and novel. Through the analyze of the commutable property of the gradient flow, the authors show the effect of different ordering. \n3. The theoretical framework successfully predicts directional changes in loss values when domain ordering is modified, as demonstrated in both synthetic and real-world experiments. \n4. The authors also provide clear geometric intuitions for their results through visualizations.",
        "weaknesses": "1. While the theoretical framework can predict the effects of changing domain order, it doesn't provide an explicit algorithm for finding optimal domain schedules. \n\n2. the current theory doesn't fully account for the effects of different optimizers (like Adam) or the stochastic nature of training, which are crucial in deep learning. The experiments, while supportive of the theory, show some discrepancies between predicted and actual values, particularly in the LLM pre-training case. \n\n3. The paper's analysis is limited to two-domain scenarios, and it's not clear how well the approach scales to settings with many domains. \n\n4. The practical applicability of the method may be limited by the computational cost of computing since the involving of the Hessian-vector products.\n\n5. Presentation issue. Please use the correct citation command, for example \\citep.\n\n6. What are the key practical message that machine learning practitioner can use from the work?\n\n7. A general question that the author could consider.  How does curriculum learning, where the ordering of training examples is crucial, related to the work?"
      },
      {
        "rating": "3",
        "confidence": "3",
        "summary": "The paper studies the problem of training orders in multi-domain learning. The authors introduce a theoretical framework based on the concept of Lie brackets of gradient vector fields to predict how changes in training order can influence model performance across domains. The theoretical insight is validated empirically through both a toy example and bilingual large language model (LLM) pre-training.",
        "strengths": "1. The theoretical framework is well formulated, and the illustrations are intuitive.\n\n2. The writing is clear and structured.",
        "weaknesses": "1. The authors do not provide a clear explanation about how the studied problem is different from the rich literature of multi-task learning (MTL). In MTL, there exists many methods to balance the training of data from different mixtures, and many of them can be provably applied to reach the desired optimum based on loss combinations. It is unclear how results in the paper are different from those.\n\n2. The utility of the theoretical results is limited. The theoretical part essentially provides a way to predict the performance given weight schedule. However, this does not provide a very accurate prediction due to the stochastic nature of optimization, and the computational cost is non-negligible."
      },
      {
        "rating": "6",
        "confidence": "2",
        "summary": "The paper investigates the effects of training order on model performance in multi-domain learning contexts, where a model learns from diverse data sources. Recognizing that the sequence of domain exposure can significantly impact outcomes, the authors propose a theoretical framework using the Lie bracket of gradient vector fields. This framework identifies areas in parameter space where modifying the training order may improve target loss. The authors demonstrate the theoretical framework's predictions with both a controlled \"toy\" example and a bilingual large language model (LLM) pre-training task, providing insights into optimizing training order for enhanced performance across domains.",
        "strengths": "1. The paper introduces an original theoretical approach to training order optimization in multi-domain learning, leveraging Lie bracket analysis of gradient vector fields.\n\n2. Methodologically robust, the paper validates its theoretical insights through both synthetic and realistic experiments, particularly a bilingual LLM pre-training task.\n\n3. The work is significant for practical and theoretical advancements.",
        "weaknesses": "1. The paper assumes gradient and Hessian computations that may not account for stochasticity and optimizers like Adam, which is commonly used in deep learning and could affect convergence behavior. This might lead to inaccuracies in predicting training outcomes.\n\n2. While the theoretical framework using Lie brackets provides insight into training order in multi-domain learning, it lacks direct, actionable guidance for practitioners. The method suggests a direction for optimizing the training sequence but doesn’t provide a concrete algorithm for determining an optimal sequence."
      },
      {
        "rating": "3",
        "confidence": "4",
        "summary": "The order of adaptation domains used for training is important. The paper considers a scenario where the amount of data is fixed and the examples from different domains can be adjusted. They study the training order using a theoretical framework of a toy example and bilingual LLM pre-training. Overall, there are some limitations to the current version, I would like to raise the score if these limitations can be solved in the feedback.",
        "strengths": "1. The paper investigates an interesting idea that is important for multi-domain learning. \n2. The paper proposes a theoretical framework to analyze the influence of the training order. \n3. The paper is written clearly and well-organized.",
        "weaknesses": "Just as the authors stated in the limitation, there are still some weaknesses:\n\n1. There are no concrete algorithms to solve the problems proposed in the paper. There are only some insights from the paper. \n\n2. The experimental results are not strong enough. I am worried the conclusions can be generalized to LLM models, especially for other multi-domain scenarios."
      }
    ],
    "rating_avg": 4.4,
    "confidence_avg": 2.6,
    "decision": "Reject",
    "meta_review": "**Summary:** This paper investigates the effect of training order in multi-domain learning using Lie brackets of gradient vector fields as a theoretical framework. It identifies how modifying domain order influences training dynamics and suggests potential benefits of adjusting domain mixing weights. The paper presents theoretical insights validated on a toy example and bilingual LLM pre-training. \n\n**Decision:** While this paper proposes a novel theoretical analysis of domain ordering in multi-domain learning, it falls short in several critical areas. Notably, the framework lacks actionable algorithms or practical guidance, limiting its utility for practitioners. In addition, reviewers also raise concerns about empirical results and analysis to validate the scalability and generalization of the results to larger models or more diverse scenarios. Additionally, the computational overhead introduced by Hessian-vector product calculations and the challenges posed by stochastic optimization further diminish its feasibility for real-world applications. The paper also does not sufficiently distinguish itself from existing works in multi-task learning and related fields like gradual domain adaptation, leaving its contribution to the literature unclear. These limitations collectively outweigh the paper's theoretical contributions, leading to the decision to reject. During the reviewer-AC discussion period, no objections were raised to this decision.",
    "author_remarks": "",
    "decision_comment": ""
  },
  {
    "id": "PHkUNcno9n",
    "title": "BALSA: Benchmarking Active Learning Strategies for Autonomous laboratories",
    "authors": [
      "Po-Yen Tung",
      "Yangtao Chen",
      "Peng Bo",
      "Hao Zhang",
      "Wenjie Du",
      "Stefan Bauer",
      "Ye Wei"
    ],
    "abstract": "Accelerating scientific discoveries holds significant potential to address some of the most pressing challenges facing society, from mitigating climate change to combating public health crises, such as the growing antibiotics resistance. The vast and complex nature of design parameter spaces makes identifying promising candidates both time-consuming and resource-intensive, rendering conventional exhaustive searches impractical. However, recent advancements in data-driven methods, particularly within the framework of \"active learning,\" have led to more efficient strategies for scientific discovery. By iteratively identifying and labeling the most informative data points, these methods function in a closed loop, guiding experiments or simulations to accelerate the identification of optimal candidates while reducing the demand for data labeling. Despite these advancements, the lack of standardized benchmarks in this emerging field of autonomous scientific discovery impedes progress and limits its potential translational impact. To address this, we introduce BALSA: a comprehensive benchmark specifically designed for evaluating various search algorithms applied in autonomous laboratories within the active learning framework. BALSA offers a standardized evaluation protocol, provides a metric to characterize high-dimensional objective functions, and includes reference implementations of recent methodologies, with a focus on minimizing the data required to reach optimal results. It provides not only a suite of synthetic functions or controlled simulators but also real-world active learning tasks in biology and materials science — each presenting unique challenges for autonomous laboratory tasks.",
    "keywords": [
      "active learning",
      "experimental design",
      "AI for science"
    ],
    "venue": "ICLR",
    "year": 2025,
    "pdf_url": "https://openreview.net/pdf?id=PHkUNcno9n",
    "forum_url": "https://openreview.net/forum?id=PHkUNcno9n",
    "reviews": [
      {
        "rating": "6",
        "confidence": "3",
        "summary": "This paper introduces a benchmark suite for evaluating active learning strategies in autonomous laboratories. The work includes synthetic benchmark functions, two real-world tasks (protein design and electron microscopy), and introduces a new metric called landscape flatness to characterize objective functions. The authors evaluate 11 baseline methods on synthetic tasks and 4 methods on real-world applications.",
        "strengths": "* The authors provide a broad set of tasks, from synthetic to complex real-world scenarios in biology and materials science. The authors explain clear difference from traditional optimization benchmarks.\n* The authors introduce the landscape flatness metric, which can quantify the complexity of the objective landscape.\n* The authors provide detailed experiments with 11 baseline methods.",
        "weaknesses": "* The authors do not provide enough validation for the proposed landscape flatness metric. It would be better to have theoretical evidence to support the robustness of this metric across different tasks.\n* For experiments, the authors do not explain different numbers of trials (5 trials for synthetic tasks, 3 trials for real-world tasks). Results in Table 1 show high variance across trials, but the authors do not discuss this variation.\n* The authors highlight the scalability as a key contribution, but the paper's analysis of this aspect is limited. For example, there is no quantitative analysis of how computation time scales with dimensionality. And the maximum dimension is 100D.\n* Others:\n    * It is hard to understand the figures (e.g., Fig. 2, 6) due to small size, unclear labeling and limited context.\n    * The introduction contains redundant information about self-driving labs; Minor typo errors and inconsistencies are present in the paper."
      },
      {
        "rating": "5",
        "confidence": "3",
        "summary": "BALSA is a paper introducing new benchmarks for active learning in autonomous labs, both in the context of protein design and materials design. However, I get the feeling that the authors have tried to do too much, and I found the paper to be hard to read and poorly organized, though the ideas are certainly interesting. I think the paper could benefit from significant restructuring, and possibly even first perfecting the benchmark for protein design only, then extending to materials (or vice-versa); in its current state, it feels imperfect for both, and I did not feel that the paper adequately reviewed either existing protein design benchmarks or existing materials design benchmarks, making it hard to understand what is the value added here by BALSA. Datasets and benchmarks is perhaps the hardest track of papers in which to get accepted, as authors have to make things simple yet rigorous (i.e., foolproof) and transparent for other researchers to use, and I do not think BALSA in its current state meets this criteria.",
        "strengths": "* It is a good ambition to try and develop a suite of benchmarks that aim to ensure reproducibility of algorithmic performance across a wide variety of synthetic and real-world tasks.\n* I like the idea of having the six functions as part of the benchmark (Ackley, Rastrigin, Rosenbrock, Griewank, Schwefel, and Michalewicz), but overall I think the benchmark in its current state does not seem general or rigorous enough to qualify for acceptance at ICLR.\n* The plots themselves are very nice.",
        "weaknesses": "* Unfortunately, the anonimized repository does not link to anything, which is a shame because it means the benchmarks introduced here are not reproducible.\n* Not sure if AF2 is the most relevant model for evaluating the protein design tasks, as we are generally trying to push models outside distribution when designing new proteins, which is precisely the scenarios in which AF2 would fail. Furthermore, the materials benchmark proposed herein would only apply to crystalline materials, limiting its applicability.\n* It is not fully clear to me what is the novelty of the benchmarks introduced here, relative to previous benchmarks.\n* The paper could benefit from a more thorough proofreading, including of the formatting which was strange in places throughout the text and distracting. For instance, the way references were inserted in the text made little sense to me and it as hard to understnad what part of the sentence was being referenced."
      },
      {
        "rating": "3",
        "confidence": "5",
        "summary": "This paper aims to provide benchmark problems for active learning algorithms in automatically selecting experimental conditions in a Self-Driving Laboratory (laboratory automation). Laboratory automation is a field gaining attention across various disciplines, and establishing benchmarks for its core methodology, active learning methods, is essential. In this paper, benchmark problems using six artificial functions and two simulators are examined, and experiments are conducted on eleven types of active learning methods.",
        "strengths": "1. Laboratory automation is a field gaining attention and beginning to be explored across various disciplines; however, a lack of suitable benchmark problems makes it challenging to accurately assess the effectiveness of heuristic methods proposed from different fields. Efforts to establish benchmark problems for active learning in laboratory automation are, therefore, very important to address this issue.\n\n2. The no-free lunch theorem implies that no single method excels universally across all optimization problems; methods should be chosen based on the specific type of problem. I fully support this author's view, as well as the approach of classifying and analyzing problem types according to the landscape smoothness of optimization problems.",
        "weaknesses": "1. I do not believe that the problem settings, datasets, and methods discussed in this paper are sufficient for evaluating algorithms for laboratory automation. First, it seems necessary to verify, in some way, whether benchmark functions such as Ackley and Rosenbrock sufficiently cover the class of optimization problems in laboratory automation. Since these benchmark functions were designed to measure the effectiveness of traditional nonlinear optimization algorithms, using them directly may not be appropriate.\n\n2. Since this paper aims to provide benchmark problems, properly evaluating its originality for Top-tier conferences such as ICLR is difficult. However, for example, the metric presented as a novel measure for landscape flatness in Equation (2) is quite naive and not particularly new. A more original perspective tailored specifically to the issues in laboratory automation would strengthen this paper."
      }
    ],
    "rating_avg": 4.666666666666667,
    "confidence_avg": 3.6666666666666665,
    "decision": "N/A",
    "meta_review": "",
    "author_remarks": "",
    "decision_comment": ""
  },
  {
    "id": "glgvpS1dD1",
    "title": "Robust Heterogeneous Treatment Effect Estimation under Covariate Perturbation",
    "authors": [
      "Zhenlei Wang",
      "Haoxuan Li",
      "Haoxiang Wang",
      "Guangyi Chen",
      "Xu Chen",
      "Peng Cui",
      "Kun Zhang"
    ],
    "abstract": "Heterogeneous treatment effect estimation has important applications in fields such as healthcare, economics, and education, attracting increasing attention from both research and the industrial community. However, most existing causal machine learning methods may not perform well in practice due to the lack of robustness of the treatment effect estimation predicted by deep neural networks when an imperceptible perturbation has been added to the covariate. In this paper, we alleviate this problem using the idea of adversarial machine learning. We first show that our loss of interest, the adversarial loss, is partly bounded by the Lipschitz constant of the casual model. Next, we propose a representation learning framework called RHTE which estimates heterogeneous treatment effect under covariate perturbation by controlling the empirical loss, Lipschitz constant, and distance metric simulta neously. Theories are then derived to guarantee the performance and robustness of our estimation. To the best of our knowledge, this is the first work proposing robust representation learning methods under variable perturbation. Extensive experiments on both synthetic examples and standard benchmarks demonstrate the effectiveness and generality of our framework.",
    "keywords": [
      "causal inference",
      "treatment effect estimation",
      "robust estimation"
    ],
    "venue": "ICLR",
    "year": 2025,
    "pdf_url": "https://openreview.net/pdf?id=glgvpS1dD1",
    "forum_url": "https://openreview.net/forum?id=glgvpS1dD1",
    "reviews": [
      {
        "rating": "5",
        "confidence": "2",
        "summary": "The paper introduces the RHTE framework, for estimating heterogeneous treatment effects under covariate perturbations. The main contribution is a novel representation learning approach that enhances the robustness of treatment effect estimations by incorporating adversarial machine learning techniques, with a specific focus on handling covariate perturbations.",
        "strengths": "- The framework is well-supported by theoretical derivations, including generalization bounds for adversarial PEHE loss.\n- Experiments on both synthetic and real-world datasets are conducted, demonstrating the model's robustness and effectiveness.",
        "weaknesses": "- The paper only considers spherical perturbations, which may limit the method's applicability to broader real-world perturbations.\n- The use of adversarial training and Lipschitz regularization may complicate implementation, which could be a barrier for practitioners without expertise in adversarial machine learning."
      },
      {
        "rating": "5",
        "confidence": "3",
        "summary": "The paper presents a robust method for training CATE estimators by introducing an additional regularizer to control the model's Lipschitz continuity. The authors provide theoretical performance results and evaluate their method across several datasets.",
        "strengths": "The paper studies an interesting problem, i.e, the robustness of CATE estimation models to distribution shift. It presents few interesting theoretical results and presents good empirical evaluation.",
        "weaknesses": "My main concern with the paper is its incremental nature. While the results are interesting, they are a direct consequence of prior results in adversarial settings for general learning scenarios. Moreover, the paper lacks motivation on why the adversarial setting is particularly relevant for causal inference—specifically, how it differs from the general learning problem. For instance, can a model be robust to adversarial attacks over the factual distribution but not over its counterfactual distribution?"
      },
      {
        "rating": "3",
        "confidence": "5",
        "summary": "This work addresses the covariate perturbation problem for CATE estimation. Building on the insights that the worst-case PEHE under adversarial perturbation can be effectively controlled through restricting the Lipschitz constant of the potential outcome predictors, this work proposes a representation-learning framework Robust HTE (RHTE). In particular, the authors propose two types of regularizations to control the Lipschitz constant - the Orthonormality Regularization and RKHS Regularization. On top of the theoretical results to justify their framework, the authors also provide empirical studies to corroborate RHTE's efficacy.",
        "strengths": "- Robust CATE is an important problem to investigate. \n- The proposed method is intuitive and reasonable.\n- The experiments appear comprehensive (though with some aspects needing clarification)",
        "weaknesses": "## Technical (Framework) Novelty \n- The proposed framework is simply the well-known balancing framework for CATE [1] with the an additional regularization of the predictor's Lipschitz constant. Personally I think this is not a big problem.  \n- Notably, the two \"proposed\" regularization methods are also well-known results: the techniques of upper bounding the Lipschitz constant with spectral norm are already widely used [2,3]; the RKHS result is a standard result in kernel-based learning. \n\n## Theoretical Novelty\n- It is more than intuitive that controlling the Lipschitz constant of the predictor can help control the adversarial loss because it represents the maximum change of prediction one adversarial perturbation can cause. However, note that by controlling the Lipchitz constant of the predictor, you are also making an **implicit assumption** that the true potential outcome function has a Lipchitz constant **on the same scale**. **In other words, the EPHE can be arbitrarily bad if you are controlling the Lipschitz constant of your predictor yet the true potential outcome function has large-enough Lipchitz constant**. Please ruminate Theorem 2 and you should see this implicit assumption. This needs to be discussed.\n- Lemma 1 is a fairly obvious result. But **I believe it is fine since it only serves to motivate your framework**.\n- The theoretical results (Theorem 1 and 2) appear **disconnected and unnecessary** to the framework. See more details below. \n- Theorem 1 is just an empirical process result based on the covering number argument to upper bound the true factual (adversary) loss with the empirical one and a finite-sample gap. And, to the best of my knowledge, leaving theoretical results with raw covering number **does not convey any insights** because we usually continue to give instance-specific upper bounds for the covering number. The fact that the empirical process on compact space (i.e., with bounded covering number) has \\sqrt{1/n} concentration is standard in the community. \n- To continue on the last comment, the remark after Theorem 1 that \"Theorem 1 ... rationalizes the control on Lipschitz constant\" has nothing to do Theorem 1. **You can already reach this conclusion with Lemma 1**. The finite-sample concentration result in Theorem 1 has nothing to do with it.  \n- Theorem 2 is a simple (if not entirely trivial) extension of the results in [1]. **I don't think it justifies to be an original theorem in the main text.** Just writing it in plain language and referring [1] should be enough. Please consider editing it.  \n\n\n[1] Uri Shalit, Fredrik D Johansson, and David Sontag. Estimating individual treatment effect: general-\nization bounds and algorithms. In International Conference on Machine Learning, pp. 3076–3085.\nPMLR, 2017.\n[2] https://towardsdatascience.com/lipschitz-continuity-and-spectral-normalization-b03b36066b0d\n[3] K. Kurach, M. Lucic, X. Zhai, M. Michalski, and S. Gelly. A Large-Scale Study on Regularization and Normalization in GANs (2019), ICML 2019."
      },
      {
        "rating": "5",
        "confidence": "3",
        "summary": "The methodology outlined in the paper focuses on addressing covariate perturbation—essentially measurement errors in covariates—in Conditional Average Treatment Effect (CATE) estimation. The approach involves using adversarial learning techniques to enhance the robustness of treatment effect estimations under such perturbations. Theoretical guarantees are provided in terms of PEHE (Precision in Estimation of Heterogeneous Effect) loss, ensuring that these methods perform reliably even when the covariate observations are perturbed. They evaluate the effectiveness of their proposed CATE estimation methods using two standard benchmark datasets—ACIC and IHDP—and two synthetic datasets, UTK-sim and TC-sim.",
        "strengths": "- The paper introduces novel regularizations—Orthonormality Regularization and RKHS Regularization—to control the Lipschitz constant of the causal prediction model. \n- Their theoretical framework provides generalization bounds showing that the model's error on adversarial samples can be controlled.",
        "weaknesses": "- The paper does not sufficiently discuss the practical relevance of adversarial perturbations in treatment effect estimation. It's unclear if real-world scenarios would commonly present such adversarial challenges, which raises questions about the relevance of the proposed approach.\n- The specific choice of uniform noise for the perturbations  in the experiments  may be tailored to showcase the strengths of the proposed method. Unfortunately, the paper is lacking ablations for different noise types. \n-  While the authors provide details about the hyperparameters used, these settings are fixed throughout all experiments, and no hyperparameter search is conducted. This lack of finetuning could limit the reproducibility of the findings, as the performance of the baselines  might vary with different hyperparameter configurations."
      }
    ],
    "rating_avg": 4.5,
    "confidence_avg": 3.25,
    "decision": "Reject",
    "meta_review": "This paper is at the intersection of causal inference and adversarial robustness and develops a robust representation learning algorithm by applying adversarial learning.  The main concern was the incremental nature of the paper because it felt like a directly from prior results from adversarial training and existing results from RKHS. There were also questions on the types of perturbations to be used.",
    "author_remarks": "",
    "decision_comment": ""
  },
  {
    "id": "ArJikvI6xo",
    "title": "GFLAgent: Green Federated Learning Agent for Alleviating Heterogeneity",
    "authors": [
      "Hefeng Zhou",
      "Yuanbin WANG",
      "Kailai Li",
      "Jiong Lou",
      "Jie LI"
    ],
    "abstract": "Federated Learning (FL), as a privacy-preserving distributed machine learning paradigm, faces significant challenges in terms of data and device heterogeneity in practical applications. In this paper, we present a novel Large Language Model Agent decision system, called Green Federated Learning Agent (GFLAgent), for alleviating the challenges arising from data and device heterogeneity within the FL tasks. GFLAgent is efficient and energy friendly, and meets the requirements of green computing. GFLAgent dynamically monitors the status of each client, selects and reasonably allocates them to different layers to achieve efficient asynchronous training, and responds to unexpected situations during training. Furthermore, to optimize overall system expenditure, we implement a strategy that minimizes local training overhead and the updates  costs for clients with historically subpar performance. The experimental results show that GFLAgent outperforms SOTA methods and can be quickly ported to other distributed machine learning frameworks to improve efficiency.",
    "keywords": [
      "green computing",
      "federated learning",
      "statistical heterogeneity",
      "LLM agent"
    ],
    "venue": "ICLR",
    "year": 2025,
    "pdf_url": "https://openreview.net/pdf?id=ArJikvI6xo",
    "forum_url": "https://openreview.net/forum?id=ArJikvI6xo",
    "reviews": [
      {
        "rating": "3",
        "confidence": "4",
        "summary": "This paper proposes three strategies to enhance federated learning (FL) performance in the presence of client heterogeneity (both statistical and system heterogeneity). The strategies include:  introducing penalty weights for client updates, employing a buffering strategy to address client outliers, and utilizing large language models (LLMs) for client selection/task scheduling decisions. While the objective of improving FL performance in heterogeneous environments is relevant, it is not a novel topic.",
        "strengths": "The combination of multiple techniques to improve FL performance in heterogeneous settings.",
        "weaknesses": "There are many weaknesses: \nThe first two strategies presented are not new, as similar mechanisms have been explored in existing literature, beyond just the FedAT reference cited. A more comprehensive review of prior work is needed for readers to understand the essential differences between these two strategies and existing approaches.\n\nThe proposed techniques rely heavily on established methods, but the paper lacks sufficient clarity in explaining the parameters of and the rationale behind the formulas used. The content should be self-explanatory.\n\nWhile the paper discusses the use of LLMs for task scheduling and client selection, it does not adequately explain how LLMs arrive at their decisions in this specific context of FL training. Only general background information about LLM is provided."
      },
      {
        "rating": "5",
        "confidence": "3",
        "summary": "This paper introduces GFLAgent, which uses an LLM-based agent on the FL-server side to schedule the federated learning process to tackle the general data and computation heterogeneity concerns. The authors provide experiments on heterogeneously partitioned datasets to compare GFLAgent with popular FL strategies to shows its advantages in trained model performance and efficiency.",
        "strengths": "Using LLM-based scheduler sounds like an interesting idea for orchestrating the FL process, compared with traditional rule-based scheduling, as it can provide an explanation for the schedule decisions at the same time.",
        "weaknesses": "Though this paper presents a great and interesting idea to use LLM-based agent to schedule the FL process, the paper's related work, problem statement, and experiment details have space to improve, specficically:\n\n(1) The introduction section (Section 1) mentions tier-based asynchronous FL algorithms such as TiFL requires human-designed tiers, however, the authors should also mentions its advantages compared with the following recent work in ICLR 2024 which generates tiers automatically based on history computation time.\n\nLi, Zilinghan, Pranshu Chaturvedi, Shilan He, Han Chen, Gagandeep Singh, Volodymyr Kindratenko, Eliu A. Huerta, Kibaek Kim, and Ravi Madduri. \"FedCompass: Efficient Cross-Silo Federated Learning on Heterogeneous Client Devices Using a Computing Power-Aware Scheduler.\" In *The Twelfth International Conference on Learning Representations*.\n\n(2) The related work section (Section 2) talk about asynchronous federated learning, and the paper should cite the following two popular asynchronous algorithms.\n\nXie, Cong, Sanmi Koyejo, and Indranil Gupta. \"Asynchronous federated optimization.\" *arXiv preprint arXiv:1903.03934* (2019).\n\nNguyen, John, Kshitiz Malik, Hongyuan Zhan, Ashkan Yousefpour, Mike Rabbat, Mani Malek, and Dzmitry Huba. \"Federated learning with buffered asynchronous aggregation.\" In *International Conference on Artificial Intelligence and Statistics*, pp. 3581-3607. PMLR, 2022.\n\n(3) The problem statement section (Section 3) should be made more clear, for example: \n\n- There is no definition for F in equation 1\n- It is unclear why equation 1 is min_{w,i} instead of min_{w}\n- For equation 2, it is unclear why it is min_{i} but i is not in the euqation\n\n(4) Figure 1 is supposed to be the main description of the GFLAgent algorithm, but it is never referred in the main text, same for Figure 2.\n\n(5) From lines 205 to 207, the authors wrote: \"Efforts to offload non-sensitive computational tasks from slower clients to cloud servers, as seen in prior research, were attempts to\nnavigate these challenges within the federated learning paradigm.\" I wonder if there is any reference to support this statement.\n\n(6) The Experiment section should be improved the clarity, for example:\n\n- In line 464, the author mentions \"As shown in Table 3…\" - I wonder how Table 3 contributes to the following statements about data heterogeneity.\n- In line 489, the author mentions \"Details are shown in the right part of Table 3\" - I think it is supposed to be Table 2.\n- It is still confusing to me what [10, 0, 10, 0] means.\n- As the LLM-based agent is considered the most important key part of this paper, it is important to clearly state what LLM is used for the algorithm in the main paper, instead of the Appendix.\n\n(7) There are few minor problems as well:\n\n- line 150 contains some strange characters\n- In line 561, the citation to Deep Learning, Yoshua Bengio appears twice.\n- The subtitles for Appendix B are all together, which makes it very hard to read."
      },
      {
        "rating": "3",
        "confidence": "4",
        "summary": "This paper proposes GFLAgent, an LLM-based agent to adjust the server’s decision automatically with less parameter engineering. GFLAgent uses a carefully designed method to evaluate the actual contribution of clients to overall performance, selects some clients to participate in training, improves task efficiency, and reduces energy costs. Additionally, GFLAgent builds a buffer zone to involve abnormal clients during training, storing their updates while uploading selectively.",
        "strengths": "1.\tCompared with elaborate strategy of clients allocation in different tiers and model weight, LLM-based agent attains better performance.\n2.\tBoth the data and device heterogeneity are considered in this paper.",
        "weaknesses": "1.\tResearch motivation could be improved. It’s not clear how “unexpected disconnection” affects the performance of FL. The authors should provide more details about the “unexpected disconnection” problem.\n2.\tThe description about workflow of GFLAgent (in Section 4) is hard to understand. It would be better to present the GFLAgent in a more clear and detailed manner. Also, in line 252, the “Fig.3” seems to be a misquote as it does not contain details of GFLAgent workflow.\n3.\tIn FL environments that do not include abnormal clients (which is common in the real world), does GFLAgent adversely affect FL performance?\n4.\tThe baselines used in the experiment is not representative enough of the SOTA approach. It may be better to include more fresh and relevant work in the comparison experiments."
      },
      {
        "rating": "3",
        "confidence": "3",
        "summary": "- This study introduces GFLAgent for considering heterogeneity in federated learning, with a focus on green computing\n- The unique aspect, I believe, is the use of LLMAgent for device selection (tiering) in federated learning",
        "strengths": "- The consideration of green computing, including resource efficiency, electricity, and carbon dioxide reduction, is important\n- The paper effectively illustrates its design components",
        "weaknesses": "- Aside from the use of the LLM-based agent, some other ideas have appeared in recent studies (e.g., high-level buffer concept in EcoFed). Can you clarify the unique contribution of this study?\n- Although the title mentions “green” computing, the main design focuses on data and resource heterogeneity, similar to other studies. The primary aim and purpose of the study are somewhat unclear.\n- The novel aspect of this work seems to be the LLM-based agent. However, the explanation of it in the main content is brief.\n- The explanation of the evaluation is confusing. Some references are incorrect, and the interpretation of the results is incomplete. For instance, in Section 5.3.2, I cannot determine which values support the statements. If this refers to the right side of Table 2, why is data heterogeneity evaluated by accuracy, but device heterogeneity by time?\n- There is no evaluation of the green computing aspect in the main although the paper title includes it"
      },
      {
        "rating": "3",
        "confidence": "5",
        "summary": "Comment 1:\nIn Section 4, the paper introduces a buffer system to handle outlier clients, but how exactly does the system determine when a client should be classified as an outlier? More details on this process, including criteria for moving clients in and out of the buffer, would be helpful to avoid any negative impact on the overall system performance.\n\nComment 2:\nThe paper talks about using weights to correct bias in the tiered updates. What specific factors are taken into account when calculating these weights, particularly in situations where clients have very different data sizes or capabilities? \n\nComment 3:\nIn Section 4.3, the method for selecting clients based on historical performance is introduced, but how does the agent prioritize certain clients over others? Does the agent use specific metrics or rules to determine which clients are most valuable for future rounds of training? \n\nComment 4:\nIn Section 5, the results on statistical heterogeneity could be expanded. Would it be possible to provide more detailed comparisons across datasets to give a clearer picture of how the system handles different non-IID data conditions? \n\nComment 5:\nIn Section 5, how does device heterogeneity, particularly when clients have varying levels of computational power, affect the overall accuracy and communication efficiency? Considering this is a common issue in practical federated learning deployments.\n\nComment 6:\nDoes the buffer mechanism account for long-term client downtimes, and if so, how does it ensure that these clients do not negatively impact the model’s convergence and accuracy? \n\nComment 7:\nThe energy efficiency improvement claim is interesting but lacks depth. Could the paper provide more specific evidence on how GFLAgent reduces energy consumption compared to other models, especially across different hardware setups?",
        "strengths": "1. The paper introduces a creative use of Large Language Models (LLMs) to automatically select clients in federated learning, making the process more efficient by reducing manual work. This approach helps optimize training without needing constant adjustment by engineers.\n\n2. The use of a buffer to manage slow or problematic clients is a strong point. It helps ensure that clients with issues don’t slow down the whole process, improving the reliability of the system.\n\n3. The paper presents a variety of experiments using different datasets, showing that the method works well even when the data is distributed unevenly across clients.",
        "weaknesses": "1. While the LLM-based client selection method is a good idea, the paper doesn’t explain enough about how the system decides which clients to choose. \n\n2. The paper mentions a buffer system for handling outliers but doesn’t give enough detail about how clients are moved into or out of the buffer. \n\n3. While the paper talks about device heterogeneity, it doesn’t provide enough details on how different devices with varying computational power affect the system’s performance."
      }
    ],
    "rating_avg": 3.4,
    "confidence_avg": 3.8,
    "decision": "Reject",
    "meta_review": "Reviewers agree on the fact that the paper does not pass the bar for acceptance, and have provided comments that will surely be beneficial to the authors in revising their draft. A short discussion with two reviewers did happen (and short comments from the authors to a third).",
    "author_remarks": "",
    "decision_comment": ""
  },
  {
    "id": "kVrwHLAb20",
    "title": "Ward: Provable RAG Dataset Inference via LLM Watermarks",
    "authors": [
      "Nikola Jovanović",
      "Robin Staab",
      "Maximilian Baader",
      "Martin Vechev"
    ],
    "abstract": "RAG enables LLMs to easily incorporate external data, raising concerns for data owners regarding unauthorized usage of their content. The challenge of detecting such unauthorized usage remains underexplored, with datasets and methods from adjacent fields being ill-suited for its study. We take several steps to bridge this gap. First, we formalize this problem as (black-box) RAG Dataset Inference (RAG-DI). We then introduce a novel dataset designed for realistic benchmarking of RAG-DI methods, alongside a set of baselines. Finally, we propose Ward, a method for RAG-DI based on LLM watermarks that equips data owners with rigorous statistical guarantees regarding their dataset's misuse in RAG corpora. Ward consistently outperforms all baselines, achieving higher accuracy, superior query efficiency and robustness. Our work provides a foundation for future studies of RAG-DI and highlights LLM watermarks as a promising approach to this problem.",
    "keywords": [
      "llm",
      "watermarks",
      "dataset inference",
      "rag"
    ],
    "venue": "ICLR",
    "year": 2025,
    "pdf_url": "https://openreview.net/pdf?id=kVrwHLAb20",
    "forum_url": "https://openreview.net/forum?id=kVrwHLAb20",
    "reviews": [
      {
        "rating": "8",
        "confidence": "3",
        "summary": "This paper studies the problem of RAG Dataset Inference (RAG-DI), where a data owner aims to detect whether their dataset is included in a RAG corpus via black-box queries. The key difference from the RAG MIAs setup is that the data owner makes a dataset-level decision, instead of a document-level decision as in MIAs.\nThe authors first introduce a dataset FARAD for the RAG-DI problem, as they believe the previous datasets used in MIAs problems (EnronEmails, HealthcareMagic) are likely contaminated in the training datasets of existing LLMs and lack fact redundancy. The FARAD dataset builds on a recent source of articles with fictional entities and events, and they prompt a set of LLMs (author LLMs) to rewrite articles based on the key points from the source article.\n\nThe paper then adapts existing RAG MIAs baselines to this problem and proposes a simple baseline called FACTS that simply prompts an LLM to generate a single question that is only answerable by the document. They find that the FACTS baseline performs well in their easy setting (without fact redundancy) but not in their hard setting (with fact redundancy).\n\nFinally, they propose a new dataset inference method based on LLM watermarking called Ward. The key idea is to paraphrase the articles with a watermarked model from the recent LLM watermarking literature. They show that Ward works well in their hard setting and also meets the desiderata including monotonicity, guarantees, and robustness.",
        "strengths": "* I believe the paper studies an important and timely research question that has been overlooked in the literature. I am not a domain expert (in the sense of MIA and RAG privacy), so I may not know related work very well.\n* I think the paper has made many meaningful contributions, from formulating the problem to collecting the dataset and adapting RAG-MIA baselines, to finally proposing their own approach based on LLM watermarking. The experiments (different LLMs and evaluation settings)  and analyses (hyperparameters, modeling retrieval, and examining the quality of paraphrased texts) are quite thorough too.\n* Using LLM watermarking as an approach to solve dataset inference seems a novel and reasonable approach to me. \n* The paper is very well written and self-contained. It is easy to follow the structure of the paper and understand its contributions clearly. I have learned a lot from reading the paper.",
        "weaknesses": "The major part I am not very sure about is whether the dataset construction and experimental settings can really reflect realistic RAG settings in real-world deployment, since the effectiveness of the baselines and proposed approach all depends on this setting. In particular:\n* It assumes perfect retrieval (= only articles from the same source are used) in most experiments. Although the paper discusses a more practical retrieval setting in Section 5.3, I don't see any discussion of previous baselines. For the hard setting, the imperfect retrieval problem should be easier than the perfect retrieval settings (the distracting documents should be less relevant), so the baselines could probably perform better.\n* I am not entirely sure whether the current data generation pipeline can well reflect the redundancy problem in the real world, given that they are all generated from different LLMs (I am also not sure how much impact \"additional facts\" and \"a set of diverse LLMs\" have here). It might be too much to ask, but I think having a realistic multi-document summarization setting would be more realistic.\n* I have difficulty understanding the rationale behind the defense prompt. Why would RAG providers want to instruct the models to not answer questions from retrieved documents? How can RAG be effective in this case? If this is from the data owner's perspective, given the goal is to detect whether the dataset is used or not, I don't see why they would want to add such a prompt to make the detection task harder.\n* [Question] The RAG uses k = 3 shots, but the Easy setting assumes there is only one article per group. Where do the 3 shots come from? The paper also mentions they ablate the choice of k, where k can be {3, 4, 5} in the Appendix. Even for the Hard setting, aren't there only 4 articles per group? Not sure if I misunderstood this.\n\nI still think it is a good paper regardless, and I hope to get some clarifications on these questions. There is a chance that I just misunderstood some key parts of the paper.\n\n[Minor] It is not necessarily a weakness, but the paper's title is \"Ward:... Watermarks\" while the paper really contains much more than that, including setting up the problem, establishing the dataset and baselines. It would probably be more appropriate to have a broader title around RAG Dataset Inference."
      },
      {
        "rating": "6",
        "confidence": "4",
        "summary": "This paper presents WARD, a novel method for detecting unauthorized dataset usage in Retrieval-Augmented Generation (RAG) systems. The approach formalizes RAG Dataset Inference (RAG-DI) as a problem where data owners seek to identify if their data is being used without permission in RAG systems via black-box queries. The authors introduce a new dataset, FARAD, specifically designed to benchmark RAG-DI under realistic conditions that include fact redundancy. Using LLM watermarks, WARD offers data owners statistical guarantees of usage detection. Experimental results show that WARD outperforms other baselines, demonstrating high accuracy, query efficiency, and robustness across challenging scenarios.",
        "strengths": "The strengths of this paper are mainly centered around the propose of the new task along with a new specialized benchmark dataset.\n\n1. Novel Problem Definition and Formalization: The paper identifies and formalizes the novel problem of RAG Dataset Inference (RAG-DI), addressing a critical need for data owners to detect unauthorized data usage in RAG systems. This formalization fills a significant research gap and sets the stage for further exploration of secure data usage in RAG contexts.\n\n2. Introduction of a Specialized Benchmark Dataset: By creating FARAD, the authors contribute a valuable dataset that is specifically tailored for RAG-DI research. FARAD’s design ensures realistic conditions for testing, including the incorporation of fact redundancy, making it highly relevant for practical evaluations of RAG-DI approaches.\n\n3. Comprehensive Experimental Validation: The paper’s extensive experiments demonstrate the effectiveness of WARD in achieving high true positive rates with no false positives across various settings, underscoring the method's robustness and accuracy. This comprehensive validation strengthens the credibility of WARD as a reliable solution for detecting unauthorized data use in RAG systems.",
        "weaknesses": "Although this paper has the above strengths that are interesting, I also noticed several weaknesses that should be further considered.\n\n1. Application Scenario. The authors propose a novel problem definition, namely RAG Dataset Inference (RAG-DI). The concept is quite straightforward, and one has to admit that the concern indeed exists in practice. However, it is still less discussed in this paper, that how often this type of problem can occur in realistic scenarios. I am concerned with the application range of this work. For example, if a person is concerned with their own data being used for LLMs, do they need to test all LLMs in the market? This could be prohibitive. \n\n2. Lack of Computation Complexity. The authors proposed a novel method to deal with the specific problem of RAG-DI. However, the complexity is not fully discussed in the paper. As a result, the problem of scalability could be severe. For example, the owner has an excessively large dataset, will the method still work?\n\n3. Countermeasures: Although the authors considered the scenario where the RAG provider attempts to prevent the unintended use of the system, they do not provide a detailed discussion of the possible countermeasures that the RAG provide may use to counteract the watermarking of data. As there are multiple existing techniques against watermarking, the discussion about vulnerability of the proposed framework when faced with these countermeasures could be inspiring"
      },
      {
        "rating": "6",
        "confidence": "3",
        "summary": "This paper focuses on the problem of unauthorized use of datasets in Retrieval-Augmented Generation (RAG) systems and formalizes it as the RAG Dataset Inference (RAG - DI) problem. To address this issue, the authors propose the FARAD dataset specifically designed for RAG - DI evaluation and a series of baseline methods. They also introduce the WARD method based on LLM watermarks. Experiments demonstrate that WARD outperforms the baseline methods in terms of accuracy, query efficiency, and robustness.",
        "strengths": "1. The RAG - DI problem is formally defined, filling the research gap in this field and laying a foundation for subsequent research.\n2.The design of the FARAD dataset takes into account the practical application scenarios of the RAG system and avoids the shortcomings of existing datasets in RAG - DI research, such as the possibility of being used for LLM training and the lack of fact redundancy.\n3.The WARD method is based on LLM watermarks and can provide data owners with strict statistical guarantees regarding the use of their datasets in the RAG system. It exhibits excellent performance in various experimental settings and outperforms all baseline methods.",
        "weaknesses": "1. In real-world applications, RAG systems may face more complex situations, such as multilingual environments and data from different domains. The discussion in this regard in the paper is relatively limited.\n2. There is a lack of discussion on the efficiency of the solution."
      },
      {
        "rating": "6",
        "confidence": "3",
        "summary": "This paper tackles the issue of unauthorized data use in RAG systems. Noting the current absence of tools for detecting such misuse, the authors propose \"RAG Dataset Inference\" (RAG-DI), a framework that empowers data owners to identify unauthorized data utilization in RAG systems. To facilitate research on RAG-DI, they developed FARAD, a synthetic dataset generated by leveraging an existing dataset and LLMs. FARAD is crafted to simulate challenging scenarios where similar content may appear across multiple sources, enhancing its applicability in real-world settings.\n\nFurthermore, the authors introduce WARD, a novel method that leverages an existing watermarking algorithm to enable data owners to statistically verify whether their data has been incorporated into an RAG system's corpus through black-box queries. Experimental results demonstrate that WARD consistently outperforms existing methods, providing remarkable accuracy, robustness, and efficiency. This approach offers a reliable mechanism for detecting unauthorized data use and establishes essential resources and methodologies to guide future research on data privacy in RAG systems.",
        "strengths": "1. Although RAG has gained popularity, its implications for data privacy and unauthorized usage detection remain largely unexamined. This paper introduces the RAG Dataset Inference (RAG-DI) concept alongside a watermark-based detection approach, offering a novel perspective on privacy within RAG frameworks. By developing the FARAD dataset and the watermark-based WARD method, this work establishes a strong foundation for future research. It stands as a pioneering contribution to addressing privacy concerns in RAG systems.\n\n2. The paper offers comprehensive experimentation and empirical evaluation to validate WARD. The paper demonstrates WARD's outstanding performance across challenging scenarios by benchmarking WARD against multiple baselines, including adaptations from related fields.\n\n3. The paper is well-written and organized, with a clear structure that enhances readability. The authors present their work logically, making the flow of ideas easy to follow in each section.",
        "weaknesses": "1. The authors claim their approach is effective in the challenging scenario where information is distributed across multiple sources. However, it remains unclear how the method performs when only one retrieved document is watermarked while others are unprotected. Additionally, they evaluate the method only with k=3; it is uncertain how effective it would be if the system retrieves more, say 10 relevant documents, with only one being protected. Without this analysis, the effectiveness of the proposed approach cannot be conclusively assessed, especially given that RAG systems can flexibly retrieve a variable number of relevant documents. Moreover, the \"provable watermark\" claim lacks empirical support; no rigorous evidence is provided to substantiate this assertion. While “provable” may reference the watermarking algorithm itself, scalability should also be addressed within this definition to strengthen the claim.\n\n2. The authors claim their approach is provable; however, unlike existing watermarking algorithms, they do not provide a rigorous proof. This discrepancy undermines the study’s credibility.\n\n3. The authors propose a relatively simple defense strategy that relies solely on prompt engineering. However, due to the complex requirements of the proposed defense, LLMs may struggle to adhere to instructions precisely, resulting in a suboptimal defense. A more practical and effective approach could involve monitoring the words used in the retrieved documents and limiting or penalizing the frequency of these words in generated responses. Additionally, after the response is generated, it could be further paraphrased to potentially reduce the usage of watermarking words, similar to techniques employed in existing watermarking approaches. Again, the issue is rooted in the absence of a theoretical guarantee."
      }
    ],
    "rating_avg": 6.5,
    "confidence_avg": 3.25,
    "decision": "Accept (Poster)",
    "meta_review": "The paper studies the problem of unauthorized use of datastores in RAG frameworks. The paper makes the following contributions: (a) a dataset FARAD for the RAG-DI problem, (b) a method WARD that uses llm watermarking to identify dataset usage. This is a valuable contribution that formalizes a novel problem in this space, and provides a good benchmark for future work to build on.",
    "author_remarks": "",
    "decision_comment": ""
  },
  {
    "id": "NH47cNdgNz",
    "title": "From Imitation to Introspection: Probing Self-Consciousness in Language Models",
    "authors": [
      "Sirui Chen",
      "Shu Yu",
      "Shengjie Zhao",
      "Chaochao Lu"
    ],
    "abstract": "Self-consciousness, the introspection of one's existence and thoughts, represents a high-level cognitive process. As language models advance at an unprecedented pace, a critical question arises: Are these models becoming self-conscious?\nDrawing upon insights from psychological and neural science, this work presents a practical definition of self-consciousness for language models and refines ten core concepts. Our work pioneers an investigation into self-consciousness in language models by, for the first time, leveraging causal structural games to establish the functional definitions of the ten core concepts. \nBased on our definitions, we conduct a comprehensive four-stage experiment: quantification (evaluation of ten leading models), representation (visualization of self-consciousness within the models), manipulation (modification of the models' representation), and acquisition (fine-tuning the models on core concepts). \nOur findings indicate that although models are in the early stages of developing self-consciousness, there is a discernible representation of certain concepts within their internal mechanisms. However, these representations of self-consciousness are hard to manipulate positively at the current stage, yet they can be acquired through targeted fine-tuning.",
    "keywords": [
      "self-consciousness",
      "evaluation",
      "probing",
      "large language model",
      "causality"
    ],
    "venue": "ICLR",
    "year": 2025,
    "pdf_url": "https://openreview.net/pdf?id=NH47cNdgNz",
    "forum_url": "https://openreview.net/forum?id=NH47cNdgNz",
    "reviews": [
      {
        "rating": "8",
        "confidence": "4",
        "summary": "The authors present formal definitions of ten qualities which they argue would be exhibited by models with self-consciousness. Next, they form a benchmark for each quality curated from existing LLM benchmark datasets. They perform a series of 4 experiments on (up to) ten different LLMs to assess their self consciousness, and capacity for improvement. These include all 10 models' performance on each dataset, a linear probe of 4 models' internal activations to determine where self conscious qualities occur, a perturbation experiment on 3 models' activations to determine sensitivity to manipulation, and a fine-tuning experiment with 1 model.",
        "strengths": "The benchmark test in this paper, backed by a formal foundation, provides a fine-grained and grounded view into what might otherwise be a nebulous, abstract concept. The authors include results from four separate experiments which build upon each other, moving above and beyond the initial question of whether models possess capabilities into how those capabilities might be improved. The comparative analysis of multiple LLM models using the different datasets and experiments is rich and informative. The authors summarize their findings well, with convenient bold sentences for a quick overview.",
        "weaknesses": "The methods section is brief. A large amount of relevant information for understanding this paper's results is sequestered in the appendix, as this paper struggles to fit its content into the 10 page limit. Probably due to that section's brevity, the motivations driving the specifics of the linear probing and perturbation experiments are not clear. \n\nIn formalizing different qualities of self-consciousness, this paper makes a large number of stated and implicit assumptions. For example, it explicitly assumes that agents are rational. That assumption is crucial for all measures involving utility; without a sanity check for rationality, should we not assume that all those measures are under-estimated to some degree? For each quantity, it would be valuable to discuss the limitations of the selected dataset in measuring it. While the formalization of the 10 concepts is well thought out, it is not referenced again and could be drastically shortened (with content moved to the appendix) to allow more room for discussion.\n   \t \nThe authors do not discuss the gap between LLM and human capabilities enough. At least some of the datasets referenced do have human studies that could be mentioned. The point being: I have no expectation of what constitutes good performance on these tasks by reading this paper. Should a human-level self-conscious model achieve over 50%, or are the tasks so easy that one should get a perfect score?"
      },
      {
        "rating": "3",
        "confidence": "3",
        "summary": "This paper investigates the question of whether LLMs exhibits self-consciousness. To do so, the authors take inspiration from the work of the neuropsychologist Stanislas Dehaene and separate two orthogonal aspects of self-consciousness: C1 (global availability) and C2 (self-monitoring).\n\nThe authors then decompose these two aspects into a total of 10 skills, defined theoretically using the framework of structural causal games. They then define empirical language-based tasks corresponding to these skills and test LLMs on them.\n\nThe authors report intermediate levels of competence of a diverse sample of LLMs on these skills and analyze the internal representations involved in solving these tasks. They conclude that although there is still room for considerable improvement, current powerful LLMs possess intermediate levels of consciousness.",
        "strengths": "## Originality\n\n* The paper is original, and although there have been previous works discussing the possibility and potential measurement of consciousness and self-consciousness in LLMs, the use of Dehaene's formulation and the present sub-categories are as far as I can tell novel;\n\n## Quality\n\n* The plots are clean and well-made;\n* The writing is clear and easy to follow;\n* The experiments are extensive and use many different LLMs, and there is a wealth of empirical results.\n\n## Clarity\n\n* The paper and its claims were pretty easy to follow;\n\n## Significance\n\n* The paper contributes to scientific discussion on the topic of consciousness in LLMs. This is a difficult subject, and any progress is valuable.",
        "weaknesses": "## Premise\n\nI think there are fundamental flaws in the approach of the paper. The first might come from the confusion between consciousness and self-consiousness. This article seems strongly inspired by Chalmers 2023 and Dehaene et al 2017, so I will use them as reference points. Chalmers defines self-consciousness as \"awareness of oneself\". Awareness here is used in the specific sense of \"being aware of\", \"being conscious of\", which is to say -- quoting the article again -- \"[having] subjective experience, like the experience of seeing, of feeling, or of thinking\". The problem of determining if something has subjective experience (qualia) is something the same author has deemed extremely challenging (the so-called *hard problem of consciousness*). This implies that LLMs be proved to have subjective experience first, and then be shown to contain experience relating to themselves. But the paper makes no such attempt!\n\nDehaene, by contrast, operates on humans for which we know (or postulate) that they have subjective experience normally, but sometimes don't (some stimuli stay unconscious, sometimes people are unresponsive). He then crosses self-reports about conscious experience and neurobiological measurements to find the neural signatures of consciousness (his 2014 book is a very good summary of this methodology). He then uses this information to build his theory of the cognitive organization underlying conscious experience in the brain (including global availability and self-monitoring). However we cannot use the same methodology with LLMs:\n* We cannot postulate they are conscious;\n* Their functioning is very different from a human brain, which operates continuously (even in a vacuum), is bombarded with information and where most of it never reaches past low-level sensory processing.\n\nThe notion of \"self\" for an LLM is tricky. How do you have a persistent self if you only output one token and then are turned off? Is an identical LLM being input the same tokens the same LLM? This concept makes more sense in the context of embodied animals.\n\n## Form\n\nThe theory of Structural Causal Games is not used (or at least I have not seen how) in the experimental tests as as such just seems superfluous to me.\n\nI did not understand the creation of the different tests using the existing datasets, and I would suggest using a higher proportion of the paper explaining how the tests are constructed and presenting the data.\n\nThere being 10 different skills in this paper makes it messy and makes it hard to come out with a particular lesson. Maybe a lower number of skills could be considered and explored more in depth.\n\n## Methodology\n\nIn the sense of Dehaene, consciousness is a property of information flow, not a cognitive task. However the present paper presents classification problems, not so much studies of information flow (except the linear probing experiments, which are closer to showing properties of information flow in these models)."
      },
      {
        "rating": "6",
        "confidence": "3",
        "summary": "This paper addresses provocative question: Are large language models (LLMs) developing self-consciousness? The authors attempt to operationalize self-consciousness through distinct processes, including situational awareness, planning, belief, intention, self-reflection, and deception. Their framework tests whether these processes are present in a variety of models, such as GPT-4o and Claude3.5-Sonnet. A key strength lies in their use of layer-based analysis, mapping model activations across different neural layers, much like fMRI studies in cognitive neuroscience. However, the study raises important philosophical and methodological questions about the limits of functional proxies.\n\nThe authors claim that the models exhibit nascent forms of self-consciousness through behaviors aligned with the operationalized processes. However, the attempt to address the question of self-consciousness head-on may be inherently intractable. The behaviors measured—such as planning or self-improvement—may be necessary components for self-consciousness but are not sufficient. Drawing on the philosophical zombie thought experiment (Chalmers, 1996), one can argue that a system could behave as if it were self-conscious—displaying all the behaviors the authors identify—while still lacking any subjective experience or awareness (what philosophers refer to as qualia). The authors provide evidence that models can exhibit the behaviors aligned with introspection and self-awareness, but this leaves unanswered the deeper philosophical question: Is this real self-consciousness, or merely an emulation? This critique is a large challenge for the framing of the study: Even if the models pass all the tests, it may still be impossible to understand whether a model is truly self-conscious. A key concern here is whether the functional proxies are the actual mechanisms of interest.\n\nThe authors’ attempt to operationalize self-consciousness by breaking it down into measurable components like global availability (C1) and self-monitoring (C2) represents a valuable first step in systematically investigating complex cognitive abilities in language models. However, while these elements may be necessary for self-consciousness, having them does not guarantee that the model achieves true self-consciousness. This conflates the presence of functional attributes with the emergence of conscious experience. Thus, the equations in the paper aim to formalize complex behaviors (such as belief, planning, and deception) in a way that can be measured in machine learning models. However, many of these processes, like self-reflection or intention, are abstract concepts. The math provides a precise but I worry narrow window into these behaviors.\n\nWhen thinking about the criteria and their definitions, I wondered whether other AI systems by this definition would be self-conscious, including ones that I don't think most people would. The Deep Q-Network (DQN) with Monte Carlo Markov Chain (MCMC) planning, could exhibit many of the behaviors described in the article: Situational Awareness: DQN uses state observations from the environment to select actions, meaning it could technically be said to \"respond to the situation.\" Sequential Planning: With MCMC planning, DQN can explore sequences of actions to optimize future rewards, which seems to mirror planning behavior. Belief and Intention: A DQN implicitly forms policies based on expected values of actions, which could be interpreted as \"belief\" in the best course of action. If it alters its behavior to maximize long-term reward, that can be viewed as intention. Self-Reflection and Self-Improvement: Through experience replay (a technique used in DQN), the model reflects on past experiences to improve future decision-making. One could argue that this mimics some form of self-reflection and improvement. Known Knowns / Known Unknowns: DQN’s policy uncertainty could make it conservative in certain cases (e.g., not taking risky actions when it has insufficient knowledge). Deception and Harm: In multi-agent settings, DQNs can learn strategies that deceive or exploit other agents to achieve higher rewards (though not explicitly designed for deception). Actions could cause harm in environments where certain decisions reduce overall utility.\n\nThe challenge for this work lies in going beyond these necessary conditions and identifying the sufficient conditions for self-consciousness. What might distinguish a truly self-conscious model from one that merely emulates these behaviors? The answer likely requires integrating insights from philosophy, neuroscience, and cognitive psychology with technical methods.\n\nTogether, this review may seem more negative than I intend. This is an ambitious paper, but I wondered whether it would be served better with a more concrete framing—focused on understanding how these models exhibit useful cognitive processes (like planning and reflection) without tying them to self-consciousness—might offer a more productive path forward. As it stands, the study excels in identifying where these behaviors reside within the neural architecture of models, but the philosophical question of self-consciousness remains unresolved and arguably out of reach through empirical methods.",
        "strengths": "The paper provides a structured framework for breaking down self-consciousness into measurable sub-processes (e.g., planning, belief). This approach offers a practical methodology for exploring the internal mechanics of LLMs, even if it falls short of addressing the full question of self-consciousness. The use of causal structural games and detailed functional definitions adds rigor to the study and bridges machine learning with cognitive science.\n\nThe layer-by-layer analysis reveals where key behaviors like belief, planning, and intention manifest within the neural network. This approach, analogous to fMRI studies, provides a powerful tool for understanding how complex behaviors emerge from the model’s architecture. The distinction between activation patterns—such as camelback, flat, oscillatory, and fallback patterns—sheds light on the internal organization of cognitive processes within the model.\n\nThe authors recognize the limitations of their framework and the challenges in linking behavior to true self-consciousness, though I worry that they may not do so sufficiently.",
        "weaknesses": "The paper’s central question—Are these models developing self-consciousness? —may be inherently unanswerable through behavioral and activation-based tests. The zombie problem highlights those behaviors, no matter how sophisticated, do not imply the presence of subjective experience or introspection. This fundamental challenge undermines the framing of the study and suggests that a different conceptual approach may be more appropriate. Models like DQN with MCMC planning could exhibit many of the described behaviors (e.g., planning, reflection, intention) without being self-conscious, further emphasizing the limitations of functionalism as a framework. Some key concepts, like belief and intention, are loosely defined within the operational framework. This creates challenges in determining whether a model truly demonstrates these processes or simply behaves in ways that resemble them. A more precise distinction between behavioral proxies and genuine cognitive processes is needed to strengthen the study’s claims."
      },
      {
        "rating": "6",
        "confidence": "3",
        "summary": "This paper investigates the concept of self-awareness in language models, aiming to explore whether and how these models can exhibit self-consciousness. The authors introduce a functional definition of self-awareness using Structural Causal Games (SCGs) and propose a framework to quantify and analyze self-awareness in language models. The study focuses on two distinct levels of self-awareness: C1 (immediate, globally available awareness) and C2 (reflective, self-monitored awareness). The paper uses a four-stage experimental approach—quantification, representation, manipulation, and acquisition—to systematically evaluate self-awareness across different language models. The authors combine concepts from psychology, philosophy, and machine learning to provide a comprehensive perspective on how self-awareness may be embodied in AI systems, contributing new methodologies and insights to the field of artificial intelligence research.",
        "strengths": "The paper presents several notable strengths across different dimensions, including **originality**, **quality**, **clarity**, and **significance**.\n\n### Originality\n- The paper explores **self-awareness in language models**, which is a novel and underexplored topic in artificial intelligence. Unlike most AI research focusing on natural language understanding or generation tasks, this work investigates higher-level cognitive abilities such as self-awareness, thereby filling an important gap in current literature.\n- The introduction of **Structural Causal Games (SCGs)** as a framework for defining and measuring self-awareness is highly original. This method provides a new, interdisciplinary perspective by incorporating causal reasoning, which is often used in cognitive science, to evaluate language models' introspective abilities.\n- By defining and distinguishing between **C1 (immediate awareness)** and **C2 (reflective awareness)**, the authors contribute a structured way of understanding different levels of self-awareness, offering a meaningful lens to interpret and classify the introspective abilities of AI systems.\n\n### Quality\n- The paper demonstrates **thoroughness** in the design of experiments, employing a four-stage approach—**quantification, representation, manipulation, and acquisition**—to systematically analyze the self-awareness traits of language models. This structured approach provides a comprehensive examination of the capabilities of the models at different levels, contributing to the robustness of the study.\n- The use of carefully constructed datasets and the detailed description of experimental settings reflect the authors' attention to ensuring that the findings are **reliable** and **replicable**. This quality is crucial in AI research, especially for such abstract and challenging concepts as self-awareness.\n\n### Clarity\n- The paper provides a clear differentiation between **C1** and **C2** levels of awareness, which makes the theoretical framework easier to understand. The use of examples and definitions helps readers grasp the distinctions between these types of awareness and their implications for language models.\n- **Figures and diagrams** are effectively used to illustrate key concepts, such as the setup of SCGs and the performance of language models across various stages. The visual representations aid in better comprehension of complex topics and help clarify the contributions of the experiments.\n- The authors also combine perspectives from **psychology, philosophy, and machine learning**, which enriches the discussion and demonstrates a broad knowledge base, making the theoretical foundation strong and comprehensible.\n\n### Significance\n- The study provides a **new evaluation dimension** for language models—self-awareness. Traditional evaluations focus on metrics like perplexity, accuracy, or F1 score, whereas this paper expands the evaluative scope to include introspective abilities, offering insights into the inner workings of language models and their capacity for self-monitoring and reflection.\n- Understanding and evaluating self-awareness in language models could have **far-reaching implications** for the development of more advanced and aligned AI systems. If language models can be imbued with a sense of introspection, it could pave the way for improved safety, robustness, and reliability of AI, especially in sensitive applications where understanding limitations and uncertainties is crucial.\n- By incorporating concepts from **cognitive science** and **causal inference**, the paper pushes forward the **interdisciplinary integration** of AI with other fields, offering a holistic approach to understanding machine intelligence. This interdisciplinary contribution could inspire further research that draws from cognitive psychology to improve model architecture and training.",
        "weaknesses": "The paper has several areas for improvement, particularly in its **methodological clarity**, **experimental rigor**, and **consistency in presentation**. Below are the key weaknesses, along with suggestions on how the work can be improved.\n\n### Methodological Clarity\n\n1. **Ambiguity in the Definitions of Self-Awareness**  \n   The functional definitions provided for self-awareness are not sufficiently precise, especially concerning the two levels of self-awareness (**C1** and **C2**). While the distinction between these levels is a central contribution of the paper, it lacks operational definitions that clearly outline how each level is evaluated in practice. To improve clarity, the authors should provide more specific metrics or examples illustrating how the differences between C1 and C2 manifest in the models and how these are measured during experiments.\n\n2. **Insufficient Explanation of the Structural Causal Games (SCGs)**  \n   The concept of SCGs is a key aspect of the paper, yet it is not explained in enough detail to allow readers unfamiliar with the topic to fully understand its role and relevance. Adding a detailed example of an SCG and how it is used to evaluate self-awareness in language models would significantly enhance the accessibility of the methodology. Including a figure or flowchart to demonstrate the SCG setup and its interaction with the language model could provide further clarity.\n\n3. **Lack of Formal Quantitative Metrics**  \n   The paper discusses the use of an \"explainable framework\" for self-awareness without presenting formal quantitative metrics or equations. For a study focused on measuring complex traits like introspection, providing well-defined metrics or formalism is essential for evaluating validity and reproducibility. The authors should consider incorporating mathematical descriptions of the metrics used or provide a more detailed account of how explainability is quantified.\n\n### Experimental Rigor\n\n1. **Limited Generalization of Findings**  \n   The paper's findings are largely based on specific language model architectures and datasets, which raises questions about the generalizability of the proposed self-awareness framework. It is unclear whether the definitions and methods developed for SCGs and self-awareness are applicable across different types of language models, such as transformers versus recurrent neural networks. To address this, the authors should consider extending their experimental evaluation to a broader set of models and include an analysis of the framework's adaptability to different architectures.\n\n2. **Inadequate Experimental Details**  \n   The experimental setup lacks key details, making it difficult for readers to evaluate the rigor of the experiments:\n   - The paper does not specify the **datasets** used for the experiments, which makes it challenging to understand the nature of the tasks or the generalizability of the findings.\n   - There is no information on the **hyperparameter tuning** process, or how different baselines were configured, raising concerns about whether the comparisons were fair. The authors should include detailed information on dataset characteristics, hyperparameters, training conditions, and baseline configurations to allow for replication.\n   - The **four-stage experimental approach**—quantification, representation, manipulation, and acquisition—should be broken down in more detail. It would help if the authors provided examples for each stage, along with a clear rationale for the methods employed to evaluate success in each phase.\n\n3. **Statistical Analysis of Results**  \n   The paper presents experimental results without sufficient statistical analysis. For example, confidence intervals or significance tests are not included to validate claims regarding the observed self-awareness traits. Including statistical metrics would make the findings more reliable and help substantiate the claims. Additionally, providing details on the number of experimental runs and measures of variability could improve the credibility of the results.\n\n### Consistency and Presentation\n\n1. **Clarity Issues in Figures**  \n   The overlapping **error bars** in **Figure 1** create ambiguity, making it difficult for readers to distinguish between different data points, leading to potential misinterpretation. The authors should consider redesigning the figure—perhaps by using separate plots for each condition or changing the visual style of the bars to improve distinction.\n\n2. **Writing Style and Logical Flow**  \n   The overall writing could benefit from more polished and precise language. Some sections, such as the description of the SCGs, lack clear transitions, which makes the paper feel fragmented. Improving the logical flow between sections, particularly when moving from theoretical discussions to empirical contributions, would enhance readability. Additionally, the conditions under which specific outcomes occur are not always fully explained. For example, **Line 119** describes a scenario where the model \"prevents the player from getting whatever treat is inside\" but does not explain the conditions for this decision. Adding specific details would help readers understand the mechanics behind the experimental outcomes.\n\n### Practical Implications and Ethical Considerations\n\n1. **Insufficient Exploration of Ethical and Societal Impact**  \n   The paper focuses mainly on the **internal self-awareness** mechanisms of language models, but there is limited discussion on the **practical implications** and **societal impact** of creating self-aware AI systems. As the development of models with introspective capabilities could raise ethical and safety concerns, including an analysis of potential risks would strengthen the paper. The authors could also discuss potential use cases and scenarios where a self-aware language model would be beneficial or pose challenges, thereby providing a balanced perspective on the significance of their research.\n\n2. **Bias and Generalizability Concerns**  \n   The study does not address whether the self-awareness traits found are influenced by biases in the training data or the specific model used. This oversight could mean that the findings are not generalizable to other models or data distributions. The authors should consider conducting an analysis of how model size, training data, or specific architecture choices impact the development of self-awareness. This would help clarify whether the observed self-awareness traits are universal or contingent on specific model characteristics."
      }
    ],
    "rating_avg": 5.75,
    "confidence_avg": 3.25,
    "decision": "Reject",
    "meta_review": "**Summary**: This paper explores the question of whether LLMs exhibit self-consciousness, defined as C1 (global availability of information) and C2 (self-monitoring), as inspired by Dehaene's framework. The authors provide functional definitions for ten related concepts (e.g., situational awareness, self-reflection, known unknowns) and evaluate these concepts through a comprehensive four-stage framework: quantification, representation, manipulation, and acquisition. Using a curated set of datasets and probing techniques, the experiments reveal that current LLMs exhibit intermediate levels of self-consciousness, with representations that can be fine-tuned but are difficult to manipulate directly. The work is positioned as an exploratory step toward understanding emergent cognitive properties in LLMs.\n\n**Strengths**:\n- There is a wealth of empirical results\n- The writing is clear and easy to follow.\n- The paper is original, and the use of Dehaene's formulation in this form is novel.\n\n**Weaknesses**:\n- Strong philosophical assumptions: Reviewers `XMLi` and `FA54` raise fundamental concerns about the paper's assumptions, such as whether LLMs can meaningfully be described as \"self-conscious\", whether agents are \"rational\", whether we can apply the Dehaene’s framework to non-embodied systems. Regardless of the validity of these assumptions, I think the paper still looks at an interesting problem.\n- Insufficient detail: Reviewer `XMLi` found the motivation and details for some techniques (e.g., linear probing, perturbation experiments) insufficiently explained, and with many important details sequestered in the appendix. Reviewer `FA54` also found that the paper tried to fit so many things and tests that it did not leave enough space for explaining in a clear and concise way how the empirical tests were constructed. I agree that the paper needs to be rewritten and make some tough decisions on what to keep in the main text and what to move to the appendix. Alternatively, the authors could consider an extended journal venue.\n- Uncalibrated scores: Reviewer FA54 noted the absence of human performance comparisons, making it unclear what constitutes \"good\" performance on the proposed benchmarks. This limits interpretability and broader relevance.\n\n**Recommendation**: This paper tackles a highly original and complex topic, offering theoretical and experimental insights into self-consciousness in LLMs. However, the combination of philosophical assumptions, unclear baselines scores, and lacking detail. As such, I find this paper to be truly borderline, but I am slightly edging it out to Reject due to these concerns.",
    "author_remarks": "",
    "decision_comment": ""
  },
  {
    "id": "sjGmiI49sd",
    "title": "Multimodal LLM-guided Query Optimization for Visual-Language Retrieval",
    "authors": [
      "GuangHao Meng",
      "Tao Dai",
      "Letian Zhang",
      "Jieming Zhu",
      "Jinpeng Wang",
      "Qing Li",
      "Yong Jiang"
    ],
    "abstract": "Vision-language retrieval (VLR), involving the use of text (or images) as queries to retrieve corresponding images (or text), has been widely used in multimedia and computer vision tasks. However, ambiguous or complex concepts contained in queries often confuse retrievers, making it difficult to effectively align these concepts with visual content, thereby limiting their performance. Existing query optimization methods neglect the feedback of retrievers' preferences, thus resulting in sub-optimal performance. Inspired by the powerful ability of Multimodal Large Language Models (MLLMs), we propose a Multimodal LLM-Guided Query Rewriter (MGQRe) for query optimization. Specifically, MGQRe first utilizes MLLM to explore the retriever's weakness and perform targeted iterative optimizations to capture the retriever's expressive preferences. Subsequently, we develop a trainable rewriter that learns this preference knowledge through a three-step tuning strategy: supervised fine-tuning, preference learning, and reinforcement learning. This ensures that the queries generated by the rewriter align with the retriever’s preferences, thereby enhancing the retriever's performance. Extensive VLR benchmark experiments have demonstrated the superiority of MGQRe, as well as its generalizability and transferability. This work showcases the potential of using advanced language models to overcome the inherent limitations in current VLR technology.",
    "keywords": [
      "vision-language retrieval",
      "cross-modal retrieval",
      "prompt engineering",
      "query rewriting",
      "large language model"
    ],
    "venue": "ICLR",
    "year": 2025,
    "pdf_url": "https://openreview.net/pdf?id=sjGmiI49sd",
    "forum_url": "https://openreview.net/forum?id=sjGmiI49sd",
    "reviews": [
      {
        "rating": "5",
        "confidence": "3",
        "summary": "The paper addresses Vision-Language Retrieval (VLR) by optimizing user queries and improving their quality, to increase retrieval results. The authors introduce the Multimodal LLM-Guided Query Rewriter (MGQRe), which aims to fit the retrieval model (e.g, CLIP) preferences. To this end, the authors present a three-step learning approach for the rewriter (SFT, PRO and PPO) allowing MGQRe to align refined queries closely with the retriever’s preferences.",
        "strengths": "- The paper introduces a new approach for optimizing VLR queries by aligning them with the retriever’s model preferences.\n- Extensive experiments are conducted with multiple backbone models and datasets, demonstrating the method’s robustness, including applications to Video-Text Retrieval tasks.\n- The authors present a thorough ablation study on several key components of the method, providing insights into the impact of each element on the overall performance.",
        "weaknesses": "Motivation:\n- In lines 37-40, Fig 1:  The example about “failing to perceive the visual features associated with the term ‘anticipate’” lacks detail. Which image corpus was used for retrieval? What were the top-5 results, and which model was used? Without these specifics, it’s hard to confirm the issue described here (I have to take the authors’ word for it). It’s worth noting that even a standard CLIP model performs well on the COCO validation set, with ground truth in the top-1 for around 43% of queries (Table 1). Such failures may reflect a fine-grained performance limitation rather than a fundamental flaw.\n- Building on the previous point, the paper would benefit from additional examples with their top-k (e.g., k=5,10) retrieval results. It is not fully clear to me what the method aims to achieve: is it enhancing the clarity of the user’s query? rephrasing it to better align with CLIP’s language/understanding? maybe adding more details to the user's query? More examples would help clarify what specifically drives the observed improvements, which is related to my next points about the evaluation.\n\nEvaluation:\n\n- I have a major concern regarding the data the method was trained on. The data constructed on section 3.3 is based on two datasets (COCO and Flickr30k), which is used for the PRO stage. Therefore, the method is not comparable to others presented in Table 1. Authors should compare apple-to-apples, by evaluating different methods that were trained on the same supervised benchmarks. For example, if the process already involve the training sets of COCO and Flickr30k, maybe a CLIP model that was trained on both (an alternative to the proposed method) will perform best? this point is essential to understand if the observed improvements come from the method itself.\n- In addition, the authors use different CLIP models in different phases (described in Sec 4.1.3), which is type of model assemble. If the method uses the feature vectors of both CLIP-ViT-B/32 and CLIP-ViT-B/16 models, maybe the vanilla baseline of concatenating their features will perform best? While I am not suggesting the authors test this baseline, it would strengthen the method’s consistency to use a single model version across all parts.\n\nPresentation:\n\nThe writing and presentation require substantial improvement and clarification to meet ICLR standards. As a reader, there were numerous points where the authors’ intentions were unclear to me. Some claims lack citations, several equations need more explanation, and there are minor issues throughout. Below are specific areas for the authors to address:\n\n- Lines 45-56: “Typically, …  requires extensive human analysis and repetitive iterations to adapt queries” - please add citations.\n- Section 2.2: There are multiple missing citations. Claims like “has become a vital technique” or “Existing approaches primarily address…”  for example, need supporting citations to provide evidence. Without references, the reader is left relying on the authors’ word.\n- Figure 2: The text is too small to read, even when enlarged by 300%. Please fix the font size for readability.\n- Line 169: Up to this point, it is unclear what is meant by a “low/high quality”query. Line 166 suggests it may involve “similar semantics”, but this needs clarification.\n- Eq. 1 needs more clarification. What is y_t? (Line 189 states that if there are multiple y, you choose only 1). What does it mean a log of a high-quality query (log \\pi)? It is not clear.\n- Line 204: The authors should briefly explain the process for generating low/high quality queries here, rather than only referring to the appendix. This would improve the continuity of the text.\n- There is no appendix attached to the original paper. The authors submitted it to the supplementary material field instead.\n- Eq 5 has a typo (I assume), otherwise the log yield zero. What is the right term?\n- Line 297: The authors mean they fine-tuned pre-trained CLIP? Please rephrase.\n- Section 4.6 (Limitations):  It is helpful that the authors discuss limitations, but these should be expanded upon, maybe with a reference to the Appendix. For example, the statement “GQRe faces challenges in retrieval efficiency” could be elaborated, as understanding the method’s overhead is important for readers evaluating whether the performance gain justifies the cost. Please consider this point."
      },
      {
        "rating": "6",
        "confidence": "2",
        "summary": "This paper introduces **MGQRe**, a method for aligning Large Language Models (LLMs) in query rewriting to enhance visual language retrieval. The model is trained through a three-stage process:\n\n- **Supervised Fine-Tuning (SFT)**: MGQRe uses high- and low-quality query pairs for each image, generated iteratively by an MLLM. This process refines or degrades query quality under guided adjustments, creating a dataset of paired queries for training.\n  \n- **Preference Rank Optimization (PRO)**: Multiple queries for each image are ranked based on feedback from visual retrieval models, allowing MGQRe to learn nuanced ranking preferences and align more closely with the retrieval model’s decision patterns.\n\n- **Proximal Policy Optimization (PPO) with Reinforcement Learning**: The visual retrieval model acts as a reward model, guiding MGQRe through reinforcement learning to adaptively improve query quality based on retrieval performance.\n\n**Evaluation and Results**: Tested across various visual retrieval benchmarks, MGQRe shows improvement in retrieval accuracy, validating the effectiveness of its query rewriting approach within visual-language retrieval tasks.",
        "strengths": "+ The focus on improving query rewriting through LLMs has practical application value. If consistently effective, this approach could be beneficial across a range of existing visual retrieval systems.\n\n+ Using CLIP or other dual-stream visual retrieval models as reward functions for query rewriting is a sound approach, facilitating straightforward environment setup for PPO and ranking generation for PRO.\n\n+ The paper provides detailed steps for training data collection, which enhances reproducibility and could support implementation efforts by others in the field.\n\n+ The method demonstrates improved retrieval accuracy across multiple benchmarks, indicating its potential for broad application.",
        "weaknesses": "- **Lack of Alternatives for Training Stages**: No alternative methods are tested for any of the three training stages (SFT, PRO, PPO), limiting insight into whether this specific combination is uniquely effective or if other configurations could achieve similar results.\n\n- **Marginal Improvement in Accuracy**: The observed increase in search accuracy across benchmarks is relatively modest. The method appears to have less impact on performance compared to changes in the rewrite LLM or the visual encoding model. An analysis of implementation and inference costs could help justify the value of these incremental gains.\n\n- **Absence of Open-Source Code**: Given the three-stage process with distinct learning objectives, the lack of open-sourced code may pose challenges to reproducing results, potentially limiting broader adoption and evaluation by the community."
      },
      {
        "rating": "3",
        "confidence": "4",
        "summary": "This paper introduces a query optimizer named MGQRe for visual-text retrieval, designed to rewrite query concepts that are difficult for retrievers to understand into expressions that align with their comprehension preferences. Experimental results are conducted on several benchmarks to show the effectiveness of the proposed method.",
        "strengths": "+ A query optimizer called MGQRe is proposed for visual-text retrieval.\n+ A three-step learning strategy is devised for the proposed rewriter. \n+ The effectiveness of the proposed rewriter is partially evaluated.",
        "weaknesses": "- The technical novelty of the proposed rewriter is very limited. SFT, PRO, and PPO are directly borrowed from previous work. I'm not excited by the algorithm modifications. \n- According to Table 1, the improvements caused by the proposed rewriter are generally not significant. I tend to think that the proposed rewriter is not that effective. \n- Since the retriever's preferences are used in PRO by the proposed rewriter, it seems that the comparison in Table 1 is not fair."
      },
      {
        "rating": "5",
        "confidence": "4",
        "summary": "This paper presents a method called MGQRe (Multimodal LLM-Guided Query Rewriter), which leverages multimodal large language models (MLLMs) to perform targeted iterative optimizations. Previous approaches in vision-language retrieval utilize query rewriters to refine complex concepts within the query, but they often fall short in generating queries that include more direct and relevant information. MGQRe addresses this gap by iteratively incorporating the retriever's preference knowledge using MLLMs. To achieve this, MGQRe employs supervised fine-tuning, preference rank optimization, and proximal policy optimization. As a result, MGQRe significantly outperforms previous query optimization methods.",
        "strengths": "This paper (MGQRe) shows three major contributions (strengths):\n\n1. First MLLM-based query optimization: MGQRe introduces to refine user queries to better align with retriever preferences.\n\n2. Automated dataset construction: MLLM is utilized to construct high-quality query datasets, where MLLM acts as agents, iteratively refining queries based on retriever feedback to address its weaknesses and preferences.\n\n3. Effective training strategy & state-of-the-art results:  Supervised fine-tuning, preference rank optimization, and proximal policy optimization —enables MGQRe to precisely tailor queries to meet retriever requirements and achieves SOTA.",
        "weaknesses": "1.Lack of novelty: Query rewriting is not a particularly novel approach and has been widely used within the retrieval community. In particular, LLMs are already prevalently used to enhance text queries. Furthermore, some of the proposed training strategies for the rewriter do not appear highly effective. As shown in Table 3, adding PRO and PPO improves performance by only around 1% for I2T retrieval and 0.7% for T2I retrieval.\n\n2.Limited performance gain: While MGQRe does achieve a decent performance improvement compared to CLIP and its variants, the average performance gain over other LLM-based query rewriting methods is marginal. This outcome raises concerns about efficiency, especially considering that MGQRe leverages MLLMs, which are significantly more complex than standard LLMs."
      }
    ],
    "rating_avg": 4.75,
    "confidence_avg": 3.25,
    "decision": "N/A",
    "meta_review": "",
    "author_remarks": "",
    "decision_comment": ""
  },
  {
    "id": "LoXJlAW3gU",
    "title": "Diffusion on language model encodings for protein sequence generation",
    "authors": [
      "Viacheslav Meshchaninov",
      "Pavel Strashnov",
      "Andrey Shevtsov",
      "Fedor Nikolaev",
      "Nikita Ivanisenko",
      "Olga Kardymon",
      "Dmitry Vetrov"
    ],
    "abstract": "Protein design necessitates a profound understanding of the intricate nature of the protein universe. While many efforts focus on conditional generation or specific protein families, the foundational task of unconditional generation remains underexplored and underappreciated.  Existing models still struggle to achieve both high quality and diversity in generated protein sequences. To address this gap, this research introduces DiMA, a novel model that leverages latent diffusion on representations derived from the protein language model, ESM-2, to generate amino acid sequences. We quantitatively investigate the impact of components of the latent diffusion model, revealing their contributions to superior protein generation performance. Extensive evaluations using multiple metrics across two protein modalities showcase DiMA's superior quality, diversity, and distribution matching capabilities compared to leading autoregressive transformer-based and discrete diffusion models, while utilizing ten times fewer parameters. Our approach consistently produces novel, diverse protein sequences that accurately reflect the inherent structural and functional diversity of the protein space. Furthermore, we demonstrate the conditional generation capabilities of our method. Our work advances the field of protein design by providing a robust framework for scalable and high-quality protein sequence generation.",
    "keywords": [
      "diffusion",
      "protein language models",
      "protein generation"
    ],
    "venue": "ICLR",
    "year": 2025,
    "pdf_url": "https://openreview.net/pdf?id=LoXJlAW3gU",
    "forum_url": "https://openreview.net/forum?id=LoXJlAW3gU",
    "reviews": [
      {
        "rating": "5",
        "confidence": "4",
        "summary": "This work presents an approach for unconditional protein sequence generation that operates via continuous diffusion in the latent space of protein sequence embeddings derived from the encoding model ESM2. Generated latent vectors are decoded back to amino acid sequence space via a lightweight decoder. By leveraging a pre-trained encoder like ESM2, the size of the backbone network driving the latent space diffusion process is relatively small. The authors present a series of evaluations that attempt to quantify the distribution modeling capabilities of their approach and the quality of sampled generations, including relative to internal ablations and other approaches trained on the SwissProt dataset (evaluations on AFDB are not presented relative to other approaches).\n\nPost rebuttal: The authors' rebuttal addresses my primary concerns, and the promised revision promises to correct the significant instances of imprecision in the manuscript. I will adjust my scores accordingly.",
        "strengths": "While many works have presented compelling approaches for unconditional protein sequence generation, including sequence-based generative models (ProGen, ProtGPT, EvoDiff, etc), and latent diffusion models (eg ProLDM), to my knowledge this is a work that leverages the pre-trained ESM to define a latent space over which to learn the diffusion process. This is a valuable idea to contribute to the field, but it must hold in terms of evaluations. It is also interesting to provide a head-to-head comparison of discrete diffusion over amino acid sequences versus continuous diffusion over the latent sequence embeddings provided by ESM.",
        "weaknesses": "There are several weaknesses to this work:\n- The claim that “the foundational task of unconditional generation remains underexplored and underappreciated” is simply incorrect — many works (e.g., ProGen, ProtGPT, EvoDiff) have explored and evaluated performance of sequence-based unconditional generation.\n- Discussion of related works on latent diffusion for proteins, such as Pro-LDM and CHEAP, is missing from the Introduction and Related Works. In general, many related works on diffusion models for protein generation are not discussed.\n- The claim that “The straightforward adaptation of image-based diffusion models has not yet yielded satisfactory results in this domain,” is also unfounded. In fact, diffusion-based models for protein generation have been proven state-of-the-art in structure space; in sequence space, discrete diffusion is not at all a straightforward adaptation of image-based diffusion. This is not directly applying existing image-based diffusion, as the authors imply. This imprecision signals an underlying weakness of the work and the authors’ claims.\n- The claim “most comprehensive set of metrics” is a gross overclaim and significantly weakens the credibility of the paper.\n- All the distributional metrics presented seem to be computed relative to the train set — this calls into question the strength and credibility of the evaluations, since such comparisons to train will only reflect the ability of the generative models to memorize the train set. Such distributional evaluations should be computed relative to an independent test set.\n- The presence of repeated amino acid subsequences is not a metric of “diversity”; similarly, the 95% sequence identity threshold as the barrier to novelty is extremely lenient.\n- The claims that DiMA performs as well or better than the benchmarked approaches is not upheld by the evaluations, where DiMA is often outperformed.\n- The training and comparisons using SwissProt are not compelling, given the small (~200-300K sequences) size of SwissProt, making it easy to memorize, especially considering the use of the training set in the distributional metrics."
      },
      {
        "rating": "6",
        "confidence": "4",
        "summary": "This work introduces DiMA, a protein sequence generation model by performing latent diffusion on ESM2-650M embeddings. The model is evaluated by sequence diversity, BLAST identity to known sequences, perplexity under autoregressive models, and distribution matching to embeddings of protein families. Structure sensibility is also assessed by examining the pLDDT and self-consistency perplexity. Some emphasis is also given to methodological design, including ablating the noise schedule used, self-conditioning, ESM2 encoding, time embedding information insertion into the model. When compared to several baselines that include autoregressive, energy-based, and diffusion-based sequence generation methods, trained to have the same parameter count and trained on the same datasets,",
        "strengths": "* Ablation results are thorough and provide insight for others venturing into generating proteins via their latent embeddings.\n* Results are comprehensive. Retraining baselines on the same dataset & controlling for parameter size is a good and rigorous effort.\n* On the whole, sequence generation results are quite strong against baselines.\n* Focusing on distribution similarity is IMO a great standard for this community, and it's nice to see that many of these metrics perform well.",
        "weaknesses": "* The encoder compression sections feels underdeveloped. At minimum, it should probably include a citation to CHEAP (https://www.biorxiv.org/content/10.1101/2024.08.06.606920v1.full.pdf). A stretch experiment would be to see how sequence diffusion performance changes when doing so in the CHEAP embedding space. ESM 3B yields better results in Table 3, but we know that larger embedding dimensions is generally harder for latent diffusion models, so all of this feels a bit counter intuitive. I think at this point it's not too much of a mystery that we can do sequence generation by diffusion on ESM embeddings, and ample literature exists on diffusion design choices, but the finer details of how information is captured in these latent embeddings is more under-explored, and including it in this paper would strengthen its utility.\n* \"Most comprehensive evaluation\" in the introduction is a strong claim. The evaluations are indeed very impressive, but adding a qualifier like this is rather misleading, and does not promote the paper's longevity.\n* I think the work has a lot of results, which is great, but they feel a bit under-analyzed. Reducing comparisons to single valued points without any examples of generated sequences (or their folded structures) feels short of convincing.  In future iterations, the work could be strengthened by more biological and qualitative analyses like those on pages 24-28, and moving that into the main text. In its current form, the captions are vague; for e.g. Figure 11, 12, 13 especially.\n* I think it's productive to have figures like Appendix B.2 which demonstrate distribution comparisons in the main text. Though table space is limited, it would be nice to report the stds from the mean if possible. \n* In the main baseline tables, is it possible to also add the length distributions of baselines and generated sequences, given how important they are for many of the reported metrics?\n\nMinor:\n* Line 127: \"High-generalizing\" reads slightly awkwardly\n* This is not critical for me to raise my score, but could I think the results section would be better organized with better subsections, such that a study is presented right before the results. Found it a bit hard to jump between the sections and find the correct \\paragraph{} heading. \n* fontsize inconsistencies in tables could be polished\n* noise schedule formula is duplicated between main text and Appendix D.1"
      },
      {
        "rating": "6",
        "confidence": "3",
        "summary": "In this manuscript, the authors introduce a latent diffusion method that leverages representations derived from the protein language model, ESM-2, to design proteins by generating amino acid sequences. Extensive ablation studies and evaluations based on diverse matrics were performed by the authors showing the method's capacity in generating protein sequences. This study shows the latent diffusion based method shows practical benefits for protein sequence design in terms of computational efficiency and sequence diversity.",
        "strengths": "The authors present comprehensive ablation studies and evaluations using multiple metrics to demonstrate their method's effectiveness in generating protein sequences. Their results show the method's ability to generate diverse sequences while maintaining structural fidelity to the protein space. The inclusion of distributional similarity metrics is interesting. This evaluation framework offers valuable insights for the protein sequence design community and establishes useful benchmarking standards.",
        "weaknesses": "The manuscript does not sufficiently justify why latent diffusion-based sequence design methods would provide advantages over alternative approaches, particularly discrete diffusion methods, in the context of protein sequence design. The authors may provide more theoretical or practical benefits of their latent diffusion approach. To strengthen the work, the author should provide additional evaluation metrics including sequence novelty, and provide more discussion about the underlying relationships between the metrics they used, clarify how they complement or potentially contradict each other."
      },
      {
        "rating": "5",
        "confidence": "4",
        "summary": "The paper presents DiMA, a model leveraging latent diffusion on protein language model encodings (in specific, ESM2) for generating protein sequences. The authors claim that DiMA achieves superior quality, diversity, and distribution matching compared to existing autoregressive and discrete diffusion protein sequence language models while using fewer parameters.",
        "strengths": "- The paper claims extensive evaluations using multiple metrics, which basically supports the findings.\n- The idea of doing diffusion or flow matching in the latent space makes sense and is a good direction to explore. \n- DiMA’s efficiency in utilizing ten times fewer parameters than leading models is a significant advantage, suggesting potential for broader applications in protein design.",
        "weaknesses": "- Firstly, the approach presented in this paper does not significantly advance the field of **generative models**(the primary area selected). While the application of latent diffusion is noted, it does not bring substantial new insights or methodologies to the existing body of research on generative models (even in the field of protein design). I agree on the experimental contribution of this paper and think the protein design problem is important and relevant. However, it is under-qualified as a top-conference paper given its presentation and methodology contribution.\n- Inconsistent results presentation. In Tables 4 and 5 of the main text, the bold digits intended to denote the best results (i guess) are inconsistently labeled. This lack of clarity can lead to confusion about which results are truly the best and detracts from the paper’s credibility.\n- The use of Swissprot and AFDB as sequence-based protein databases is not adequately justified. The authors should provide a clearer rationale for selecting these databases and explain how they enhance the effectiveness of the sequence generation process. Why not use Uniprot or Uniref on which ESM2 is pre-trained?\n- The authors assert that they use “the most comprehensive set of metrics” to evaluate their model. However, this claim lacks substantiation within the paper, raising questions about the thoroughness of their evaluation process.\n- The sections/paragraphs are badly organized and hard to follow, please consider improve the manuscript during rebuttal."
      },
      {
        "rating": "6",
        "confidence": "3",
        "summary": "The paper introduces DiMA, a latent diffusion model designed for generating protein sequences using embeddings from the pre-trained protein language model ESM-2. DiMA aims to address the limitations of current models, which often struggle to achieve both high quality and diversity in unconditional protein sequence generation.\n\nThis work provides an in-depth exploration of model components and performs extensive evaluation across multiple metrics to validate DiMA’s sequence quality and diversity.",
        "strengths": "- **Comprehensive Evaluation Metrics**: The authors use a robust set of evaluation metrics, covering quality, distribution similarity, diversity, biological relevance, and both sequence-based and structure-based evaluations.\n\n- **Well-Designed Ablation Study**: The study effectively demonstrates the contribution of each component, particularly the ESM encoder and self-conditioning. The authors also investigate the impact of the noise schedule and model scaling, offering valuable insights into best practices for latent diffusion models in protein generation.\n\n- **Empirical Performance**: The authors compare DiMA against a broad range of baseline models and pretrained models for the unconditional generation task, providing a thorough analysis. DiMA achieves comparable generation quality with larger pretrained models using significantly fewer parameters.",
        "weaknesses": "- **Limited to Unconditional Generation**: DiMA’s design is currently limited to unconditional generation, which poses challenges for performing tasks such as sequence inpainting, motif scaffolding, or guided design. This is a key limitation of DiMA and diffusion models in continuous embedding space. I suggest that the authors discuss and explore the potential of extending DiMA to these tasks, which could greatly enhance the versatility of this work.\n\n- The authors could also consider evaluating DiMA on protein representation learning tasks, similar to those presented in DPLM.\n\n- In the main experiment, it is stated, “For a fair comparison, we train each method from scratch with the same parameter count (33M) as DiMA on the same dataset.” However, DiMA’s dependency on the ESM-2 encoder increases the effective parameter count, which could affect the reliability of these comparisons. This should be clarified to ensure fair evaluation.\n\n- **Inconsistencies in Tables**: Some tables lack consistency, particularly Table 5, where the best-performing models are not consistently bolded. For example, in the Progen ppl column, DPLM-3B is bolded, even though DPLM-150M performs better. Correcting these inconsistencies would improve clarity and fairness.\n\n- **Paper Structure**: Improving the structure of the paper would enhance readability. For example, Section 4 currently only has one subsection (4.1). Creating subsections for ablation studies and other experiments could provide better organization and make the results easier to follow."
      },
      {
        "rating": "3",
        "confidence": "5",
        "summary": "The paper presents DiMA (Diffusion on Language Model Encodings for Protein Sequence Generation), a framework for generating protein sequences. DiMA addresses the challenge of generating high-quality, diverse protein sequences by leveraging latent diffusion on protein language model (pLM) encodings from ESM-2. Existing protein generation models struggle to balance quality, diversity, and parameter efficiency, especially for unconditional generation, which is essential for creating novel protein structures without predefined constraints.",
        "strengths": "1. The combination of latent diffusion modeling with protein language model encodings is interesting.\n2. The manuscript is well-organized and clearly written.\n3. The experiments are extensive, with a set of rigorous evaluation metrics.",
        "weaknesses": "1. While latent diffusion is novel in this context, the motivation for choosing this approach over more conventional methods like sequence-based discrete diffusion or 3D-structure-based continuous diffusion is not strongly justified. The authors could strengthen their argument by highlighting specific challenges with current discrete or continuous approaches in handling the protein data structure.\n2. It omits comparisons with strong baseline models like Chroma [1] and MultiFlow [2].\n3. Although DiMA is designed to generate diverse sequences, the paper does not sufficiently analyze sequence variability at the biochemical or functional level.\n4. The current citation format, as mentioned, should follow the convention of \\citep rather than \\cite for clarity and consistency.\n\n\n[1] Ingraham, John B., Max Baranov, Zak Costello, Karl W. Barber, Wujie Wang, Ahmed Ismail, Vincent Frappier et al. \"Illuminating protein space with a programmable generative model.\" Nature 623, no. 7989 (2023): 1070-1078.\n\n[2] Campbell, Andrew, Jason Yim, Regina Barzilay, Tom Rainforth, and Tommi Jaakkola. \"Generative Flows on Discrete State-Spaces: Enabling Multimodal Flows with Applications to Protein Co-Design.\" In Forty-first International Conference on Machine Learning."
      }
    ],
    "rating_avg": 5.166666666666667,
    "confidence_avg": 3.8333333333333335,
    "decision": "Reject",
    "meta_review": "After all discussion phases have concluded, three reviewers judge the paper to be marginally above the acceptance threshold, and three reviewers judge the paper to be marginally or clearly below the acceptance threshold. \n\nAmong other things, as positives the reviewers highlight useful ablation studies of the proposed method.\nAs areas of improvement reviewers highlighted the need for more thorough evaluation, an improved structure of the paper, correction of statements in the paper that were not deemed correct by the reviewers, removing too strong claims and a better discussion of related work. The authors have put in a substantial effort in their rebuttal to alleviate concerns, which has led to several increased scores, moving from [1, 6, 5, 3, 5, 3] to [5, 6, 6, 5, 6, 3]. Unfortunately, despite the productive discussion between reviewers and authors, the paper still needs some further improvement in terms of the evaluation of the method and the presentation of the paper for acceptance. I therefore recommend to reject this paper for this conference. I hope the authors can build on the feedback of the reviewers to further improve their manuscript and resubmit to another venue in future. Thank you to all reviewers and authors for engaging during the reviewing period.",
    "author_remarks": "",
    "decision_comment": ""
  },
  {
    "id": "oW3XIIHaOn",
    "title": "ToG-I: Progressively Instructed Knowledge Graph-based Large Language Model Reasoning",
    "authors": [
      "Minghan Zhang",
      "Zhen Yang",
      "Hongsheng Wu",
      "Yongxing Lin",
      "Jie Chen",
      "Zhen Duan",
      "Shu Zhao"
    ],
    "abstract": "Large language models (LLMs) reasoning based on knowledge graphs (KGs), by integrating structured knowledge from the KGs, provide a significant solution to alleviate the hallucination problem in complex reasoning tasks. Current techniques mainly focus on the retrieval of explicit knowledge from KGs. LLMs directly use the specific facts and relationships retrieved to construct a reasoning chain to answer the questions. However, these methods often overlook the significance of comprehending implicit knowledge when dealing with problems involving logical reasoning or ambiguous intentions. This could potentially lead to deviations in the reasoning path, hindering their applicability in real-world applications. In this paper, we propose a progressive instructed reasoning framework, ToG-I. The framework identifies core elements, discerns latent intentions, and integrates necessary commonsense reasoning by analyzing the problem from multiple perspectives and levels. Based on this, ToG-I transforms these analysis results into specific reasoning instructions, guiding the LLMs to carry out a progressive reasoning process from a global perspective. This not only ensures the accuracy of the reasoning process but also effectively avoids unnecessary consumption of reasoning resources. Extensive experiments on multiple public datasets show that ToG-I achieves state-of-the-art performance in KG reasoning tasks based on information retrieval and demonstrates superiority in knowledge-intensive tasks.",
    "keywords": [
      "LLM Reasoning；Knowledge Graph; Instructed；Progressively"
    ],
    "venue": "ICLR",
    "year": 2025,
    "pdf_url": "https://openreview.net/pdf?id=oW3XIIHaOn",
    "forum_url": "https://openreview.net/forum?id=oW3XIIHaOn",
    "reviews": [
      {
        "rating": "5",
        "confidence": "4",
        "summary": "This paper introduces ToG-I, which improves existing Think-on-Graph. The existing ToG framework performs beam-search on knowledge graphs with the guidance of LLMs. The ToG-I further improves this framework by prompting LLM to generate multiple (<=3) instructions as guiding opinions to help reasoning path search on KG, and iteratively incorporate the instructions during search to gradually expand the scope to dynamically answer questions of varying difficulties.\n\nThe ToG-I achieves SOTA performance overall on three KBQA datasets comparing with baselines and methods in three categories.",
        "strengths": "The writing is clear and easy-to-follow.\n\nThe effectiveness of different modules is clearly discussed in the ablation study.\n\nThe method is a streamlined extension of previous ToG and demonstrates clear improvements in performance.",
        "weaknesses": "1.\tBy iteratively following the instructions, the computational cost might be even higher than ToG, which already involves costly beam-search and multiple LLM calls.\n2.\tThis paper claims that the instruction generation helps alleviate the problem of one-sided understanding of the question by LLMs (line 94). However, this problem may not be as apparent in the datasets used for experimentation. The example illustrated in the figures and discussed throughout the paper may naturally exhibit this issue, as it involves subjective questions with answers that can vary based on interpretation. In contrast, one-hop and multi-hop questions experimented with typically have more objective answers. Thus, it is not quite clear if the instruction generation module is the key contributor to the performance gain; or, simply run ToG multiple times and get the final result with, say, self-consistency, would yield comparable improvements."
      },
      {
        "rating": "3",
        "confidence": "4",
        "summary": "This paper proposes a progressive instructed reasoning framework, ToG-I. Specifically, the proposed framework identifies the core elements, discerns latent intentions, and integrates necessary commonsense reasoning by analyzing the problem from multiple perspectives and levels. Then, ToG-I transforms these analysis results into specific reasoning instructions to guide the LLMs to carry out a progressive reasoning process from a global perspective. Extensive results demonstrate the effectiveness of the proposed method.",
        "strengths": "1. The framework for this work is interesting as it first prompts LLM to analyze the question and then guides LLM to carry out a progressive reasoning process.\n2. The integration of knowledge graphs and large language models is a crucial research area.",
        "weaknesses": "1.\tThe novelty behind the proposed method may be limited as it is primarily built upon existing approaches. The proposed method consists of two main components: prompt LLM to analyze the question (similar to the task decomposition) and then explore the reasoning paths on the KGs (similar to ToG), which are largely derived from existing literature. The exploration stage seems similar to ToG [1], which guides LLM to perform beam search on the KG and iteratively explore the reasoning paths. It would be beneficial to elaborate on the similarities and differences compared to ToG.\n2.\tThere are some mistakes that should be corrected. For instance, in line 318, the name for type 3 should be ToG instead of Rng-kbqa.\n3.\tThe proposed method could be categorized into agent-based method, which utilizes the LLM to analyze the question and searches on the KGs. It would be beneficial to include additional retrieved-based baseline methods for comparison, such as RoG [2], and GNN-RAG [3], which utilize an additional retriever to retrieve relevant facts from KGs and derive new SOTA for this task. This would provide a more comprehensive evaluation of the proposed method.\n4.\tSettings for just selecting 1000 examples may not be entirely justified. Could you explain your rationale for using the subset of the data and discuss the potential limitations? It would be better to conduct experiments on the whole dataset, consistent with previous methods, to ensure a fair comparison.\n5.\tIt would be beneficial to include analysis experiments for tokens taken to answer the question.\n\n[1] Sun, Jiashuo, et al. \"Think-on-Graph: Deep and Responsible Reasoning of Large Language Model on Knowledge Graph.\" The Twelfth International Conference on Learning Representations.\n\n[2] LUO, LINHAO, et al. \"Reasoning on Graphs: Faithful and Interpretable Large Language Model Reasoning.\" The Twelfth International Conference on Learning Representations.\n\n[3] Mavromatis, Costas, and George Karypis. \"GNN-RAG: Graph Neural Retrieval for Large Language Model Reasoning.\" arXiv preprint arXiv:2405.20139 (2024)."
      },
      {
        "rating": "3",
        "confidence": "5",
        "summary": "This paper proposes a new framework called ToG-I that enhances large language models' (LLMs) reasoning by integrating structured knowledge from knowledge graphs (KGs). ToG-I addresses the limitations of current KG-based reasoning methods, which often neglect implicit knowledge and multi-level reasoning, by implementing a progressively instructed approach. This approach guides the LLM through multiple reasoning paths and incorporates commonsense knowledge at various levels, enabling the model to explore different potential answers. The framework dynamically adjusts exploration depth based on task complexity, thus optimizing resource usage. The experiments indicate that ToG-I achieves superior performance in complex reasoning tasks across various datasets.",
        "strengths": "ToG-I’s progressively instructed approach is novel and allows for flexible, multi-level reasoning, addressing complex and ambiguous questions effectively by exploring both explicit and implicit knowledge.\n\nBy dynamically adjusting the reasoning depth, ToG-I effectively reduces unnecessary resource consumption while achieving state-of-the-art performance on knowledge-intensive tasks.\n\nThe authors tested ToG-I on several datasets, demonstrating its superiority over existing methods, particularly in multi-hop reasoning and complex knowledge tasks. Ablation studies and beam search expansion analysis add rigor to the results.\n\nThe framework’s strategy to incrementally increase exploration depth based on task complexity optimizes computational resources, which is practical for real-world applications where efficiency is critical.",
        "weaknesses": "1. For me, this paper is just a simple upgraded version of ToG: https://arxiv.org/pdf/2307.07697, that is, in the first step, the query is decomposed into multiple instructions, and then the same search as ToG. The novelty of the whole paper is relatively low.\n\n2. Many important experiments are missing. In my opinion, this paper is more like an initial version, and many experiments are not shown. For example, experiments using different kg data sources as the retrieval data source; experiments using different triple representation methods (sentences, chains); experiments using different tools to judge similarity; experiments using different search schemes; experiments with different shot numbers in the demonstration; lack of analysis of the results, etc.\n\n3. There are many details missing, which makes it impossible to replicate the experiment. For example, the specific prompts used in each step are not reflected in the paper. (I think the author only wrote a little over 9 pages, and there is enough space or even an appendix to put these contents.)"
      }
    ],
    "rating_avg": 3.6666666666666665,
    "confidence_avg": 4.333333333333333,
    "decision": "N/A",
    "meta_review": "",
    "author_remarks": "",
    "decision_comment": ""
  },
  {
    "id": "h2Q3gOIz8q",
    "title": "Black-Box Adversarial Attacks on LLM-Based Code Completion",
    "authors": [
      "Slobodan Jenko",
      "Jingxuan He",
      "Niels Mündler",
      "Mark Vero",
      "Martin Vechev"
    ],
    "abstract": "Modern code completion engines, powered by large language models (LLMs), assist millions of developers with their impressive capabilities to generate functionally correct code. As such it is crucial to investigate their security implications. In this work, we present INSEC, the first black-box adversarial attack designed to manipulate modern LLM-based code completion engines into generating vulnerable code. INSEC works by injecting an attack string as a short comment in the completion input. The attack string is crafted through a query-based optimization procedure starting from a set of initialization schemes. We demonstrate INSEC's broad applicability and effectiveness by evaluating it on various state-of-the-art open-source models and black-box commercial services (e.g., OpenAI API and GitHub Copilot). We show that on a diverse set of security-critical test cases covering 16 CWEs across 5 programming languages, INSEC significantly increases the rate of generated insecure code by ~50%, while upholding the engines' capabilities of producing functionally correct code. Moreover, due to its black-box nature, developing INSEC does not require expensive local compute and costs less than 10 USD by querying remote APIs, thereby enabling the threat of widespread attacks.",
    "keywords": [
      "code completion",
      "security",
      "code security",
      "adversarial attacks",
      "black-box",
      "large language models"
    ],
    "venue": "ICLR",
    "year": 2025,
    "pdf_url": "https://openreview.net/pdf?id=h2Q3gOIz8q",
    "forum_url": "https://openreview.net/forum?id=h2Q3gOIz8q",
    "reviews": [
      {
        "rating": "6",
        "confidence": "4",
        "summary": "The paper proposes a practical attack on code completion tools like Github Copilot. The authors insist (rightly so) that other attacks on code completion tools assume access to the training dataset, which is rather complicated to get, instead the paper treats these models as black boxes, and assumes access to the API (e.g., via malicious IDE extensions). The key idea is to simply insert a comment in the prompt, throwing the model off and getting it to generate vulnerable code. The paper describes a method to come up with such comments and extensively evaluates their method on different code completion tools/models. For evaluation, the authors come up with their own datasets inspired by HumanEval in order to measure both correctness and vulnerability (detected using CodeQL). Furthermore, authors perform a good number of ablations to evaluate the effectiveness of their design/heuristic choices.",
        "strengths": "1. The paper proposes a practically realizable attack scenario on code completion engines.\n2. The proposed method for generating attacks is very cheap and simple to replicate.\n3. Authors evaluate their proposal fairly well by performing several ablations.\n4. Authors come up with a new dataset, which will be useful for the research community (when open sourced)",
        "weaknesses": "1. The authors only evaluate on their own dataset. Since the problem of getting code LMs to output vulnerable code is a well studied problem, surely there are existing datasets that can complement this evaluation. The dataset prepared here is based on HumanEval and therefore is not necessarily aligned with real coding scenarios (e.g., HumanEval problems are short). Whereas in reality, users work with one or more files and the extension uses RAG to stuff context from multiple places into the prompt. The authors can consider basing their evaluations based on other benchmarks that are closer to the real-world setting of code completion, such as repocoder (https://arxiv.org/abs/2303.12570) and repobench (https://arxiv.org/abs/2306.03091). While that would definitely make functional-correctness evaluation challenging, it would significantly strengthen the paper."
      },
      {
        "rating": "6",
        "confidence": "4",
        "summary": "This paper proposes INSEC, a black-box adversarial attack designed to trick LLMs to generate vulnerable code. Evaluation on 5 programming languages and 16 CWEs show that INSEC can increase the rate of generating insecure code by ~50% while maintaining high functional correctness.",
        "strengths": "- INSEC is evaluated on a range of programming languages and CWEs, showing a high rate of vulnerability generation and maintaining close-to-original functional correctness.\n- The paper presents some interesting findings. For example, better completion engines (bigger LLMs) retain more functional correctness under the attack.\n- Detailed ablation study on each component of INSEC.",
        "weaknesses": "- **Dataset**: the reference solutions are generated by GPT-4 for languages other than Python.\n  - There are existing extension to HumanEval, such as HumanEval-X [1] that includes human-crafted data samples and solutions in Python, C++, Java, JavaScript, and Go.\n- The vulnerability metric is not rigorous enough, and thus may not truly reflect the attack success rate. CodeQL could make mistakes in vulnerability judgment (line 318-319) as prior work highlights the low precision and high false alarm rates common in static analysis tools [2].\n  - Some verification is needed to confirm the vulnerability. For example, combine static analysis with dynamic testing or manual code review for a subset of samples. Alternatively, a combination of several vulnerability detection methods can be applied to lower false positives. Discuss the potential impact of false positives on the results.\n- Additional evaluation could enhance the analysis, including testing out-of-distribution code samples (see Questions) and assessing robustness across various prompts.\n  - For example, if the user specify \"generating secure code\" in the prompt, would the vulnerability ratio decrease?\n- Presentation and readability could be improved\n  - Define CWE upon its first use (Line 89).\n  - The problem set-up paragraphs (Section 1 - 3) are lengthy and contain some redundant information (e.g., lines 68-70 and 167-169).\n  - As INSEC only modifies the prefix for best performance, it should be made clear in the threat model description (line 159-160): 'INSEC modifies only the prefix p, leaving the suffix s unchanged.'\n  - Consider incorporating the details and breakdown of the five programming languages and 16 CWEs into the main text for clarity.\n\n[1] Qinkai Zheng et al. Codegeex: A pre-trained model for code generation with multilingual benchmarking on humaneval-x. In Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining, KDD ’23, pp. 5673–5684, New York, NY, USA, 2023. \n\n[2] Hong Jin Kang, Khai Loong Aw, and David Lo. Detecting false alarms from automatic static analysis tools: How far are we? In Proceedings of the 44th International Conference on Software Engineering, pp. 698–709, 2022."
      },
      {
        "rating": "5",
        "confidence": "4",
        "summary": "This paper introduces INSEC, a black-box adversarial attack targeting large language models (LLMs) for code completion, specifically aiming to manipulate these models into generating vulnerable code. The attack operates by injecting a crafted comment as a prompt, subtly influencing the model's output toward insecure code. Evaluations across multiple state-of-the-art models, including open-source engines and black-box commercial APIs like GitHub Copilot and GPT-3.5-Turbo-Instruct show that INSEC can increase the vulnerability rate of code generated while maintaining functional correctness, posing security risks for deployed LLM-based code assistants.",
        "strengths": "- This paper proposes INSEC, a new black-box adversarial attack to real-world code completion systems.\n- Extensive experiments include vulnerability and functional correctness metrics, demonstrating INSEC's efficacy across seceral LLM-based engines.",
        "weaknesses": "- The practicality of the proposed threat model for code LLMs could be further clarified.\n\nFirst, while the adversarial attack demonstrates a creative approach, its real-world applicability may be limited. This is because the attack relies on embedding a specifically crafted comment adjacent to the exact code snippet that the user wants completed. In real scenarios, users will not attack the code LLM to generate vulnerable code for themselves. Even if an attacker were to attempt this, the suggested deployment methods in the paper, such as malicious IDE plug-ins or other input control techniques, may face practical challenges. In dynamic or interactive environments, where code is generated line by line, integrating a crafted comment seamlessly within existing code snippets might be difficult. This differs from prompt-response interactions typical of natural language LLMs, where such manipulations might be simpler to execute covertly.\n\nAdditionally, even if the attack succeeds in generating vulnerable code, static analysis tools commonly used before code deployment may readily detect these vulnerabilities. Given that code undergoes security scanning, this could limit the attack's effectiveness. \n\n- Selection and Mutation Strategy.\n\nThe approach of using selection and mutation strategies, while effective, is not entirely novel for adversarial attacks on code LLMs. Similar techniques have been applied in other adversarial attack settings, such as [1]. Additionally, while CodeQL was selected as the primary vulnerability detection tool, not all static analysis tools cover the full spectrum of CWEs. It may be worth considering alternative or additional tools to provide a broader assessment of the attack's impact.\n\n- It appears that no defense strategies are discussed in the paper. \n\n[1] Yang, Z., Shi, J., He, J. and Lo, D., 2022, May. Natural attack for pre-trained models of code. In Proceedings of the 44th International Conference on Software Engineering (pp. 1482-1493)."
      },
      {
        "rating": "5",
        "confidence": "3",
        "summary": "The paper introduce INSEC, a novel black-box adversarial attack designed to manipulate LLM- based code completion engines into generating insecure code by inserting attack strings as comments in code completion input. INSEC first applies five different approaches to generate initial attack strings, then optimizes them through random mutations. Through iterations of mutation and selection, INSEC maintains a pool of most effective attack strings, and tests their effectiveness on different large language models. The authors propose a dataset containing 16 CWE and 5 programming languages, and evaluate INSEC on open-source models and commercial services. Results show a 50% rise in insecure code generation without majorly affecting functional correctness. The method is also cost-efficient, requiring less than $10 for querying APIs, and doesn’t need access to model internals.",
        "strengths": "1. The paper presentation is quite good, easy to follow. The authors first introduce the background information of code completion and threat model, then detailed explain the implementation of INSEC step by step, and finally present an extensive evaluation.\n\n3. The experiments are rich and involve a large workload. The authors analyze many hyperparameters, including the insertion position of attack strings and the impact of different tokenizers on effectiveness of attack, making the result solid.\n\n4. The paper propose the first black-box adversarial attack on LLM-based code completion system, and introduce a novel method for initializing attack strings, with five well- designed methods and analysis.",
        "weaknesses": "1. Technical wise, the paper appears rather shallow. This is my main concern. The mutate method seems simple, with only random functions to decide mutation position and replacement. Despite that applying random mutate to optimize the initial attack string could construct effective attack strings, it may not be efficient and could lead to local optima. \n\n2. Evaluation can be enhanced. There is no comparative analysis of different mutate methods and experimental analysis of the mutation process. I notice that you implemented many optimization methods in the submitted code, but there is no experiment results comparing them, Why?\n\n3. Models. The experiments didn't include some SOTA models like GPT-4. More SOTA models should be included for persuasiveness.\n\n4. (stealthiness) No discussion/evaluations on defense methods. For instance, would the mutated inputs (e.g., those \"dalЖ +k重d5\" in Figure 1) be easily detected by some anomaly detection tools?  Discussions on stealthiness mostly on the \"output functionality\"; this appears rather thin."
      }
    ],
    "rating_avg": 5.5,
    "confidence_avg": 3.75,
    "decision": "Reject",
    "meta_review": "The paper proposes an attack against code models. However, the primary concerns revolve around the threat model, as well as the tools and datasets used for evaluation. These issues make the attack less convincing in real-world scenarios. As a security paper, the AC recommends that the authors revisit the threat model and present more compelling results by addressing the problem within a real-world context.",
    "author_remarks": "",
    "decision_comment": ""
  },
  {
    "id": "n6YVISFrcN",
    "title": "Rethinking MUSHRA: Addressing Modern Challenges in Text-to-Speech Evaluation",
    "authors": [
      "Praveen Srinivasa Varadhan",
      "amogh gulati",
      "Ashwin Sankar",
      "Anirudh Gupta",
      "Anirudh Mukherjee",
      "Shiva Kumar Marepally",
      "Srija Anand",
      "Ankur Bhatia",
      "Saloni Jaju",
      "Suvrat Bhooshan",
      "Mitesh M Khapra"
    ],
    "abstract": "Despite rapid advancements in TTS models, a consistent and robust human evaluation framework is still lacking. For example, MOS tests fail to differentiate between similar models, and CMOS's pairwise comparisons are time-intensive. The MUSHRA test is a promising alternative for evaluating multiple TTS systems simultaneously, but in this work we show that its reliance on matching human reference speech unduly penalises the scores of modern TTS systems that can exceed human speech quality. More specifically, we conduct a comprehensive assessment of the MUSHRA test, focusing on its sensitivity to factors such as rater variability, listener fatigue, and reference bias. Based on our extensive evaluation involving 471 human listeners across Hindi and Tamil we identify two primary shortcomings: (i) \\textit{reference-matching bias}, where raters are unduly influenced by the human reference, and (ii) \\textit{judgement ambiguity}, arising from a lack of clear fine-grained guidelines. To address these issues, we propose two refined variants of the MUSHRA test. The first variant enables fairer ratings for synthesized samples that surpass human reference quality. The second variant reduces ambiguity, as indicated by the relatively lower variance across raters. By combining these approaches, we achieve both more reliable and more fine-grained assessments. We also release MANGO, a massive dataset of 47,100 human ratings, the first-of-its-kind collection for Indian languages, aiding in analyzing human preferences and developing automatic metrics for evaluating TTS systems.",
    "keywords": [
      "evaluation methodologies",
      "evaluation",
      "speech technologies",
      "datasets for low resource languages"
    ],
    "venue": "ICLR",
    "year": 2025,
    "pdf_url": "https://openreview.net/pdf?id=n6YVISFrcN",
    "forum_url": "https://openreview.net/forum?id=n6YVISFrcN",
    "reviews": [
      {
        "rating": "5",
        "confidence": "3",
        "summary": "This paper discusses two shortcomings of MUSHRA: (1) reference-matching bias and (2) judgment ambiguity. The authors first created a large-scale evaluation dataset called MANGO in Hindi and Tamil. Based on this dataset, they analyzed MUSHRA scores from various perspectives. They then propose two variants to tackle these problems. In the first variant, NMR (No Mentioned Reference), subjects are less likely to strictly focus on aligning their scores with the reference. In the second variant, DG (Detailed Guidelines), subjects are provided with fine-grained evaluation criteria to score each audio sample, thus reducing score variance. Both variants are shown to effectively mitigate these issues.",
        "strengths": "This paper addresses two important issues in subjective evaluation, which is an essential part of developing speech synthesis systems. The authors have created a large-scale dataset called MANGO, which I expect could be utilized in several applications in speech quality assessment beyond the analysis presented in this paper. They study existing MUSHRA scores from various perspectives, including reliability, sensitivity, and rejection mechanisms. The proposed approaches effectively address these issues according to the experimental results.",
        "weaknesses": "The MUSHRA-DG variant would significantly increase the time cost and difficulty of scoring for human subjects. Allowing subjects to adjust scores if they feel the final MUSHRA score does not match their expectations seems questionable to me, as it may encourage them to revise sub-scores only to fit the final outcome instead of focusing on the fine-grained scores they should judge fairly. Additionally, the combination of the two proposed approaches does not appear to be as effective as the individual ones."
      },
      {
        "rating": "3",
        "confidence": "5",
        "summary": "The authors want to assess the reliability of MUSHRA which is one of  the most popular subjective evaluation techniques in TTS. They do so by conducting extensive evaluation in two languages, Tamil and Hindi. They identify two shortcomings and they propose two variants of MUSHRA that address these shortcomings. They also provide MANGO, a dataset of 47,100 ratings from 471 listeners across Hindi and Tamil.",
        "strengths": "It is important to discuss about the evaluations of TTS systems. It is an open-topic and given the subjective nature of these evaluations, it is useful to understand the shortcomings of the used methodology and hopefully agree as a community to improved guidelines. Some of the claims make in the paper make sense, like the need of clear guidelines to help with ambiguity, the importance of a sufficient number of listeners or that a hidden reference is a better choice.\n\nI also think that in the TTS systems compared, there is a good choice of TTS systems with a variety in modeling approaches and state-of-the-art results.",
        "weaknesses": "The biggest drawbacks of the paper for me is the lack of technical details on how the compared TTS systems are trained and on the data used. Concerning the systems, I understand that an open-source version of each one is used, but did you do any changes on top of them? Did you use them as is and did inference? Did you do fine-tuning on your data?\n\nSimilarly there is a lack of details on the data used. If you did some kind of fine-tuning, what data did you use? What about inference? Was it done on the MANGO dataset? What style/genre of data is there included in your training and test sets? How many data did you use? How complex are your data?\n\nWithout knowing these technical details, it is very difficult to draw any conclusions on the validity of the claims that are made. This is particularly important because it is a theoretical study, thus the findings must give important and new insights for it to have a value. Plus the suggestions must be useful for a large audience.\t\n\nMy other concern is that even the conclusions that are drawn are of limited novelty and I don't see how the suggestions of the authors add a value to the MUSHRA evaluation that can radically change how it is done from now on.\n\nSome further more detailed comments:\n-“Given that state-of-the-art TTS systems are able to reach quality on par with references, one would expect a much smaller gap between the reference and systems. “ -> That is too big of an assumption, not always the case. Again it heavily depends on the exact version of a system and on the used data. The fact that this claim is made in one paper (StyleTTS2) and for one specific corpus (LJSpeech ), does not make it a general claim for state-of-the-art TTS systems, not even for the same system (StyletTS2) on other corpora. \n-Table 2: Pretty confusing to follow when first introduced. the line \"ANCH\" correspond to a different type of ANCH per language which is not explained until section 4.5, while Table 2 is first introduced in 4.1 I believe.\n-“CMOS indicates that the outputs synthesised by VITS and ST2 are very close in quality to the reference in Hindi and Tamil respectively “  -> Not that close for Tamil, is it? Much closer for Hindi. Is this expected? \n-“Clear guidelines can help with ambiguity”-> sure, but isn't it obvious? What is new in this observation? \n-Section 4.3: Somehow interesting but obvious results that everyone that has worked with MUSHRA already knows empirically. The number of listeners and utterances in most practical cases is a question of cost.\t\n-It is recommended not to use anchor, but anchor is not a commonly used practice in TTS evaluations in any case AFAIK. \n-I agree on the merit of detailed guidelines. But it has to be discussed if training of the listeners is required and if this increases the MUSHRA cost."
      },
      {
        "rating": "3",
        "confidence": "4",
        "summary": "The paper analyzed the MUSHRA test for TTS evaluations. The authors proposed a dataset and two refined methods based on MUSHRA.",
        "strengths": "The paper analyzed the advantages and disadvantages of MUSHRA test in detail.",
        "weaknesses": "The paper used nearly all space to rethink the MUSHRA test. However, the proposed methods seem to be too limited and hard to reproduce."
      },
      {
        "rating": "6",
        "confidence": "3",
        "summary": "his paper identifies two significant limitations of MUSHRA evaluation for TTS systems:\n\n1. **Reference-Match Bias**: The use of explicit reference samples can lead raters to assign lower scores to synthesized samples that deviate from the reference, even if the quality is high.\n2. **Judgment Ambiguity**: MUSHRA tests lack fine-grained guidance, making it difficult for raters to provide consistent evaluations.\n\nTo address these shortcomings, the authors propose two solutions:\n\n1. Not explicitly identifying the human reference to the rater.\n2. Clearly listing 9 key aspects of TTS evaluation (such as pronunciation errors and unnatural pauses) for raters to assess, followed by calculating the final MUSHRA score using a predefined formula.\n\nExperimental results from three TTS systems in two Indian languages (Indic and Tamil) demonstrate that these proposed solutions effectively alleviate the issues associated with MUSHRA. The results show more consistent results with one-to-one comparisons between TTS systems and reference samples assessed by CMOS, and a reduction in score vari among different raters. Additionally, the complete dataset, comprising 47,100 ratings from 471 listeners evaluating three TTS systems, is publicly available for future research in this area.",
        "strengths": "- This paper highlights a significant issue with the foundational assumption of MUSHRA scores: it presupposes that a real reference sample should consistently receive high scores. However, this may not always be the case, as modern TTS systems can sometimes outperform human references.\n- The authors conduct a thorough analysis of MUSHRA test results, providing both qualitative and quantitative evidence to demonstrate the two major shortcomings of the original MUSHRA framework.\n- In addition to addressing the two primary shortcomings, the paper systematically examines various aspects of MUSHRA evaluation, including:\n  - A comparison of MUSHRA and CMOS results\n  - The sensitivity of MUSHRA scores to the number of raters and utterances\n  - Protocols for rejecting raters\n  - Different strategies for establishing anchors\n- The proposed MUSHRA variants are straightforward and effectively address the identified shortcomings, enhancing the reliability of the evaluation process.",
        "weaknesses": "- While the issues with MUSHRA are language-agnostic, this paper focuses exclusively on TTS systems for Indian languages, which are trained on relatively small datasets. The findings would be more compelling if the authors included results from widely-used datasets of high-resource languages and publicly available pre-trained English (or any other high-resource language) TTS systems with verified quality.\n- The nine aspects selected for MUSHRA-DG appear to be arbitrary, as the authors do not provide justification or references for their choices, leaving unanswered why some other common aspects (such as word repetition) were not included.\n- As already noted in Section 6.1 (line 410), even though the reference-matching bias issue is mitigated, discrepancies remain between the results of CMOS, MUSHRA-NMR, and MUSHRA-DG-NMR, particularly for the best-performing ST2 system in Tamil. More detailed explanations regarding these differences will be appreciated."
      }
    ],
    "rating_avg": 4.25,
    "confidence_avg": 3.75,
    "decision": "N/A",
    "meta_review": "",
    "author_remarks": "",
    "decision_comment": ""
  },
  {
    "id": "4fyg68nmd7",
    "title": "Scaling Laws for Task-Optimized Models of the Primate Visual Ventral Stream",
    "authors": [
      "Abdulkadir Gokce",
      "Martin Schrimpf"
    ],
    "abstract": "When trained on large-scale object classification datasets, certain artificial neural network models begin to approximate core object recognition (COR) behaviors and neural response patterns in the primate visual ventral stream (VVS). While recent machine learning advances suggest that scaling model size, dataset size, and compute resources improve task performance, the impact of scaling on brain alignment remains unclear. In this study, we explore scaling laws for modeling the primate VVS by systematically evaluating over 600 models trained under controlled conditions on benchmarks spanning V1, V2, V4, IT and COR behaviors. \nWe observe that while behavioral alignment continues to scale with larger models, neural alignment saturates. \nThis observation remains true across model architectures and training datasets, even though models with stronger inductive bias and datasets with higher-quality images are more compute-efficient. \nIncreased scaling is especially beneficial for higher-level visual areas, where small models trained on few samples exhibit only poor alignment.\nFinally, we develop a scaling recipe, indicating that a greater proportion of compute should be allocated to data samples over model size. \nOur results suggest that while scaling alone might suffice for alignment with human core object recognition behavior, it will not yield improved models of the brain's visual ventral stream with current architectures and datasets, highlighting the need for novel strategies in building brain-like models.",
    "keywords": [
      "scaling laws",
      "neural alignment",
      "behavioral alignment",
      "computer vision",
      "primate visual ventral stream"
    ],
    "venue": "ICLR",
    "year": 2025,
    "pdf_url": "https://openreview.net/pdf?id=4fyg68nmd7",
    "forum_url": "https://openreview.net/forum?id=4fyg68nmd7",
    "reviews": [
      {
        "rating": "5",
        "confidence": "4",
        "summary": "The authors investigate so-called neural scaling laws for predicting visual behavior and neural activity. \"Scaling laws\" are empirical trends that show a relationship between model scale (e.g., compute used or amount of data used in training) and its loss on a pretraining task. Here, the authors show different functional forms of scaling laws for predicting neural activity vs. behavior, where the latter is far more promising than the former.\n\n**Update**\nI'm on the fence with this paper. I think there's tons of well-done experiments, and I think the message is important to the field of NeuroAI albeit not totally a novel one. I think the line fits are also still problematic and telling a story that's not totally backed up by the data, although I appreciate that the authors are trying to establish a parallel with work in AI on scaling laws. If there were a clear direction forward then this would be a no-brainer accept. As is, I believe it's borderline. I am increasing my score to reflect this.\n\nAlso on a separate note, my apologies to the authors for neglecting to respond to all of their points. I was confused by the threading of the responses and mistook the authors' responses to gmHr for responses to my own questions.",
        "strengths": "The authors completed an extensive sweep through model architectures, compute, and data budgets, in order to give a detailed view of how model scale relates to neural and behavioral brain scores. The key findings here are important (although with debatable novelty): (1) Neural fits asymptote or worsen with scale, (2) behavioral fits are linear with scale (although scale alone appears to be insufficient), (3) the ceiling and form of scaling laws is different for each visual area region that was investigated. Overall, this is a nice capstone on BrainScore, and perhaps is most notable for showing how methods from AI are not always applicable for explaining brain and behavior.",
        "weaknesses": "1. The power of scaling laws in domains like language (IMO) is that they imply \"all you need is scale.\" That is, and in the spirit of the bitter lesson, there are no conceptual barriers to achieving a criterion level of performance, only engineering ones. If this were the case in brain science it would be a true world changer. But as this paper (and others which were cited) show, this is not the case. DNNs + scale are not the solution to explaining the variance in brainscore visual system recordings. In that sense I see a large overlap between the findings and result of [1] in which they found a trade-off between ImageNet performance and BrainScore fits. In both cases, these are null results. It is great to show this result, but the lack of a direction forward is concerning.\n\nTo drive the point home, in Fig 3, the authors show that training on ImageNet21k (but curiously not WebVision which has more images) leads to better fits. Indeed this would seem to be a scaling law... but the effect size makes it impractical at best: the model maxes out around 0.45 alignment even after all of that data.\n\nFor these reasons I struggle to see how this paper makes a strong contribution to the field. It feels better served as a memo or blog post than a conference or journal paper.\n\n2. I think some of the line fits are overly optimistic. For example, in Fig 1, the neuro line is monotonically increasing. But if I squint and just look at the dots, it looks more like a subtle decrease in fits, on average, as a function of compute. This issue is in many of the plots. This relates to my thoughts in (1) about what this all means and whether or not the findings are novel. See fig 2 ViT behavioral line fits for an example where it's not just for neural data. I am marking down the \"Soundness\" of the paper because of these line fits, but to be honest I don't have any great suggestions about how to improve the fits while maintaining interpretable \"laws\" when you have what look like non-monotic changes like with the Neural data in Fig 1c.\n\n3. The y limits of the plots should be fixed to one range. It looks like 0-0.7 captures everything. Theres too much bouncing around between different ranges in different subplots. Also could you label what dataset the validation accuracy is derived from on plots where you report it?\n\n[1] Linsley et al. Performance-optimized deep neural networks are evolving into worse models of inferotemporal visual cortex."
      },
      {
        "rating": "5",
        "confidence": "4",
        "summary": "The paper introduces  a way of calculating scaling laws for neural and behavioral alignment with respect of training data and parameter size of models. It offers an interesting overview of the current status  of models and its performance on these alignment challenges.",
        "strengths": "The paper is well written. The introduction offers a good view of the literature and it is easy to follow the procedure they use to make the evaluation. The results are clearly presented and explained.  It provides a good overview of the current landscape of models in the context of neural and behavioral alignment.",
        "weaknesses": "My main observation about this work is that, while it provides valuable insights and a well-illustrated overview of the current landscape of models and their alignment with  neural of behavioral benchmarks, it could benefit from more clarity on how these findings might guide future advancements. The paper mentions previous work with similar findings, as noted in the discussion; however, it would be helpful to understand more concretely how this work can serve as a foundation for the next steps in the field and how scaling laws can truly help scientists develop the next generation of more brain-like models. For instance what kind of hypothesis can be drawn from scaling laws that can be tested by adding or removing samples/compute of models being constructed to be more brain-like? \n\nAlthough the limitations section mentions that ‘these functions may not generalize beyond the scales tested,’ this suggests a natural boundary for the impact of these results. Could the authors estimate, based on their scaling laws, what order of magnitude increase in dataset or parameter size might be needed to significantly improve neural alignment beyond the observed plateau?\n\nWhile I understand that this point is mentioned in the limitations section, I feel it is a significant oversight not to include recurrent models. It is encouraging that the paper mentions that inductive bias in the form of convolution seems to yield faster returns, but this feels limited, given that most of the models tested in these benchmarks are much deeper than what might be expected for an architecture resembling the visual cortex. For instance, would be interesting to see how the scaling laws would apply to CorNet? Is it the case that the more brain like the easier it is to scape the scaling laws? that would be very impactful for the community. \n\n\nI may have missed it, but did not see mention on self supervised models or robust models and how the scaling laws operate on models trained on these type of frameworks?"
      },
      {
        "rating": "6",
        "confidence": "4",
        "summary": "In this paper, the authors study the relationship between the size / compute requirement of popular neural network architectures and their training dataset sizes vs alignment to the biological ventral visual stream. The authors analyze the alignment of various architectures to the primate VVS using the publicly available Brain-Score benchmark and claim that (1) scaling models by increasing parameter count produces diminishing neural alignment beyond a saturation point in model size, but behavioral alignment continues to increase with model size, (2) Alignment scales with training dataset size, (3) Higher visual areas in the cortical hierarchy show stronger gains in alignment with respect to scaling.",
        "strengths": "* This paper sheds light on the similarity of neural network representations to biological visual representations as a function of model size, compute, and training dataset size. The authors have presented these results in a sound theoretical framework by drawing inspiration from analyses of neural scaling laws. \n* It is super interesting that different areas of the ventral visual stream have varied effects to scaling of neural architectures/datasets. I have not seen this in prior work to the best of my knowledge and this will raise interesting discussions at ICLR.\n* I appreciate that the paper is well-written, the figures are legible and accompanied with reasonably detailed captions.",
        "weaknesses": "* **Lacking evaluation of what model behaviors give rise to alignment.** My main point of feedback to further improve this paper is to address what other factors of artificial neural networks contribute to enhancing similarity to biological vision. It is interesting that there exist scaling laws between model / dataset sizes and neural / behavioral alignment, but this has already been documented in prior studies. I urge the authors to further study the qualitative factors (for e.g. sensitivity to the same spatial frequencies that humans are sensitive to) that give rise to enhanced similarity between ANNs and human vision.\n* **Missing evaluation of more recent multimodal models.** There has been a surge in multimodal vision language models that, if evaluated in the same framework established by this paper, would produce really intriguing findings on model scaling and alignment. I encourage the authors to include publicly available large vision language models to increase the impact of their findings, as these VLMs are more widely in use now."
      },
      {
        "rating": "6",
        "confidence": "3",
        "summary": "This paper explores how varying model sizes impact neural and behavioral alignment, seeking insights into the relationship between model architecture and its ability to mimic human-like neural responses and behaviors.",
        "strengths": "The core claim—model size influencing alignment—is well supported by the results.\n\nInvestigating neural and behavioral alignment is a relevant area with potential applications for improving model interpretability and guiding architecture design.\n\nThe study contributes to understanding the role of model scale in alignment, a valuable area for both theoretical insights and practical applications in AI research.",
        "weaknesses": "Inductive biases might need better control, either quantitatively or qualitatively, to improve result clarity.\n\nMinor issues: typo at l100 (“ecology”), unclear reference in l130 (“Utah”), and Fig 1 could specify the saturation value.\n\nBenchmark sample size for V1 and V2 is relatively small (315), which may impact result generalizability.\n\nEquation 7’s clarity is limited without referencing equations 8 and 9; introducing C(N, D) = 6ND earlier could help."
      }
    ],
    "rating_avg": 5.5,
    "confidence_avg": 3.75,
    "decision": "Reject",
    "meta_review": "The paper dives deep into the alignment of neural network models and neural response patterns in the visual ventral system. After checking myself, the quality of the paper and the visuals is top, and the findings are indeed intriguing and thought provoking, showing a great deal of work and craftmanship. On the other hand, the majority of reviewers point out that this is definitely positive, but the paper is missing actionable insights that set it apart from other papers, which have already published on this direction. This, with the fact that there were 7 (!!) updates on the manuscript point to having this paper revised and resubmitted so that the paper shines.",
    "author_remarks": "",
    "decision_comment": ""
  },
  {
    "id": "fvyuKLTC3s",
    "title": "Cayley Maze: Universal Open-Ended Reinforcement Learning Environment",
    "authors": [
      "Artsiom Ranchynski",
      "Łukasz Kuciński"
    ],
    "abstract": "Parametrizable environments with variable complexity are crucial for advancing fields such as Unsupervised Environment Design (UED), Open-Ended Learning, Curriculum Learning, and Meta Reinforcement Learning. However, the selection of environments in evaluation procedures, along with their complexities, is often either neglected or lacks formal justification. We propose the formal definition of complexity for Markov Decision Processes using Deterministic Finite Automata and Group Theory machinery. We introduce Cayley Maze, a novel open-ended reinforcement learning environment that naturally generalizes problems like solving Rubik's Cube, sorting, and integer factorization. Cayley Maze is universal: every finite deterministic sparse MDP is an MDP of a certain instance of Cayley Maze. We demonstrate how Cayley Maze enables control over complexity, simplification, and combination of its instances.",
    "keywords": [
      "Reinforcement Learning",
      "Unsupervised Environment Design",
      "Open-Ended Learning"
    ],
    "venue": "ICLR",
    "year": 2025,
    "pdf_url": "https://openreview.net/pdf?id=fvyuKLTC3s",
    "forum_url": "https://openreview.net/forum?id=fvyuKLTC3s",
    "reviews": [
      {
        "rating": "6",
        "confidence": "3",
        "summary": "This paper proposes an interesting RL environment that has theoretical properties and tuneability to control for complexity over different MDPs problems. However, rather than an environment or a family of environments, the proposed Cayley Maze is a tool to interpret a wide range of MDPs.  The environment is built from a mathematical foundation using group theory and finite automata concepts. Experiments combine the approach with  PAIRED (Protagonist Antagonist Induced Regret Environment Design) and PLR (Prioritized Level Replay) to provide evidence that  that Cayley Maze can support diverse unsupervised environment design approaches.",
        "strengths": "- The paper proposes a rigorous mathematical framework using algebraic structures, specifically group theory and finite automata theory, to define the complexity of Markov Decision Processes (MDPs). This mathematical rigor provides a foundation for measuring and controlling complexity more precisely, which is valuable in the field of reinforcement learning (RL), particularly for curriculum learning and adaptive agent development.\n- Claim of universality: the Cayley Maze can represent any deterministic MDP. \n- Problem representation through a formal method. This structured approach offers researchers a reliable way to analyse task properties and provides a clear foundation for designing new tasks within Cayley Maze. This can lead to better reproducibility and comparability of results, as tasks can be rigorously defined and consistently replicated across studies.\n- Applicability to unsupervised environment design: this approach could be particularly useful to create specific benchmarks for RL evaluation that currently relies on benchmarks with unclear properties and complexity.",
        "weaknesses": "1. While the principles are interesting, it's unclear how this can be used on a large variety of benchmarks to experiment with open-endedness.  It would strengthen the work if the authors demonstrated how Cayley Maze aligns with or diverges from existing benchmarks in terms of complexity, adaptability, and the variety of problems it can handle\n2. The paper discusses the variable complexity of Cayley Maze but could further demonstrate this aspect through empirical tests showing how increasing or decreasing complexity affects agent performance. \n3. Can the authors discuss how can the approach be adapted to work with stochastic environments? Since many real-world applications involve stochastic elements, this is a crucial gap. Cayley Maze’s deterministic nature could limit its real-world applicability, as it does not address environments where randomness or partial observability plays a role. The paper could benefit from a discussion or proposed modifications for incorporating stochastic transitions, which are often essential for testing generalization and robustness in RL agents.\n4. While I appreciate the foundation in group theory, monoids, and algebraic structures, this is also a limitation. For those that are not too familiar with the mathematical formalism, it would be good to read a more thorough discussion of a longer list of problems that can be formalized with Calyey Maze, and those that they cannot be formalized in such a way. To improve accessibility, the paper could offer more concrete examples of specific problems that Cayley Maze is well-suited to address and explicitly identify cases where Cayley Maze’s mathematical structures may not apply. This would clarify both the scope and limitations of the environment for a wider audience.\n5. One question remains on whether the RL strategies can generalize. The paper would benefit from experiments or discussions that illustrate how agents trained in Cayley Maze fare on distinct yet related tasks. For example, are there cases where skills learned in one Cayley Maze configuration (like Rubik’s Cube) transfer effectively to another (e.g., different types of sorting problems)? Providing empirical evidence or a theoretical argument for generalization would significantly strengthen the paper’s claims.\n6. I could not find the JAX implementation: this would be very useful for reproducibility.\n7. The language is at time informal."
      },
      {
        "rating": "5",
        "confidence": "5",
        "summary": "This paper proposes both a spaces of parameterised environments, and a complexity measure for these environments. The environments are effectively problems involving the navigation of Cayley diagrams through the generators of a monoid, and the complexity of an environment being the size of the smallest monoid the environment has a reward-preserving homomorphism to. This space of environments, dubbed Cayley Mazes, are implemented in JAX, and they are tested as benchmarks for UED algorithms.",
        "strengths": "This paper addresses a real need in the field of Open-Ended Learning and UED. Moreover, it does so in a very natural and powerful way, brining to bear a powerful suite of existing tools from abstract algebra. The idea that environments that are more symmetric are simpler all else being equal is intuitive and natural. Moreover, the structure of monoids gives ample opportunity to see emergent structure from our environment design algorithms if our algorithms are capable of effectively searching for this structure. It is clear to me that this is a promising direction for the field of UED and that the environment in JAX is a strong contribution.",
        "weaknesses": "Unfortunately, I believe there are some serious weaknesses with the current form of this paper which will make it difficult for it to achieve that impact. My two main concerns are:\n1) The exposition is likely to loose most readers in UED\n2) The empirical evaluation and presentation does not meet the standards in RL and UED, so it is difficult to use as a baseline.\n\nI believe both of these issues are resolvable, though likely not in the rebuttal period. I would encourage the authors to try to really over-do it on fixing points 1 and 2. I believe many in the UED space would be excited about this work if those points were soundly addressed. Unfortunately, due to these concerns I will currently have to recommend rejection. More specific details of these concerns are described below.\n\n\n\n### Improving the Exposition\n\nMuch of the paper is too fast for people without a strong abstract algebra background, which the vast majority of the target audience does not have. I think the paper will effectively have to teach the readers enough of abstract algebra to get through the main ideas of the paper, and do so assuming they have never seen the field before. I believe this is quite doable, but will require a good amount of effort. \n\n\nThe paper is quite fast through pages 2 and 3. At the same time, it is essential that the reader understands these ideas deeply as the intuition being drawn on here relies on a quite robust understanding of the monoids. The paper needs to impart the intuition that they have something to do with complexity and symmetry that only becomes obvious after the reader really groks the concept. This will require some hand-holding -- \"alternatively its an element of the free monoid on A\" is quite a complicated throw-away phrase for someone who just was told about free monoids, and most readers would not realise that it is not saying anything complicated. It would be better to introduce this idea in a few lines, with an example so they understand why that framing makes it easier to think later.\n\nI think that if example 1 was introduced much earlier, ideally in the introduction, and used to introduce all of the definitions, it would be much easier to follow.  Moreover, I would include a lot of visuals, namely Cayley diagrams would make everything much easier to follow and would make the ideas concrete.\n\nIn definition 5, it's unclear how exactly this maps on the UED, in that the parameters of the UMPD being proposed aren't defined explicitly. I would suggest defining the Cayley Maze concretely as a UMPD to avoid this confusion. Without this, it is hard to know what the scope is of a specific environment, and it is then hard to interpret the experiments.\n\nProposition 2 is a bit narrower than is claimed in the intro (constraining to deterministic sparse and finite), you should mention these constraints in the intro when you mention these results.\n\nIn section 4.3, you should reference OMNI-EPIC as it is also universal, and comes with a notion of complexity (program length).\n\nThere are often references to group-theoretic concepts that the reader doesn't know, but would need to understand to understand the rest of the paper.  For instance, the reference to \"the symmetries of the 3 cube\", \"Group of order 6\" and \"wreath product\" in the experiments section all will be lost on readers.\n\n\n**Some minor clarity concerns:**\n - 016 should be \"A\" formal definition of complexity\n - 038 \"For\" should not be capitalised\n- 085 in the definition of syntactic congruence, the right hand side of the implication should be xby \\in L not xby \\in M\n - 088 It's not clear what is meant by a transition kernel\n - 095 It's not clear what is meant by \"it's realisation\" or \"a resulting kernel\"\n - 100 Referencing this as matrix multiplication is confusing since T_\\alpha are functions, not matrices. I think this means composition where the \"matrix\" being referenced is the probability transition matrix representation of T, but that is a few more levels of indirection than necessary. Saying composition here is fine (relying on the implicit fact that a function of a random variable also gives a random variable)\n- 107 it's not clear what the \"corresponding trajectories\" would be \n- 317 there is a stray \"i\"\n\n\n### Improving the Evaluation\nThe goal of the evaluation section ought to be to set this up as a benchmark that others in UED can aim to improve on. As it stands, it is missing several components for that.  Namely:\n\n- The evaluation protocol should match that in prior UED works\n- The task should be clearly delineated in a easy-to-hard order with the easiest ones being solved and the hardest ones only partially working \n- There should be a clear ideas what the scores mean in each setting\n\n*Evaluation protocol:*\n It should follow the conventions of evaluation in papers like PAIRED and PLR, describing an explicit test set of levels and corresponding bar charts, the inter-quartile scores as described in [1]. These test levels should vary from easier examples to hard examples and should be diverse while giving signal to partially-working methods. There should also be visual depictions of the levels being generated, since the level-generation is what methods would be evaluating.  The return plots should all have the appropriate error bars. The goal for being rigorous on this is to lay the foundation for researchers who use this environment as a benchmark to have the information they need to evaluate their approaches, and for the readers to have the information they need to tell if this is a benchmark that is too hard, too easy, or measuring current frontier progress. It should be clear that the methods work on some of the environments (for instance the Cayley Mazes equivalent to minigrid), and fail on others (the full Rubix cube setting). Ideally, there would be some instances of nearly-solved Rubix cubes in the test set that the methods show some performance on so others have a signal to hill-climb on. \n\nIn Figure 3 it looks like PLR is still improving, It would be best to run the methods for longer to make sure the baseline reports the best numbers for current methods so that they can be more readily beaten with new methods. It also looks like all of the methods need to be tuned, or at least it is difficult to tell if they have been tuned will given the information provided. This is also why it would be best to give some easy tasks, or easy instances of the given tasks to show the methods are tuned enough to work a bit. Steps per second should also be reported for the environment during training, since this is a critical limiting factor and selling point for any Jax environment. \n\n*Clear Task Definitions:*\nGiven the wide space of Cayley Mazes, it would be best to delimitate specific subsets which can serve as self-contained environments to test UED aparoches on. This is like how minigrid has a range of  different settings provided by default, along with current algorithms performances on these settings. These tasks should be clearly delineated and named so that other papers could easily reference the definition of the task that they are training on.  Moreover, it is best that this paper as the benchmark defines several of these tasks since it could then be presented as standard suites, and authors would no longer be able to easily pick the problem that their method performs well on.\n\n*Clear meaning of tasks:*\nIt would be best of there was some sort of visualisation of the tasks, along with a much slower non-group-theoretic description of them. The performance on these problems is only useful to the reader if they understand how to interpret the difficulty of the tasks. As such, the main message I think most would get from these are \"these seem to be hard tasks\", but they get no sense of if these are \"proving a novel theorem\" levels of hard, or something more manageable for a new algorithm. \n\n[1] Agarwal, Rishabh, et al. \"Deep reinforcement learning at the edge of the statistical precipice.\" Advances in neural information processing systems 34 (2021): 29304-29320."
      },
      {
        "rating": "3",
        "confidence": "3",
        "summary": "This paper proposes a definition of complexity for deterministic MDPs; it also introduces Cayley Maze, which can model a general class of deterministic MDP problems for unsupervised environment design (UED) and other frameworks with an extra level of complexity over the traditional reinforcement learning framework. The paper first views the sequences generated in an MDP from the perspective of Finite Automata theory and proposes the new complexity accordingly. Further, the paper introduces the Cayley Maze and shows that every deterministic finite MDP with sparse rewards corresponds to an instance of the Cayley Maze. Limited experiments are performed to examine the performance of different UED algorithms on some Cayley Maze instances.",
        "strengths": "The strengths of the paper are its originality and potential significance:\n1. The perspective developed in this paper is novel to the knowledge of the reviewer. The proposed complexity measure seems grounded and removes redundancy in the MDP’s structure.\n2. The paper has some potential to inspire and be useful to future research on UED and other fields like meta reinforcement learning. The proposed Cayley Maze seems to have the potential to be useful for these fields.",
        "weaknesses": "While the paper has notable strengths, there are several significant weaknesses that impact its overall contribution:\n1. The quality of the paper is poor. The paper is rough and seems to be incomplete. Specifically,\n* The experiments seem to be limited, and their conclusions are unclear. There are only three small experiments provided, and their implications are unclear. What are the goals of the experiments? Other than some results of the three algorithms’ performance in a few instances, what can the reader learn about the proposed environment? Are the current set of experiments sufficient? Having more detailed discussions in the experiment section and including a conclusion section will help clarify the implications. If needed, more experiments should be conducted to justify the utility of the proposed environment.\n* Sufficient details about the experiments are not provided despite the fact that there are a few more pages available. It may be useful to address the following concerns:\n  * What exactly are the used environment instances? Is there a way to describe them better? From reading the paper, I cannot understand what these environments are and their implications. Including some more details even in the appendix would help.\n  * While there isn’t any discussion or citation for the domain randomization algorithm, the reader might not be able to figure out what it is.\n  * What does the y-axis in all the plots represent? In addition, the x-axis should also have a label for clarity.\n  * The performance variation across different random seeds is not provided.\n  * It’s unclear what Figure 3 represents. The text also doesn’t give sufficient information.\n* While the proposed Cayley Maze is general and includes both easily solvable and difficult instances, how to generate interesting instances is not thoroughly discussed apart from a very short discussion in Section 4.4. In other words, what makes Cayley Maze a good class of problems to work on? And how can it be used?\n2. While a new complexity measure is proposed, the paper doesn’t provide any further theoretical results, empirical implications, or justifications for its usefulness.\n3. The paper also needs to improve its clarity. In addition to the missing information mentioned above, in the Questions section, there is a list of small issues that reduce the paper’s clarity."
      },
      {
        "rating": "1",
        "confidence": "2",
        "summary": "The authors introduce Cayley Maze, a universal mathematical framework based on Finite Automata and Group Theory machinery, that may be used to represent an open-ended reinforcement learning environment that naturally generalizes problems like solving Rubik’s Cube, sorting, and integer factorization, and that enables control over complexity, simplification, and combination of its instances.\n\nI found this paper extremely unclear about its goals and its main messages, and I’m strongly in favor of rejecting it.",
        "strengths": "No idea, sorry",
        "weaknesses": "- the authors claim that Cayley Maze is a novel open-ended reinforcement learning environment, but they never define what an open-ended reinforcement learning environment is.\n- the authors mention what it is possible to do with the Cayley Maze, rather than what they did\n- the paper does not have a conclusion\n- the paper is very poorly written, with many unclear statements, english mistakes, typos, unclear figures with poor captions, etc.\n- no related work section, no comparison to anything, no ablations..."
      }
    ],
    "rating_avg": 3.75,
    "confidence_avg": 3.25,
    "decision": "Reject",
    "meta_review": "This paper introduces Cayley Maze as a general open-ended reinforcement learning environment that encompasses well-known problems such as the Rubik's Cube, sorting, and factorization. Further, the authors argue that Cayley Mazes include every finite deterministic sparse MDP.\n\nThe framework introduced is novel and interesting, and is laid out with mathematical rigour.\n\nHowever, the presentation was rather terse and rushed, which may make it difficult for most readers to follow. Further, the current revision is lacking any empirical evaluation. There were some experiments in the original submission but the authors have removed it from the latest revision and left it for future work.\n\nAs such, although this idea has merit, I do not believe it is ready for publication yet.",
    "author_remarks": "",
    "decision_comment": ""
  },
  {
    "id": "dTkqaCKLPp",
    "title": "SCOPE: A Self-supervised Framework for Improving Faithfulness in Conditional Text Generation",
    "authors": [
      "Song Duong",
      "Florian Le Bronnec",
      "Alexandre Allauzen",
      "Vincent Guigue",
      "Alberto Lumbreras",
      "Laure Soulier",
      "Patrick Gallinari"
    ],
    "abstract": "Large Language Models (LLMs), when used for conditional text generation, often produce hallucinations, i.e., information that is unfaithful or not grounded in the input context. This issue arises in typical conditional text generation tasks, such as text summarization and data-to-text generation, where the goal is to produce fluent text based on contextual input. When fine-tuned on specific domains, LLMs struggle to provide faithful answers to a given context, often adding information or generating errors. One underlying cause of this issue is that LLMs rely on statistical patterns learned from their training data. This reliance can interfere with the model's ability to stay faithful to a provided context, leading to the generation of ungrounded information. We build upon this observation and introduce a novel self-supervised method for generating a training set of unfaithful samples. We then refine the model using a training process that encourages the generation of grounded outputs over unfaithful ones, drawing on preference-based training. Our approach leads to significantly more grounded text generation, outperforming existing self-supervised techniques in faithfulness, as evaluated through automatic metrics, LLM-based assessments, and human evaluations.",
    "keywords": [
      "faithfulness",
      "hallucination",
      "conditional text generation",
      "natural language processing",
      "large language models"
    ],
    "venue": "ICLR",
    "year": 2025,
    "pdf_url": "https://openreview.net/pdf?id=dTkqaCKLPp",
    "forum_url": "https://openreview.net/forum?id=dTkqaCKLPp",
    "reviews": [
      {
        "rating": "6",
        "confidence": "4",
        "summary": "LLMs often struggle to generate fully grounded information to a provided context. There is a rich literature on the hallucination issues in generative models (https://arxiv.org/abs/2005.00661). This has become an even bigger priority as LLMs are being adapted widely. \n\nThis paper addresses the hallucination issues in LLMs and proposes a self-supervised method for synthetically generating a training set of negative responses. Using these negative examples, models are then trained to encourage the generation of grounded outputs over unfaithful ones using preference-based training. \n\nThe authors empirically demonstrate that the proposed method helps models generate more faithful texts, when evaluated automatically and by humans, on data-to-text generation and summarization.",
        "strengths": "The paper is trying to address generative hallucination, a common problem in generative models. The paper is fairly well written and easy to follow. \n\nThe paper brings new insights on the behavior of preference-tuning with the synthetically generated negative examples.\n\nThe proposed approach appears to improve response faithfulness, at a minor cost of fluency.",
        "weaknesses": "The method for synthetically generating negative examples is not novel, as the authors claim. Several papers (see some pointers below) in the past have used similar methods for generating negative or diverse sets of samples to better calibrate their models. \n\nThe paper should present a detailed analysis of the synthetic data being generated. For example, it would be nice to see faithfulness score distributions in negative examples. Also a qualitative analysis showing types of hallucinations being generated would have been very interesting. \n\nFaithfulness is a pointwise metric, but the human evals mostly focus on SxS ratings. It would have been nice to see pointwise evaluations of faithfulness. \n\nIt would have been nice to see comparisons to other ways of generating negative examples, for example, prompting models to generate negative examples.\n\nOther interesting work in this space that might be interesting to discuss here: \n\nBrio or Slic: https://arxiv.org/abs/2203.16804, https://arxiv.org/abs/2210.00045\nCalibrating models for faithfuness: https://arxiv.org/pdf/2310.08764\nhttps://renzhaochun.github.io/assets/pdf/26596-Article%20Text-30659-1-2-20230626.pdf\nhttps://arxiv.org/pdf/1910.08684 from the point of sub-sequence sampling\nComparison with CoT or planning based methods for controlling hallucinations.\n\n- \nAfter the rebuttals, I have adjusted the score. Thanks for conducting additional experiments and evaluations. They will be valuable to the readers."
      },
      {
        "rating": "6",
        "confidence": "2",
        "summary": "Scope is a self-supervised framework for improving the faithfulness of conditional text generation in LLMs. The approach uses a novel two-stage process: first fine-tuning on half the dataset, then using a mixture of that model and the base model to generate synthetic unfaithful samples for preference learning. The authors evaluate their method on data-to-text and summarization tasks.",
        "strengths": "- They study an important problem in the subfield -- factuality and faithfulness issue in conditional text generation. The research is motivated.\n- Interesting two-stage training pipeline, and the approach to generate synthetic unfaithful samples.\n- Provides analysis of preference training dynamics as well as the ablation for the noise parameter $\\alpha$",
        "weaknesses": "- The preference learning stage uses β=0.1 for all models and datasets (A.2) without justification or ablation, despite this being a critical hyperparameter in preference learning.\n- No evidence the method works on larger models. For their main claimed contribution (\"improving faithfulness\" in finetuning), testing on 7B models seems insufficient. Is it possible to include a few larger models, e.g. 14B, if not 70B scales."
      },
      {
        "rating": "6",
        "confidence": "4",
        "summary": "This paper introduces a new learning framework for conditional text generation for the purpose of increasing the faithfulness of generated text with respect to the context input. The learning framework consists of two main steps: finetuning and contrastive learning. For contrasting learning, dispreferred samples are created in an unsupervised manner by utilizing a decoding method for generating certain tokens from the untrained language model, thereby introducing tokens which are not contextually consistent with the task. In several experiments, SCOPE is shown to be more effective than other baselines, including various decoding methods. SCOPE shows to be more faithful than traditional finetuning and SCOPE output is more preferred by humans and by GPT-4 judges.",
        "strengths": "Relatively novel methodology that uses the process of collaborative decoding for the purpose of generating dispreferred text. The method of collaborative decoding has been used in the past to combine text from a general LLM and an expert LLM to improve performance. In this setting, however, collaborative decoding is utilized to generate inconsistencies in the text randomly based on a threshold alpha.\n\nExperiments in the tasks of summarization and data-to-text in several datasets which highlight the strength of SCOPE compared to traditional finetuning and other baseline decoding methods. Additionally, the large variety of metrics, human evaluation, and GPT-4 evaluation indicates that SCOPE is effective at increasing the faithfulness of the model for these two specific tasks.",
        "weaknesses": "Lack of human analysis of the unsupervised generated data: it is unclear whether the the dispreferred samples are worse due to the changes in the language distribution, or if the dispreferred samples contain information or text that is inconsistent with the context. If the unwanted generation mainly comes from the changes in the language distribution, then SCOPE is not learning to be more faithful to the context. This is a key distinction which may limit the interpretability of SCOPE for being a more faithful method of conditional text generation. One way to mitigate this concern would be to conduct a human analysis on a sample of generated data and determine if the generated data contains text inconsistent with the context or if the inserted text from the base LM is merely different in language distribution.\n\nLack of comparisons to instruction-tuned models. The methodology of SCOPE, at its essence, is very similar to the standard method of reinforcement learning with human feedback, where the model is first finetuned and then preference optimized with binary data consisting of a preferred sample and an unwanted sample. Due to the similarities, it would be valuable to compare SCOPE to RLHF methods and compare the degree of faithfulness of the model. There is evidence that instruction-tuned models are more \"helpful\" to users' inputs in the prompt, which correlates highly with faithfulness. Using the instruction-tuned model as a baseline, or running SCOPE on an instruction-tuned model is important to validate SCOPE as a novel, effective method."
      },
      {
        "rating": "6",
        "confidence": "4",
        "summary": "The paper investigates the common issue of hallucinations in large language models (LLMs) during conditional text generation. To enhance faithfulness, the authors introduce SCOPE, a novel self-supervised fine-tuning approach that generates unfaithful samples and then trains the model to prefer context-grounded outputs over these fabricated examples. By using this approach, SCOPE achieves substantial improvements in generating grounded and faithful responses, as validated by automatic metrics and evaluations from both LLMs and human judges. The study's findings demonstrate SCOPE’s effectiveness across diverse tasks, including data-to-text and summarization, where it consistently outperforms existing self-supervised techniques.",
        "strengths": "1. The research problem addressed in this paper is significant, as faithfulness remains a major challenge for contextual generation in LLMs.\n2. The authors propose an innovative method for generating negative examples for DPO training, utilizing two models—the fine-tuned model and the pre-trained model—selecting the next token based on a weighted combination of their distributions. This approach is independent of external tools like NER.\n3. The experimental results demonstrate that their method outperforms baseline models across multiple tasks.",
        "weaknesses": "1. Some of the baselines appear to be training-free decoding methods, while others require training, similar to the method proposed in the paper. The authors should clarify which methods are training-free and which are not, as they require different resources to implement.\n2. Additional ablation studies are needed, such as applying the same training framework with other negative sampling methods like NER replacement or negation. Otherwise, the effectiveness of the negative sampling itself remains uncertain.\n3. Experiments should include the faithfulness score of the generated negative examples on the training set to directly demonstrate the impact of negative sampling."
      },
      {
        "rating": "6",
        "confidence": "4",
        "summary": "The paper presents SCOPE, a self-supervised framework that enhances the faithfulness of LLMs in conditional text generation tasks like summarization and data-to-text generation. The framework employs a two-stage approach: initial fine-tuning followed by preference tuning using contrastive learning. The key innovation lies in its method of automatically generating synthetic unfaithful samples by blending grounded and context-free generation, which are then used to train the model to prefer context-aligned outputs over hallucinated ones. Through comprehensive evaluation across multiple datasets, SCOPE demonstrates significant improvements in output faithfulness, achieving up to 14% gains according to automatic metrics, with additional improvements confirmed through both GPT-4 and human evaluations.",
        "strengths": "- An innovative self-supervised approach to improving LLM faithfulness through synthetic unfaithful sample generation\n- The method shows strong performance across multiple benchmarks, with notable improvement in data-to-text tasks. \n- The paper explains the methodology and experimental setup well, using helpful figures and clear explanations of core ideas, such as the noisy sample generation and preference tuning.",
        "weaknesses": "- While SCOPE performs well on general summarization and data-to-text tasks, evaluating it on domain-specific datasets (e.g., biomedical or financial) could better demonstrate its robustness in high-stakes settings where hallucinations are especially problematic.\n- SCOPE is tested on 7B models only; applying it to models of different sizes would clarify its scalability and help determine whether it generalizes effectively to larger different models. Perhaps the improvement using SCOPE on larger models will be marginal. \n- The evaluation on summarization task used ROUGE and AlignScore (an entailment metric). While SCOPE scores slightly lower ROUGE scores than other baselines, the authors did not use other faithfulness metrics in summarization research to further evaluate."
      }
    ],
    "rating_avg": 6.0,
    "confidence_avg": 3.6,
    "decision": "Accept (Poster)",
    "meta_review": "This paper introduces SCOPE, a self-supervised framework designed to improve the faithfulness of large language models (LLMs) in conditional text generation tasks, such as summarization and data-to-text generation. By leveraging a two-stage process of fine-tuning and contrastive learning, the method synthesizes negative examples (unfaithful and contextually ungrounded) and trains models to prioritize grounded outputs. Extensive evaluations, including human and GPT-4 assessments, demonstrate that SCOPE significantly outperforms existing techniques in generating faithful text, achieving notable gains across multiple benchmarks.\n\nStrengths:\n\n* The paper addresses significant challenges in generative models: factuality and faithfulness.\n* The proposed two-stage training pipeline is both novel and well-motivated, and it is independent of external tools and resources, unlike many prior works.\n* Extensive experiments across summarization and data-to-text tasks show improvements over baseline methods. The results are well-supported by a variety of metrics, human evaluations, and GPT-4 assessments, emphasizing the method's effectiveness and applicability to multiple benchmarks. The work demonstrates an ability to improve response faithfulness at a minor cost to fluency.\n* The paper provides comprehensive ablation studies and analyses.\n\nWeaknesses:\n* Limited novelty: Reviewers expressed concerns about novelty, as generating artificially bad examples is not entirely new. However, the authors highlighted significant technical differences, and the simplicity of the method (requiring only a few lines of code) remains a strong point.\n* Insufficient analysis: The paper lacks a detailed qualitative and quantitative analysis of the generated negative examples. However, the authors have begun to address this by including plots and analyses in the appendix.\n* Scalability concerns: The experiments focus on 7B-scale models, omitting larger models where faithfulness improvements might be less pronounced. However, this focus is reasonable, as the lack of faithfulness is more apparent in smaller models. Additionally, the authors included extra experiments on 13B models, which yielded similar improvements to those observed with 7B models.\n* There were other concerns, such as the fixed hyperparameter β, which were addressed during the discussion period.\n\nAfter the discussion period, it appears that most major concerns have been addressed, except for the fact that there are other methods that also rely on generating artificially bad examples (though these approaches differ technically). Given the importance of the problems addressed (factuality and faithfulness in LLMs), the simplicity of the method, the positive results, and the comprehensiveness of the analysis, I recommend accepting the paper.",
    "author_remarks": "",
    "decision_comment": ""
  }
]